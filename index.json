[{"content":"I miss the aiport and airplane vibes.\n \u0026hellip;ということで飛行機専門（＋乗り物系）のTumblrブログのリンク並べてみた。\n 以下は2021年暮れ時点でactive。微妙なのもあるが。\n take flight. So Nice Cars airviation Aviation Lover   以下はnon active。\n StopDreaming.StartFlying Airbus A380 L-AEROPORT Wan Arief Lmran on Tumblr Fuckyeah Airplaness   Non activeであっても、ブログを消さないでくれているだけでもありがたい。世界の誰かの「めっちゃ好き！」が、誰かの活力になるんだもんな。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/aviation-blog/","summary":"I miss the aiport and airplane vibes.\n \u0026hellip;ということで飛行機専門（＋乗り物系）のTumblrブログのリンク並べてみた。\n 以下は2021年暮れ時点でactive。微妙なのもあるが。\n take flight. So Nice Cars airviation Aviation Lover   以下はnon active。\n StopDreaming.StartFlying Airbus A380 L-AEROPORT Wan Arief Lmran on Tumblr Fuckyeah Airplaness   Non activeであっても、ブログを消さないでくれているだけでもありがたい。世界の誰かの「めっちゃ好き！」が、誰かの活力になるんだもんな。\n ","title":"飛行機画像ブログのリンク集"},{"content":"murmur：ぶつぶつ言う、不満をつぶやく\n類：grumble\n\u0026ldquo;Zazie in the Metro\u0026rdquo;(Raymond Queneau) / 地下鉄のザジ（レーモン・クノー）から拾ったが、他の英文小説にも割と頻繁に登場する単語。それだけ普遍的な行為ということか。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/english-murmur/","summary":"murmur：ぶつぶつ言う、不満をつぶやく\n類：grumble\n\u0026ldquo;Zazie in the Metro\u0026rdquo;(Raymond Queneau) / 地下鉄のザジ（レーモン・クノー）から拾ったが、他の英文小説にも割と頻繁に登場する単語。それだけ普遍的な行為ということか。\n ","title":"英語メモ - murmur"},{"content":"村上龍著「愛と幻想のファシズム」より\n  俺達は何も知らない。快楽もない。十万人の哀れな日本人が俺を恐れ、あがめるのは、俺が日本人の中では、生態系の情報と快楽を知っているからだ。\n   恐怖に勝てるのは興奮だけなんだよ\n   厳しさを知ってる奴だけが生き残るんだ、動物だって同じだよ、人間の残飯を漁る熊や狐はすぐに撃たれる、世の中が同じようにずっと続くと思ってる奴はすぐにくたばる、\n  ","permalink":"https://ecnedaced-seirots.github.io/post/a/ryu-quotes-3/","summary":"村上龍著「愛と幻想のファシズム」より\n  俺達は何も知らない。快楽もない。十万人の哀れな日本人が俺を恐れ、あがめるのは、俺が日本人の中では、生態系の情報と快楽を知っているからだ。\n   恐怖に勝てるのは興奮だけなんだよ\n   厳しさを知ってる奴だけが生き残るんだ、動物だって同じだよ、人間の残飯を漁る熊や狐はすぐに撃たれる、世の中が同じようにずっと続くと思ってる奴はすぐにくたばる、\n  ","title":"「愛と幻想のファシズム」より(3)"},{"content":"CloudWatch Logsから、LmabdaでログをS3にエクスポートする。対象のロググループとバケット内の第一階層を引数で指定するようにした。今回の事例ではエクスポートの範囲は「前日0時〜実行当日の0時」となる。\n参考\nboto3 API Reference\nLambdaよりCloudWatchログをS3に保存方法紹介\n 今回の検証に使用したアイテム（個人メモ）    アイテム 名称     Lambda用IAMロール lambda_basic_execution   Lambda関数 log-export-function   S3バケット log-export-xxxxxxxx     Lambda用IAMロールの権限はlogsフルアクセスのみ。S3もいると思ってたがなくてもできた。バケットポリシー側で許可しているからか。S3バケット名は環境変数で指定した。\n S3バケットポリシー（log-export-xxxxxxxx）\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::log-export-xxxxxxxx\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::log-export-xxxxxxxx/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;s3:x-amz-acl\u0026#34;: \u0026#34;bucket-owner-full-control\u0026#34; } } } ] }  Lambdaコード(Python3.9)\nimport boto3 import collections from datetime import datetime, date, time, timedelta import os def lambda_handler(event, context): log_g = event.get('loggrp') key1 = event.get('key_name') # 日付情報取得 yesterday = datetime.combine(date.today()-timedelta(1),time()) today = datetime.combine(date.today(),time()) unix_start = datetime(1970,1,1) # 日付範囲指定。範囲は実行時点を基準としたUNIXタイムスタンプの日本時間(+9h) from_t = int((yesterday-unix_start).total_seconds() * 1000) to_t = int((today-unix_start).total_seconds() * 1000) # S3 bucket + prefix定義（bucket/key1/YYYY/mmDD） bucket = os.environ['S3_BUCKET'] key2 = yesterday.strftime(\u0026quot;%Y\u0026quot;) key3 = yesterday.strftime(\u0026quot;%m-%d\u0026quot;) s3_key = key1 + \u0026quot;/\u0026quot; + key2 + \u0026quot;/\u0026quot; + key3 try: logs = boto3.client('logs') response = logs.create_export_task( logGroupName = log_g, fromTime = from_t, to = to_t, destination = bucket, destinationPrefix = s3_key ) except Exception as e: print(e)  では、Lambda関数をCLIから実行してみる。ま、普通はEventBridge経由とかでやると思うけど。（でもEventBridgeって引数指定できるんかな？）\n--payloadオプションのロググループ名、S3バケットの最初の階層となるサービス種別（ここではEC2)を指定している。これはJSONなので、file://parameter.jsonなどとしてファイル指定でもよい。\n$ aws lambda invoke --function-name log-export-function \\ --payload '{ \u0026quot;loggrp\u0026quot; : \u0026quot;/ec2/var/log/messages\u0026quot;,\u0026quot;key_name\u0026quot; : \u0026quot;EC2\u0026quot; }' \\ --cli-binary-format raw-in-base64-out \\ response.json  実行すると、Prefixはできていたが中身は書き込みテスト用ファイルしかない。このコード上の仕様は、前日の00:00:00 から当日の00:00:00までをエクスポートの対象としている。指定したロググループのログは、実行した時点で定義された日付範囲に含まれていないためである。\n（つまり、12/18の日中にインスタンスを起動してログが送信されたとする。しかしエクスポート対象は前日の2021-12-17 00:00:00 〜 当日の2021-12-18 00:00:00までとなるため、この期間内にログがなければ対象は存在しないことになる）\nちなみに関数が実行されるEC2のタイムゾーンはUTC。Lamabaの環境変数でタイムゾーンをJSTにするのは非推奨らしいので、コード側で制御するのが望ましい、とのこと。タイムゾーンの問題を考え始めるといつも頭の中がジグソーパズル状態になる。\nLambda のタイムゾーンを環境変数TZで指定してはいけないっていう話\nAWS Lambda でのタイムゾーン変換\n  「コード内での時間は常に UTC で扱い、表示する段階でローカル時間に変換する」を意識していればいいかなと思います。\n  これを当てはめると、「コード内の基準はUTCとし、JSTとして処理する必要になった時点でJSTに変換する」と考えればいいか。\nところでPythonでのタイムゾーン変換で検索すると大抵上記リンクと同様にpytzを使ったコードが紹介されている。pytzを使えば簡単なのだが、それができない事情があったから以下のように別の方法でやった。今回のコードではまた別の方法になっているが\u0026hellip;、どこまでも執拗に追ってくるしつこい敵なので、一度タイムゾーン処理単体で記事を書こうかと思う。\nCloudWatchアラーム + SNSからのメール本文をカスタマイズする(3) \n 話がそれたが、翌日再試行して、今度は無事エクスポートが実行された。今回のコード上の指定では以下スクショの階層でログがアップロードされる。（長いランダム文字列のプレフィックス配下に複数のログストリームのプレフィックス、最後に圧縮ログファイル）\n しかし、引数にLambda自体のログを指定するとエクスポートされない。なぜなんだ〜！\u0026hellip;と思ったら、数時間後にリトライしたら期待値になった。試しにひとつログをDLして中身を覗いてみる。\n$ gunzip -c 000000.gz 2021-12-18T09:30:45.236Z START RequestId: 4880df55-4576-4ccd-8edc-daecb18b0686 Version: $LATEST  このログは、マネコンの画面上ではJST（実際にLambdaを実行した時刻の日本時間）となっている。\n2021-12-18T18:30:45.236+09:00 #Timestamp列の値 START RequestId: 4880df55-4576-4ccd-8edc-daecb18b0686 Version: $LATEST  うーん、これでいいのか？コード内でJSTに変換しているけど、逆にしなくていいのか？脳内パズル。\n\u0026hellip;だが、Lambda関数が実行されるUTCのTZから、エクスポート対象のログ範囲をUTCのTZで指定すると、実際にログが吐き出されたJSTの時刻とは異なる日付範囲になる。だから関数でJSTに変換するのは正しい、と捉えてよい気がする。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatchlogs-export/","summary":"CloudWatch Logsから、LmabdaでログをS3にエクスポートする。対象のロググループとバケット内の第一階層を引数で指定するようにした。今回の事例ではエクスポートの範囲は「前日0時〜実行当日の0時」となる。\n参考\nboto3 API Reference\nLambdaよりCloudWatchログをS3に保存方法紹介\n 今回の検証に使用したアイテム（個人メモ）    アイテム 名称     Lambda用IAMロール lambda_basic_execution   Lambda関数 log-export-function   S3バケット log-export-xxxxxxxx     Lambda用IAMロールの権限はlogsフルアクセスのみ。S3もいると思ってたがなくてもできた。バケットポリシー側で許可しているからか。S3バケット名は環境変数で指定した。\n S3バケットポリシー（log-export-xxxxxxxx）\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::log-export-xxxxxxxx\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::log-export-xxxxxxxx/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;s3:x-amz-acl\u0026#34;: \u0026#34;bucket-owner-full-control\u0026#34; } } } ] }  Lambdaコード(Python3.","title":"CloudWatch LogsからS3にエクスポート(Lambda/Python)"},{"content":"村上龍著「愛と幻想のファシズム」より\n  強者は嫌われない。ゴミのような人間達は、強者と同化したがるのだ。\n   馬の臓物も、猪の肉も、からだを腹の底から暖める。野生の肉は血管を拡げるのだ。俺達は湧き出すように汗をかく。\n   「その婆さんは、よく晴れた日に、二人の孫を連れて、山菜を採りに行ったんだ、そして虎に襲われた、ばあさんは棘のついた木の枝で虎の注意をそらしながら、飛びかかって、虎の耳を食いちぎったんだそうだ、そのばあさんのコメントは中国でも有名になった、圧倒的に強い敵にギリギリまで追いつめられた時、残された唯一の手段、それは戦うことだ、ばあさんは、そう言ったんだとさ」\n   「圧倒的に強い敵にギリギリまで追いつめられた時、残された唯一の手段、それは戦うことだ」\n","permalink":"https://ecnedaced-seirots.github.io/post/a/ryu-quotes-2/","summary":"村上龍著「愛と幻想のファシズム」より\n  強者は嫌われない。ゴミのような人間達は、強者と同化したがるのだ。\n   馬の臓物も、猪の肉も、からだを腹の底から暖める。野生の肉は血管を拡げるのだ。俺達は湧き出すように汗をかく。\n   「その婆さんは、よく晴れた日に、二人の孫を連れて、山菜を採りに行ったんだ、そして虎に襲われた、ばあさんは棘のついた木の枝で虎の注意をそらしながら、飛びかかって、虎の耳を食いちぎったんだそうだ、そのばあさんのコメントは中国でも有名になった、圧倒的に強い敵にギリギリまで追いつめられた時、残された唯一の手段、それは戦うことだ、ばあさんは、そう言ったんだとさ」\n   「圧倒的に強い敵にギリギリまで追いつめられた時、残された唯一の手段、それは戦うことだ」","title":"「愛と幻想のファシズム」より(2)"},{"content":"何日か前に読了した、村上龍著「愛と幻想のファシズム」より。\n  「それで、人間というのは、他の動物でもそうだけど、嫌いなことをやり続けると拒絶反応を起こすんだ、病気になるんだよ、トウジお前IBMのセールスマンになれるか？」\n「止めてくれ、死んじゃうよ」\n「そうだろ、とにかく人間は嫌いなことはできないようになっている、ところがだ、嫌いなことでもやる奴がいる」\n「いるな」\n「いるだろ？」\n「誰だ？」\n「好きなことが何なのか捜すのに疲れた奴、あきらめた連中だ、楽をしたいと思う奴らだよ、そいつらは、奴隷だ」\n「奴隷？」\n「俺は奴隷を信頼しない」\n「どうして？」\n「人を裏切るのは気分が悪いものだ、そうだよな、誰だって人を裏切るのは嫌いなはずだ、だから嫌いなことを普段やってないやつ、つまり奴隷じゃない奴は、とりあえず信頼できるんだ」\n   「（略）\u0026hellip;俺は快楽を知っている、狩猟の快楽は他の何よりもすごい、だが俺はその快楽を必死になって手に入れたんだ、あいつらは黙っていても手に入れることができる、努力して手に入れるものに価値があるのというのは、芸術家とスポーツ選手にだけ言えることで、貧乏人には当てはまらない、嘘なんだ」\n   「そうだ、俺はいやなんだ、俺は快楽主義者だからな、小さな快楽で我慢しろなんて言われて黙っているのがいやなんだ、\n  すっげぇ、いやもうこれ、この年になってもわかるよ、ビンビンくるよ、あぁ、そうなんだよ、本当にそうなんだよ。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/ryu-quotes-1/","summary":"何日か前に読了した、村上龍著「愛と幻想のファシズム」より。\n  「それで、人間というのは、他の動物でもそうだけど、嫌いなことをやり続けると拒絶反応を起こすんだ、病気になるんだよ、トウジお前IBMのセールスマンになれるか？」\n「止めてくれ、死んじゃうよ」\n「そうだろ、とにかく人間は嫌いなことはできないようになっている、ところがだ、嫌いなことでもやる奴がいる」\n「いるな」\n「いるだろ？」\n「誰だ？」\n「好きなことが何なのか捜すのに疲れた奴、あきらめた連中だ、楽をしたいと思う奴らだよ、そいつらは、奴隷だ」\n「奴隷？」\n「俺は奴隷を信頼しない」\n「どうして？」\n「人を裏切るのは気分が悪いものだ、そうだよな、誰だって人を裏切るのは嫌いなはずだ、だから嫌いなことを普段やってないやつ、つまり奴隷じゃない奴は、とりあえず信頼できるんだ」\n   「（略）\u0026hellip;俺は快楽を知っている、狩猟の快楽は他の何よりもすごい、だが俺はその快楽を必死になって手に入れたんだ、あいつらは黙っていても手に入れることができる、努力して手に入れるものに価値があるのというのは、芸術家とスポーツ選手にだけ言えることで、貧乏人には当てはまらない、嘘なんだ」\n   「そうだ、俺はいやなんだ、俺は快楽主義者だからな、小さな快楽で我慢しろなんて言われて黙っているのがいやなんだ、\n  すっげぇ、いやもうこれ、この年になってもわかるよ、ビンビンくるよ、あぁ、そうなんだよ、本当にそうなんだよ。\n ","title":"「愛と幻想のファシズム」より(1)"},{"content":"あーあ、今日も、疲れた。気がついたら20時なんだもん、ひっでぇな。\nそして本来やるべきことの、半分もできていない。雑用の波が押し寄せる。言いたいことは多々あるが、ぶちまけ大会するわけにはいかない。このモヤモヤを一体どうしたらいいのか。\n  ま、でも今日も上手い寿司が食えたからな。寿司だ。寿司が今のオレのプライドを支えてるんだ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/life-1214/","summary":"あーあ、今日も、疲れた。気がついたら20時なんだもん、ひっでぇな。\nそして本来やるべきことの、半分もできていない。雑用の波が押し寄せる。言いたいことは多々あるが、ぶちまけ大会するわけにはいかない。このモヤモヤを一体どうしたらいいのか。\n  ま、でも今日も上手い寿司が食えたからな。寿司だ。寿司が今のオレのプライドを支えてるんだ。","title":"Non title"},{"content":"今日のTerraform loopネタはLambda関数作成。ログ監視の一貫なので、CloudWatchLogsのロググループとサブスクリプションフィルタ作成も一緒にやる。\nこの例でのディレクトリ構成は以下の通り。lambda/upload配下のzipファイルはTerraformにより生成されたもので、初回は空である。\nwork_dir ├── config.tf #初期化ファイル ├── lambda │ ├── code │ │ ├── func001 │ │ │ └── lambda-func001.py │ │ ├── func002 │ │ │ └── lambda-func002.py │ │ └── func003 │ │ └── lambda-func003.py │ └── upload │ ├── lambda-func001.zip │ ├── lambda-func002.zip │ └── lambda-func003.zip ├── lambda.auto.tfvars ├── lambda_cwl.tf ├── terraform.tfvars #regionのみ定義 └── variables.tf  最初に、すべて定数で記述したパターン。\nlambda_logs.tf（定数バージョン）\n################################################# # Lambda archive data ################################################# data \u0026quot;archive_file\u0026quot; \u0026quot;data-lambda-func001\u0026quot; { type = \u0026quot;zip\u0026quot; source_dir = \u0026quot;lambda/code/func001\u0026quot; output_path = \u0026quot;lambda/upload/lambda-func001.zip\u0026quot; } ################################################# # Lambda function ################################################# resource \u0026quot;aws_lambda_function\u0026quot; \u0026quot;lambda-func001\u0026quot; { filename = data.archive_file.data-lambda-func001.output_path function_name = \u0026quot;lambda-func001\u0026quot; role = \u0026quot;arn:aws:iam::012345678910:role/send-log-filter-role\u0026quot; handler = \u0026quot;lambda-func001.lambda_handler\u0026quot; source_code_hash = base64sha256(\u0026quot;lambda/upload/lambda-func001.zip\u0026quot;) timeout = 60 runtime = \u0026quot;python3.9\u0026quot; environment { variables = { \u0026quot;SNS_TOPIC_ARN\u0026quot; = \u0026quot;arn:aws:sns:ap-northeast-1:012345678910:log-monitor-topic\u0026quot; } } } ################################################# # Lambda Permission ################################################# resource \u0026quot;aws_lambda_permission\u0026quot; \u0026quot;func-perm001\u0026quot; { action = \u0026quot;lambda:InvokeFunction\u0026quot; function_name = aws_lambda_function.lambda-func001.arn principal = \u0026quot;logs.ap-northeast-1.amazonaws.com\u0026quot; source_arn = \u0026quot;arn:aws:logs:ap-northeast-1:012345678910:log-group:*:*\u0026quot; } ################################################# # CloudWatchLogs group ################################################# resource \u0026quot;aws_cloudwatch_log_group\u0026quot; \u0026quot;cwl-group001\u0026quot; { name = \u0026quot;log-group001\u0026quot; retention_in_days = \u0026quot;7\u0026quot; } ################################################# # CloudWatchLogs subscription filter ################################################# resource \u0026quot;aws_cloudwatch_log_subscription_filter\u0026quot; \u0026quot;cwl-subscription001\u0026quot; { name = \u0026quot;cwl-filter001\u0026quot; log_group_name = aws_cloudwatch_log_group.cwl-group001.name filter_pattern = \u0026quot;[( msg=\\\u0026quot;*error*\\\u0026quot; || msg=\\\u0026quot;*Error*\\\u0026quot; ) \u0026amp;\u0026amp; ( msg!=\\\u0026quot;*test*\\\u0026quot; \u0026amp;\u0026amp; msg!=\\\u0026quot;*Test*\\\u0026quot; \u0026amp;\u0026amp; msg!=\\\u0026quot;*TEST*\\\u0026quot; )]\u0026quot; destination_arn = aws_lambda_function.lambda-func001.arn }  これをapplyするとそれぞれ単体でリソースが作成される。次にloop処理の例。\nlambda_logs.tf（loopバージョン）\n################################################# # Lambda archive data ################################################# data \u0026quot;archive_file\u0026quot; \u0026quot;data-lambda-func\u0026quot; { for_each = var.lambda_param_list source_dir = lookup(each.value, \u0026quot;src_dir\u0026quot;) output_path = lookup(each.value, \u0026quot;out_path\u0026quot;) type = \u0026quot;zip\u0026quot; } ################################################# # Lambda function ################################################# resource \u0026quot;aws_lambda_function\u0026quot; \u0026quot;lambda-func\u0026quot; { for_each = var.lambda_param_list filename = lookup(each.value, \u0026quot;out_path\u0026quot;) function_name = lookup(each.value, \u0026quot;func_name\u0026quot;) role = var.lambda_role handler = \u0026quot;${lookup(each.value, \u0026quot;func_name\u0026quot;)}.lambda_handler\u0026quot; source_code_hash = base64sha256(\u0026quot;${lookup(each.value, \u0026quot;out_path\u0026quot;)}\u0026quot;) timeout = 60 runtime = \u0026quot;python3.9\u0026quot; environment { variables = { \u0026quot;SNS_TOPIC_ARN\u0026quot; = var.topic_arn } } } ################################################# # Lambda Permission ################################################# resource \u0026quot;aws_lambda_permission\u0026quot; \u0026quot;my-func-perm\u0026quot; { for_each = var.lambda_param_list action = \u0026quot;lambda:InvokeFunction\u0026quot; function_name = \u0026quot;arn:aws:lambda:ap-northeast-1:012345678910:function:${lookup(each.value, \u0026quot;func_name\u0026quot;)}\u0026quot; principal = \u0026quot;logs.ap-northeast-1.amazonaws.com\u0026quot; source_arn = var.src_arn } ################################################# # CloudWatchLogs group ################################################# resource \u0026quot;aws_cloudwatch_log_group\u0026quot; \u0026quot;cwl-group\u0026quot; { for_each = var.logs_param_list name = lookup(each.value, \u0026quot;log_grp\u0026quot;) retention_in_days = \u0026quot;7\u0026quot; } ################################################# # CloudWatchLogs subscription filter ################################################# resource \u0026quot;aws_cloudwatch_log_subscription_filter\u0026quot; \u0026quot;cwl-subscription\u0026quot; { for_each = var.logs_param_list name = lookup(each.value, \u0026quot;filter\u0026quot;) log_group_name = lookup(each.value, \u0026quot;log_grp\u0026quot;) filter_pattern = lookup(each.value, \u0026quot;pattern\u0026quot;) destination_arn = aws_lambda_function.lambda-func[\u0026quot;param1\u0026quot;].arn }  archive_fileによりTerraformがLambda用のzipファイルを生成してくれる。source_code_hashがzipのハッシュ値の差分をチェックして変更があればデプロイする。と、いうことだがこの記述だとコードを変更しなくても都度zipファイルが生成されてタイムスタンプが更新され、変更していなくても変更したと判断されてデプロイされる。デプロイされてもコードは同じだから害はないんだが、どうも納得がいかん。変更扱いにしたくなければarchive_fileのブロックを全部コメントしておくか、source_code_hashをコメントするか。どういう運用がいいんだろう？\nちなみに最初のapplyは比較対象のzipファイルがなくてエラーになるため、source_code_hashは初回のみコメントアウトしておく。\nsubscription filterで、Lambdaをloopで作ったのにここで単体で指定しているのは、こういう例もあるということで。この参照の場合は、logs_param_listにLambdaのARNの変数が存在しなくても問題ない。\nlambda.auto.tfvars（tfコードが参照する変数）\n################################################# # Lambda function loop vars ################################################# lambda_param_list = { param1 = { src_dir = \u0026quot;lambda/code/func001\u0026quot; out_path = \u0026quot;lambda/upload/lambda-func001.zip\u0026quot; func_name = \u0026quot;lambda-func001\u0026quot; } param2 = { src_dir = \u0026quot;lambda/code/func002\u0026quot; out_path = \u0026quot;lambda/upload/lambda-func002.zip\u0026quot; func_name = \u0026quot;lambda-func002\u0026quot; } param3 = { src_dir = \u0026quot;lambda/code/func003\u0026quot; out_path = \u0026quot;lambda/upload/lambda-func003.zip\u0026quot; func_name = \u0026quot;lambda-func003\u0026quot; } } ################################################# # Lambda function vars ################################################# lambda_role = \u0026quot;arn:aws:iam::012345678910:role/send-log-filter-role\u0026quot; topic_arn = \u0026quot;arn:aws:sns:ap-northeast-1:012345678910:log-monitor-topic\u0026quot; ################################################# # Lambda Permission vars ################################################# src_arn = \u0026quot;arn:aws:logs:ap-northeast-1:012345678910:log-group:*:*\u0026quot; ################################################# # CloudWatchLogs group \u0026amp; filter loop vars ################################################# logs_param_list = { param1 = { log_grp = \u0026quot;log-group001\u0026quot; filter = \u0026quot;logs-filter001\u0026quot; pattern = \u0026quot;[( msg=\\\u0026quot;*error*\\\u0026quot; || msg=\\\u0026quot;*Error*\\\u0026quot; ) \u0026amp;\u0026amp; ( msg!=\\\u0026quot;*test*\\\u0026quot; \u0026amp;\u0026amp; msg!=\\\u0026quot;*Test*\\\u0026quot; \u0026amp;\u0026amp; msg!=\\\u0026quot;*TEST*\\\u0026quot; )]\u0026quot; } param2 = { log_grp = \u0026quot;log-group002\u0026quot; filter = \u0026quot;logs-filter002\u0026quot; pattern = \u0026quot;[( msg=\\\u0026quot;*error*\\\u0026quot; || msg=\\\u0026quot;*ERROR*\\\u0026quot; ) \u0026amp;\u0026amp; ( msg!=\\\u0026quot;*test*\\\u0026quot; \u0026amp;\u0026amp; msg!=\\\u0026quot;*Test*\\\u0026quot; \u0026amp;\u0026amp; msg!=\\\u0026quot;*TEST*\\\u0026quot; )]\u0026quot; } param3 = { log_grp = \u0026quot;log-group003\u0026quot; filter = \u0026quot;logs-filter003\u0026quot; pattern = \u0026quot;[( msg=\\\u0026quot;*FAIL*\\\u0026quot; || msg=\\\u0026quot;*fail*\\\u0026quot; || msg=\\\u0026quot;*Fail*\\\u0026quot; ) \u0026amp;\u0026amp; ( msg!=\\\u0026quot;*test*\\\u0026quot; \u0026amp;\u0026amp; msg!=\\\u0026quot;*Test*\\\u0026quot; \u0026amp;\u0026amp; msg!=\\\u0026quot;*TEST*\\\u0026quot; )]\u0026quot; } }  フィルタパターンが汚なくて見るに耐えないがこればかりはどうしようもない\u0026hellip;\nvariables.tf（宣言のみ）\n################################## # main ################################## variable \u0026quot;region\u0026quot; { type = string description = \u0026quot;\u0026quot; } ################################## # lambda loop ################################## variable \u0026quot;lambda_param_list\u0026quot; { type = map(map(string)) description = \u0026quot;\u0026quot; } ################################## # lambda role ################################## variable \u0026quot;lambda_role\u0026quot; { type = string description = \u0026quot;\u0026quot; } ################################## # topic ################################## variable \u0026quot;topic_arn\u0026quot; { type = string description = \u0026quot;\u0026quot; } ################################## # lambda parmission ################################## variable \u0026quot;src_arn\u0026quot; { type = string description = \u0026quot;\u0026quot; } ################################## # logs loop ################################## variable \u0026quot;logs_param_list\u0026quot; { type = map(map(string)) description = \u0026quot;\u0026quot; }  これによりログ監視に必要なリソースが一気に作成される。最初にコード書くのは面倒だけど、やっぱり自動化の仕組み作っておくと楽だな。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform-loop-example-5/","summary":"今日のTerraform loopネタはLambda関数作成。ログ監視の一貫なので、CloudWatchLogsのロググループとサブスクリプションフィルタ作成も一緒にやる。\nこの例でのディレクトリ構成は以下の通り。lambda/upload配下のzipファイルはTerraformにより生成されたもので、初回は空である。\nwork_dir ├── config.tf #初期化ファイル ├── lambda │ ├── code │ │ ├── func001 │ │ │ └── lambda-func001.py │ │ ├── func002 │ │ │ └── lambda-func002.py │ │ └── func003 │ │ └── lambda-func003.py │ └── upload │ ├── lambda-func001.zip │ ├── lambda-func002.zip │ └── lambda-func003.zip ├── lambda.auto.tfvars ├── lambda_cwl.tf ├── terraform.tfvars #regionのみ定義 └── variables.tf  最初に、すべて定数で記述したパターン。\nlambda_logs.tf（定数バージョン）\n################################################# # Lambda archive data ################################################# data \u0026quot;archive_file\u0026quot; \u0026quot;data-lambda-func001\u0026quot; { type = \u0026quot;zip\u0026quot; source_dir = \u0026quot;lambda/code/func001\u0026quot; output_path = \u0026quot;lambda/upload/lambda-func001.","title":"Terraform loop処理の応用編(4) - Lambda"},{"content":"過去記事Terraform loop処理の応用編(2)で、AWS Code兄弟のリソースをTerraformのloop処理で作成した。それとは別に、CodePipelineのトリガーをEventBridgeルールにしたかったので追加処理を書いた。パイプラインの数だけ対応するルールを作成するため、これもloop処理で書く。Code兄弟の分も含めて全て同じtfファイルにまとめてもよいが、ここでは分割している。\n以下tfコード本体に、ルールとターゲットを作成する処理を書く。\nevent_rule.tf\n######################################## # EventBridge rule ######################################## resource \u0026quot;aws_cloudwatch_event_rule\u0026quot; \u0026quot;pln-rule\u0026quot; { for_each = var.events_param_list name = lookup(each.value, \u0026quot;name\u0026quot;) description = \u0026quot;Start the pipeline when detect CodeCommit repository state change.\u0026quot; event_pattern = \u0026lt;\u0026lt;-EOT { \u0026quot;source\u0026quot;: [\u0026quot;aws.codecommit\u0026quot;], \u0026quot;detail-type\u0026quot;: [\u0026quot;CodeCommit Repository State Change\u0026quot;], \u0026quot;resources\u0026quot;: [\u0026quot;arn:aws:codecommit:ap-northeast-1:012345678910:${lookup(each.value, \u0026quot;repo_name\u0026quot;)}\u0026quot;], \u0026quot;detail\u0026quot;: { \u0026quot;event\u0026quot;: [\u0026quot;referenceCreated\u0026quot;, \u0026quot;referenceUpdated\u0026quot;], \u0026quot;referenceType\u0026quot;: [\u0026quot;branch\u0026quot;], \u0026quot;referenceName\u0026quot; : [\u0026quot;master\u0026quot;] } } EOT } ######################################## # EventBridge target ######################################## resource \u0026quot;aws_cloudwatch_event_target\u0026quot; \u0026quot;pln-rule\u0026quot; { for_each = var.events_param_list rule = lookup(each.value, \u0026quot;name\u0026quot;) arn = lookup(each.value, \u0026quot;pipeline\u0026quot;) role_arn = var.events_role depends_on = [aws_cloudwatch_event_rule.pln-rule] }  当初event_patternのJSONはJSONファイルを外出しにしてファイル名指定でいくつもりだった。が、loop処理で回すのができなかった。いくつか試したのだが\u0026hellip;。パターンとしては可変になるのがCodeCommitリポジトリ名だけなので、そこをloopで回せばいけるんじゃないかと思いヒアドキュメントでやったらできた。このような場合JSONファイルをルールの数だけ用意するより、ヒアドキュメントの方が意外と楽だ。\nJSON定義の一部。以下の\u0026quot;repo_name\u0026quot;に対して、変数リストから取り出したCodeCommitリポジトリ名が格納される。\n\u0026quot;resources\u0026quot;: [\u0026quot;arn:aws:codecommit:ap-northeast-1:012345678910:${lookup(each.value, \u0026quot;repo_name\u0026quot;)}\u0026quot;],  loop処理が参照する変数リストは以下の通り。\n rule.auto.tfvars\n################### # rule vars ################### events_param_list = { param1 = { name = \u0026quot;cicd-event001\u0026quot; pipeline = \u0026quot;arn:aws:codepipeline:ap-northeast-1:012345678910:pipeline001\u0026quot; repo_name = \u0026quot;repo001\u0026quot; } param2 = { name = \u0026quot;cicd-event002\u0026quot; pipeline = \u0026quot;arn:aws:codepipeline:ap-northeast-1:012345678910:pipeline002\u0026quot; repo_name = \u0026quot;repo002\u0026quot; } param3 = { name = \u0026quot;cicd-event003\u0026quot; pipeline = \u0026quot;arn:aws:codepipeline:ap-northeast-1:012345678910:pipeline003\u0026quot; repo_name = \u0026quot;repo003\u0026quot; } } ################### # Events role ################### events_role = \u0026quot;arn:aws:iam::012345678910:role/codepipeline-exe-role\u0026quot;  上記ルールだけapplyした結果、成功。CICDリソース作成用のtfコードも含めて実行した結果も、成功。\nちなみにイベントルールを別途作成しない場合、パイプラインに紐付くルールが自動で生成される。ルールを実行するためのIAMロールも、ルールと1:1で個別に自動生成される。親切と言えば親切だが、そんなにボコボコ作られてもなー、と思った。このIAMロールはリソースとして指定したCodePipelineを実行するだけだから、リソースを* にすればひとつで事足りる。各アイテムの名称も管理下におきたい。\n\u0026hellip;ということで、ここでは自動生成ではなく別途ルールを作成したけれども、そこまでこだわらないのであれば自動生成でもいいだろう。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform-loop-example-4/","summary":"過去記事Terraform loop処理の応用編(2)で、AWS Code兄弟のリソースをTerraformのloop処理で作成した。それとは別に、CodePipelineのトリガーをEventBridgeルールにしたかったので追加処理を書いた。パイプラインの数だけ対応するルールを作成するため、これもloop処理で書く。Code兄弟の分も含めて全て同じtfファイルにまとめてもよいが、ここでは分割している。\n以下tfコード本体に、ルールとターゲットを作成する処理を書く。\nevent_rule.tf\n######################################## # EventBridge rule ######################################## resource \u0026quot;aws_cloudwatch_event_rule\u0026quot; \u0026quot;pln-rule\u0026quot; { for_each = var.events_param_list name = lookup(each.value, \u0026quot;name\u0026quot;) description = \u0026quot;Start the pipeline when detect CodeCommit repository state change.\u0026quot; event_pattern = \u0026lt;\u0026lt;-EOT { \u0026quot;source\u0026quot;: [\u0026quot;aws.codecommit\u0026quot;], \u0026quot;detail-type\u0026quot;: [\u0026quot;CodeCommit Repository State Change\u0026quot;], \u0026quot;resources\u0026quot;: [\u0026quot;arn:aws:codecommit:ap-northeast-1:012345678910:${lookup(each.value, \u0026quot;repo_name\u0026quot;)}\u0026quot;], \u0026quot;detail\u0026quot;: { \u0026quot;event\u0026quot;: [\u0026quot;referenceCreated\u0026quot;, \u0026quot;referenceUpdated\u0026quot;], \u0026quot;referenceType\u0026quot;: [\u0026quot;branch\u0026quot;], \u0026quot;referenceName\u0026quot; : [\u0026quot;master\u0026quot;] } } EOT } ######################################## # EventBridge target ######################################## resource \u0026quot;aws_cloudwatch_event_target\u0026quot; \u0026quot;pln-rule\u0026quot; { for_each = var.","title":"Terraform loop処理の応用編(3) - Event rule"},{"content":"\u0026ldquo;SNS\u0026quot;は\u0026quot;Social Networking Service\u0026quot;の略だ。この言葉の上では、プラットフォーム自体がサービスなのだ。しかし、そこに参加した途端に、自分自身が他者にサービスせざるを得なくなる。俗に言う、フォロバとかいいね返しとか、そういうことだ。\nそういうのは嫌いだ、しかしそこに参加している限り、鍵垢でもない限り、その渦から完全に逃れることはできない、この、人付き合いが嫌いな俺様であってもだ、しかし嫌いなものは嫌いなんだ、反応に対していちいち反応してたら自分のやりたいことができないし、余計にエネルギーを使うことになる。つまり、反応した相手の投稿をチェックするという作業自体が余剰作業なのだ、他人にサービスするためにやってるんじゃないからね。\nこれは、SNSの面倒で嫌いな部分だが、いいこともある、「反応に対する反応」により、センスがいいナイスなアカウントを発見することも多々あるからだ。tumblrの場合、ナイスなポストがあればreblogするし、この人は光る何かを持っている、とピピっときたらフォローせざるを得ない。相手が素晴らしいセンスの持ち主だと、サービスを通り越して夢中になってしまうこともある。\n  でも最近疲れてきたな、夢中になりすぎて疲れたのか、疲れたから夢中になれなくなったのか知らんが、あまり楽しくない。結局「お付き合い」の比重が多くなると、本来の目的からずれてしまうんだ、リアルワールドでやることのプライオリティが上がっているせいもあるな。\nしかしよく考えると、SNSとの付き合いなんてそれくらいか、それより低程度がいいのである、本来は。リアルワールドで重要なことが多いほど、SNSにかまけていられる時間やエネルギーは減る。つまり、「あんまり楽しくない」程度に捉えている方が自然なのである。\nそういう意味では、俺もやっと自然に戻れたんだろうか。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/sns/","summary":"\u0026ldquo;SNS\u0026quot;は\u0026quot;Social Networking Service\u0026quot;の略だ。この言葉の上では、プラットフォーム自体がサービスなのだ。しかし、そこに参加した途端に、自分自身が他者にサービスせざるを得なくなる。俗に言う、フォロバとかいいね返しとか、そういうことだ。\nそういうのは嫌いだ、しかしそこに参加している限り、鍵垢でもない限り、その渦から完全に逃れることはできない、この、人付き合いが嫌いな俺様であってもだ、しかし嫌いなものは嫌いなんだ、反応に対していちいち反応してたら自分のやりたいことができないし、余計にエネルギーを使うことになる。つまり、反応した相手の投稿をチェックするという作業自体が余剰作業なのだ、他人にサービスするためにやってるんじゃないからね。\nこれは、SNSの面倒で嫌いな部分だが、いいこともある、「反応に対する反応」により、センスがいいナイスなアカウントを発見することも多々あるからだ。tumblrの場合、ナイスなポストがあればreblogするし、この人は光る何かを持っている、とピピっときたらフォローせざるを得ない。相手が素晴らしいセンスの持ち主だと、サービスを通り越して夢中になってしまうこともある。\n  でも最近疲れてきたな、夢中になりすぎて疲れたのか、疲れたから夢中になれなくなったのか知らんが、あまり楽しくない。結局「お付き合い」の比重が多くなると、本来の目的からずれてしまうんだ、リアルワールドでやることのプライオリティが上がっているせいもあるな。\nしかしよく考えると、SNSとの付き合いなんてそれくらいか、それより低程度がいいのである、本来は。リアルワールドで重要なことが多いほど、SNSにかまけていられる時間やエネルギーは減る。つまり、「あんまり楽しくない」程度に捉えている方が自然なのである。\nそういう意味では、俺もやっと自然に戻れたんだろうか。\n ","title":"ソーシャルな反応に対する反応とか"},{"content":"前回投稿Terraform loop処理の応用編 の続き。CodeDeployを作成するTerraformコードに、CodeCommit, CodePipelineを追加して通して作ってみる。\n cicd.tf\n#################################### # CodeCommit #################################### resource \u0026quot;aws_codecommit_repository\u0026quot; \u0026quot;codecommit_repos\u0026quot; { for_each = var.codecommit_param_list repository_name = lookup(each.value, \u0026quot;repository_name\u0026quot;) description = lookup(each.value, \u0026quot;description\u0026quot;) } #################################### # CodeDeploy Application #################################### resource \u0026quot;aws_codedeploy_app\u0026quot; \u0026quot;codedeploy\u0026quot; { for_each = var.deploy_param_list name = lookup(each.value, \u0026quot;name\u0026quot;) compute_platform = \u0026quot;Server\u0026quot; } #################################### # CodeDeploy Deployment Group #################################### resource \u0026quot;aws_codedeploy_deployment_group\u0026quot; \u0026quot;codedeploy_grp\u0026quot; { for_each = var.deploy_param_list app_name = lookup(each.value, \u0026quot;name\u0026quot;) deployment_group_name = lookup(each.value, \u0026quot;deployment_group_name\u0026quot;) depends_on = [aws_codedeploy_app.codedeploy] service_role_arn = var.deploy_role deployment_config_name = \u0026quot;CodeDeployDefault.AllAtOnce\u0026quot; ec2_tag_set { ec2_tag_filter { key = \u0026quot;Name\u0026quot; type = \u0026quot;KEY_AND_VALUE\u0026quot; value = lookup(each.value, \u0026quot;value\u0026quot;) } } deployment_style { deployment_option = \u0026quot;WITHOUT_TRAFFIC_CONTROL\u0026quot; deployment_type = \u0026quot;IN_PLACE\u0026quot; } auto_rollback_configuration { enabled = true events = [\u0026quot;DEPLOYMENT_FAILURE\u0026quot;] } } #################################### # CodePipeline #################################### resource \u0026quot;aws_codepipeline\u0026quot; \u0026quot;pipeline\u0026quot; { for_each = var.pipeline_param_list name = lookup(each.value, \u0026quot;name\u0026quot;) role_arn = var.pipeline_role artifact_store { location = var.bucket type = \u0026quot;S3\u0026quot; } stage { name = \u0026quot;Source\u0026quot; action { category = \u0026quot;Source\u0026quot; configuration = { BranchName = \u0026quot;master\u0026quot; PollForSourceChanges = \u0026quot;true\u0026quot; RepositoryName = lookup(each.value, \u0026quot;repository_name\u0026quot;) } input_artifacts = [] name = \u0026quot;Source\u0026quot; namespace = \u0026quot;SourceVariables\u0026quot; output_artifacts = [\u0026quot;SourceArtifact\u0026quot;] owner = \u0026quot;AWS\u0026quot; provider = \u0026quot;CodeCommit\u0026quot; region = var.region run_order = 1 version = \u0026quot;1\u0026quot; } } stage { name = \u0026quot;Deploy\u0026quot; action { category = \u0026quot;Deploy\u0026quot; configuration = { ApplicationName = lookup(each.value, \u0026quot;app_name\u0026quot;) DeploymentGroupName = lookup(each.value, \u0026quot;deployment_group_name\u0026quot;) } input_artifacts = [\u0026quot;SourceArtifact\u0026quot;] name = \u0026quot;Deploy\u0026quot; namespace = \u0026quot;DeployVariables\u0026quot; output_artifacts = [] owner = \u0026quot;AWS\u0026quot; provider = \u0026quot;CodeDeploy\u0026quot; region = var.region run_order = 1 version = \u0026quot;1\u0026quot; } } }  cicd.auto.tfvars\n######################################## # codecommit repos vars ######################################## codecommit_param_list = { param1 = { repository_name = \u0026quot;repo001\u0026quot; description = \u0026quot;desciption for repo001\u0026quot; } param2 = { repository_name = \u0026quot;repo002\u0026quot; description = \u0026quot;desciption for repo002\u0026quot; } param3 = { repository_name = \u0026quot;repo003\u0026quot; description = \u0026quot;desciption for repo003\u0026quot; } } ######################################## # codedeploy vars ######################################## deploy_param_list = { param1 = { name = \u0026quot;deploy_app001\u0026quot; deployment_group_name = \u0026quot;deploy_grp001\u0026quot; value = \u0026quot;ec2-tag001\u0026quot; } param2 = { name = \u0026quot;deploy_app002\u0026quot; deployment_group_name = \u0026quot;deploy_grp002\u0026quot; value = \u0026quot;ec2-tag002\u0026quot; } param3 = { name = \u0026quot;deploy_app003\u0026quot; deployment_group_name = \u0026quot;deploy_grp003\u0026quot; value = \u0026quot;ec2-tag003\u0026quot; } } ######################################## # codedeploy vars ######################################## pipeline_param_list = { param1 = { name = \u0026quot;pipeline001\u0026quot; app_name = \u0026quot;deploy_app001\u0026quot; deployment_group_name = \u0026quot;deploy_grp001\u0026quot; repository_name = \u0026quot;repo001\u0026quot; } param2 = { name = \u0026quot;pipeline002\u0026quot; app_name = \u0026quot;deploy_app002\u0026quot; deployment_group_name = \u0026quot;deploy_grp002\u0026quot; repository_name = \u0026quot;repo002\u0026quot; } param3 = { name = \u0026quot;pipeline003\u0026quot; app_name = \u0026quot;deploy_app003\u0026quot; deployment_group_name = \u0026quot;deploy_grp003\u0026quot; repository_name = \u0026quot;repo003\u0026quot; } } ######################################## # CI/CD IAM role vars ######################################## deploy_role = \u0026quot;arn:aws:iam::[aws-account-id]:role/CodeDeployRole\u0026quot; pipeline_role = \u0026quot;arn:aws:iam::[aws-account-id]:role/PipelineRole\u0026quot; ######################################## # S3 vars ######################################## bucket = \u0026quot;codepipeline-bucket-name\u0026quot;  variables.tf （宣言のみ）\n################# # main ################# variable \u0026quot;region\u0026quot; { type = string description = \u0026quot;\u0026quot; } ################# # IAM ################# variable \u0026quot;deploy_role\u0026quot; { type = string description = \u0026quot;\u0026quot; } variable \u0026quot;pipeline_role\u0026quot; { type = string description = \u0026quot;\u0026quot; } ################# # S3 ################# variable \u0026quot;bucket\u0026quot; { type = string description = \u0026quot;\u0026quot; } ################# # codecommit ################# variable \u0026quot;codecommit_param_list\u0026quot; { type = map(map(string)) description = \u0026quot;\u0026quot; } ################# # codedeploy ################# variable \u0026quot;deploy_param_list\u0026quot; { type = map(map(string)) description = \u0026quot;\u0026quot; } ################# # codepipeline ################# variable \u0026quot;pipeline_param_list\u0026quot; { type = map(map(string)) description = \u0026quot;\u0026quot; }  cicd.tfのPollForSourceChangesはトリガーの定義だが、EventBridgeルール経由でやるのが望ましいから本来はfalseにする想定。ルールを別途作成する必要があるが、それが面倒なので一旦trueにしておいた。（関連付けたルールが存在しない場合、勝手に作成される）\nこれで実行したところ、一応期待値になった。ルールは、各パイプラインとルールがペアになるように個別に作成する。ルールが使用するIAMロールは共通のひとつでよい。このIAMの権限はコードパイプラインをスタートするだけなのだが、リソースを*にして共通で使えばよい。\n ところでtfvarsでloop処理が参照するmap変数をサービス毎に分割しているが、分ける必要ないんじゃね？と思った。重複している値が複数あって、冗長だ。key名を適当に変えれば、同じparam_listで全部賄えそうな気がしてきた。次回の課題。\n 追記\n後日param_listを全部まとめるバージョンでやってみたところ、期待値になった。だからリソース毎に個別にリストを作成する必要はない。ただし、それは参照されるリストの要素の数が全部揃っている場合。\n例えばloopで作成するCodeCommitリポジトリの数が10でCodeDeploy、CodePipelineの数は8、とかだったら共通のリストにすると失敗する。このようなケースでは、CodeCommitのリストとCodeDeploy/CodePipeline用のリストは別に分ける必要がある。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform-loop-example-3/","summary":"前回投稿Terraform loop処理の応用編 の続き。CodeDeployを作成するTerraformコードに、CodeCommit, CodePipelineを追加して通して作ってみる。\n cicd.tf\n#################################### # CodeCommit #################################### resource \u0026quot;aws_codecommit_repository\u0026quot; \u0026quot;codecommit_repos\u0026quot; { for_each = var.codecommit_param_list repository_name = lookup(each.value, \u0026quot;repository_name\u0026quot;) description = lookup(each.value, \u0026quot;description\u0026quot;) } #################################### # CodeDeploy Application #################################### resource \u0026quot;aws_codedeploy_app\u0026quot; \u0026quot;codedeploy\u0026quot; { for_each = var.deploy_param_list name = lookup(each.value, \u0026quot;name\u0026quot;) compute_platform = \u0026quot;Server\u0026quot; } #################################### # CodeDeploy Deployment Group #################################### resource \u0026quot;aws_codedeploy_deployment_group\u0026quot; \u0026quot;codedeploy_grp\u0026quot; { for_each = var.deploy_param_list app_name = lookup(each.value, \u0026quot;name\u0026quot;) deployment_group_name = lookup(each.value, \u0026quot;deployment_group_name\u0026quot;) depends_on = [aws_codedeploy_app.codedeploy] service_role_arn = var.","title":"Terraform loop処理の応用編(2)"},{"content":"過去記事Terraform loop処理の超シンプルな例 の続き。loopで作成したTerraformリソースの参照方法を検証したらやはりハマったので記録書いておく。\n前回はCodeCommitリポジトリを作成したが、今回はそれ抜きでCodeDeployのリソースを作成した。CodeDeployは (1)アプリケーションと、(2)デプロイメントグループの2つのリソースを作成する。(2)は(1)に依存している。\n作業ディレクトリ構成\nwork_dir ├── cicd.auto.tfvars ├── cicd.tf ├── config.tf #初期化用config ├── terraform.tfvars #regionのみ定義 └── variables.tf  cicd.tf （リソース作成用コード）\n#################################### # CodeDeploy Application #################################### resource \u0026quot;aws_codedeploy_app\u0026quot; \u0026quot;codedeploy\u0026quot; { for_each = var.deploy_param_list name = lookup(each.value, \u0026quot;name\u0026quot;) compute_platform = \u0026quot;Server\u0026quot; } #################################### # CodeDeploy Deployment Group #################################### resource \u0026quot;aws_codedeploy_deployment_group\u0026quot; \u0026quot;codedeploy_grp\u0026quot; { for_each = var.deploy_param_list app_name = lookup(each.value, \u0026quot;name\u0026quot;) deployment_group_name = lookup(each.value, \u0026quot;deployment_group_name\u0026quot;) service_role_arn = var.deploy_role deployment_config_name = \u0026quot;CodeDeployDefault.AllAtOnce\u0026quot; ec2_tag_set { ec2_tag_filter { key = \u0026quot;Name\u0026quot; type = \u0026quot;KEY_AND_VALUE\u0026quot; value = lookup(each.value, \u0026quot;value\u0026quot;) } } deployment_style { deployment_option = \u0026quot;WITHOUT_TRAFFIC_CONTROL\u0026quot; deployment_type = \u0026quot;IN_PLACE\u0026quot; } auto_rollback_configuration { enabled = true events = [\u0026quot;DEPLOYMENT_FAILURE\u0026quot;] } }  cicd.auto.tfvars（cicd.tfが参照する変数）\n######################################## # codedeploy vars ######################################## deploy_param_list = { param1 = { name = \u0026quot;deploy_app001\u0026quot; deployment_group_name = \u0026quot;deploy_grp001\u0026quot; value = \u0026quot;ec2-tag001\u0026quot; } param2 = { name = \u0026quot;deploy_app002\u0026quot; deployment_group_name = \u0026quot;deploy_grp002\u0026quot; value = \u0026quot;ec2-tag002\u0026quot; } param3 = { name = \u0026quot;deploy_app003\u0026quot; deployment_group_name = \u0026quot;deploy_grp003\u0026quot; value = \u0026quot;ec2-tag003\u0026quot; } } ######################################## # CodeDeploy IAM role var ######################################## deploy_role = \u0026quot;arn:aws:iam::[my-account-id]:role/CodeDeployRole\u0026quot;  variables.tf （宣言のみ行う）\n################# # main ################# variable \u0026quot;region\u0026quot; { type = string description = \u0026quot;\u0026quot; } ################# # IAM ################# variable \u0026quot;deploy_role\u0026quot; { type = string description = \u0026quot;\u0026quot; } ################# # codedeploy ################# variable \u0026quot;deploy_param_list\u0026quot; { type = map(map(string)) description = \u0026quot;\u0026quot; }  この状態で、plan実行時はエラーなし。しかしapplyしたところ、以下のエラーになった。参照するアプリケーション\u0026quot;deploy_app001\u0026quot;がないよ、と。\n No application found for name: deploy_app001\n  この時点でマネコンから確認すると、アプリケーションは出来ているが配下のデプロイメントグループが存在しない状態。実際にはdeploy_app00*は作成されているのだが、terraform実行時にうまく参照できていないらしい。当初、特別な記述をしなくてもTerraformがよしなにやってくれるもんだと思っていたんだけどなぁ。\n│ Error: Error creating CodeDeploy deployment group: ApplicationDoesNotExistException: No application found for name: deploy_app001 │ │ with aws_codedeploy_deployment_group.codedeploy_grp[\u0026quot;param1\u0026quot;], │ on cicd.tf line 16, in resource \u0026quot;aws_codedeploy_deployment_group\u0026quot; \u0026quot;codedeploy_grp\u0026quot;: │ 16: resource \u0026quot;aws_codedeploy_deployment_group\u0026quot; \u0026quot;codedeploy_grp\u0026quot; { │   この後でもう一回applyすると、今度はデプロイメントグループ（deploy_app00*）が作成された。しかし初回にエラーになるのはよろしくない。ありがちな事象だから何らかのソリューションはあるだろう、と調べる。\n 以下はツールGraphvizにより出力した、この時点におけるTerraformリソースの依存関係を表したグラフ。aws_codedeploy_appとaws_codedeploy_deployment_groupが並列になっていて、互いに関連を持たないように見える。（記事では削っているが実はCodeCommitの記述も含まれているため、グラフに表現されている）\n Terraformの依存関係の定義には「暗黙的な依存関係定義」と「明示的な依存関係定義」の2種類がある。後者は、前者が利用できないケースで使用するべき、とのこと。\n暗黙的な依存関係定義は、公式ドキュメントにもよく登場する role_arn = aws_iam_role.role001.arnといった記述で、意識せずとも普段から書いているやつ。今回みたく参照リソースがloopの場合、個別の値はaws_codedeploy_app.codedeploy[\u0026quot;param1\u0026quot;].idのような記述になるが、参照する側もloopだからこの方式では書けない。\n 一方、明示的な依存関係はdepends_onを利用する。\ndepends_on = [aws_iam_role.role001]  以下の記事を読むとloop処理の場合は別の記述方法が要るようなこと書いてあった。面倒くさそうだなぁ〜、と引いてしまう。（こちらはloop処理をcountで実行）\nTerraformリソース間の依存関係を確認する\nしかし以下フォーラムによれば、for_eachの場合これだけでいけそうではある。\nFor_each depends_on\nと、いうことでやってみる。一旦destroyしてクリーンにしてから、cicd.tfにdepends_on = [aws_codedeploy_app.codedeploy] 1行を追記。\nこの時点で、グラフを出力すると以下の通りに変化した。一応参照関係が描かれているように見える。\n 再びapplyしたところ成功。loop処理でも、for_eachはdepends_on記述だけでOKと判明した。やれやれ。\n 更新版のcicd.tf\n#################################### # CodeDeploy Application #################################### resource \u0026quot;aws_codedeploy_app\u0026quot; \u0026quot;codedeploy\u0026quot; { for_each = var.deploy_param_list name = lookup(each.value, \u0026quot;name\u0026quot;) compute_platform = \u0026quot;Server\u0026quot; } #################################### # CodeDeploy Deployment Group #################################### resource \u0026quot;aws_codedeploy_deployment_group\u0026quot; \u0026quot;codedeploy_grp\u0026quot; { for_each = var.deploy_param_list app_name = lookup(each.value, \u0026quot;name\u0026quot;) deployment_group_name = lookup(each.value, \u0026quot;deployment_group_name\u0026quot;) depends_on = [aws_codedeploy_app.codedeploy] service_role_arn = var.deploy_role deployment_config_name = \u0026quot;CodeDeployDefault.AllAtOnce\u0026quot; ec2_tag_set { ec2_tag_filter { key = \u0026quot;Name\u0026quot; type = \u0026quot;KEY_AND_VALUE\u0026quot; value = lookup(each.value, \u0026quot;value\u0026quot;) } } deployment_style { deployment_option = \u0026quot;WITHOUT_TRAFFIC_CONTROL\u0026quot; deployment_type = \u0026quot;IN_PLACE\u0026quot; } auto_rollback_configuration { enabled = true events = [\u0026quot;DEPLOYMENT_FAILURE\u0026quot;] } }  ちなみにec2_tag_filterは、apply実行時に指定したタグを持つEC2インスタンスが存在しなくても成功する。あとはこれに、前半にCodeCommit, 後半にCodePipelineを追加して、一気にCI/CDリソース作成目指したい。\n 余談：Graphvizインストール 参照した記事に記載があって気になったので入れてみた。本来はdot言語で記述したテキストデータをグラフで表現してくれるもので、terraform以外でも使える。現状深掘りしてる余裕はないけど別の機会に遊んでみよう。\nテキストデータをグラフ画像に変換するツール「Graphviz」ことはじめ\nGraphvizとdot言語でグラフを描く方法のまとめ\n $ brew install graphviz （すっげぇ膨大な依存関係ライブラリが一緒に入ってくる...） $ dot -V dot - graphviz version 2.49.3 (20211023.0002)  Terraform作業ディレクトリ内で、以下のようなコマンドを実行してグラフを出力する。\n$ terraform graph | dot -Tpng \u0026gt; cicd_graph.png  ","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform-loop-example-2/","summary":"過去記事Terraform loop処理の超シンプルな例 の続き。loopで作成したTerraformリソースの参照方法を検証したらやはりハマったので記録書いておく。\n前回はCodeCommitリポジトリを作成したが、今回はそれ抜きでCodeDeployのリソースを作成した。CodeDeployは (1)アプリケーションと、(2)デプロイメントグループの2つのリソースを作成する。(2)は(1)に依存している。\n作業ディレクトリ構成\nwork_dir ├── cicd.auto.tfvars ├── cicd.tf ├── config.tf #初期化用config ├── terraform.tfvars #regionのみ定義 └── variables.tf  cicd.tf （リソース作成用コード）\n#################################### # CodeDeploy Application #################################### resource \u0026quot;aws_codedeploy_app\u0026quot; \u0026quot;codedeploy\u0026quot; { for_each = var.deploy_param_list name = lookup(each.value, \u0026quot;name\u0026quot;) compute_platform = \u0026quot;Server\u0026quot; } #################################### # CodeDeploy Deployment Group #################################### resource \u0026quot;aws_codedeploy_deployment_group\u0026quot; \u0026quot;codedeploy_grp\u0026quot; { for_each = var.deploy_param_list app_name = lookup(each.value, \u0026quot;name\u0026quot;) deployment_group_name = lookup(each.value, \u0026quot;deployment_group_name\u0026quot;) service_role_arn = var.deploy_role deployment_config_name = \u0026quot;CodeDeployDefault.AllAtOnce\u0026quot; ec2_tag_set { ec2_tag_filter { key = \u0026quot;Name\u0026quot; type = \u0026quot;KEY_AND_VALUE\u0026quot; value = lookup(each.","title":"Terraform loop処理の応用編"},{"content":"過去記事からの派生案件で、Terraformで使うtfvarsファイルについて、繰り返しデータを多数投入する想定のため、これを自動生成したいと考えた。\nTerraform loop処理の超シンプルな例 \nPython - Jinja2テンプレートで連続データを処理したい\n 実際に使用するファイル群は過去記事に記載しているがこんな想定で。（もちろん実際は他にもいろいろ必要）自動生成したいのは、以下の*印をつけたcodecommit.auto.tfvarsである。（この時点では手動で値を記述したもの）\nwork_dir/ ├── codecommit.auto.tfvars * ├── codecommit.tf ├── config.tf ├── terraform.tfvars ├── variables.tf └── vpc.tf  これとは別に、tfvars自動生成作業用ディレクトリの作業前はこの状態。以下3つのファイルを用意する。codecommit.tmplはテンプレートとなる。このファイル名はスクリプトから呼び出すので名称に注意。対象のAWSリソースによって変えるが、tfファイルの名称に合わせておけばよい。\nscript_dir/ ├── codecommit.tmpl ├── create_vars.py └── data.csv  codecommit.tmpl\n param{{ num }} = { repository_name = \u0026quot;{{ repo_name }}\u0026quot; description = \u0026quot;{{ des }}\u0026quot; }  data.csv （今回の例ではヘッダーありの前提）\nnum,repo_name,des 1,\u0026quot;my-repo001\u0026quot;,\u0026quot;my-repo001の説明\u0026quot; 2,\u0026quot;my-repo002\u0026quot;,\u0026quot;my-repo002の説明\u0026quot; 3,\u0026quot;my-repo003\u0026quot;,\u0026quot;my-repo003の説明\u0026quot;  create_vars.py\nimport sys import pandas as pd from jinja2 import Environment, FileSystemLoader def main(): # テンプレート読み込み env = Environment(loader=FileSystemLoader(\u0026#39;./\u0026#39;, encoding=\u0026#39;utf8\u0026#39;)) tmpl = env.get_template(template) # CSV読み込み df = pd.read_csv(\u0026#34;data.csv\u0026#34;, encoding=\u0026#39;utf-8\u0026#39;, header=0 ) # CSVデータをJSONに変換 df.to_json(\u0026#39;data.json\u0026#39;) df_js = pd.read_json(\u0026#34;data.json\u0026#34;) # 代入処理。テンプレートにデータを投入後、変数ファイル(xxx.auto.vars)に書き出す。 def loop(): pre = n + \u0026#39;_param_list = {\u0026#39; + \u0026#39;\\n\u0026#39; end = \u0026#39;}\u0026#39;+ \u0026#39;\\n\u0026#39; with open(varsfile, \u0026#39;w\u0026#39;) as f: f.write(pre) for i in range(len(df_js)): data = df_js.iloc[i] config = tmpl.render(data) f.write(config) f.write(\u0026#39;\\n\u0026#39;) f.write(end) loop() if __name__ == \u0026#34;__main__\u0026#34;: args = sys.argv if len(args) == 2: n = args[1] template = n + \u0026#39;.tmpl\u0026#39; varsfile = n + \u0026#39;.auto.tfvars\u0026#39; main() else: print (\u0026#39;Usage: Specify one of AWS resource name. e.g. s3,iam,cloudwatch...etc.\u0026#39;) sys.exit()  CSVファイルのヘッダー列の値と、xxxx.tmplファイル内の代入箇所の値は一致させる。すると代入処理時に特に指定しなくてもうまいことやってくれる。pandasのヘッダー行の扱いがよくわからなくてはまったが、一応上記で期待値になった。CSV読み込み時はheaderを指定しなくても勝手に判断してこれもうまいことやってくれるらしいが、一応作法としてheader=0を指定。\nヘッダーあり・なしで挙動が変わり、認識させるために複数の方法があるが、あれこれ考えるの面倒だから、CSVにヘッダ入れておくのが一番簡単だろうと思った。ちなみに当初はこんな記述にしてた。namesがカラム名となるのだが、これを定数ではなく自動で取得したいというモチベーションにより、結果的に上記の通りになった。\n変更前のCSV読み込み処理（この時点ではCSVのヘッダーなし）\n# CSV読み込み df = pd.read_csv(\u0026#34;data.csv\u0026#34;, encoding=\u0026#39;utf-8\u0026#39;, names=(\u0026#34;num\u0026#34;,\u0026#34;repo_name\u0026#34;,\u0026#34;des\u0026#34;) )  CSVのヘッダ仕様については以下参考にした。\nCSVファイルから読み込みを行うには（pandas編）\nread_csv でヘッダあり・なしCSVの読み込み\n 代入処理ではループの都度ファイルに書き出している。当初、一度値を全部配列に格納してそれを書き出そうかと思ったが、フォーマットが崩れるからそれを整形したりとか面倒だからやめた。\n繰り返し代入処理の部分は以下記事が参考になった。助かった。\n【jinja2】テンプレートエンジンでデータの連続差し込み\n 実行時は引数として作成対象のAWSリソース名を指定する。テンプレート（今回の場合codecommit.tmpl）のファイル名に合わせる。ここで指定した値が[リソース名].auto.tfvarsのリソース名になる。\n$ python3 create_vars.py codecommit  生成されたcodecommit.auto.tfvars。\ncodecommit_param_list = { param1 = { repository_name = \u0026quot;my-repo001\u0026quot; description = \u0026quot;my-repo001の説明\u0026quot; } param2 = { repository_name = \u0026quot;my-repo002\u0026quot; description = \u0026quot;my-repo002の説明\u0026quot; } param3 = { repository_name = \u0026quot;my-repo003\u0026quot; description = \u0026quot;my-repo003の説明\u0026quot; } }  tfvars生成後は不要となるが、参考までに中間地点で生成されたJSONの中身。\ndata.json\n{\u0026#34;num\u0026#34;:{\u0026#34;0\u0026#34;:1,\u0026#34;1\u0026#34;:2,\u0026#34;2\u0026#34;:3},\u0026#34;repo_name\u0026#34;:{\u0026#34;0\u0026#34;:\u0026#34;my-repo001\u0026#34;,\u0026#34;1\u0026#34;:\u0026#34;my-repo002\u0026#34;,\u0026#34;2\u0026#34;:\u0026#34;my-repo003\u0026#34;},\u0026#34;des\u0026#34;:{\u0026#34;0\u0026#34;:\u0026#34;my-repo001\\u306e\\u8aac\\u660e\u0026#34;,\u0026#34;1\u0026#34;:\u0026#34;my-repo002\\u306e\\u8aac\\u660e\u0026#34;,\u0026#34;2\u0026#34;:\u0026#34;my-repo003\\u306e\\u8aac\\u660e\u0026#34;}}  こんな短いコードだがめっちゃ紆余曲折した。まーでも、これでひと安心。これはサンプルだから3アイテムだけだけど、AWSリソースの単位で十数個とか数十個とかアイテムがあって、さらにそれが複数重なったら手動で記述なんてやってられない。いや、3アイテムだけでも十分面倒だし、ミスる可能性ありありだ。\n今回のやり方はAWSリソース毎にCSVを分けて作っていく必要あるけど、それくらいならいいだろう。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform_auto_create_tfvars/","summary":"過去記事からの派生案件で、Terraformで使うtfvarsファイルについて、繰り返しデータを多数投入する想定のため、これを自動生成したいと考えた。\nTerraform loop処理の超シンプルな例 \nPython - Jinja2テンプレートで連続データを処理したい\n 実際に使用するファイル群は過去記事に記載しているがこんな想定で。（もちろん実際は他にもいろいろ必要）自動生成したいのは、以下の*印をつけたcodecommit.auto.tfvarsである。（この時点では手動で値を記述したもの）\nwork_dir/ ├── codecommit.auto.tfvars * ├── codecommit.tf ├── config.tf ├── terraform.tfvars ├── variables.tf └── vpc.tf  これとは別に、tfvars自動生成作業用ディレクトリの作業前はこの状態。以下3つのファイルを用意する。codecommit.tmplはテンプレートとなる。このファイル名はスクリプトから呼び出すので名称に注意。対象のAWSリソースによって変えるが、tfファイルの名称に合わせておけばよい。\nscript_dir/ ├── codecommit.tmpl ├── create_vars.py └── data.csv  codecommit.tmpl\n param{{ num }} = { repository_name = \u0026quot;{{ repo_name }}\u0026quot; description = \u0026quot;{{ des }}\u0026quot; }  data.csv （今回の例ではヘッダーありの前提）\nnum,repo_name,des 1,\u0026quot;my-repo001\u0026quot;,\u0026quot;my-repo001の説明\u0026quot; 2,\u0026quot;my-repo002\u0026quot;,\u0026quot;my-repo002の説明\u0026quot; 3,\u0026quot;my-repo003\u0026quot;,\u0026quot;my-repo003の説明\u0026quot;  create_vars.py\nimport sys import pandas as pd from jinja2 import Environment, FileSystemLoader def main(): # テンプレート読み込み env = Environment(loader=FileSystemLoader(\u0026#39;.","title":"Terraformのtfvarsファイルを自動生成する"},{"content":" Some say luck is when preparation meets opportunity.\n - Once Upon a Time in Hollywood\u0026quot;の小説版 (Quentin Tarantino) より。\n わかる、その発想好きだ。リアルワールドにおいてシャロン・テートを斬殺したチャールズ・マンソンのモノローグとして登場する言葉ってのがアレだけど\u0026hellip;\n個人的な経験からしても、preparation（準備）はopportunity（好機）を引き寄せるのは実感として理解できる。だから “preparation gets opportunity” とも言えるんじゃないか？\n   ","permalink":"https://ecnedaced-seirots.github.io/post/a/quotes-tarantino-movie-1/","summary":" Some say luck is when preparation meets opportunity.\n - Once Upon a Time in Hollywood\u0026quot;の小説版 (Quentin Tarantino) より。\n わかる、その発想好きだ。リアルワールドにおいてシャロン・テートを斬殺したチャールズ・マンソンのモノローグとして登場する言葉ってのがアレだけど\u0026hellip;\n個人的な経験からしても、preparation（準備）はopportunity（好機）を引き寄せるのは実感として理解できる。だから “preparation gets opportunity” とも言えるんじゃないか？\n   ","title":"Quotes - タランティーノ小説より(1)"},{"content":"Jinja2テンプレートで連続データを処理したい。元データはCSVとかで。いや、Jinja2でなくてもいいかもしれないけど、ちょっと思いつかないな\u0026hellip;\nとりあえず参考リンク。最初のリンクは、CSVをJSONに変換しているんだよな、CSVのままでやりたいんだけど。しかし例は分かりやすい。\n  【jinja2】テンプレートエンジンでデータの連続差し込み PythonのテンプレートエンジンJinja2を使ってみた   ","permalink":"https://ecnedaced-seirots.github.io/post/a/jinja2-python/","summary":"Jinja2テンプレートで連続データを処理したい。元データはCSVとかで。いや、Jinja2でなくてもいいかもしれないけど、ちょっと思いつかないな\u0026hellip;\nとりあえず参考リンク。最初のリンクは、CSVをJSONに変換しているんだよな、CSVのままでやりたいんだけど。しかし例は分かりやすい。\n  【jinja2】テンプレートエンジンでデータの連続差し込み PythonのテンプレートエンジンJinja2を使ってみた   ","title":"Python - Jinja2テンプレートで連続データを処理したい"},{"content":"前回投稿で言及したTerraformのループ処理を、めっちゃシンプルなパターンでやってみた。\n前回投稿\nTerraform loop処理のリンク集\n参考記事\nTerraformで配列をloopする時はfor_eachを使った方がいい\n やったこと Terraformのセットアップは割愛。作業ディレクトリには以下のtfコードがある。\nwork_dir/ ├── codecommit.tf ├── init.tf ├── variables.tf └── vpc.tf  以下は初期化ファイル。terraform init で初期化実行すみである。VPCも別途サクッと作ってある。ひとりPoCだからremote_stateにする必要もないのだが、なんとなくtfstateをS3に保管するためbackendの定義がある。\ninit.tf\nterraform { required_providers { aws = { source = \u0026quot;hashicorp/aws\u0026quot; version = \u0026quot;3.66.0\u0026quot; } } } terraform { required_version = \u0026quot;1.0.11\u0026quot; backend \u0026quot;s3\u0026quot; { bucket = \u0026quot;my-terraform-poc-repository\u0026quot; key = \u0026quot;poc/poc.tfstate\u0026quot; region = \u0026quot;ap-northeast-1\u0026quot; } }  で、肝心のloop処理。最初なので脳に優しく、超シンプルなパターンでいく。CodeCommitリポジトリの作成はパラメータが少ないので、参考記事を参照し、これで試した。他にもパラメータが少ないやつならなんでもいいけど。今回セットする値はrepository_nameとdescriptionの2点だけ。\nvariable.tf\nvariable \u0026quot;codecommit_param_list\u0026quot; { type = map(map(string)) default = { param1 = { repository_name = \u0026quot;repo001\u0026quot; description = \u0026quot;desciption for repo001\u0026quot; } param2 = { repository_name = \u0026quot;repo002\u0026quot; description = \u0026quot;desciption for repo002\u0026quot; } param3 = { repository_name = \u0026quot;repo003\u0026quot; description = \u0026quot;desciption for repo003\u0026quot; } } }  codecommit.tf\nresource \u0026quot;aws_codecommit_repository\u0026quot; \u0026quot;codecommit_repos\u0026quot; { for_each = var.codecommit_param_list repository_name = lookup(each.value, \u0026quot;repository_name\u0026quot;) description = lookup(each.value, \u0026quot;description\u0026quot;)  codecommit.tfの\u0026quot;codecommit_repos\u0026quot;は任意の名称。2行目、for_eachでvariables.tfのcodecommit_param_listを呼び出している。今回の場合はリポジトリ名がrepo001, repo002\u0026hellip;となる。この状態でplanを実行すると以下の出力になる。\n: Terraform will perform the following actions: # aws_codecommit_repository.codecommit_repos[\u0026quot;param1\u0026quot;] will be created + resource \u0026quot;aws_codecommit_repository\u0026quot; \u0026quot;codecommit_repos\u0026quot; { + arn = (known after apply) + clone_url_http = (known after apply) + clone_url_ssh = (known after apply) + description = \u0026quot;desciption for repo001\u0026quot; + id = (known after apply) + repository_id = (known after apply) + repository_name = \u0026quot;repo001\u0026quot; + tags_all = (known after apply) } # aws_codecommit_repository.codecommit_repos[\u0026quot;param2\u0026quot;] will be created + resource \u0026quot;aws_codecommit_repository\u0026quot; \u0026quot;codecommit_repos\u0026quot; { + arn = (known after apply) + clone_url_http = (known after apply) + clone_url_ssh = (known after apply) + description = \u0026quot;desciption for repo002\u0026quot; + id = (known after apply) + repository_id = (known after apply) + repository_name = \u0026quot;repo002\u0026quot; + tags_all = (known after apply) } (repo003も同様） Plan: 3 to add, 0 to change, 0 to destroy.  terraform applyを実行。期待値になった。（repo003だけ時間がずれているのは、1点間違いがあってやり直したから）\n やれることはわかったのでこいつ達は削除する。\nリポジトリを削除する。しかしいきなりdestroyすると別途作ったvpcまで消えてしまう。同じ階層にvpc.tfがあるのでそれはそのまま、codecommit.tfを作業ディレクトリから退避。この状態でapplyするとcodecommitリポジトリは消えてvpcは残る。以下でやっていることはapplyでもdestroyなので注意。\n$ terraform apply : aws_codecommit_repository.codecommit_repos[\u0026quot;param3\u0026quot;]: Destroying... [id=repo003] aws_codecommit_repository.codecommit_repos[\u0026quot;param1\u0026quot;]: Destroying... [id=repo001] aws_codecommit_repository.codecommit_repos[\u0026quot;param2\u0026quot;]: Destroying... [id=repo002] aws_codecommit_repository.codecommit_repos[\u0026quot;param1\u0026quot;]: Destruction complete after 0s aws_codecommit_repository.codecommit_repos[\u0026quot;param3\u0026quot;]: Destruction complete after 0s aws_codecommit_repository.codecommit_repos[\u0026quot;param2\u0026quot;]: Destruction complete after 0s Apply complete! Resources: 0 added, 0 changed, 3 destroyed.  課題 コツは掴めたけど、コード本体に書く値がvariablesに移動しただけという気もする。パラメータが増えるほど、結局variablesが肥大化することになる。変数定義を分割できないか？\n この課題については、変数定義をさらにtfvarsに外出しすることで解決可能。変数定義ファイルが増えることにはなるが、1ファイルが肥大化するよりいい。今回やった分だけでいうと、以下の構成になる。\nwork_dir/ ├── codecommit.auto.tfvars ├── codecommit.tf ├── config.tf ├── terraform.tfvars ├── variables.tf └── vpc.tf  xxxxx.auto.tfvarsに個別に分割した要素の値を記述すると、apply実行時に自動で呼び出される。\ncodecommit.tfはこれまでと同じ。\nvariables.tfには値は記述せず、宣言だけ記述する。\nterraform.tfvarsにはリージョンなど全てに共通の値、IAMなど他のリソースから共通で参照されるリソースの値を記述。\nvariables.tf\n# main variable \u0026quot;region\u0026quot; { type = string description = \u0026quot;\u0026quot; } # codecommit variable \u0026quot;codecommit_param_list\u0026quot; { type = map(map(string)) description = \u0026quot;\u0026quot; }  codecommit.auto.tfvars\n# codecommit repos definition codecommit_param_list = { param1 = { repository_name = \u0026quot;repo004\u0026quot; description = \u0026quot;desciption for repo004\u0026quot; } param2 = { repository_name = \u0026quot;repo005\u0026quot; description = \u0026quot;desciption for repo005\u0026quot; } param3 = { repository_name = \u0026quot;repo006\u0026quot; description = \u0026quot;desciption for repo006\u0026quot; } }  terraform.tfvars\nregion = \u0026quot;ap-northeast-1\u0026quot;  codecommit.auto.tfvarsは例なのでこれだけだが、例えばネットワーク周り、アプリ系リソース、監視、ジョブ等の大枠に分割して、その枠毎にtfvarsを用意すれば小回りが効く構成になるんじゃないかと。て、なんかloop処理のことを書くつもりが変数周りのネタメインになった気がする。ま、いいか。\n 課題2 loopで作成したリソースの参照方法はどうすればいいのか？が気になって調査してみた。今回だと、Terraformで作成したCodeCommitリポジトリ名をCodePipeline作成時のコードで参照するケースとか。リポジトリrepo001を参照するなら以下の記述になる。\ncodecommit_repository.codecommit_repos[\u0026quot;param1\u0026quot;].id  参照名はcodecommit_repository.codecommit_repos[\u0026quot;param1\u0026quot;].repository_nameではないことに注意。それはいいとして、CodePipeline自体もloopで作成するとしたらこの記述は使えないから、結局同じtfvarsの値を参照して作ることになるかな。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform-loop-example/","summary":"前回投稿で言及したTerraformのループ処理を、めっちゃシンプルなパターンでやってみた。\n前回投稿\nTerraform loop処理のリンク集\n参考記事\nTerraformで配列をloopする時はfor_eachを使った方がいい\n やったこと Terraformのセットアップは割愛。作業ディレクトリには以下のtfコードがある。\nwork_dir/ ├── codecommit.tf ├── init.tf ├── variables.tf └── vpc.tf  以下は初期化ファイル。terraform init で初期化実行すみである。VPCも別途サクッと作ってある。ひとりPoCだからremote_stateにする必要もないのだが、なんとなくtfstateをS3に保管するためbackendの定義がある。\ninit.tf\nterraform { required_providers { aws = { source = \u0026quot;hashicorp/aws\u0026quot; version = \u0026quot;3.66.0\u0026quot; } } } terraform { required_version = \u0026quot;1.0.11\u0026quot; backend \u0026quot;s3\u0026quot; { bucket = \u0026quot;my-terraform-poc-repository\u0026quot; key = \u0026quot;poc/poc.tfstate\u0026quot; region = \u0026quot;ap-northeast-1\u0026quot; } }  で、肝心のloop処理。最初なので脳に優しく、超シンプルなパターンでいく。CodeCommitリポジトリの作成はパラメータが少ないので、参考記事を参照し、これで試した。他にもパラメータが少ないやつならなんでもいいけど。今回セットする値はrepository_nameとdescriptionの2点だけ。\nvariable.tf\nvariable \u0026quot;codecommit_param_list\u0026quot; { type = map(map(string)) default = { param1 = { repository_name = \u0026quot;repo001\u0026quot; description = \u0026quot;desciption for repo001\u0026quot; } param2 = { repository_name = \u0026quot;repo002\u0026quot; description = \u0026quot;desciption for repo002\u0026quot; } param3 = { repository_name = \u0026quot;repo003\u0026quot; description = \u0026quot;desciption for repo003\u0026quot; } } }  codecommit.","title":"Terraform loop処理の超シンプルな例"},{"content":"Terraformでループ処理ってどうするんだっけ\u0026hellip;と調べたらいろいろ出てきた。読んでも全然頭に入らないがとりあえず参考リンクをメモ。パッと見る限りcountよりfor_eachの方がお勧め？ひとつのリソースに2個以上のパラメータをセットする場合は以下記事の「for_eachを使った書き方（その2）」を参考にすればいいかな。\n  for_eachを知らずにcountを使って作成したところ、追加や削除の際に色々と意図しない挙動になったので、回避策について備忘録を残しておきたいと思います。\n  Terraformで配列をloopする時はfor_eachを使った方がいい   以下もちゃんと読めば有益そうなのだが、マニアックすぎて理解が追いつかない。\n Terraformでのloop処理の書き方（for, for_each, count） Terraformのループ処理(for_each,for)について Terraformでimportを使う理由とfor_eachをつかったリソース定義に実リソースをimportする方法   これはcountを使う方法。多分使わないけど比較用にメモ。\n Terraformで超サクッとループでリソースを用意する方法   上記記事のリンクにあったこっちの記事の方にピピっときた。IntelliJでTerraformね、これはやってみよう。仕事じゃ使えないけど。\n 新記法対応！ IntelliJ IDEAを使ってTerraformを書いてみた   IntelliJはさておき、久しぶりに使ってみたらプロバイダの記述方法が変わっていてハマった。今現在は以下の方式で書く。\nterraform { required_providers { aws = { source = \u0026quot;hashicorp/aws\u0026quot; version = \u0026quot;3.66.0\u0026quot; } } }  以下記事に最近変わった細かい規則とかいろいろ書いてある。ロックファイルとか面倒くせぇな、なくていいのに。\u0026hellip;と思ったが、ドキュメント読む限り気にしなくてよさげ。\n Terraform職人再入門2020   ","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform-loop-memo/","summary":"Terraformでループ処理ってどうするんだっけ\u0026hellip;と調べたらいろいろ出てきた。読んでも全然頭に入らないがとりあえず参考リンクをメモ。パッと見る限りcountよりfor_eachの方がお勧め？ひとつのリソースに2個以上のパラメータをセットする場合は以下記事の「for_eachを使った書き方（その2）」を参考にすればいいかな。\n  for_eachを知らずにcountを使って作成したところ、追加や削除の際に色々と意図しない挙動になったので、回避策について備忘録を残しておきたいと思います。\n  Terraformで配列をloopする時はfor_eachを使った方がいい   以下もちゃんと読めば有益そうなのだが、マニアックすぎて理解が追いつかない。\n Terraformでのloop処理の書き方（for, for_each, count） Terraformのループ処理(for_each,for)について Terraformでimportを使う理由とfor_eachをつかったリソース定義に実リソースをimportする方法   これはcountを使う方法。多分使わないけど比較用にメモ。\n Terraformで超サクッとループでリソースを用意する方法   上記記事のリンクにあったこっちの記事の方にピピっときた。IntelliJでTerraformね、これはやってみよう。仕事じゃ使えないけど。\n 新記法対応！ IntelliJ IDEAを使ってTerraformを書いてみた   IntelliJはさておき、久しぶりに使ってみたらプロバイダの記述方法が変わっていてハマった。今現在は以下の方式で書く。\nterraform { required_providers { aws = { source = \u0026quot;hashicorp/aws\u0026quot; version = \u0026quot;3.66.0\u0026quot; } } }  以下記事に最近変わった細かい規則とかいろいろ書いてある。ロックファイルとか面倒くせぇな、なくていいのに。\u0026hellip;と思ったが、ドキュメント読む限り気にしなくてよさげ。\n Terraform職人再入門2020   ","title":"Terraform loop処理のリンク集"},{"content":"以下過去記事の続き。この時はメール本文がJSON生データで送信された。これを、人間が状況を判別可能な状態までもっていきたい。\nAWS EventBridge + SNSからのメール件名をカスタマイズする\n とういことで、再度検証。使用したAWS各種サービスのリソースは前回と同様で、Lambda関数のコードだけ入れ替え。何度も同じようなことをやっていて何がなんだか分からなくなっているがもうヤケクソ。\n lambda_function.py （イベント監視メール通知用）\nimport boto3 import json import os import re from botocore.exceptions import ClientError from datetime import datetime, timezone, timedelta from dateutil import parser print(\u0026#39;Loading function\u0026#39;) sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] def lambda_handler(event, context): data = event s = json.dumps(data) e = json.loads(s) print(e) # eventから項目を抽出 dtl = e[\u0026#39;detail\u0026#39;] #詳細(detail)を定義 e_type = e[\u0026#39;detail-type\u0026#39;] # イベントタイプ 例：\u0026#39;AWS API Call via CloudTrail\u0026#39; t = e[\u0026#39;time\u0026#39;] # 発生時刻 evt_name = dtl[\u0026#39;eventName\u0026#39;] # イベント名 例：DeleteBucket evt_src = dtl[\u0026#39;eventSource\u0026#39;] # イベントソース 例：s3.amazonaws.com evt_usr = dtl[\u0026#39;userIdentity\u0026#39;][\u0026#39;arn\u0026#39;] # 実行ユーザ 例：arn:aws:iam::012345678910:user/hoge_user evt_ip = dtl[\u0026#39;sourceIPAddress\u0026#39;] # ソースIPアドレス #123.123.123.123 # 時刻変換 JST = timezone(timedelta(hours=+9), \u0026#39;JST\u0026#39;) utcstr_parsed = parser.parse(t) ux_time = utcstr_parsed.timestamp() epoch = int(ux_time) # unixタイムスタンプをJSTに変換。dtはこの時点でdatetime.datetime型 dt = datetime.fromtimestamp(epoch).replace(tzinfo=timezone.utc).astimezone(tz=JST) # dtを整形 dt_str = dt.strftime(\u0026#39;%Y-%m-%d%H:%M:%S\u0026#39;) # イベントリクエスト 例：{\u0026#39;bucketName\u0026#39;: \u0026#39;hoge-test-bucket-0001\u0026#39;, \u0026#39;Host\u0026#39;: \u0026#39;s3-ap-northeast-1.amazonaws.com\u0026#39;} evt_req_d = e[\u0026#39;detail\u0026#39;][\u0026#39;requestParameters\u0026#39;] req_str = json.dumps(evt_req_d) evt_req = re.sub(r\u0026#34;[{}\\\u0026#34;]\u0026#34;, \u0026#34;\u0026#34;, req_str) # 件名整形 subject_str = \u0026#34;本番環境イベント監視 \u0026#34; + evt_name + \u0026#34; - \u0026#34; + evt_src # メッセージ本文整形 fix_msg = \u0026#34;以下のイベントが発生しました\u0026#34; + \u0026#34;\\n\u0026#34; type_msg = \u0026#34;イベントタイプ:\u0026#34; + \u0026#34;\\n\u0026#34; + e_type time_msg = \u0026#34;発生時刻(JST):\u0026#34; + \u0026#34;\\n\u0026#34; + dt_str ename_msg = \u0026#34;イベント名:\u0026#34; + \u0026#34;\\n\u0026#34; + evt_name esrc_msg =\u0026#34;イベントソース:\u0026#34; \u0026#34;\\n\u0026#34; + evt_src ereq_msg =\u0026#34;イベントリクエスト:\u0026#34; \u0026#34;\\n\u0026#34; + evt_req eusr_msg =\u0026#34;実行ユーザ:\u0026#34; \u0026#34;\\n\u0026#34; + evt_usr eip_msg =\u0026#34;ソースIPアドレス:\u0026#34; \u0026#34;\\n\u0026#34; + evt_ip msg = fix_msg + \u0026#34;\\n\\n\u0026#34; + type_msg + \u0026#34;\\n\\n\u0026#34; + time_msg + \u0026#34;\\n\\n\u0026#34; + ename_msg + \u0026#34;\\n\\n\u0026#34; + esrc_msg + \u0026#34;\\n\\n\u0026#34; + ereq_msg + \u0026#34;\\n\\n\u0026#34; + eusr_msg + \u0026#34;\\n\\n\u0026#34; + eip_msg try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = msg, Subject = subject_str ) except Exception as e: print(e)  テスト用にサンプルデータを貼り付けて、エラーが出ない状態にまでもっていった。これでもういいかと思ったがやはりちゃんとしたメールが届くのが見たい\u0026hellip;ということで、再びCloudTrailを有効にしてイベントを発生させることにした。前回無効にしたCloudTrailログ用の残骸バケットが残っていたのでそれを削除したら、まさにその行為がイベントとして検知され、メールが届いた。よしよし。\n 上記はテストデータ残骸の内容が表示されているが、実際のイベント発生時のメールも別途ちゃんと届いている。上記画面では「APIタイプ」が含まれているがこれはいらないと判断したため、この後コードから削除した。\n ちなみに、JSON生データからkey:valueの抽出を行うときはこんなんでやった。JSONデータをファイルに保存してから：\n\u0026gt;\u0026gt;\u0026gt; import json \u0026gt;\u0026gt;\u0026gt; event_file = open('event_msg_sample.json','r') \u0026gt;\u0026gt;\u0026gt; event = json.load(event_file) \u0026gt;\u0026gt;\u0026gt; for k,v in event.items(): ... print(k,v)  ","permalink":"https://ecnedaced-seirots.github.io/post/a/aws-events-custom-mail-2/","summary":"以下過去記事の続き。この時はメール本文がJSON生データで送信された。これを、人間が状況を判別可能な状態までもっていきたい。\nAWS EventBridge + SNSからのメール件名をカスタマイズする\n とういことで、再度検証。使用したAWS各種サービスのリソースは前回と同様で、Lambda関数のコードだけ入れ替え。何度も同じようなことをやっていて何がなんだか分からなくなっているがもうヤケクソ。\n lambda_function.py （イベント監視メール通知用）\nimport boto3 import json import os import re from botocore.exceptions import ClientError from datetime import datetime, timezone, timedelta from dateutil import parser print(\u0026#39;Loading function\u0026#39;) sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] def lambda_handler(event, context): data = event s = json.dumps(data) e = json.loads(s) print(e) # eventから項目を抽出 dtl = e[\u0026#39;detail\u0026#39;] #詳細(detail)を定義 e_type = e[\u0026#39;detail-type\u0026#39;] # イベントタイプ 例：\u0026#39;AWS API Call via CloudTrail\u0026#39; t = e[\u0026#39;time\u0026#39;] # 発生時刻 evt_name = dtl[\u0026#39;eventName\u0026#39;] # イベント名 例：DeleteBucket evt_src = dtl[\u0026#39;eventSource\u0026#39;] # イベントソース 例：s3.","title":"AWS EventBridge + SNSからのメール本文をカスタマイズする"},{"content":"表題のテーマ、過去にもCloudWatchアラーム通知メールのカスタマイズについて書いたが、表示時刻がUTCなのでJSTに変換しようと考えた。\n 過去記事\nCloudWatchアラーム + SNSからのメール本文をカスタマイズする(2)\nCloudWatchアラーム + SNSからのメール件名をカスタマイズする\n CloudWatchアラームから渡されるeventの、元データの時刻表示は例えば'2021-10-24T09:35:10Z\u0026rsquo;となっている。これをJSTにするのに手っ取り早いのはpytzを使う方法だが、諸事情により標準ライブラリの範囲でやる必要がある。\nで、試行錯誤。当初datetime型にしてからJSTに変換しようとしたがいいやり方が見つからなかったため「unixタイムスタンプに変換後、JSTに変換」とすることにした。\nfrom datetime import datetime, timezone, timedelta from dateutil import parser JST = timezone(timedelta(hours=+9), 'JST') utcstr = '2021-10-24T09:35:10Z' utcstr_parsed = parser.parse(utcstr) #UNIXタイムスタンプに変換 ux_time = utcstr_parsed.timestamp() #int型にする epoch = int(ux_time) #JSTに変換 dt = datetime.fromtimestamp(epoch).replace(tzinfo=timezone.utc).astimezone(tz=JST) print(dt) 2021-10-25 03:35:10+09:00  当初JSTに変換した後の時間が変だ+18時間になってる何故だ、と悩んだが、拠点にした時間から+18時間になるのはおそらく実行環境がJSTだから。UTCの環境でやれば+9時間になるんだろう。くそ、こんなことで数時間週末を無駄にした。俺の休息時間はいつなんだ？\nともあれ、修正したのが以下。コメントの「時刻変換」と、「件名に投入するアラーム名を抽出」を追加した。前回はメール件名規則を「任意の文字列 + 発生契機 + 対象リソース(dimention)」としていたが、発生契機はいらないから代わりにアラーム名にした。\n lambda_function.py （時刻表示JSTバージョン）\nimport boto3 import json import os import re from botocore.exceptions import ClientError from datetime import datetime, timezone, timedelta from dateutil import parser print(\u0026#39;Loading function\u0026#39;) sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] def lambda_handler(event, context): data = event s = json.dumps(data) e = json.loads(s) print(e) # eventから項目を抽出 t = e[\u0026#39;time\u0026#39;] trig = e[\u0026#39;detail-type\u0026#39;] alarm = e[\u0026#39;resources\u0026#39;] # 時刻変換 JST = timezone(timedelta(hours=+9), \u0026#39;JST\u0026#39;) utcstr_parsed = parser.parse(t) ux_time = utcstr_parsed.timestamp() epoch = int(ux_time) # unixタイムスタンプをJSTに変換。dtはこの時点でdatetime.datetime型 dt = datetime.fromtimestamp(epoch).replace(tzinfo=timezone.utc).astimezone(tz=JST) # dtを整形 dt_str = dt.strftime(\u0026#39;%Y-%m-%d%H:%M:%S\u0026#39;) # 件名に投入するアラーム名を抽出 alm_list = alarm[0].split(\u0026#39;:\u0026#39;) alm_name = alm_list[-1] # 「理由」となる詳細抽出 reason = e[\u0026#39;detail\u0026#39;][\u0026#39;state\u0026#39;][\u0026#39;reason\u0026#39;] # リソース（ここではインスタンスID)を抽出し、文字列整形 resource = e[\u0026#39;detail\u0026#39;][\u0026#39;configuration\u0026#39;][\u0026#39;metrics\u0026#39;][0][\u0026#39;metricStat\u0026#39;][\u0026#39;metric\u0026#39;][\u0026#39;dimensions\u0026#39;] res_str = json.dumps(resource) res = re.sub(r\u0026#34;[{}\\\u0026#34;]\u0026#34;, \u0026#34;\u0026#34;, res_str) # 件名整形 subject_str = \u0026#34;本番環境アラーム \u0026#34; + alm_name + \u0026#34; - \u0026#34; + res # メッセージ本文整形 fix_msg = \u0026#34;以下のアラームが発生しました\u0026#34; + \u0026#34;\\n\u0026#34; trig_msg = \u0026#34;発生契機:\u0026#34; + \u0026#34;\\n\u0026#34; + trig time_msg = \u0026#34;発生時刻(JST):\u0026#34; + \u0026#34;\\n\u0026#34; + dt_str alm_msg = \u0026#34;アラームARN:\u0026#34; + \u0026#34;\\n\u0026#34; + alarm[0] res_msg =\u0026#34;対象リソース:\u0026#34; \u0026#34;\\n\u0026#34; + res dtl_msg =\u0026#34;理由:\u0026#34; \u0026#34;\\n\u0026#34; + reason msg = fix_msg + \u0026#34;\\n\\n\u0026#34; + trig_msg + \u0026#34;\\n\\n\u0026#34; + time_msg + \u0026#34;\\n\\n\u0026#34; + alm_msg + \u0026#34;\\n\\n\u0026#34; + res_msg + \u0026#34;\\n\\n\u0026#34; + dtl_msg try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = msg, Subject = subject_str ) except Exception as e: print(e)  上記コードにてLambdaを再デプロイしてec2インスタンスでCPU負荷発生させたところ、一応期待値となるメールが届いた。画面下の「理由」に記載の時刻はUTCとなっているが、「発生時刻(JST)」は日本時刻表記である。（ほぼ実際にCPU負荷をかけた時間）\n  参考\n[Python]UNIX秒(UTC)をISO8601(JST)に変換する\nPythonで日付をunixtimeに変換する方法【初心者向け】\n まぁこんなことやったところで誰も感謝もしてくれないがね。映画\u0026quot;Taxi Driver\u0026quot;のトラヴィスの気持ちも分かるってもんだ。（\u0026hellip;若干くされ気分）\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatch-alarm-lambda-3/","summary":"表題のテーマ、過去にもCloudWatchアラーム通知メールのカスタマイズについて書いたが、表示時刻がUTCなのでJSTに変換しようと考えた。\n 過去記事\nCloudWatchアラーム + SNSからのメール本文をカスタマイズする(2)\nCloudWatchアラーム + SNSからのメール件名をカスタマイズする\n CloudWatchアラームから渡されるeventの、元データの時刻表示は例えば'2021-10-24T09:35:10Z\u0026rsquo;となっている。これをJSTにするのに手っ取り早いのはpytzを使う方法だが、諸事情により標準ライブラリの範囲でやる必要がある。\nで、試行錯誤。当初datetime型にしてからJSTに変換しようとしたがいいやり方が見つからなかったため「unixタイムスタンプに変換後、JSTに変換」とすることにした。\nfrom datetime import datetime, timezone, timedelta from dateutil import parser JST = timezone(timedelta(hours=+9), 'JST') utcstr = '2021-10-24T09:35:10Z' utcstr_parsed = parser.parse(utcstr) #UNIXタイムスタンプに変換 ux_time = utcstr_parsed.timestamp() #int型にする epoch = int(ux_time) #JSTに変換 dt = datetime.fromtimestamp(epoch).replace(tzinfo=timezone.utc).astimezone(tz=JST) print(dt) 2021-10-25 03:35:10+09:00  当初JSTに変換した後の時間が変だ+18時間になってる何故だ、と悩んだが、拠点にした時間から+18時間になるのはおそらく実行環境がJSTだから。UTCの環境でやれば+9時間になるんだろう。くそ、こんなことで数時間週末を無駄にした。俺の休息時間はいつなんだ？\nともあれ、修正したのが以下。コメントの「時刻変換」と、「件名に投入するアラーム名を抽出」を追加した。前回はメール件名規則を「任意の文字列 + 発生契機 + 対象リソース(dimention)」としていたが、発生契機はいらないから代わりにアラーム名にした。\n lambda_function.py （時刻表示JSTバージョン）\nimport boto3 import json import os import re from botocore.exceptions import ClientError from datetime import datetime, timezone, timedelta from dateutil import parser print(\u0026#39;Loading function\u0026#39;) sns_arn = os.","title":"CloudWatchアラーム + SNSからのメール本文をカスタマイズする(3)"},{"content":"into the bargain = in addition\n\u0026ldquo;Zazie in the Metro\u0026rdquo;(Raymond Queneau) / 地下鉄のザジ（レーモン・クノー）より\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/english-into-the-bargain/","summary":"into the bargain = in addition\n\u0026ldquo;Zazie in the Metro\u0026rdquo;(Raymond Queneau) / 地下鉄のザジ（レーモン・クノー）より\n ","title":"英語メモ - into the bargain"},{"content":"表題の件、過去記事ではメール件名カスタマイズが主題だったが、メール本文を人間が判読可能なフォーマットにすべく、Lambdaコードを改良してみた。これがSNSに渡り、整形された本文がメール送信される想定である。前回はメール件名を環境変数にしたが今回はコード内から値を取り出している。\n類似の過去記事\nCloudWatchアラーム + SNSからのメール件名をカスタマイズする\n lambda_function.py\nimport boto3 import json import os import re from botocore.exceptions import ClientError print(\u0026#39;Loading function\u0026#39;) sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] def lambda_handler(event, context): data = event s = json.dumps(data) e = json.loads(s) print(e) # eventから項目を抽出 t = e[\u0026#39;time\u0026#39;] trig = e[\u0026#39;detail-type\u0026#39;] alarm = e[\u0026#39;resources\u0026#39;] #これはリスト。文字列にするにはalarm[0] # 「理由」となる詳細抽出 reason = e[\u0026#39;detail\u0026#39;][\u0026#39;state\u0026#39;][\u0026#39;reason\u0026#39;] # リソース（ここではインスタンスID)を抽出し、文字列整形 resource = e[\u0026#39;detail\u0026#39;][\u0026#39;configuration\u0026#39;][\u0026#39;metrics\u0026#39;][0][\u0026#39;metricStat\u0026#39;][\u0026#39;metric\u0026#39;][\u0026#39;dimensions\u0026#39;] res_str = json.dumps(resource) res = re.sub(r\u0026#34;[{}\\\u0026#34;]\u0026#34;, \u0026#34;\u0026#34;, res_str) # 件名整形 subject_str = \u0026#34;本番環境 - アラーム \u0026#34; + trig + \u0026#34; - \u0026#34; + res # メッセージ本文整形 fix_msg = \u0026#34;以下のアラームが発生しました\u0026#34; + \u0026#34;\\n\u0026#34; trig_msg = \u0026#34;発生契機:\u0026#34; + \u0026#34;\\n\u0026#34; + trig time_msg = \u0026#34;発生時刻:\u0026#34; + \u0026#34;\\n\u0026#34; + t alm_msg = \u0026#34;アラーム:\u0026#34; + \u0026#34;\\n\u0026#34; + alarm[0] res_msg =\u0026#34;対象リソース:\u0026#34; \u0026#34;\\n\u0026#34; + res dtl_msg =\u0026#34;理由:\u0026#34; \u0026#34;\\n\u0026#34; + reason msg = fix_msg + \u0026#34;\\n\\n\u0026#34; + trig_msg + \u0026#34;\\n\\n\u0026#34; + time_msg + \u0026#34;\\n\\n\u0026#34; + alm_msg + \u0026#34;\\n\\n\u0026#34; + res_msg + \u0026#34;\\n\\n\u0026#34; + dtl_msg try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = msg, Subject = subject_str ) except Exception as e: print(e)  マネコン上でテストしたらいくつかエラー出たので対処して、エラー出ないところまでもってきた。で、ec2インスタンスに負荷をかけてアラームステータスにしたが\u0026hellip;メールが届かない。あぁ。\n明日以降考えよ。\n 追記\n翌日Lambdaの画面からなんとなくEventBridgeルールのリンクを辿ったら、なんとルールがdisableになっていた！そりゃ何も起こらないわけだ。enableに変更して、改めてインスタンスで負荷をかけたところ、カスタムメールが届いた！大したことじゃないけど、こういうのはいつまでたっても嬉しいもんだ。\n  しかしよく見ると日付が変だ。Lambdaテスト用に使った過去データの値みたいだ。な、なんでこうなるんだ。でももう遅いから寝る\u0026hellip;\n 追記2\nさらにその翌日、テストデータ削除して再試行してみたところ、期待値となるまともなメールが届いた。\n 時間はUTC表記。これどうするかな。以下でやれるのはわかったけど。\n\u0026gt;\u0026gt;\u0026gt; from pytz import timezone \u0026gt;\u0026gt;\u0026gt; from dateutil import parser \u0026gt;\u0026gt;\u0026gt; time = \u0026quot;2021-11-03T10:17:51Z\u0026quot; \u0026gt;\u0026gt;\u0026gt; utc_string = time \u0026gt;\u0026gt;\u0026gt; jst_time = parser.parse(utc_string).astimezone(timezone('Asia/Tokyo')) \u0026gt;\u0026gt;\u0026gt; print(jst_time) 2021-11-03 19:17:51+09:00 参考\nPythonの UTC ⇔ JST、文字列(UTC) ⇒ JST の変換とかのメモ\n しかし、今日はもう寝たいんだ。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatch-alarm-lambda-2/","summary":"表題の件、過去記事ではメール件名カスタマイズが主題だったが、メール本文を人間が判読可能なフォーマットにすべく、Lambdaコードを改良してみた。これがSNSに渡り、整形された本文がメール送信される想定である。前回はメール件名を環境変数にしたが今回はコード内から値を取り出している。\n類似の過去記事\nCloudWatchアラーム + SNSからのメール件名をカスタマイズする\n lambda_function.py\nimport boto3 import json import os import re from botocore.exceptions import ClientError print(\u0026#39;Loading function\u0026#39;) sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] def lambda_handler(event, context): data = event s = json.dumps(data) e = json.loads(s) print(e) # eventから項目を抽出 t = e[\u0026#39;time\u0026#39;] trig = e[\u0026#39;detail-type\u0026#39;] alarm = e[\u0026#39;resources\u0026#39;] #これはリスト。文字列にするにはalarm[0] # 「理由」となる詳細抽出 reason = e[\u0026#39;detail\u0026#39;][\u0026#39;state\u0026#39;][\u0026#39;reason\u0026#39;] # リソース（ここではインスタンスID)を抽出し、文字列整形 resource = e[\u0026#39;detail\u0026#39;][\u0026#39;configuration\u0026#39;][\u0026#39;metrics\u0026#39;][0][\u0026#39;metricStat\u0026#39;][\u0026#39;metric\u0026#39;][\u0026#39;dimensions\u0026#39;] res_str = json.dumps(resource) res = re.sub(r\u0026#34;[{}\\\u0026#34;]\u0026#34;, \u0026#34;\u0026#34;, res_str) # 件名整形 subject_str = \u0026#34;本番環境 - アラーム \u0026#34; + trig + \u0026#34; - \u0026#34; + res # メッセージ本文整形 fix_msg = \u0026#34;以下のアラームが発生しました\u0026#34; + \u0026#34;\\n\u0026#34; trig_msg = \u0026#34;発生契機:\u0026#34; + \u0026#34;\\n\u0026#34; + trig time_msg = \u0026#34;発生時刻:\u0026#34; + \u0026#34;\\n\u0026#34; + t alm_msg = \u0026#34;アラーム:\u0026#34; + \u0026#34;\\n\u0026#34; + alarm[0] res_msg =\u0026#34;対象リソース:\u0026#34; \u0026#34;\\n\u0026#34; + res dtl_msg =\u0026#34;理由:\u0026#34; \u0026#34;\\n\u0026#34; + reason msg = fix_msg + \u0026#34;\\n\\n\u0026#34; + trig_msg + \u0026#34;\\n\\n\u0026#34; + time_msg + \u0026#34;\\n\\n\u0026#34; + alm_msg + \u0026#34;\\n\\n\u0026#34; + res_msg + \u0026#34;\\n\\n\u0026#34; + dtl_msg try: sns = boto3.","title":"CloudWatchアラーム + SNSからのメール本文をカスタマイズする(2)"},{"content":"表題の件、以下の過去記事に書いたが、この時点では送信される本文ががログメッセージだけとなっていて、通知メールとしては不十分なため本文もカスタマイズしてみた。\nCloudWatchLogsのログ監視 - サブスクリプションフィルタ + Lambdaでメール送信\n 各種設定は冒頭の過去記事と同様のため割愛するとして、コードは変更前・後両方載せておく。\n変更前：lambda_function.py(1)\nimport base64 import json import zlib import datetime import os import boto3 from botocore.exceptions import ClientError print(\u0026#39;Loading function\u0026#39;) def lambda_handler(event, context): data = zlib.decompress(base64.b64decode(event[\u0026#39;awslogs\u0026#39;][\u0026#39;data\u0026#39;]), 16+zlib.MAX_WBITS) data_json = json.loads(data) log_entire_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;], ensure_ascii=False)) log_entire_len = len(log_entire_json) print(log_entire_json) for i in range(log_entire_len): log_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;][i], ensure_ascii=False)) try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = log_json[\u0026#39;message\u0026#39;], Subject = os.environ[\u0026#39;ALARM_SUBJECT\u0026#39;] ) except Exception as e: print(e) 参考\nCloudWatch Logs を文字列検知してログ内容をメールを送信してみた サブスクリプションフィルター版\n 変更後：lambda_function.py(2)\nimport base64 import json import zlib import datetime import os import boto3 from botocore.exceptions import ClientError print(\u0026#39;Loading function\u0026#39;) def lambda_handler(event, context): data = zlib.decompress(base64.b64decode(event[\u0026#39;awslogs\u0026#39;][\u0026#39;data\u0026#39;]), 16+zlib.MAX_WBITS) data_json = json.loads(data) log_entire_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;], ensure_ascii=False)) log_entire_len = len(log_entire_json) print(log_entire_json) for i in range(log_entire_len): # ロググループ名取得 log_group = data_json[\u0026#39;logGroup\u0026#39;] # ログストリーム名取得 log_stm = data_json[\u0026#39;logStream\u0026#39;] # LogEvents取得 log_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;][i], ensure_ascii=False)) #UNIX時間→時刻/JST変換 datetime_utc = log_json[\u0026#39;timestamp\u0026#39;] / 1000.0 datetime_utc = datetime.datetime.fromtimestamp(datetime_utc).strftime(\u0026#39;%Y/%m/%d%H:%M:%S\u0026#39;) datetime_utc = datetime.datetime.strptime(datetime_utc, \u0026#39;%Y/%m/%d%H:%M:%S\u0026#39;) datetime_jst = datetime_utc + datetime.timedelta(hours = 9) # メール件名整形 subject_str = \u0026#34;本番環境 - ログアラート \u0026#34; + log_group # メッセージ本文整形 fix_msg = \u0026#34;以下のアラートが発生しました\u0026#34; + \u0026#34;\\n\u0026#34; log_group_msg = \u0026#34;ロググループ名:\u0026#34; + \u0026#34;\\n\u0026#34; + log_group log_stm_msg = \u0026#34;ログストリーム名:\u0026#34; + \u0026#34;\\n\u0026#34; + log_stm time_msg = \u0026#34;発生時刻:\u0026#34; + \u0026#34;\\n\u0026#34; + str(datetime_jst) log_msg = \u0026#34;メッセージ:\u0026#34; + \u0026#34;\\n\u0026#34; + log_json[\u0026#39;message\u0026#39;] msg = fix_msg + \u0026#34;\\n\\n\u0026#34; + log_group_msg + \u0026#34;\\n\\n\u0026#34; + log_stm_msg + \u0026#34;\\n\\n\u0026#34; + time_msg + \u0026#34;\\n\\n\u0026#34; + log_msg try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = msg, Subject = subject_str ) except Exception as e: print(e) 参考\n【AWS】CloudWatch Logsからシステムログをメール通知する。\n 改良後のコードでは本文整形の他、メール件名を環境変数決め打ちからコード内でeventの情報から取得、に変更している。ログ種別は多義に渡るしログ監視以外のメール送信もあるから、動的に対応できる方が望ましいということで。本文冒頭に決め打ちメッセージ追加と変数名を変えたくらいで基本は参考元とほぼ同じ。タイムスタンプ変換まで書いてもらって非常にありがたい。\n 最終的に、送信されたメールはこんな感じ。\n 参考サイトさんのおかげですんなりできて助かった。（2度目）ちなみに、当初自力で応用しようとしてハマってた。Logs(サブスクリプションフィルタ)からLambdaに渡されるデータ構造が不明だったからだ。しかし以下公式にちゃんとサンプルと説明があったということを、最後に知った。\nCloudWatch Logs サブスクリプションフィルターの使用\n 以下、データサンプルの抜粋\n{ \u0026#34;owner\u0026#34;: \u0026#34;111111111111\u0026#34;, \u0026#34;logGroup\u0026#34;: \u0026#34;CloudTrail\u0026#34;, \u0026#34;logStream\u0026#34;: \u0026#34;111111111111_CloudTrail_us-east-1\u0026#34;, \u0026#34;subscriptionFilters\u0026#34;: [ \u0026#34;Destination\u0026#34; ], \u0026#34;messageType\u0026#34;: \u0026#34;DATA_MESSAGE\u0026#34;, \u0026#34;logEvents\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;31953106606966983378809025079804211143289615424298221568\u0026#34;, \u0026#34;timestamp\u0026#34;: 1432826855000, \u0026#34;message\u0026#34;: \u0026#34;{\\\u0026#34;eventVersion\\\u0026#34;:\\\u0026#34;1.03\\\u0026#34;,\\\u0026#34;userIdentity\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;Root\\\u0026#34;}\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;31953106606966983378809025079804211143289615424298221569\u0026#34;, \u0026#34;timestamp\u0026#34;: 1432826855000, \u0026#34;message\u0026#34;: \u0026#34;{\\\u0026#34;eventVersion\\\u0026#34;:\\\u0026#34;1.03\\\u0026#34;,\\\u0026#34;userIdentity\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;Root\\\u0026#34;}\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;31953106606966983378809025079804211143289615424298221570\u0026#34;, \u0026#34;timestamp\u0026#34;: 1432826855000, \u0026#34;message\u0026#34;: \u0026#34;{\\\u0026#34;eventVersion\\\u0026#34;:\\\u0026#34;1.03\\\u0026#34;,\\\u0026#34;userIdentity\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;Root\\\u0026#34;}\u0026#34; } ] }  そして上記ページにたどり着いたのは以下記事のコメントによる。\ncloudwatchlogs -\u0026gt; lambda -\u0026gt; SNSを試してみた\n 先に記載したコードはこのコメントで言及されている「複数イベントへの対処」が行われているバージョンとなる。改めて、先駆者の方々のおかげで非常に助かった。（3度目）\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatchlogs-send-filter-mail-2/","summary":"表題の件、以下の過去記事に書いたが、この時点では送信される本文ががログメッセージだけとなっていて、通知メールとしては不十分なため本文もカスタマイズしてみた。\nCloudWatchLogsのログ監視 - サブスクリプションフィルタ + Lambdaでメール送信\n 各種設定は冒頭の過去記事と同様のため割愛するとして、コードは変更前・後両方載せておく。\n変更前：lambda_function.py(1)\nimport base64 import json import zlib import datetime import os import boto3 from botocore.exceptions import ClientError print(\u0026#39;Loading function\u0026#39;) def lambda_handler(event, context): data = zlib.decompress(base64.b64decode(event[\u0026#39;awslogs\u0026#39;][\u0026#39;data\u0026#39;]), 16+zlib.MAX_WBITS) data_json = json.loads(data) log_entire_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;], ensure_ascii=False)) log_entire_len = len(log_entire_json) print(log_entire_json) for i in range(log_entire_len): log_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;][i], ensure_ascii=False)) try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = log_json[\u0026#39;message\u0026#39;], Subject = os.","title":"CloudWatchLogsのログ監視 - サブスクリプションフィルタ + Lambdaでメール送信(2)"},{"content":"elaborate   複雑な、入り組んだ 精巧な、精密な 入念な、苦心の末の  他動詞としては「〜を詳しく調べる」\n Irvine Welshの\u0026quot;Trainspotting\u0026quot;読書中に登場した単語だと思うが、何ページかはもう覚えていない。\n  ","permalink":"https://ecnedaced-seirots.github.io/post/a/english-elaborate/","summary":"elaborate   複雑な、入り組んだ 精巧な、精密な 入念な、苦心の末の  他動詞としては「〜を詳しく調べる」\n Irvine Welshの\u0026quot;Trainspotting\u0026quot;読書中に登場した単語だと思うが、何ページかはもう覚えていない。\n  ","title":"英語メモ - elaborate"},{"content":"AWSで過去普通にやってた監視実装も、2,3年経つと（或いはそれより短い周期で）陳腐化する。以前は限られたサービスのリソース範囲でやれることをやっていればよかったが、今はSSM(Systems Manager)、Lambda、EventBridgeなどの「登場人物」が増えて、カスタマイズが可能になったからだ。やれることが増えた分、実装が複雑になる。その分チャレンジングな分野になって楽しめると言えないこともないが\u0026hellip;、時間が足りないんだ。頭痛ぇな、まったく。絡み合った糸をほぐすためにまとめてみる。\n監視の種別としては大枠としてノード監視、閾値監視、ログ監視、プロセス監視、イベント監視と想定する。それぞれの実装方式が若干異なってくるため整理したい。\n  監視方式大枠  ノード監視\nCloudWatchアラーム(ステータスチェック) ー＞ (EventBridgeルール) ー＞ Lambda ー＞ SNSトピック ー＞ メール送信  ※ハード障害等でインスタンスが落ちた時に発動される想定。手動で落とした時は発動しないので通知は来ない。\n閾値監視\nCloudWatchアラーム（閾値チェック） ー＞ (EventBridgeルール) ー＞ Lambda ー＞ SNSトピック ー＞ メール送信  ※EC2インスタンスのCPU使用率、ディスク使用率を想定。メモリ監視は別途カスタムメトリクスの実装がいる。\nログ監視\nCloudWatchLogsでログ出力（サブスクリプションフィルタキーワード検知）ー＞ Lambda ー＞ SNSトピック ー＞ メール送信  ※これだけEventBridgeを使用しない。\nプロセス監視\nEC2インスタンス上のプロセス数監視に相当する。検索すると「プロセス落ちていたらインスタンス再起動」アクションの事例が多いが、今回やりたいのはメール通知だけ。一応メモっておくけど。  CWエージェント + SSM + インスタンス停止、Lamabdaなし\nEC2上のプロセスを監視し自動復旧する\nCWエージェント + SSM + 自動再起動、Lamabdaなし\nAWSでプロセス監視を実装したい\nCWエージェント + Lamabda + SSM + 自動再起動\nEC2のプロセス監視と自動再起動\n procstat事例\n以下はSSMを使用せず、procstatプラグインを使用してプロセス監視する例。記事には監視設定以降の通知イベント事例はなし。\nCloudWatch Agent でProcstatプラグインの利用が可能になりました\nSSMを使わずCloudwatchでEC2上のプロセス監視をしてみる\n 以下は途中まで参照したところ（後半は有料サービスの案内）、アラームを作成するところまでわかりやすかった。であれば、閾値監視と同様にEBルールを挟んでLambdaをターゲットに指定 ー＞ SNSトピックに渡されてメール送信、でいけるはず。\nCloudWatchでプロセス監視する手順をLinuxとWindowsともに詳しく紹介\nイベント監視\nイベント発生 ー＞ (EventBridgeルール) ー＞ Lambda ー＞ SNSトピック ー＞ メール送信  ※1. 2. のアラームがイベントに置き換わるだけで、後続のフローは同様となる想定。\n  上記の中で、私的には4.のプロセス監視が一番面倒な気がする。プロセス監視の詳細は保留として、全体の登場人物を整理しておこう。\n 登場人物整理 整理したらこうなった。方式をどうするかによって変わる部分もあるが、今のところこの想定。すべての監視でLambdaを使うのは、メール件名や本文をカスタマイズしたいため。\n    ノード監視 閾値監視 ログ監視 プロセス監視 イベント監視     CloudWatchAlarm ● ● - ● -   CloudWatchLogs - - ● - -   SSM(Systems Manager) - - - ● -   EventBridge rule ● ● - ● ●   Lambda ● ● ● ● ●   SNS topic ● ● ● ● ●     次のステップとして、これらの各アイテムにおいて「共通化できるもの / 個別に作成するもの」に分類する必要がある。\n  その他メモ  メール件名のカスタマイズ\nメール件名のカスタマイズをLambdaの環境変数でやるかコード本体でやるか。\nイベントの中身を拾って詳細に設定するならLambdaコード内でやるしかないが、そんな体力はない。そもそもイベントの中身が元ネタによって異なるからメッセージ内容別に大幅な差分が発生するはず。やれなくもないがそんな体力は(ry)。となると、カッコ悪いかもしれないがほぼ決め打ちの値で環境変数にセット、でいく方がいい。   メッセージ本文のカスタマイズ\n① Lambdaコード内で実装\n② EventBridgeルールの入力トランスフォーマーで実装  ②を試したが期待値ならず。深追いしている時間はない。どっちにしろログ監視では本文をLambdaに渡しているからそっちに寄せる方がいい。ここでやってるマッピングがLambdaコードにも適用できるか検討しようと思ったが、スキーマレジストリとかよくわからん。\n aws configの通知をどうするか\nconfigのログはS3にしか飛ばせない。ログ監視ではなく、イベント監視でやる。検知を制御したい時はイベント検知無効化で対応とか。   Amazon CloudWatch Events を使用すると、AWS Config イベントのステータスで変更を検出し対応することができます。\n AWS Config でのログ記録とモニタリング\n Configの変更はCloudTrailにつながるから、下手すると監視が重複するかもしれない。が、考えてる時間が(ry) 以下はCloudTrailの設定で直接SNSを指定しているっぽいが、これもEventBridgeに渡す、に統一させた方がよさげ。\n CloudTrail が、新しいログファイルを Amazon S3 バケットに発行するときに通知を受け取ることができます。\n CloudTrail の Amazon SNS 通知の設定\n 以下は通知事例の記載はないが一応メモ\nAWSリソースの設定変更履歴を管理する「AWS Config」とは？実際に使用してみた\n  果てしない旅路。\n （追記）\nSSM(Systems Manager)は使わずにprocstatプラグインだけでもなんとかなりそう。SSMを使えばもっと楽になるらしいが、よくわかっていない。ちゃんと調べればいいんだが、時間がないんだ\u0026hellip;\n","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatch-monitoring-idea/","summary":"AWSで過去普通にやってた監視実装も、2,3年経つと（或いはそれより短い周期で）陳腐化する。以前は限られたサービスのリソース範囲でやれることをやっていればよかったが、今はSSM(Systems Manager)、Lambda、EventBridgeなどの「登場人物」が増えて、カスタマイズが可能になったからだ。やれることが増えた分、実装が複雑になる。その分チャレンジングな分野になって楽しめると言えないこともないが\u0026hellip;、時間が足りないんだ。頭痛ぇな、まったく。絡み合った糸をほぐすためにまとめてみる。\n監視の種別としては大枠としてノード監視、閾値監視、ログ監視、プロセス監視、イベント監視と想定する。それぞれの実装方式が若干異なってくるため整理したい。\n  監視方式大枠  ノード監視\nCloudWatchアラーム(ステータスチェック) ー＞ (EventBridgeルール) ー＞ Lambda ー＞ SNSトピック ー＞ メール送信  ※ハード障害等でインスタンスが落ちた時に発動される想定。手動で落とした時は発動しないので通知は来ない。\n閾値監視\nCloudWatchアラーム（閾値チェック） ー＞ (EventBridgeルール) ー＞ Lambda ー＞ SNSトピック ー＞ メール送信  ※EC2インスタンスのCPU使用率、ディスク使用率を想定。メモリ監視は別途カスタムメトリクスの実装がいる。\nログ監視\nCloudWatchLogsでログ出力（サブスクリプションフィルタキーワード検知）ー＞ Lambda ー＞ SNSトピック ー＞ メール送信  ※これだけEventBridgeを使用しない。\nプロセス監視\nEC2インスタンス上のプロセス数監視に相当する。検索すると「プロセス落ちていたらインスタンス再起動」アクションの事例が多いが、今回やりたいのはメール通知だけ。一応メモっておくけど。  CWエージェント + SSM + インスタンス停止、Lamabdaなし\nEC2上のプロセスを監視し自動復旧する\nCWエージェント + SSM + 自動再起動、Lamabdaなし\nAWSでプロセス監視を実装したい\nCWエージェント + Lamabda + SSM + 自動再起動\nEC2のプロセス監視と自動再起動\n procstat事例\n以下はSSMを使用せず、procstatプラグインを使用してプロセス監視する例。記事には監視設定以降の通知イベント事例はなし。\nCloudWatch Agent でProcstatプラグインの利用が可能になりました\nSSMを使わずCloudwatchでEC2上のプロセス監視をしてみる","title":"AWS監視の方式を整理したい"},{"content":"タウリンの効果。過去に見つけたネタをバラバラにメモっていたのをまとめておく。\n タウリンとは、一言で言うと。\nタウリンは分子量124の含硫アミノ酸。タンパク質の構成成分にはならないが、細胞内の遊離アミノ酸としてはグルタミンと並んでもっとも高濃度に存在し、かつグルタミンに類似する成分。またタウリンは脳内のアミノ酸の中では2番目に多く存在する。\nタウリンは疲れが溜まっていると多く消費される、年齢を重ねると減少、男性より女性が不足しがち、とも言われている。\nタウリンの効果としてはアセトアルデヒトの代謝促進による肝機能サポートがよく知られているが、記憶力や認知能力の改善、目の網膜の保護、便通の改善等、意外な効能もある様子。\nそんなタウリンの効果について、とりあえず箇条書きで。\n  神経伝達、海馬の増強や安定化をサポート。 記憶力に関与するグリア細胞の活性化を促進する。(注1) アルコールや有害物質から発生するアセトアルデヒトの代謝を促進する。 心筋を強くして疲労回復を促す。（ただし即効性はないらしい？） 心臓のポンプ作用を高めて筋肉により多くの血液を送り込み、持久力を高める。（ドイツの研究より） 細胞のミトコンドリアの数を増やす（ミトコンドリアのタンパク質合成に必須）(注2) 目の網膜や角膜を保護する。 腸管の抗炎症作用 血圧や血糖値のバランスをサポート。 肝臓・心臓の機能強化 胆汁を生成し、コレステロールや中性脂肪の代謝をコントロール インスリン分泌促進 便の水分を増やし、便秘を改善する。 ニューロンのカリウム除去をサポートし、ニューロンが過度に活発化することを防ぐ。 タウリンはレシチンと併用することで細胞の細胞膜を丈夫にし、細胞が正常な形状を保つようにサポートをする。 髪の毛の成長にも不可欠なタンパク質IGF-1(インスリン様成長因子)を増やす   (注1) 記憶を司ると言われる海馬にはグリア細胞が多く存在する。\nまた以下のように認知機能の改善を示す研究がある。\n 迷路試験（Y-maze test）と受動的回避試験（passive avoidance test）で、タウリンを摂取したマウスの認知機能が正常な状態に回復することが確認された。さらに、アルツハイマー病の症状である大脳皮質の炎症が抑えられたほか、脳の海馬から分泌されるアミロイドベータの量も減り、記憶力に深く関与するグリア細胞の活性化が促進されることが確認された。\n注目すべき特徴は、タウリンの脳機能改善効果がアルツハイマー病において選択的に表れるということだ。従来の治療薬物が正常のマウスでは脳機能の異常を来たしたのに対し、タウリンは正常のマウスで脳機能の異常を来たすことはなかった。タウリンの持つもう一つの特性は、タウリンが脳の血管壁を透過しやすいため、口から摂取しても脳にうまく吸収されることだ。別途の複雑な投与過程を経る必要がなく、飲料水などの食物からタウリンを摂っても効果が高い。\n タウリンがアルツハイマー病治療に有効だと判明\n(注2) 「ただしタウリンが細胞内のエネルギー生産組織であるミトコンドリアの数を増やすのは、タウリン サプリを継続的に数か月～半年ほど摂取した場合に限られます。」（参照リンクは消滅）\n タウリンを多く含む食材\n 貝・甲殻類（サザエ、牡蠣、帆立、蛤、あさり、しじみ、タコ、イカ、カニ等） ブリやカツオの血合い 鯵や鯖などの近海魚  タウリンを多く含む食材としてはタコ・イカのイメージが強かったのだが、ダントツで多いのは牡蠣だった。100g中1180mg。サザエの方が100g1500mgで含有量としては多いが、摂取量・摂取回数は一般的に考えて少ない。\n余談だが牡蠣は亜鉛も多く含んでいて、その亜鉛はグルタミン酸興奮毒性（神経細胞死の一因）から脳を守る機能を果たす。また、記憶を司る海馬には最高濃度の亜鉛が存在する。脳の海馬をサポートするタウリンと亜鉛を両方含む牡蠣は、最強ブレインフードだった！\nタウリンを多く含む食品一覧 ポイントは魚介類と血合肉\n タウリン摂取時の注意\n 食間・空腹時の摂取が有効。 アスピリンと併用しないこと。（薬理作用を増強させてしまうため余計な負担がかかる。バファリンは原材料としてアスピリンを含む）   \u0026hellip;と、万能選手的なタウリンではあるが、日本国内ではタウリン単体のサプリメントは販売されていない。このためタウリンのサプリはiHerbで時々購入しているが、在庫切れのことが多く割と入手困難ではある。日本の薬事法に規制があって、一回で購入可能な量・個数が制限されているから、まとめ買いもできないのだ。（おそらく鷲のマークの製薬会社の圧力）\niHerb独自ブランドのタウリンサプリが安価で嬉しいけど、数ヶ月前から在庫切れ状態が続いている。しょうがないから、今日別の高いやつをポチってしまった。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/healthcare-taurine/","summary":"タウリンの効果。過去に見つけたネタをバラバラにメモっていたのをまとめておく。\n タウリンとは、一言で言うと。\nタウリンは分子量124の含硫アミノ酸。タンパク質の構成成分にはならないが、細胞内の遊離アミノ酸としてはグルタミンと並んでもっとも高濃度に存在し、かつグルタミンに類似する成分。またタウリンは脳内のアミノ酸の中では2番目に多く存在する。\nタウリンは疲れが溜まっていると多く消費される、年齢を重ねると減少、男性より女性が不足しがち、とも言われている。\nタウリンの効果としてはアセトアルデヒトの代謝促進による肝機能サポートがよく知られているが、記憶力や認知能力の改善、目の網膜の保護、便通の改善等、意外な効能もある様子。\nそんなタウリンの効果について、とりあえず箇条書きで。\n  神経伝達、海馬の増強や安定化をサポート。 記憶力に関与するグリア細胞の活性化を促進する。(注1) アルコールや有害物質から発生するアセトアルデヒトの代謝を促進する。 心筋を強くして疲労回復を促す。（ただし即効性はないらしい？） 心臓のポンプ作用を高めて筋肉により多くの血液を送り込み、持久力を高める。（ドイツの研究より） 細胞のミトコンドリアの数を増やす（ミトコンドリアのタンパク質合成に必須）(注2) 目の網膜や角膜を保護する。 腸管の抗炎症作用 血圧や血糖値のバランスをサポート。 肝臓・心臓の機能強化 胆汁を生成し、コレステロールや中性脂肪の代謝をコントロール インスリン分泌促進 便の水分を増やし、便秘を改善する。 ニューロンのカリウム除去をサポートし、ニューロンが過度に活発化することを防ぐ。 タウリンはレシチンと併用することで細胞の細胞膜を丈夫にし、細胞が正常な形状を保つようにサポートをする。 髪の毛の成長にも不可欠なタンパク質IGF-1(インスリン様成長因子)を増やす   (注1) 記憶を司ると言われる海馬にはグリア細胞が多く存在する。\nまた以下のように認知機能の改善を示す研究がある。\n 迷路試験（Y-maze test）と受動的回避試験（passive avoidance test）で、タウリンを摂取したマウスの認知機能が正常な状態に回復することが確認された。さらに、アルツハイマー病の症状である大脳皮質の炎症が抑えられたほか、脳の海馬から分泌されるアミロイドベータの量も減り、記憶力に深く関与するグリア細胞の活性化が促進されることが確認された。\n注目すべき特徴は、タウリンの脳機能改善効果がアルツハイマー病において選択的に表れるということだ。従来の治療薬物が正常のマウスでは脳機能の異常を来たしたのに対し、タウリンは正常のマウスで脳機能の異常を来たすことはなかった。タウリンの持つもう一つの特性は、タウリンが脳の血管壁を透過しやすいため、口から摂取しても脳にうまく吸収されることだ。別途の複雑な投与過程を経る必要がなく、飲料水などの食物からタウリンを摂っても効果が高い。\n タウリンがアルツハイマー病治療に有効だと判明\n(注2) 「ただしタウリンが細胞内のエネルギー生産組織であるミトコンドリアの数を増やすのは、タウリン サプリを継続的に数か月～半年ほど摂取した場合に限られます。」（参照リンクは消滅）\n タウリンを多く含む食材\n 貝・甲殻類（サザエ、牡蠣、帆立、蛤、あさり、しじみ、タコ、イカ、カニ等） ブリやカツオの血合い 鯵や鯖などの近海魚  タウリンを多く含む食材としてはタコ・イカのイメージが強かったのだが、ダントツで多いのは牡蠣だった。100g中1180mg。サザエの方が100g1500mgで含有量としては多いが、摂取量・摂取回数は一般的に考えて少ない。\n余談だが牡蠣は亜鉛も多く含んでいて、その亜鉛はグルタミン酸興奮毒性（神経細胞死の一因）から脳を守る機能を果たす。また、記憶を司る海馬には最高濃度の亜鉛が存在する。脳の海馬をサポートするタウリンと亜鉛を両方含む牡蠣は、最強ブレインフードだった！\nタウリンを多く含む食品一覧 ポイントは魚介類と血合肉\n タウリン摂取時の注意\n 食間・空腹時の摂取が有効。 アスピリンと併用しないこと。（薬理作用を増強させてしまうため余計な負担がかかる。バファリンは原材料としてアスピリンを含む）   \u0026hellip;と、万能選手的なタウリンではあるが、日本国内ではタウリン単体のサプリメントは販売されていない。このためタウリンのサプリはiHerbで時々購入しているが、在庫切れのことが多く割と入手困難ではある。日本の薬事法に規制があって、一回で購入可能な量・個数が制限されているから、まとめ買いもできないのだ。（おそらく鷲のマークの製薬会社の圧力）\niHerb独自ブランドのタウリンサプリが安価で嬉しいけど、数ヶ月前から在庫切れ状態が続いている。しょうがないから、今日別の高いやつをポチってしまった。","title":"タウリン(taurine)の効能いろいろ"},{"content":"CloudWatchアラーム + SNSトピックでメール飛ばす時の件名を変更したい。ということで、過去記事 AWS EventBridge + SNSからのメール件名をカスタマイズする でイベントからのメール通知でやったことを、アラームに変えてやってみた。アラームのトリガーはEC2インスタンスCPU使用率閾値超えとする。\n ベースの参照は以下クラメソさんネタ。ただしこちらは本文のカスタマイズであり、件名は変えていない。またLambdaも使用していない。これに先の過去記事パターンを合体させてやってみた。\nCloudWatch アラームの通知メールを少しでも読みやすくしたい\n 処理概要  CloudWatchアラームのステータスがALARMに変わる。 Lambda関数起動 SNSに連携される メール通知   作業概要  SNSトピック作成〜サブスクライブ CloudWatchアラーム作成 Lambda関数作成（Lambda用IAMロールは既存流用） EventBridgeルール作成 EventBridgeルールのターゲットに3.のLambda関数を設定する 対象EC2インスタンスのCPU負荷を上げてアラームステータスにする メール通知確認   検証に使用したアイテム    アイテム 名称     SNSトピック alarm-notification-topic   CloudWatchアラーム CPU_Utilization_Test   Lambda関数 cw-alarm-sns-function   EventBridgeルール cw-alarm-rule    やったこと SNSトピック作成、Lambda関数作成は冒頭のリンク過去記事でもやったので省略。Lambda関数の環境変数でSNSトピック、メール件名を指定している。一応後半にスクショあり。\nCLIよりCloudWatchアラーム作成。少ない負荷でもアラームステータスになるように閾値は10%にしてある。\n$ aws cloudwatch put-metric-alarm --alarm-name \u0026quot;CPU_Utilization_Test\u0026quot; \\ --metric-name \u0026quot;CPUUtilization\u0026quot; \\ --namespace \u0026quot;AWS/EC2\u0026quot; \\ --statistic \u0026quot;Maximum\u0026quot; \\ --period 60 \\ --evaluation-periods 1 \\ --datapoints-to-alarm 1 \\ --threshold 10 \\ --comparison-operator \u0026quot;GreaterThanThreshold\u0026quot; \\ --dimensions \u0026quot;Name=InstanceId,Value=i-0xxxxxxxxxxx9\u0026quot;  EventBridgeルールの作成。以下の場合、\u0026ldquo;CPU_Utilization_\u0026ldquo;を含むアラームと関連付けられる\n$ AWSREGION=ap-northeast-1 $ AWSACCOUNT=my-account-id $ aws events put-rule --name \u0026quot;cw-alarm-rule\u0026quot; \\ --event-pattern \u0026quot;{\\\u0026quot;source\\\u0026quot;: [\\\u0026quot;aws.cloudwatch\\\u0026quot;],\\\u0026quot;detail-type\\\u0026quot;: [\\\u0026quot;CloudWatch Alarm State Change\\\u0026quot;],\\\u0026quot;resources\\\u0026quot;: [{\\\u0026quot;prefix\\\u0026quot;: \\\u0026quot;arn:aws:cloudwatch:${AWSREGION}:${AWSACCOUNT}:alarm:CPU_Utilization_\\\u0026quot;}],\\\u0026quot;detail\\\u0026quot;: {\\\u0026quot;state\\\u0026quot;: {\\\u0026quot;value\\\u0026quot;: [\\\u0026quot;ALARM\\\u0026quot;]}}}\u0026quot;  以下の様にルールが作成された。\n { \u0026quot;source\u0026quot;: [\u0026quot;aws.cloudwatch\u0026quot;], \u0026quot;detail-type\u0026quot;: [\u0026quot;CloudWatch Alarm State Change\u0026quot;], \u0026quot;resources\u0026quot;: [{ \u0026quot;prefix\u0026quot;: \u0026quot;arn:aws:cloudwatch:ap-northeast-1:0123456789102:alarm:CPU_Utilization_\u0026quot; }], \u0026quot;detail\u0026quot;: { \u0026quot;state\u0026quot;: { \u0026quot;value\u0026quot;: [\u0026quot;ALARM\u0026quot;] } } }  しかしこの段階ではまだターゲットが存在しない。前回はコマンドでターゲット指定したが、今回はマネコンからやった。対象のルールを選択して「Edit」ー＞ 「Select targets」で作成済みのLambda関数を指定して、「Update」\n すると、以下の様にLambda側のトリガーとして、セットしたルールが設定される。\n ここまでやったら、以下の流れでメール通知される、はず。\n① EC2インスタンスのCPU使用率を上げてアラーム発行させる ② EventBridgeルールでターゲットに指定したLambdaに渡される ③ Lambdaで設定したSNSに渡される\nちなみにCPU使用率UP時はこんなのをshellにしてバックグラウンドで複数実行させた。アラームの設定で閾値10%にしたが、これをt3.microマシン上で3回くらい同時に回せば軽く90%くらいになる。\nCNT=0; while [ $CNT -lt 100000 ]; do CNT=$(( CNT + 1 ));done\n 少し経つとアラームのステータスが変わって、カスタム件名のメールが届いた！しかし本文がひどい\u0026hellip;\n サンプルコードではMessage=json.dumps(event) としているから、JSONデータをそのまま吐き出しているだけ。本文をカスタマイズする場合はこのeventをいじる必要がある。冒頭のクラメソさんの事例もはっきりいって面倒くさそうだったが、コードでやるのも面倒だなぁ、何せサンデープログラマだから。\neventに相当するJSONデータ\n{\u0026#34;version\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;86fa8a3f-7470-8c16-ef56-aaba9821771e\u0026#34;, \u0026#34;detail-type\u0026#34;: \u0026#34;CloudWatch Alarm State Change\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;aws.cloudwatch\u0026#34;, \u0026#34;account\u0026#34;: \u0026#34;123456789101\u0026#34;, \u0026#34;time\u0026#34;: \u0026#34;2021-11-03T10:17:51Z\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-northeast-1\u0026#34;, \u0026#34;resources\u0026#34;: [\u0026#34;arn:aws:cloudwatch:ap-northeast-1:123456789101:alarm:CPU_Utilization_Test\u0026#34;], \u0026#34;detail\u0026#34;: {\u0026#34;alarmName\u0026#34;: \u0026#34;CPU_Utilization_Test\u0026#34;, \u0026#34;state\u0026#34;: {\u0026#34;value\u0026#34;: \u0026#34;ALARM\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;Threshold Crossed: 1 out of the last 1 datapoints [100.0 (03/11/21 10:11:00)] was greater than the threshold (10.0) (minimum 1 datapoint for OK -\u0026gt; ALARM transition).\u0026#34;, \u0026#34;reasonData\u0026#34;: \u0026#34;{\\\u0026#34;version\\\u0026#34;:\\\u0026#34;1.0\\\u0026#34;,\\\u0026#34;queryDate\\\u0026#34;:\\\u0026#34;2021-11-03T10:17:51.018+0000\\\u0026#34;,\\\u0026#34;startDate\\\u0026#34;:\\\u0026#34;2021-11-03T10:11:00.000+0000\\\u0026#34;,\\\u0026#34;statistic\\\u0026#34;:\\\u0026#34;Maximum\\\u0026#34;,\\\u0026#34;period\\\u0026#34;:60,\\\u0026#34;recentDatapoints\\\u0026#34;:[100.0],\\\u0026#34;threshold\\\u0026#34;:10.0,\\\u0026#34;evaluatedDatapoints\\\u0026#34;:[{\\\u0026#34;timestamp\\\u0026#34;:\\\u0026#34;2021-11-03T10:11:00.000+0000\\\u0026#34;,\\\u0026#34;sampleCount\\\u0026#34;:5.0,\\\u0026#34;value\\\u0026#34;:100.0}]}\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2021-11-03T10:17:51.020+0000\u0026#34;}, \u0026#34;previousState\u0026#34;: {\u0026#34;value\u0026#34;: \u0026#34;INSUFFICIENT_DATA\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;Insufficient Data: 1 datapoint was unknown.\u0026#34;, \u0026#34;reasonData\u0026#34;: \u0026#34;{\\\u0026#34;version\\\u0026#34;:\\\u0026#34;1.0\\\u0026#34;,\\\u0026#34;queryDate\\\u0026#34;:\\\u0026#34;2021-11-03T10:13:51.019+0000\\\u0026#34;,\\\u0026#34;statistic\\\u0026#34;:\\\u0026#34;Maximum\\\u0026#34;,\\\u0026#34;period\\\u0026#34;:60,\\\u0026#34;recentDatapoints\\\u0026#34;:[],\\\u0026#34;threshold\\\u0026#34;:10.0,\\\u0026#34;evaluatedDatapoints\\\u0026#34;:[{\\\u0026#34;timestamp\\\u0026#34;:\\\u0026#34;2021-11-03T10:13:00.000+0000\\\u0026#34;}]}\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2021-11-03T10:13:51.023+0000\u0026#34;}, \u0026#34;configuration\u0026#34;: {\u0026#34;metrics\u0026#34;: [{\u0026#34;id\u0026#34;: \u0026#34;4cbe7286-d70f-fcb9-4a0a-758612d568db\u0026#34;, \u0026#34;metricStat\u0026#34;: {\u0026#34;metric\u0026#34;: {\u0026#34;namespace\u0026#34;: \u0026#34;AWS/EC2\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;CPUUtilization\u0026#34;, \u0026#34;dimensions\u0026#34;: {\u0026#34;InstanceId\u0026#34;: \u0026#34;i-0b22a89b0bb3faf49\u0026#34;}}, \u0026#34;period\u0026#34;: 60, \u0026#34;stat\u0026#34;: \u0026#34;Maximum\u0026#34;}, \u0026#34;returnData\u0026#34;: true}]}}}  と、ここで別途最近実施した、特別カスタマイズをしないアラーム + SNS送信検証時のメールを見たら、英語のみとはいえこっちの方がまだ全然見やすい。そりゃわかりにくいけど、JSON生データよりマシ。もう本文はこれでいいんじゃね？という気もするんだが。件名も、アラーム名が件名に入るんだから識別・フィルタしやすいアラーム名にすればどうにかなりそうな気もする。\u0026hellip;と、減速気味になってきた。\n \u0026hellip;が！以下の補足事項を思い出した。アラーム単体では無効化・有効化の制御ができない。となると、やはりEventBridgに組み込む方がいいんだよな。うーむ\u0026hellip;。頭痛いから明日考えよう。明後日かもしれない。\n 補足 アラームを一時無効化したい場合は、Rule側で制御する。マネコンで対象のルールを選択して、「Distable/無効にする」ボタンを押下。（アラーム単体ではこの機能がない）\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatch-alarm-lambda/","summary":"CloudWatchアラーム + SNSトピックでメール飛ばす時の件名を変更したい。ということで、過去記事 AWS EventBridge + SNSからのメール件名をカスタマイズする でイベントからのメール通知でやったことを、アラームに変えてやってみた。アラームのトリガーはEC2インスタンスCPU使用率閾値超えとする。\n ベースの参照は以下クラメソさんネタ。ただしこちらは本文のカスタマイズであり、件名は変えていない。またLambdaも使用していない。これに先の過去記事パターンを合体させてやってみた。\nCloudWatch アラームの通知メールを少しでも読みやすくしたい\n 処理概要  CloudWatchアラームのステータスがALARMに変わる。 Lambda関数起動 SNSに連携される メール通知   作業概要  SNSトピック作成〜サブスクライブ CloudWatchアラーム作成 Lambda関数作成（Lambda用IAMロールは既存流用） EventBridgeルール作成 EventBridgeルールのターゲットに3.のLambda関数を設定する 対象EC2インスタンスのCPU負荷を上げてアラームステータスにする メール通知確認   検証に使用したアイテム    アイテム 名称     SNSトピック alarm-notification-topic   CloudWatchアラーム CPU_Utilization_Test   Lambda関数 cw-alarm-sns-function   EventBridgeルール cw-alarm-rule    やったこと SNSトピック作成、Lambda関数作成は冒頭のリンク過去記事でもやったので省略。Lambda関数の環境変数でSNSトピック、メール件名を指定している。一応後半にスクショあり。\nCLIよりCloudWatchアラーム作成。少ない負荷でもアラームステータスになるように閾値は10%にしてある。\n$ aws cloudwatch put-metric-alarm --alarm-name \u0026quot;CPU_Utilization_Test\u0026quot; \\ --metric-name \u0026quot;CPUUtilization\u0026quot; \\ --namespace \u0026quot;AWS/EC2\u0026quot; \\ --statistic \u0026quot;Maximum\u0026quot; \\ --period 60 \\ --evaluation-periods 1 \\ --datapoints-to-alarm 1 \\ --threshold 10 \\ --comparison-operator \u0026quot;GreaterThanThreshold\u0026quot; \\ --dimensions \u0026quot;Name=InstanceId,Value=i-0xxxxxxxxxxx9\u0026quot;  EventBridgeルールの作成。以下の場合、\u0026ldquo;CPU_Utilization_\u0026ldquo;を含むアラームと関連付けられる","title":"CloudWatchアラーム + SNSからのメール件名をカスタマイズする"},{"content":"職場とか、いろんなチーム・グループの中で、「この人がいてくれると安心」「いてくれるだけでいい」と思える人が稀にいる。本当に、稀に、だが。そういう人と、その他の人々の違いは一体何なのか、とモヤっと不思議に思っていた。若干解明できそうなのが、以下の記事。ここに書かれている要因だけではないと思うが、理由の一部としては納得できる。\n「いるだけでチームの雰囲気をよくする人」の口癖4つ。“ど” から始まるあの言葉がかなり使える\n （以降軽くNSFW画像あり。閲覧注意）\n 記事では「いるだけでチームの雰囲気をよくする人」の4つの要素を述べている。\n 「ちょうどよかった」悪い状況にある時でもポジティブに捉える 「ありがとう」を言う時に別途感謝の言葉を添える どの、どのように、どちらか、等「ど」ではじまる質問で相手の話を引き出す 「教えてください」で相手へのリスペクトの気持ちを表す   上記のうち、1.と2.は他の自己啓発系コンテンツでもよく目にする話なので割愛する。まぁ「感謝の言葉を出し惜しみしない」、これは確かに大事だよ、俺も実践してる。相手によるけどね。\n3.は、俺はこれは実践する気ないけど、要するに聞き上手になって相手の気分をよくしてやれ、つうことだ。\n  ハーバード大学の研究論文（2012年）によると、自分の話をしているとき、おいしい食事をするときや収入を得るときと同じように脳の報酬系という部位が活性化したことが、 約300人の脳をfMRIでスキャンした結果からわかったのだそう。私たちが聞き上手な人に好感を抱くのは、「自分の話をするのが好き！」という人間の本能を満たしてくれるからなのかもしれません。\n  「上手に質問をすれば共感力が上がり、相手に好感を抱かせることができる」につながる、と。俺は「聞き上手ボランティア」をやる気はさらさらないが、興味深いのは先の引用にある「自分の話をするのが好き！という人間の本能」だ。よくいるよな、人の話は全然聞かないで、延々と自分のことを話したがるやつ。（ま、経験上女に多いという傾向は、ある）\n俺は今までそういうやつのことを、ただ自己愛が強くて、その自己愛を充足させるために他人に自分話を押売りして聞かせているもんだと思っていた。しかし上記引用で、「自分の話をしているときに脳の報酬系が活性化する」というのを読んで「そうか！」とひらめいた。脳の報酬系とはドーパミンのことである。ドーパミンは快楽を司る神経伝達物質だ。つまり自分のことを話すのは、人類共通の快感だったのだ！\nまぁ確かに、自分だってそういう面があるのは認めるよ。よく「話を聞いてもらってスッキリした」って言うもんな。何で話すだけでスッキリするのかって、ちゃんと理由があったんだな。しかしこれも度がすぎると聞かされる相手が迷惑だし、みっともないという自覚はある。自分のことを延々と話す人は、その制御が効かなくて、自らの快感原則に従って暴走しているんだろう。プラス自己愛もあるだろうけどね、どっちにしろこの手の人間とは遠い距離を置きたいものである。相手だけ満足して、自分はエネルギー吸い取られるだけだからな\u0026hellip;\n  話が大分脱線した、本来の主旨に戻る。うまい質問の仕方。「ど」で始まる疑問符がキーらしいが、具体的には記事の引用を俺なりにアレンジすると以下のようになる。（仕事関連の想定じゃないとピンと来ないもんで\u0026hellip;）\n   キーワード 質問例     What ー＞「どう、どんな」 どんな理由でこの仕事を始めたんですか？   Who ー＞「どの人、どんな人」 どんな人と仕事してみたいですか？   When ー＞「どんなとき、どのタイミング」 どんなときに達成感を感じますか？   Where ー＞「どこに、どこで」 どこでその分野を学んだのですか？   Why ー＞「どうして」 どうしてその製品に人気が集中するんでしょうね？   Which ー＞「どれ、どっち」 どちらのアイデアが気に入りましたか？   How ー＞「どうやって、どのように」 どのようにしてその課題を解決したんですか？     自己愛満々野郎の自分話を聞かされるのはゴメンだが、まともな相手とのコミュニケーション手法としては頭の片隅においておこう。\n   人はだれでも、自分に助言を求めてくる人の見識を高く評価する\n（We all admire the wisdom of people who come to us for advice.）\n ー 19世紀のイギリスの作家 アーサー・ヘルプスの言葉\n 最後の「教えてください」。これは相手を間接的に褒める手法だそうだ。ほぉぉ。\n  ブリガム・ヤング大学助教授で、組織の対人関係を研究するケイティ・リルエンクイスト氏らは、「助言を求められることは、基本的に嬉しいことだ」と言います。 なぜなら、助言を求める行為には、暗黙に「あなたの考えや価値観を支持している」というメッセージが含まれるから。 「教えてください」とアドバイスを求めることは、相手を立てることと同様の意味をもつのです。\n  これはわかる気がするな、同じ助言の依頼でも「教えてくれくれ」的に無作法または横暴に聞かれると不愉快でしかないが、リスペクトの気持ちを込めた依頼は、相手の気分をよくすることができる。\nそこには「あなたは私が知らない知見/情報を持っていると思う、あなたのその知恵を私に分けて貰えたら非常にうれしい」という、メタメッセージが込められているんだ。そういうメッセージを受け取って悪い気分になる人間は滅多にいない。\n  まぁ自分今もいろいろ思うことがあってこの記事を書いているわけだが\u0026hellip;.、まったく関係なく、ふと別の言葉を思い出した。\n村上龍の小説「5分後の世界」に登場するミズノ少尉は、「絶対に最悪の事態を想像するな」と言った。俺はミズノ少尉のような器ではない。けど、ミズノ少尉のような存在をリスペクトするし、こういう人物と一緒に仕事ができたら嬉しいし、（それこそ、いてくれるだけでいい）少なくとも自分もミズノ少尉に近づけるように努めたいとは思う。\n 何か主旨が散逸してしまい、「いてくれるだけでいい人」の理由は解明されていない気がする。まぁ理由は他にもいろいろあるよね、ということで。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/skill-in-communication/","summary":"職場とか、いろんなチーム・グループの中で、「この人がいてくれると安心」「いてくれるだけでいい」と思える人が稀にいる。本当に、稀に、だが。そういう人と、その他の人々の違いは一体何なのか、とモヤっと不思議に思っていた。若干解明できそうなのが、以下の記事。ここに書かれている要因だけではないと思うが、理由の一部としては納得できる。\n「いるだけでチームの雰囲気をよくする人」の口癖4つ。“ど” から始まるあの言葉がかなり使える\n （以降軽くNSFW画像あり。閲覧注意）\n 記事では「いるだけでチームの雰囲気をよくする人」の4つの要素を述べている。\n 「ちょうどよかった」悪い状況にある時でもポジティブに捉える 「ありがとう」を言う時に別途感謝の言葉を添える どの、どのように、どちらか、等「ど」ではじまる質問で相手の話を引き出す 「教えてください」で相手へのリスペクトの気持ちを表す   上記のうち、1.と2.は他の自己啓発系コンテンツでもよく目にする話なので割愛する。まぁ「感謝の言葉を出し惜しみしない」、これは確かに大事だよ、俺も実践してる。相手によるけどね。\n3.は、俺はこれは実践する気ないけど、要するに聞き上手になって相手の気分をよくしてやれ、つうことだ。\n  ハーバード大学の研究論文（2012年）によると、自分の話をしているとき、おいしい食事をするときや収入を得るときと同じように脳の報酬系という部位が活性化したことが、 約300人の脳をfMRIでスキャンした結果からわかったのだそう。私たちが聞き上手な人に好感を抱くのは、「自分の話をするのが好き！」という人間の本能を満たしてくれるからなのかもしれません。\n  「上手に質問をすれば共感力が上がり、相手に好感を抱かせることができる」につながる、と。俺は「聞き上手ボランティア」をやる気はさらさらないが、興味深いのは先の引用にある「自分の話をするのが好き！という人間の本能」だ。よくいるよな、人の話は全然聞かないで、延々と自分のことを話したがるやつ。（ま、経験上女に多いという傾向は、ある）\n俺は今までそういうやつのことを、ただ自己愛が強くて、その自己愛を充足させるために他人に自分話を押売りして聞かせているもんだと思っていた。しかし上記引用で、「自分の話をしているときに脳の報酬系が活性化する」というのを読んで「そうか！」とひらめいた。脳の報酬系とはドーパミンのことである。ドーパミンは快楽を司る神経伝達物質だ。つまり自分のことを話すのは、人類共通の快感だったのだ！\nまぁ確かに、自分だってそういう面があるのは認めるよ。よく「話を聞いてもらってスッキリした」って言うもんな。何で話すだけでスッキリするのかって、ちゃんと理由があったんだな。しかしこれも度がすぎると聞かされる相手が迷惑だし、みっともないという自覚はある。自分のことを延々と話す人は、その制御が効かなくて、自らの快感原則に従って暴走しているんだろう。プラス自己愛もあるだろうけどね、どっちにしろこの手の人間とは遠い距離を置きたいものである。相手だけ満足して、自分はエネルギー吸い取られるだけだからな\u0026hellip;\n  話が大分脱線した、本来の主旨に戻る。うまい質問の仕方。「ど」で始まる疑問符がキーらしいが、具体的には記事の引用を俺なりにアレンジすると以下のようになる。（仕事関連の想定じゃないとピンと来ないもんで\u0026hellip;）\n   キーワード 質問例     What ー＞「どう、どんな」 どんな理由でこの仕事を始めたんですか？   Who ー＞「どの人、どんな人」 どんな人と仕事してみたいですか？   When ー＞「どんなとき、どのタイミング」 どんなときに達成感を感じますか？   Where ー＞「どこに、どこで」 どこでその分野を学んだのですか？   Why ー＞「どうして」 どうしてその製品に人気が集中するんでしょうね？   Which ー＞「どれ、どっち」 どちらのアイデアが気に入りましたか？   How ー＞「どうやって、どのように」 どのようにしてその課題を解決したんですか？     自己愛満々野郎の自分話を聞かされるのはゴメンだが、まともな相手とのコミュニケーション手法としては頭の片隅においておこう。","title":"「いてくれるだけでいい人」の理由"},{"content":"AWSでのログ監視メール送信はサブスクリプションフィルタ + Lambda + SNSを使用するのがスタンダード。みんなやっていそうなことだが未経験だったのでやってみた。基本参考にしたのは王道クラメソさんの記事だったが、ちょっとわかりにくいところがあったので他の記事も合わせて参照して若干やり方変えつつ検証した。\n今回はマネコン作業メインでやったが、CLIやTerraformなどAPI経由で実装する場合追加作業が発生するため注意が必要。(後述 補足事項に記載)\n 参考\n CloudWatch Logs を文字列検知してログ内容をメールを送信してみた サブスクリプションフィルター版 【AWS】CloudWatch Logsからシステムログをメール通知する。 CloudWatch Logs のサブスクリプションフィルタを使って特定文字列を検知したログをEメール通知する ※CLI実装例   以下は今後の参考用\n CloudWatchLogsの内容をフィルタリングしてLambdaで通知させたい ※除外キーワードをコードで記述する例 CloudWatchLogsからLambda経由でログメッセージを通知する ※Terraform実装例   処理概要  CWLにログが出力される CWLのサブスクリプションフィルタでキーワード検知 Lambda関数起動 SNSに連携される メール通知   作業概要  SNSトピック作成〜サブスクライブ Lambda用IAMロール作成 Lambda関数作成 ロググループ/ログストリーム作成 ロググループにサブスクリプションフィルタ作成 （配信先に3.のLambda関数を指定） テストログ送信〜メール通知確認  ※ログストリーム作成は検証時のみ。通常は自動生成される。\n 今回の検証に使用したアイテム（個人メモ）    アイテム 名称     SNSトピック log-monitor-topic   Lambda用IAMロール send-log-filter-role   Lambda関数 send-log-filter-function   サブスクリプションフィルタ send-log-filter     やったこと  SNSトピック作成〜サブスクライブ\n過去記事:AWS EventBridge + SNSからのメール件名をカスタマイズするに書いたので省略。ここではCLIでやってるけどマネコンでも特にハマるところはない。アクセスポリシーはデフォルトにした。   Lambda用IAMロール作成\nとりあえず以下のマネージドポリシーをアタッチ。   CloudEatchLogsFullAccess AmazonSNSFullAccess   Lambda関数作成\n(1) 参考ブログのコード貼り付け  import base64 import json import zlib import datetime import os import boto3 from botocore.exceptions import ClientError print(\u0026#39;Loading function\u0026#39;) def lambda_handler(event, context): data = zlib.decompress(base64.b64decode(event[\u0026#39;awslogs\u0026#39;][\u0026#39;data\u0026#39;]), 16+zlib.MAX_WBITS) data_json = json.loads(data) log_entire_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;], ensure_ascii=False)) log_entire_len = len(log_entire_json) print(log_entire_json) for i in range(log_entire_len): log_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;][i], ensure_ascii=False)) try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = log_json[\u0026#39;message\u0026#39;], Subject = os.environ[\u0026#39;ALARM_SUBJECT\u0026#39;] ) except Exception as e: print(e)  (2) 環境変数をセット(Configration/設定タブ ー＞ 左ペインのEnvironment variables/環境変数)\n   Key Value     SNS_TOPIC_ARN arn:aws:sns:ap-northeast-1:my-account-id:log-monitor-topic   CUSTOM_SUBJECT エラーログ送信テスト    ロググループ/ログストリーム作成\nマネコンから普通にできるので省略。   サブスクリプションフィルタ作成\nロググループの画面から作成する。   配信先として先に作成したLambda関数を指定する。ログフォーマットは当初OtherにしたがJSONでいいらしい。（まだよくわかっていない\u0026hellip;）\n 事前にメッセージを投入しておけばここでテストできる。メッセージが何もない場合はスキップ。\n 最後に[Start streaming]押下で完了。\n 作成後のサブスクリプションフィルタ。作成後に変更したい場合はマネコンからはできないため、CLIから設定する。詳細は後述の補足事項に記載。\n テストログ送信〜メール通知確認\nこのテストログ送信方法については、クラメソさんや他の記事ではCLIからput-log-eventsを実行しているが、正直面倒くさい。マネコンからやる方が簡単なのでここではその手順を記載。  対象のログストリーム画面から、[Actions(アクション)] ー＞ [Create log event（ログイベントの作成）]と遷移し、テストイベントを発行する。\n メール通知を確認。届いた！\n \u0026hellip;と、ここまで普通にできたっぽく書いているが、実際には何かとハマって手こずってしまった。当初メールが届かなくてね。複数の記事を参考にしているが、それぞれ微妙に手順や実装が異なるから、少しどこかをいじるとNGになったりする。\nメールが届かないのはSNSが原因と思ったけど（Lambdaでエラー出ていないから）、Lambda自体のログにテストイベントのメッセージが何も出力されていないことに気づいて、Lambdaがイベントを取得できていなくてSNSにメッセージが渡っていないことが原因とわかった。コードも若干入れ替えたり編集したりしたんで。自分は紆余曲折しておかしなことになったが、最初はクラメソさんのコードをそのまま使って手順通りにやればできるはず。応用はその後。\n 補足事項  サブスクリプション作成後の変更\nサブスク作成後はマネコンからは直接変更できないが、CLIで編集可能。aws logs put-subscripution-filterで同じサブスク名を指定すれば設定が上書きされる。  $ aws logs put-subscription-filter ¥ --log-group-name [your log group name] ¥ --filter-name [your subscription filter name] ¥ --filter-pattern [your filter pattern] ¥ --destination-arn [your destination arn] ※今回の場合Lambda関数のARN  フィルタパターン編集\nフィルタパターンでOR条件するには、キーワード間はスペース区切りとし、各キーワードの先頭に?をつける。除外フィルタはまた別に必要で複雑になる。Lambda関数内で設定することも可能なので、要件に応じて検討。  フィルタパターンOR条件例\nこれを作成済みのサブスクに適用したい場合は、上記1.のCLIコマンドの--filter-patternオプションの値として指定すればよい。\n\u0026quot;?error ?Error ?ERROR ?fail ?Fail ?FAIL\u0026quot;  除外キーワードをセットするのはちょっと面倒で、こんな風になる。以下の場合、メッセージが\u0026quot;error event\u0026quot;の場合は検知され、\u0026ldquo;error test\u0026quot;の場合は検知されない。\n\u0026quot;[( msg=¥\u0026quot;*error*¥\u0026quot; || msg=¥\u0026quot;*Error*¥\u0026quot; ) \u0026amp;\u0026amp; ( msg!=¥\u0026quot;*test*¥\u0026quot; \u0026amp;\u0026amp; msg!=¥\u0026quot;*Test*¥\u0026quot; \u0026amp;\u0026amp; msg!=¥\u0026quot;*TEST*¥\u0026quot; )]\u0026quot;  Lambdaコード内で除外キーワード定義することも可能だが、検知キーワードと除外キーワードが別れるのもどうなんかと思うし、迷うところ。\n APIから実装する際の追加作業\nサブスクリプションフィルタ作成時、マネコンだと自動で付与される権限がCLIでは付与されないため、事前にLambda側で権限を追加する。--statement-idは適当な文字列でいいと思われる。多分。  $ aws lambda add-permission ¥ --function-name [your function name] ¥ --statement-id \u0026quot;your statement id\u0026quot; ¥ --principal \u0026quot;logs.ap-northeast-1.amazonaws.com\u0026quot; ¥ --action \u0026quot;lambda:InvokeFunction\u0026quot; ¥ --source-arn \u0026quot;arn:aws:logs:ap-northeast-1:[your account id]:log-group:*:*\u0026quot; ¥ --source-account [your account id]  TerraformやCFnから作成する場合も同じ作業が必要になるはずだから要注意。\n参考: add-permission\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatchlogs-send-filter-mail/","summary":"AWSでのログ監視メール送信はサブスクリプションフィルタ + Lambda + SNSを使用するのがスタンダード。みんなやっていそうなことだが未経験だったのでやってみた。基本参考にしたのは王道クラメソさんの記事だったが、ちょっとわかりにくいところがあったので他の記事も合わせて参照して若干やり方変えつつ検証した。\n今回はマネコン作業メインでやったが、CLIやTerraformなどAPI経由で実装する場合追加作業が発生するため注意が必要。(後述 補足事項に記載)\n 参考\n CloudWatch Logs を文字列検知してログ内容をメールを送信してみた サブスクリプションフィルター版 【AWS】CloudWatch Logsからシステムログをメール通知する。 CloudWatch Logs のサブスクリプションフィルタを使って特定文字列を検知したログをEメール通知する ※CLI実装例   以下は今後の参考用\n CloudWatchLogsの内容をフィルタリングしてLambdaで通知させたい ※除外キーワードをコードで記述する例 CloudWatchLogsからLambda経由でログメッセージを通知する ※Terraform実装例   処理概要  CWLにログが出力される CWLのサブスクリプションフィルタでキーワード検知 Lambda関数起動 SNSに連携される メール通知   作業概要  SNSトピック作成〜サブスクライブ Lambda用IAMロール作成 Lambda関数作成 ロググループ/ログストリーム作成 ロググループにサブスクリプションフィルタ作成 （配信先に3.のLambda関数を指定） テストログ送信〜メール通知確認  ※ログストリーム作成は検証時のみ。通常は自動生成される。\n 今回の検証に使用したアイテム（個人メモ）    アイテム 名称     SNSトピック log-monitor-topic   Lambda用IAMロール send-log-filter-role   Lambda関数 send-log-filter-function   サブスクリプションフィルタ send-log-filter     やったこと  SNSトピック作成〜サブスクライブ","title":"CloudWatchLogsのログ監視 - サブスクリプションフィルタ + Lambdaでメール送信"},{"content":"昨年の過去ツイのスレッドでちょっと気になるのを見つけたので、若干手を入れてここにまとめて書いておく。\n  暴力の加害者に対して被害者が好意を抱く「ストックホルム症候群」と567脳、マスク厨の心理は似てないか？側から見ると、あの人たちは自由や人権を奪われている今の状況を愛しているように見える。\nその裏では「認知的不協和の解消」が発生している可能性がある。これは、自分の内部の矛盾に一貫性を持たせようとする機能。「新しい生活様式」だの、自粛しろマスクつけろだの、不自由で不本意な状況を強いられているが、それを受け入れている自分に葛藤が生じているはずなのだ。\nだからマナーだの何だの言って正当化している。または無意識に自分を麻痺させている。どちらにしても認知に修正を加えて不協和（矛盾）を解消しようとしているわけで、つまり認知に歪みが発生している。だから苦痛さえ感じなくなっているのではないかと想像する。\nそれから、「沖縄から貧困がなくならない本当の理由」（樋口耕太郎著）からの引用なのだが、こういった自己防衛の心理も働いているかとも。\n 人間は激しい痛みを感じると、自分の感覚を鈍らせて自己防衛を図る性質があるが、それは絶望の耐え難い痛みを和らげるために、自分自身に打つ麻酔のようなものだ。\n  自分に麻酔を打って思考や身体感覚を麻痺させたり、自ら認知を歪ませれば、見かけ上は苦痛が和らぐ。しかし同時に生きる上でのあらゆる喜びもまた、感じることができなくなる。そして本来あるべき自分の自由と権利を、忘却の彼方に押しやっている。それは虚構の世界を生きているだけなのだ。\n  \u0026hellip;と、まぁ当時はこんなことを思いつくままに呟いてみたが、大半の世間のコロナ恐怖脳はここまで複雑な心理の綾などなく、自分で調べたり考察することもなくひたすら垂れ流される情報を鵜呑みにして怖いね怖いねと決まり文句を言ってるだけのように見える、それが世間の掟だから。\nもちろん、マスク・アルコール消毒・検温や在宅勤務を強制または半強制されることに疑問を抱くこともない。一切の疑問も抱かずに、受け入れているのだ。昼の外食時に周りから聞こえてくる会話を聞いていると呆れる、それなりに一流と呼ばれる企業に勤めていてある程度の地位についていそうな人たちが、そんな具合なのである。\nまぁ何にせよ、認知の歪みが生じていることは確か、40度近い真夏日に病気でもないのにマスクとか異常でしかないよ。\n それから「家庭内ストックホルム症候群」という言葉もある。児童虐待やDVを受けている被害者が、自分を虐待・無視などで苦しめる親や配偶者（多くの場合夫）に不満や憎しみを抱きつつも、見捨てられたらどうしようと、過剰な不安や恐怖心が芽生える。そこで無意識の内に親や配偶者が気に入られるように「良い子」「良い妻」を演じてしまう\u0026hellip;ということらしい。\nいやでもこれって別に、ストックホルム症候群という名称を持ち出すまでもなく、より普遍的な事象だと思うな、人間が暴力・抑圧・嫌がらせに対して自分の心を麻痺させて適応を試みる心理が働くのは、きっと人間のデフォルト機能なんだよ、悲しい機能だけど。\nDVの他に大学内の教授と生徒の間に発生する「アカハラ」、職場のパワハラでも同様の状態になるよね、理不尽なハラスメントを受けているのに、それを客観視できない状態にあると、相手に気に入られようとして相手に従い、相手の意に沿うように行動してしまうんだ。\nこれには2つの要因がある、生き延びるための生存本能と、他者に愛されたい、承認されたいという、ヒトとしての社会的本能。しかしそれで相手がハラスメントを辞めるかと言ったら逆だ、「こいつはいじめれば何でも言うことをきく」と思われてエスカレートするだけだ、全く本質的な解決にはならず、状況が悪化するだけなんだよ。\n  ここまでの文章は、今年2021年の1月に別のブログに投稿した内容を編集・加筆したものだ。そこに置いておいても塩漬けになるだけだからこっちに持ってきた。文章中に登場するツイは、とうにアカウント削除したので今は存在しない。「家庭内ストックホルム症候群」から先は今回追記したもの。主旨が途中からずれている気がするが、まぁ気にしない。\nTwitterなんか最低のクソメディアだと思うが、ふと思いついて書いたことでも後でこうして振り返って考察することもあるから、そういう意味では少しはやる価値あったかな。\n結局何が言いたいのかってね、多くの人間は、ハラスメントを受けている最中は、状況を客観視できないんだよ、かつ、生存本能と社会的本能のためにその状況に適応しようとして、自分を押し殺してハラスメントをする相手や周囲に従ったり、意に沿わない行動をとったりしがちなんだ。これは自覚しないといけないし、あらゆるハラスメントには声をあげ、全力で抵抗しなけりゃいけないんだ、それこそ、羊や奴隷ではなく、主権を持った人間として生きるために。\n  過去記事にも書いたDylan Thomasの詩の一部。本来の詩の主旨は違うけど、今のこの世界に対して、全く同じことを言いたいね。\n Do not go gentle into that good night,\nRage, rage against the dying of the light.\n  あぁまったく、俺はやっぱりこのまま死ぬわけにはいかねぇ、大人しく従ってちゃダメなんだ、激怒して、憤怒して、死にもの狂いで抵抗しなくちゃいけないんだ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/stockholm-syndrome/","summary":"昨年の過去ツイのスレッドでちょっと気になるのを見つけたので、若干手を入れてここにまとめて書いておく。\n  暴力の加害者に対して被害者が好意を抱く「ストックホルム症候群」と567脳、マスク厨の心理は似てないか？側から見ると、あの人たちは自由や人権を奪われている今の状況を愛しているように見える。\nその裏では「認知的不協和の解消」が発生している可能性がある。これは、自分の内部の矛盾に一貫性を持たせようとする機能。「新しい生活様式」だの、自粛しろマスクつけろだの、不自由で不本意な状況を強いられているが、それを受け入れている自分に葛藤が生じているはずなのだ。\nだからマナーだの何だの言って正当化している。または無意識に自分を麻痺させている。どちらにしても認知に修正を加えて不協和（矛盾）を解消しようとしているわけで、つまり認知に歪みが発生している。だから苦痛さえ感じなくなっているのではないかと想像する。\nそれから、「沖縄から貧困がなくならない本当の理由」（樋口耕太郎著）からの引用なのだが、こういった自己防衛の心理も働いているかとも。\n 人間は激しい痛みを感じると、自分の感覚を鈍らせて自己防衛を図る性質があるが、それは絶望の耐え難い痛みを和らげるために、自分自身に打つ麻酔のようなものだ。\n  自分に麻酔を打って思考や身体感覚を麻痺させたり、自ら認知を歪ませれば、見かけ上は苦痛が和らぐ。しかし同時に生きる上でのあらゆる喜びもまた、感じることができなくなる。そして本来あるべき自分の自由と権利を、忘却の彼方に押しやっている。それは虚構の世界を生きているだけなのだ。\n  \u0026hellip;と、まぁ当時はこんなことを思いつくままに呟いてみたが、大半の世間のコロナ恐怖脳はここまで複雑な心理の綾などなく、自分で調べたり考察することもなくひたすら垂れ流される情報を鵜呑みにして怖いね怖いねと決まり文句を言ってるだけのように見える、それが世間の掟だから。\nもちろん、マスク・アルコール消毒・検温や在宅勤務を強制または半強制されることに疑問を抱くこともない。一切の疑問も抱かずに、受け入れているのだ。昼の外食時に周りから聞こえてくる会話を聞いていると呆れる、それなりに一流と呼ばれる企業に勤めていてある程度の地位についていそうな人たちが、そんな具合なのである。\nまぁ何にせよ、認知の歪みが生じていることは確か、40度近い真夏日に病気でもないのにマスクとか異常でしかないよ。\n それから「家庭内ストックホルム症候群」という言葉もある。児童虐待やDVを受けている被害者が、自分を虐待・無視などで苦しめる親や配偶者（多くの場合夫）に不満や憎しみを抱きつつも、見捨てられたらどうしようと、過剰な不安や恐怖心が芽生える。そこで無意識の内に親や配偶者が気に入られるように「良い子」「良い妻」を演じてしまう\u0026hellip;ということらしい。\nいやでもこれって別に、ストックホルム症候群という名称を持ち出すまでもなく、より普遍的な事象だと思うな、人間が暴力・抑圧・嫌がらせに対して自分の心を麻痺させて適応を試みる心理が働くのは、きっと人間のデフォルト機能なんだよ、悲しい機能だけど。\nDVの他に大学内の教授と生徒の間に発生する「アカハラ」、職場のパワハラでも同様の状態になるよね、理不尽なハラスメントを受けているのに、それを客観視できない状態にあると、相手に気に入られようとして相手に従い、相手の意に沿うように行動してしまうんだ。\nこれには2つの要因がある、生き延びるための生存本能と、他者に愛されたい、承認されたいという、ヒトとしての社会的本能。しかしそれで相手がハラスメントを辞めるかと言ったら逆だ、「こいつはいじめれば何でも言うことをきく」と思われてエスカレートするだけだ、全く本質的な解決にはならず、状況が悪化するだけなんだよ。\n  ここまでの文章は、今年2021年の1月に別のブログに投稿した内容を編集・加筆したものだ。そこに置いておいても塩漬けになるだけだからこっちに持ってきた。文章中に登場するツイは、とうにアカウント削除したので今は存在しない。「家庭内ストックホルム症候群」から先は今回追記したもの。主旨が途中からずれている気がするが、まぁ気にしない。\nTwitterなんか最低のクソメディアだと思うが、ふと思いついて書いたことでも後でこうして振り返って考察することもあるから、そういう意味では少しはやる価値あったかな。\n結局何が言いたいのかってね、多くの人間は、ハラスメントを受けている最中は、状況を客観視できないんだよ、かつ、生存本能と社会的本能のためにその状況に適応しようとして、自分を押し殺してハラスメントをする相手や周囲に従ったり、意に沿わない行動をとったりしがちなんだ。これは自覚しないといけないし、あらゆるハラスメントには声をあげ、全力で抵抗しなけりゃいけないんだ、それこそ、羊や奴隷ではなく、主権を持った人間として生きるために。\n  過去記事にも書いたDylan Thomasの詩の一部。本来の詩の主旨は違うけど、今のこの世界に対して、全く同じことを言いたいね。\n Do not go gentle into that good night,\nRage, rage against the dying of the light.\n  あぁまったく、俺はやっぱりこのまま死ぬわけにはいかねぇ、大人しく従ってちゃダメなんだ、激怒して、憤怒して、死にもの狂いで抵抗しなくちゃいけないんだ。","title":"「ストックホルム症候群」の心理はヒトのデフォルト機能だった"},{"content":"Mac上のpython3。しばらく前にhomebrewと一緒に削除してしまったので入れ直した。\n$ brew install python3  $ which python3 /usr/local/bin/python3 $ python3 -V Python 3.9.7 $ pip3 -V pip 21.2.4 from /usr/local/lib/python3.9/site-packages/pip (python 3.9)  pythonだけで実行するとゴニョゴニョ言われる。\n$ python Your PYTHONPATH points to a site-packages dir for Python 3.x but you are running Python 2.x! PYTHONPATH is currently: \u0026quot;/usr/local/lib/python3.9/site-packages:\u0026quot; You should `unset PYTHONPATH` to fix this. $ unset PYTHONPATH  で、この後pythonを実行すると2系になってしまう。\n$ python WARNING: Python 2.7 is not recommended. This version is included in macOS for compatibility with legacy software. Future versions of macOS will not include Python 2.7. Instead, it is recommended that you transition to using 'python3' from within Terminal. Python 2.7.16 (default, Aug 30 2021, 14:43:11) [GCC Apple LLVM 12.0.5 (clang-1205.0.19.59.6) [+internal-os, ptrauth-isa=deploy on darwin Type \u0026quot;help\u0026quot;, \u0026quot;copyright\u0026quot;, \u0026quot;credits\u0026quot; or \u0026quot;license\u0026quot; for more information. \u0026gt;\u0026gt;\u0026gt;  python3を実行するにはpython3とタイプ。\n$ python3 Python 3.9.7 (default, Oct 13 2021, 06:45:31) [Clang 13.0.0 (clang-1300.0.29.3)] on darwin Type \u0026quot;help\u0026quot;, \u0026quot;copyright\u0026quot;, \u0026quot;credits\u0026quot; or \u0026quot;license\u0026quot; for more information. \u0026gt;\u0026gt;\u0026gt;  boto3が消えていたのでこれも再インストールした。\n$ pip3 install boto3 $ pip3 freeze boto3==1.18.63 botocore==1.21.63 Jinja2==2.11.2 jmespath==0.10.0 MarkupSafe==1.1.1 python-dateutil==2.8.2 PyYAML==5.3.1 s3transfer==0.5.0 six==1.16.0 urllib3==1.26.7  全く無関係に在りし日の記録。\n  はるばるアルゼンチンから、こんなに大勢の人が日本に来てくれたんだよ？嗚呼。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/mac-python3-re-install/","summary":"Mac上のpython3。しばらく前にhomebrewと一緒に削除してしまったので入れ直した。\n$ brew install python3  $ which python3 /usr/local/bin/python3 $ python3 -V Python 3.9.7 $ pip3 -V pip 21.2.4 from /usr/local/lib/python3.9/site-packages/pip (python 3.9)  pythonだけで実行するとゴニョゴニョ言われる。\n$ python Your PYTHONPATH points to a site-packages dir for Python 3.x but you are running Python 2.x! PYTHONPATH is currently: \u0026quot;/usr/local/lib/python3.9/site-packages:\u0026quot; You should `unset PYTHONPATH` to fix this. $ unset PYTHONPATH  で、この後pythonを実行すると2系になってしまう。\n$ python WARNING: Python 2.7 is not recommended. This version is included in macOS for compatibility with legacy software.","title":"MacにPython3を再インストール"},{"content":"あー、マジやべぇ、息が詰まりそうだ、いろいろと、勘弁してくれよもう的な動きが多くてさ、めっちゃやり辛い。まじで、10月入ってからすげえやり辛くなった。鬱屈がたまってどうしようもねぇ。\nしばらく前から通勤時に英文小説読む余力もないし、Tumblrやり過ぎるとDVT症候群で頭痛と目眩がするし、イヤホンで大音量で音楽聴きすぎて耳がイカレそうだし、もう何を支えにしていいかわからないな、オレは生き延びることができるんだろうか？\nそりゃ仕事があるだけありがたい立場だってことは忘れちゃいけないけどね、もし今「戦争」状態じゃなかったらいつでも出ていけるんだからな、なにせ俺様能力高いからな。\n うん、そのつもりでやっていくしかねぇ。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/life-1027/","summary":"あー、マジやべぇ、息が詰まりそうだ、いろいろと、勘弁してくれよもう的な動きが多くてさ、めっちゃやり辛い。まじで、10月入ってからすげえやり辛くなった。鬱屈がたまってどうしようもねぇ。\nしばらく前から通勤時に英文小説読む余力もないし、Tumblrやり過ぎるとDVT症候群で頭痛と目眩がするし、イヤホンで大音量で音楽聴きすぎて耳がイカレそうだし、もう何を支えにしていいかわからないな、オレは生き延びることができるんだろうか？\nそりゃ仕事があるだけありがたい立場だってことは忘れちゃいけないけどね、もし今「戦争」状態じゃなかったらいつでも出ていけるんだからな、なにせ俺様能力高いからな。\n うん、そのつもりでやっていくしかねぇ。\n ","title":"ひとり言 - 10月27日"},{"content":"10月25日の明け方に見た夢。コンサート会場みたいなところ。そこはロンドンである。観客が大勢いて賑わっている。そしてノーマスク。「あぁ、マスク圧解禁されたのか！」と嬉しい。よく見ると数人はマスクしている、でもほぼノーマスク。あぁ。\n もうずっとリアル世界で不快なものしか見てないから、せめてここだけでも。これくらいいいだろ\u0026hellip;.\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/life-1025/","summary":"10月25日の明け方に見た夢。コンサート会場みたいなところ。そこはロンドンである。観客が大勢いて賑わっている。そしてノーマスク。「あぁ、マスク圧解禁されたのか！」と嬉しい。よく見ると数人はマスクしている、でもほぼノーマスク。あぁ。\n もうずっとリアル世界で不快なものしか見てないから、せめてここだけでも。これくらいいいだろ\u0026hellip;.\n ","title":"Eye Candyがいるんだ"},{"content":"表題の件、通知メールの件名はわかりやすいのにしたいよねというニーズに対応すべく、以下参考に試してみた。やったことはほぼこちらの記事の通り。\nAmazon SNS で送られる CloudWatch Events ルールの通知内容をカスタマイズする\n 上記の通りやっていけばできるんだけれど、整理するためにも自分用に記録残す。ちなみに2021年10月現在、CloudWatch EventsはEventBridgeになっている。移行期間中だからまだ違和感があるが、この記事では名称は「EventBridge」とする。それと後半で書いているが、今回の事例ではCloudTrailが有効になっていることが前提なので、現状無効の場合は有効にしておく。\n各種リソースに類似の名称が多くて混乱するので、これも自分用に整理。以下、今回作成したリソース名称。\n   アイテム 名称     SNSトピック custom-event-notification   Lambda用IAMロール custom-event-mail-role   Lambda関数 custom-mail-function   evetnsルール custom-mail-rule     ではここから作業内容の記録に入る。\nSNSトピック作成\n$ aws sns create-topic --name custom-event-notification  サブスク（サブスクリプション）作成\n$ aws sns subscribe --topic-arn arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification --protocol email --notification-endpoint [my mail address] { \u0026quot;SubscriptionArn\u0026quot;: \u0026quot;pending confirmation\u0026quot; }  指定したアドレスにメールが届くので、リンク押下してconfirmする。その後マネコンのSNS画面を見るとサブスクのステータスがconfirmedになっているはず。\nまたは、以下確認コマンド\n$ aws sns list-subscriptions-by-topic --topic-arn arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification  ここからLambdaの作業に入る。最初にLambda用のIAMロールを作成。以下の内容で信頼ポリシー用のJSONファイルを用意し、それを指定してロール作成実行。\ntrust-policy.json\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;lambda.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] }  $ aws iam create-role --role-name custom-event-mail-role --assume-role-policy-document file://trust-policy.json  ロールにAWSマネージドポリシーをアタッチ。\n$ aws iam attach-role-policy --role-name custom-event-mail-role --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole $ aws iam attach-role-policy --role-name custom-event-mail-role --policy-arn arn:aws:iam::aws:policy/AmazonSNSFullAccess  ここまでで、IAMロール完成。次に、以下内容のLambda関数のコードを用意する。\ncustom-mail.py\nimport boto3 import json import os sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] custom_subject = os.environ[\u0026#39;CUSTOM_SUBJECT\u0026#39;] def lambda_handler(event, context): print(sns_arn) client = boto3.client(\u0026#34;sns\u0026#34;) resp = client.publish(TargetArn=sns_arn, Message=json.dumps(event), Subject=custom_subject)  これをzipにする。\n$ zip custom-mail.zip custom-mail.py  IAMロールとzipファイルを指定してLambda関数を作成。\n$ aws lambda create-function --function-name custom-mail-function --role arn:aws:iam::my-account-id:role/custom-event-mail-role --runtime python3.8 --handler custom-mail.lambda_handler --zip-file fileb://custom-mail.zip  環境変数をセット。ここでSNSトピックARNと、送信したいメール件名を定義している。\n$ aws lambda update-function-configuration --function-name custom-mail-function --environment Variables='{SNS_TOPIC_ARN=\u0026quot;arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification\u0026quot;,CUSTOM_SUBJECT=\u0026quot;カスタムメールタイトル送信テスト\u0026quot;}'     変数名 値     SNS_TOPIC_ARN arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification   CUSTOM_SUBJECT カスタムメールタイトル送信テスト     トリガーとなるイベントルールを作成。本当はec2のCPU使用率のアラームでメール飛ばしたいがここは参考ページの通りにする。\nevent-pattern.json\n{ \u0026#34;source\u0026#34;: [ \u0026#34;aws.s3\u0026#34; ], \u0026#34;detail-type\u0026#34;: [ \u0026#34;AWS API Call via CloudTrail\u0026#34; ], \u0026#34;detail\u0026#34;: { \u0026#34;eventSource\u0026#34;: [ \u0026#34;s3.amazonaws.com\u0026#34; ], \u0026#34;eventName\u0026#34;: [ \u0026#34;CreateBucket\u0026#34;, \u0026#34;DeleteBucket\u0026#34; ] } }  eventsのルールを作成する。\n$ aws events put-rule --name custom-mail-rule --event-pattern file://event-pattern.json { \u0026quot;RuleArn\u0026quot;: \u0026quot;arn:aws:events:ap-northeast-1:my-account-id:rule/custom-mail-rule\u0026quot; }  Lambdaにルールの実行権限を追加。\n$ aws lambda add-permission --function-name custom-mail-function --statement-id 1 --principal events.amazonaws.com --action 'lambda:InvokeFunction' --source-arn arn:aws:events:ap-northeast-1:my-account-id:rule/custom-mail-rule { \u0026quot;Statement\u0026quot;: \u0026quot;{\\\u0026quot;Sid\\\u0026quot;:\\\u0026quot;1\\\u0026quot;,\\\u0026quot;Effect\\\u0026quot;:\\\u0026quot;Allow\\\u0026quot;,\\\u0026quot;Principal\\\u0026quot;:{\\\u0026quot;Service\\\u0026quot;:\\\u0026quot;events.amazonaws.com\\\u0026quot;},\\\u0026quot;Action\\\u0026quot;:\\\u0026quot;lambda:InvokeFunction\\\u0026quot;,\\\u0026quot;Resource\\\u0026quot;:\\\u0026quot;arn:aws:lambda:ap-northeast-1:my-account-id:function:custom-mail-function\\\u0026quot;,\\\u0026quot;Condition\\\u0026quot;:{\\\u0026quot;ArnLike\\\u0026quot;:{\\\u0026quot;AWS:SourceArn\\\u0026quot;:\\\u0026quot;arn:aws:events:ap-northeast-1:my-account-id:rule/custom-mail-rule\\\u0026quot;}}}\u0026quot; }  Lambda関数をルールのターゲットとしてセットする。\n$ aws events put-targets --rule custom-mail-rule --targets \u0026quot;Id\u0026quot;=\u0026quot;Target1\u0026quot;,\u0026quot;Arn\u0026quot;=\u0026quot;arn:aws:lambda:ap-northeast-1:my-account-id:function:custom-mail-function\u0026quot; { \u0026quot;FailedEntryCount\u0026quot;: 0, \u0026quot;FailedEntries\u0026quot;: [] }  バケットを作成して通知テスト\n$ aws s3 mb s3://custom-mail-sending-test-xxxx  \u0026hellip;しかしメール届かない。て、CloudTrailが無効になっているんだから当然である。で、CloudTrailを有効にしてから先ほど作成したバケットを消してみる。したら、\u0026hellip;設定した件名「カスタムメールタイトル送信テスト」で通知メールが届いた！\nLambda関数の画面ではトリガーがEventBridgeになっているが、移行期間中はカッコでCloudWatche Eventsも併記されるっぽい。\n Events側でもルールとLambda関数が紐付いていることがわかる。ちなみにこれはCloudWatche Eventsの画面から見ているが、同じルールがEventBridgeの画面にも存在するはずである。\n メール本文。JSONの生データそのまんま。「人間」の感覚としてはこんなん送られてもなぁ\u0026hellip;としか思えないが、\u0026ldquo;DeleteBucket\u0026quot;の記録があることは一応わかる。\n CloudTrailはもういらんので削除。\u0026hellip;で、SNSからのメールは件名カスタマイズできるのはわかったが、アラームと組み合わせるとなるとまた別の調整が必要。その辺がわからん。次回の課題。\n（追記）以下、後日やってみた記録。\nCloudWatchアラーム + SNSからのメール件名をカスタマイズする \n 本文のカスタマイズ例。これはLambda使ってないけど、今回のコードをアレンジすればできるっぽいからそっちに寄せたい感じ。\nCloudWatch アラームの通知メールを少しでも読みやすくしたい\nEventBridgeって結局元CloudWatchEventsのことなんだが、まだよくわかっていないのでこの辺も調べておく。\nAmazon EventBridgeとは何か\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/aws-events-custom-mail/","summary":"表題の件、通知メールの件名はわかりやすいのにしたいよねというニーズに対応すべく、以下参考に試してみた。やったことはほぼこちらの記事の通り。\nAmazon SNS で送られる CloudWatch Events ルールの通知内容をカスタマイズする\n 上記の通りやっていけばできるんだけれど、整理するためにも自分用に記録残す。ちなみに2021年10月現在、CloudWatch EventsはEventBridgeになっている。移行期間中だからまだ違和感があるが、この記事では名称は「EventBridge」とする。それと後半で書いているが、今回の事例ではCloudTrailが有効になっていることが前提なので、現状無効の場合は有効にしておく。\n各種リソースに類似の名称が多くて混乱するので、これも自分用に整理。以下、今回作成したリソース名称。\n   アイテム 名称     SNSトピック custom-event-notification   Lambda用IAMロール custom-event-mail-role   Lambda関数 custom-mail-function   evetnsルール custom-mail-rule     ではここから作業内容の記録に入る。\nSNSトピック作成\n$ aws sns create-topic --name custom-event-notification  サブスク（サブスクリプション）作成\n$ aws sns subscribe --topic-arn arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification --protocol email --notification-endpoint [my mail address] { \u0026quot;SubscriptionArn\u0026quot;: \u0026quot;pending confirmation\u0026quot; }  指定したアドレスにメールが届くので、リンク押下してconfirmする。その後マネコンのSNS画面を見るとサブスクのステータスがconfirmedになっているはず。\nまたは、以下確認コマンド\n$ aws sns list-subscriptions-by-topic --topic-arn arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification  ここからLambdaの作業に入る。最初にLambda用のIAMロールを作成。以下の内容で信頼ポリシー用のJSONファイルを用意し、それを指定してロール作成実行。","title":"AWS EventBridge + SNSからのメール件名をカスタマイズする"},{"content":"CloudWatchLogsからS3へログをエクスポートする。基本的に以下の通りにやればできるのだが、説明が冗長だったりわかりにくいところがあるので自分用に書いておく。IAMユーザ作成の手順とかいらん。親切のつもりだろうけど、無駄に記事が長くなって読む気が失せる\u0026hellip;\nコンソールを使用してログデータを Amazon S3 にエクスポートする\n 概要。ログストリームのエクスポートはログストリームの画面ではなく、ロググループの画面から行う。事前にログエクスポート専用S3バケットを用意し、ドキュメントの通りにバケットポリシーを設定しておく。適当なランダム値のプレフィクスを作成し、バケットポリシーに反映する。\n バケットポリシーサンプル\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::my-app-logs\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; } }, { \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34; , \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::my-app-logs/sjh6dert3a/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;s3:x-amz-acl\u0026#34;: \u0026#34;bucket-owner-full-control\u0026#34; } }, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; } } ] }  上記前提条件が整った上で、以下実行する。カッコ内は英語表記の場合。\n 対象のログストリーム画面上で、「アクション」(Actions)のプルダウンから、「データをAmazon S3に エクスポート」(Export data to Amazon S3)を選択。 次画面でバケット名、作成しておいたS3のプレフィクス名、ログストリーム、時間の範囲指定を行い、「エクスポート」実行   エクスポート先のS3では確かzip化された状態で格納されていたと思う。\nドキュメント中の表現一部「ランダムに生成されたプレフィクス」、これがわかりにくかった。ログエクスポート先のS3にランダム文字列のプレフィクスが存在するのが望ましいようだ。なぜ普通の文字列ではなくランダム値が望ましいのかはよくわからん。「生成されたランダム文字列」と書かれているもんだから、どこで生成してるんだ？と混乱した。これは自分で適当に決めた値でよい。\n 上記に書いた作業はもちろん必要に応じてアドホック的に行う対応であり、定常的対応であればLambdaなりshellなりでバッチ化するのが普通だろう。しかしね、たかがログエクスポートだろ？て舐めちゃいけないよ、作り込みがいけてないせいで、処理に24時間以上かかる例があったんだから。（もちろん作ったのはオレじゃない）\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/cwl-s3-export/","summary":"CloudWatchLogsからS3へログをエクスポートする。基本的に以下の通りにやればできるのだが、説明が冗長だったりわかりにくいところがあるので自分用に書いておく。IAMユーザ作成の手順とかいらん。親切のつもりだろうけど、無駄に記事が長くなって読む気が失せる\u0026hellip;\nコンソールを使用してログデータを Amazon S3 にエクスポートする\n 概要。ログストリームのエクスポートはログストリームの画面ではなく、ロググループの画面から行う。事前にログエクスポート専用S3バケットを用意し、ドキュメントの通りにバケットポリシーを設定しておく。適当なランダム値のプレフィクスを作成し、バケットポリシーに反映する。\n バケットポリシーサンプル\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::my-app-logs\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; } }, { \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34; , \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::my-app-logs/sjh6dert3a/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;s3:x-amz-acl\u0026#34;: \u0026#34;bucket-owner-full-control\u0026#34; } }, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; } } ] }  上記前提条件が整った上で、以下実行する。カッコ内は英語表記の場合。\n 対象のログストリーム画面上で、「アクション」(Actions)のプルダウンから、「データをAmazon S3に エクスポート」(Export data to Amazon S3)を選択。 次画面でバケット名、作成しておいたS3のプレフィクス名、ログストリーム、時間の範囲指定を行い、「エクスポート」実行   エクスポート先のS3では確かzip化された状態で格納されていたと思う。\nドキュメント中の表現一部「ランダムに生成されたプレフィクス」、これがわかりにくかった。ログエクスポート先のS3にランダム文字列のプレフィクスが存在するのが望ましいようだ。なぜ普通の文字列ではなくランダム値が望ましいのかはよくわからん。「生成されたランダム文字列」と書かれているもんだから、どこで生成してるんだ？と混乱した。これは自分で適当に決めた値でよい。\n 上記に書いた作業はもちろん必要に応じてアドホック的に行う対応であり、定常的対応であればLambdaなりshellなりでバッチ化するのが普通だろう。しかしね、たかがログエクスポートだろ？て舐めちゃいけないよ、作り込みがいけてないせいで、処理に24時間以上かかる例があったんだから。（もちろん作ったのはオレじゃない）\n ","title":"CloudWatchLogsからS3へログをエクスポートする"},{"content":"GitHub ActionsでCIか。このブログについては今の時点でも不自由していないから無理にやらなくてもいい気がする、けど調べておこう。\nHugo + GitHub Pages + GitHub Actions で独自ドメインのウェブサイトを構築する\n  今日はとうとう電車の中で堂々と中指を突き立てた俺様であったが、週末くらいは心穏やかに過ごそう、ふぅ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/github-actions/","summary":"GitHub ActionsでCIか。このブログについては今の時点でも不自由していないから無理にやらなくてもいい気がする、けど調べておこう。\nHugo + GitHub Pages + GitHub Actions で独自ドメインのウェブサイトを構築する\n  今日はとうとう電車の中で堂々と中指を突き立てた俺様であったが、週末くらいは心穏やかに過ごそう、ふぅ。","title":"Github Actionsメモ"},{"content":"そして俺は相変わらず中指を1000本くらい突き立てたい気分の日々が継続中なのだ。日々アドレナリンが過剰放出されてしまい、心身によろしくない。けど怒りをそのままぶちまけるのは芸がないし、自分にとってプラスにならないからね、俺はプラスになることだけやりたいわけ、だから少しでも勉強になることを書く。\n \u0026ldquo;middle finger\u0026quot;って言ったらあれです、特別な意味を持つ「中指」。\n以下はすべて同じ意味。\u0026ldquo;the finger\u0026quot;でも同じ意味になるとは知らなかった。\n middle finger second finger the finger   侮蔑や怒りを示すジェスチャーとなる「中指を立てる」行為は以下の表現。\n give the middle finger give the finger   以下も同じ意味。知らなかった。でもどれだけポピュラーなんだろう？\n flip the bird fly the bird    しばらく前までは心の中だけで中指を突き立てていたが、最近もう耐えられなくなって物理的にも公の場で中指を立てている俺様なのだった。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/the-finger/","summary":"そして俺は相変わらず中指を1000本くらい突き立てたい気分の日々が継続中なのだ。日々アドレナリンが過剰放出されてしまい、心身によろしくない。けど怒りをそのままぶちまけるのは芸がないし、自分にとってプラスにならないからね、俺はプラスになることだけやりたいわけ、だから少しでも勉強になることを書く。\n \u0026ldquo;middle finger\u0026quot;って言ったらあれです、特別な意味を持つ「中指」。\n以下はすべて同じ意味。\u0026ldquo;the finger\u0026quot;でも同じ意味になるとは知らなかった。\n middle finger second finger the finger   侮蔑や怒りを示すジェスチャーとなる「中指を立てる」行為は以下の表現。\n give the middle finger give the finger   以下も同じ意味。知らなかった。でもどれだけポピュラーなんだろう？\n flip the bird fly the bird    しばらく前までは心の中だけで中指を突き立てていたが、最近もう耐えられなくなって物理的にも公の場で中指を立てている俺様なのだった。","title":"middle finger周辺の表現など"},{"content":"\u0026ldquo;rage\u0026quot;という英単語がある。名詞としては「激情、激怒、憤怒」、自動詞として「怒る、暴れる」という意味だ。これを知ったきっかけは、Tumblrで見かけた以下の引用だった。\n Do not go gentle into that good night.\nRage, rage against the dying of the light.\n  パッと見てすぐに意味は理解できなかったが何か心を捉えられた感があった。\u0026ldquo;rage\u0026quot;という単語を初めて見たので調べたところ、意味は先述の通り。\nこれはウェールズの詩人ディラン・トーマス(Dylan Thomas) の詩の一部である。でもTumblrの投稿にはOscar Wildeって書いたあったような記憶がある。それで最近までずっとこの引用元をOscar Wildeだと思い込んでいたんだから。間違いだったんだなあれは。\nそれはさておき、今日この詩について少し文献を調べてみたら、この引用に対して今までの自分の解釈が若干ズレていたことがわかった。以下は引用元の詩全体である。\n  Do not go gentle into that good night,\nOld age should burn and rage at close of day;\nRage, rage against the dying of the light.\nThough wise men at their end know dark is right,\nBecause their words had forked no lightning they\nDo not go gentle into that good night.\nGood men, the last wave by, crying how bright\nTheir frail deeds might have danced in a green bay,\nRage, rage against the dying of the light.\nWild men who caught and sang the sun in flight,\nAnd learn, too late, they grieved it on its way,\nDo not go gentle into that good night.\nGrave men, near death, who see with blinding sight\nBlind eyes could blaze like meteors and be gay,\nRage, rage against the dying of the light.\nAnd you, my father, there on the sad height,\nCurse, bless me now with your fierce tears, I pray.\nDo not go gentle into that good night.\nRage, rage against the dying of the light.\n (Dylan Thomas, Do Not Go Gentle Into That Good Night)\n  この詩は、ディランが死に瀕した父親へ向けて書いた詩である。（\u0026hellip;というのはもちろん拾った情報）\n詩を理解するのは難しい、言葉としての意味を理解するのと文脈を理解すること、さらにその裏に表現された暗喩を理解するのは別のことだ。しかも母国語以外で。\n俺の英語力はお粗末なので、言葉の意味と文脈はどうにか掴めても、その奥の本質までは手が届きそうで届かない。しかしこの時点で今までの自分の解釈がズレていたことに気づいた。\n俺はTumblrでこの引用を初めて目にしたとき、「大人しくなんかなるなよ、消えゆく灯りに激怒しろ、憤怒しろ」と文字通りの意味に捉えていた、作家がオスカー・ワイルドと思っていたせいもあり、今そこでまだエネルギーを保持して生きている人間が自分または他人をさらに奮い立たせる意図の言葉と解釈した。それで、何か心が「ザワザワッ」としたのである。そしてrageという単語を覚えたのである。\n  話変わって数ヶ月後、村上龍の「ピアッシング」を英語翻訳版で読む機会があった。そしてそこでrageという単語に再会した。コールガールのChiakiが妄想に取り憑かれた男Kawashimaに客として出会い、ふとしたきっかけでrageな状態に至る。そのシーンで、先の引用を真っ先に思い出した。ピピピッときたよね。\nその後また別の英文小説を読んだら、そこでも単語rageが登場してピピピッときた。言葉というものは、こういうプロセスを経て自分の内部に取り込まれていくのである。だからそのプロセスは、人の数だけバリエーションが存在する。\nで、話は戻って俺の英語力ではこの詩の奥深い意味を捉えるのは無理めだったので日本語訳を探してみたところ、素晴らしい翻訳があった。全部載せるのはアレなので一部だけ引用させてもらうと。\n  あんな風に「おやすみ」なんて言ってさっさと諦めるなよ\nもう若くなくたって，一日が人生が終わりそうなら，烈火のごとく怒り狂って，ギャアギャアそこで喚くんだ；\n太陽の光が薄れて消えていっても，死にものぐるいで抵抗しなきゃ\n Do Not Go Gentle Into That Night ディラン・トーマス (Dylan Thomas) より\n 全文はリンク先で読んでもらうとして、訳者ご本人が認めているようにかなり意訳色が強い翻訳である。しかし素晴らしい、最高だ。気持ちがストレートに伝わってくる。そしてこのリンク記事が2020年の大晦日に投稿され、「暗いニュースばかりが目立ったこの一年ですが，最後をこの力強い詩で締めくくりたい」と記されていることにもグッときた。泣けてくるぜ\u0026hellip;\n他の訳も発見したが、同じ原文がこうも異なる訳になるのかと驚く。どれが正しいということではないのだが、自分はやはり上のが一番だな。\n Do Not Go Gentle Into That Night （正当古典派訳）\natheistの意味は? – Do not go gentle into that good night （中庸派的訳）\n  話はあちこちに逸脱したが、この記事ではrageという単語がどのような経緯で自分に取り込まれたのかを書きたかったのである。何故書きたかったのか？まぁこうやって頭を整理しつつ記事を書くのも、一種のアンガー・マネジメントなのかもしれない。\n中指1000本突き立てても気が済まないくらいrageな日々を送っているが、整理して調べていく過程で先ほどの素晴らしい翻訳に出会うことができた。これは幸運の極みだよ、力強く美しい言葉は、人間に偉大な力を与えてくれるんだから。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/dylan-thomas/","summary":"\u0026ldquo;rage\u0026quot;という英単語がある。名詞としては「激情、激怒、憤怒」、自動詞として「怒る、暴れる」という意味だ。これを知ったきっかけは、Tumblrで見かけた以下の引用だった。\n Do not go gentle into that good night.\nRage, rage against the dying of the light.\n  パッと見てすぐに意味は理解できなかったが何か心を捉えられた感があった。\u0026ldquo;rage\u0026quot;という単語を初めて見たので調べたところ、意味は先述の通り。\nこれはウェールズの詩人ディラン・トーマス(Dylan Thomas) の詩の一部である。でもTumblrの投稿にはOscar Wildeって書いたあったような記憶がある。それで最近までずっとこの引用元をOscar Wildeだと思い込んでいたんだから。間違いだったんだなあれは。\nそれはさておき、今日この詩について少し文献を調べてみたら、この引用に対して今までの自分の解釈が若干ズレていたことがわかった。以下は引用元の詩全体である。\n  Do not go gentle into that good night,\nOld age should burn and rage at close of day;\nRage, rage against the dying of the light.\nThough wise men at their end know dark is right,\nBecause their words had forked no lightning they","title":"単語rageを覚えたきっかけはディラン・トーマスの詩だった"},{"content":"Mac OSで標準搭載されているdateコマンドはBSD版であり、Linux標準のGNU版と微妙に異なる。Linuxと実行結果が異なったり、使用できないオプションがあったりとか。それが困るから、自宅のMacでもGNU版のdateが使いたいのである。数年前に標準のdateを入れたのだが、その後Mac本体を買い替えたタイミングで消えてしまった。\n Mac OSでgnu/dateを使いたい場合、brewから入れる。install dateではなく、coreutilsとする。（他のGNU系コマンド一式が含まれる）\n$ brew install coreutils  /usr/local/bin/gdateにインストールされた。（正確にはシンボリックリンク）\nこのままだとコマンドがgdateなので、gdateを\u0026quot;date\u0026quot;で実行できるようにする。以下エイリアスを.bashrcに追記。\nalias date='/usr/local/bin/gdate'  やっとできた。以下は所定の日付時刻をエポックタイム(UNIXタイムスタンプ)に変換するコマンド。Mac版のdateだと使えないんだよこれが。\n$ date -d '2018/5/17 00:00:00' +'%s' 1526482800  参考\nMacでdateコマンドが違う件について\nUNIX時間に変換・UNIX時間を取得する方法\n (RWC2019, Tokyo Stadium)\n","permalink":"https://ecnedaced-seirots.github.io/post/a/mac-installe-gdate/","summary":"Mac OSで標準搭載されているdateコマンドはBSD版であり、Linux標準のGNU版と微妙に異なる。Linuxと実行結果が異なったり、使用できないオプションがあったりとか。それが困るから、自宅のMacでもGNU版のdateが使いたいのである。数年前に標準のdateを入れたのだが、その後Mac本体を買い替えたタイミングで消えてしまった。\n Mac OSでgnu/dateを使いたい場合、brewから入れる。install dateではなく、coreutilsとする。（他のGNU系コマンド一式が含まれる）\n$ brew install coreutils  /usr/local/bin/gdateにインストールされた。（正確にはシンボリックリンク）\nこのままだとコマンドがgdateなので、gdateを\u0026quot;date\u0026quot;で実行できるようにする。以下エイリアスを.bashrcに追記。\nalias date='/usr/local/bin/gdate'  やっとできた。以下は所定の日付時刻をエポックタイム(UNIXタイムスタンプ)に変換するコマンド。Mac版のdateだと使えないんだよこれが。\n$ date -d '2018/5/17 00:00:00' +'%s' 1526482800  参考\nMacでdateコマンドが違う件について\nUNIX時間に変換・UNIX時間を取得する方法\n (RWC2019, Tokyo Stadium)","title":"MacにGNU版dateをインストール"},{"content":"AWS CLI v2でデフォルトになっているページャを無効化する方法は2種類ある。\n configで設定  ~/.aws/configに以下記載する。\n[default] cli_pager=  環境変数で設定  $ export AWS_PAGER=\u0026quot;\u0026quot;  1.の方が推奨されているようだが、k8s(Kubernetes)のPodの場合は、マニフェストのENVに2.の環境変数を書いておけば期待値になる。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/awscli-pager/","summary":"AWS CLI v2でデフォルトになっているページャを無効化する方法は2種類ある。\n configで設定  ~/.aws/configに以下記載する。\n[default] cli_pager=  環境変数で設定  $ export AWS_PAGER=\u0026quot;\u0026quot;  1.の方が推奨されているようだが、k8s(Kubernetes)のPodの場合は、マニフェストのENVに2.の環境変数を書いておけば期待値になる。\n ","title":"AWS CLIのページャを無効化する"},{"content":"AWSで、CloudWatchアラームのメッセージをSNSトピックかましてメール送信。昔からよくあるオーソドックスなパターンだが、しばらく縁がなかったので記憶がかすんでいる。過去に構築した時の記録を掘り返してみる。\n数年前、CloudFormation（CFn）で環境構築したのだが（主担当は別のメンバー）、CWアラーム作成はCFnで作るのに不向きということでAWS CLIで作成していた。何故CFnが不向きなのか、理由は何だったか思い出せない。以下の記事を見ると普通にCFnでアラーム作成しているから問題なさそうではあるのだが\u0026hellip;\nCloudFormationでCloudWatchAlermを作成する\n ここで、書いていてうっすら思い出した。過去事例ではオートスケールのアラームだったが、その場合は他のアラームと異なるのかもしれない。（つまりオートスケールのアラームはポリシーを別出しにする）確かASG（オートスケーリンググループ）自体もCFnで作るのは不向きということでCLIで作成してた。CFnだと勝手に変な名前付けられるから、って理由だったかな。しかしハッキリとは思い出せない。\nもやもや感が払拭しきれないが、とりあえず過去のメモ書きをのせておく。\n ここから。\nオートスケーリンググループのCloudWatchアラーム作成時のポイントは、先にSNSトピック、ポリシーを作成する。ポリシー作成のCLIを実行するとARNが出力されるので、その値を定義してアラームを作成する。SNSトピック自体はCFnで作成していた。サブスクリプション作成はコンソールからやったような。グダグダな記憶だが、メールアドレスをサブスクライブする時に手動での承認が発生するのは確か。（設定したメールアドレスに届いたメール内のリンクを押下すると承認が完了する）\nサブスクリプション承認は手動になるが、アラーム作成時に指定するのはトピックARN。承認しないと後続作業ができないわけではない、と思われる。（ただし承認対応は3日以内に実施すること）\n以下、ec2オートスケーリングのスケールアウト/インポリシー作成CLIの例。ec2のオートスケールってパターンもすでにオールドファッション化しているけど\u0026hellip;、数年前の事例なので。\nスケールアウトポリシー\n$ aws autoscaling put-scaling-policy \\ --auto-scaling-group-name test-web-asg \\ --policy-name test-web-scaleout-policy \\ --scaling-adjustment 2 \\ --adjustment-type ChangeInCapacity \\ --cooldown 300 \\ --region ap-northeast-1  スケールインポリシー\n$ aws autoscaling put-scaling-policy \\ --auto-scaling-group-name test-web-asg \\ --policy-name test-web-scalein-policy \\ --scaling-adjustment -2 \\ --adjustment-type ChangeInCapacity \\ --cooldown 600 \\ --region ap-northeast-1  この後、以下のCLIを実行。スケールアウトアラーム作成CLI例。--alarm-actions オプションで 先に作成しておいた$snstopic, $scaleoutpolicy の値を指定している。\nsnstopic=\u0026quot;arn:aws:sns:ap-northeast-1:[AWSアカウントID]:test-alert-mail\u0026quot; scaleoutpolicy=\u0026quot;arn:aws:autoscaling:ap-northeast-1:[AWSアカウントID]:scalingPolicy:[ランダム値]:autoScalingGroupName/test-web-asg:policyName/test-web-scaleout-policy\u0026quot; $ aws cloudwatch put-metric-alarm \\ --alarm-name \u0026quot;test-web-scaleout-alarm\u0026quot; \\ --alarm-description \u0026quot;Alarm when CPU exceeds 70%\u0026quot; \\ --metric-name CPUUtilization \\ --namespace AWS/EC2 \\ --statistic Average \\ --period 60 \\ --threshold 70 \\ --comparison-operator GreaterThanThreshold \\ --dimensions Name=AutoScalingGroupName,Value=\u0026quot;test-web-asg\u0026quot; \\ --evaluation-periods 4 \\ --alarm-actions $scaleoutpolicy $snstopic \\ --unit Percent \\ --region ap-northeast-1  スケールイン時のアラームも同様に作成する。\n 以下備忘録。静観対応をどうするか\nCloudWatch アラームのダウンタイム（特定期間の発報抑止）を Metric Math を使用して実現してみた\n","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatch-alarm-memo/","summary":"AWSで、CloudWatchアラームのメッセージをSNSトピックかましてメール送信。昔からよくあるオーソドックスなパターンだが、しばらく縁がなかったので記憶がかすんでいる。過去に構築した時の記録を掘り返してみる。\n数年前、CloudFormation（CFn）で環境構築したのだが（主担当は別のメンバー）、CWアラーム作成はCFnで作るのに不向きということでAWS CLIで作成していた。何故CFnが不向きなのか、理由は何だったか思い出せない。以下の記事を見ると普通にCFnでアラーム作成しているから問題なさそうではあるのだが\u0026hellip;\nCloudFormationでCloudWatchAlermを作成する\n ここで、書いていてうっすら思い出した。過去事例ではオートスケールのアラームだったが、その場合は他のアラームと異なるのかもしれない。（つまりオートスケールのアラームはポリシーを別出しにする）確かASG（オートスケーリンググループ）自体もCFnで作るのは不向きということでCLIで作成してた。CFnだと勝手に変な名前付けられるから、って理由だったかな。しかしハッキリとは思い出せない。\nもやもや感が払拭しきれないが、とりあえず過去のメモ書きをのせておく。\n ここから。\nオートスケーリンググループのCloudWatchアラーム作成時のポイントは、先にSNSトピック、ポリシーを作成する。ポリシー作成のCLIを実行するとARNが出力されるので、その値を定義してアラームを作成する。SNSトピック自体はCFnで作成していた。サブスクリプション作成はコンソールからやったような。グダグダな記憶だが、メールアドレスをサブスクライブする時に手動での承認が発生するのは確か。（設定したメールアドレスに届いたメール内のリンクを押下すると承認が完了する）\nサブスクリプション承認は手動になるが、アラーム作成時に指定するのはトピックARN。承認しないと後続作業ができないわけではない、と思われる。（ただし承認対応は3日以内に実施すること）\n以下、ec2オートスケーリングのスケールアウト/インポリシー作成CLIの例。ec2のオートスケールってパターンもすでにオールドファッション化しているけど\u0026hellip;、数年前の事例なので。\nスケールアウトポリシー\n$ aws autoscaling put-scaling-policy \\ --auto-scaling-group-name test-web-asg \\ --policy-name test-web-scaleout-policy \\ --scaling-adjustment 2 \\ --adjustment-type ChangeInCapacity \\ --cooldown 300 \\ --region ap-northeast-1  スケールインポリシー\n$ aws autoscaling put-scaling-policy \\ --auto-scaling-group-name test-web-asg \\ --policy-name test-web-scalein-policy \\ --scaling-adjustment -2 \\ --adjustment-type ChangeInCapacity \\ --cooldown 600 \\ --region ap-northeast-1  この後、以下のCLIを実行。スケールアウトアラーム作成CLI例。--alarm-actions オプションで 先に作成しておいた$snstopic, $scaleoutpolicy の値を指定している。\nsnstopic=\u0026quot;arn:aws:sns:ap-northeast-1:[AWSアカウントID]:test-alert-mail\u0026quot; scaleoutpolicy=\u0026quot;arn:aws:autoscaling:ap-northeast-1:[AWSアカウントID]:scalingPolicy:[ランダム値]:autoScalingGroupName/test-web-asg:policyName/test-web-scaleout-policy\u0026quot; $ aws cloudwatch put-metric-alarm \\ --alarm-name \u0026quot;test-web-scaleout-alarm\u0026quot; \\ --alarm-description \u0026quot;Alarm when CPU exceeds 70%\u0026quot; \\ --metric-name CPUUtilization \\ --namespace AWS/EC2 \\ --statistic Average \\ --period 60 \\ --threshold 70 \\ --comparison-operator GreaterThanThreshold \\ --dimensions Name=AutoScalingGroupName,Value=\u0026quot;test-web-asg\u0026quot; \\ --evaluation-periods 4 \\ --alarm-actions $scaleoutpolicy $snstopic \\ --unit Percent \\ --region ap-northeast-1  スケールイン時のアラームも同様に作成する。","title":"CloudWatchアラーム作成時のメモ（過去事例）"},{"content":"SNSって誰をフォローするかも大きいけど誰にフォローされるか、も相当影響でかいんだなと思う。\nもともとSNS嫌いだからほとんどやってないけど、Tumblrは例外で、ここしばらく依存症に近いくらい使っている。全然使っていなかった時期もあるんだけどね。今は諸事情によりヘビーユーザー。\n当初はフォロワー僅か、だったが逆に好き勝手なことが書けた。Tumblrってテキスト投稿には向いてないと思うけど、それすら気にせずに画像だろうが音声だろうがテキストだろうが、好きなように投稿する。それがTumblrの良さ。\n当初投稿するのは自分の写真が中心で、たまにテキストあり、リブログはあまりしていなかった。特にフォローしたいアカウントもなかったけどたまに癒し系とか懐かし系画像投稿したいから適当に複数アカウントフォローしてた。でも、楽しくはなかったんだよね。「たまにこっち系の画像ポストするのはいいけどそれメインでやりたいわけじゃないし、なんか違う気がするなぁ」と違和感を覚え始めて、フォロー解除した。\n  しかしその後、何がきっかけか覚えていないのだが、あるアカウントとその周辺アカウントをフォロー開始してから、めっちゃ楽しくなってしまった。それらのアカウントは毎日投稿しているけど、リブログせずにいられないような、何かしらカッコイイポストが必ずある。経由されたポストやソースをポストしたアカウントを追うとこれまたセンスが良くて、芋づる式に夢中でlike,reblogしてしまうのである。\nTumblrのすごいところは、オリジナルのポスト作成者じゃなくても、センスのいいポストで構成されたブログが甚大な価値を持つことだ。「あなたのセンスは素晴らしい、本当に尊敬する！」と叫びたくなるようなアカウントが複数存在する。まだ出会えていないブログもあるかもしれない。実際最近になっても、「こんなセンスいいブログがあったんだ！」と新たに発見することがある。（もちろんそんなときに直接メッセージを送ったりはしない。1%程度の例外はあるだろうが、Tumblrでは誰もそんなこと望んでいないのだから）\nいいポストを集めたブログは自然にいいブログになる。オリジナルの作者かどうか、の区別はもはや意味をなさなくなる。いいものを発見してコレクションする、そのエネルギーが、見る人にインスピレーションや刺激を与えるのだ。それがTumblrの良さ。（二度目）\nこのことに気づいてから、俺は夢中になってしまった。Tumblr自体はずっと前からやっているのに、こんなに楽しいと感じたのは初めてといってもいい。\n  以上は「誰をフォローするか」による影響の話。ここから先、「誰にフォローされるか」について書いてみる。\n少し前のある日、これまで細々とした件数だった、零細アカウントの俺の通知が飛躍的に伸びた。たまに特定のポストのリアクションが増加することはあったが、その日は過去にない規模の反響だった。「何かあったか？」と追ってみると、ある人気アカウントが自分のポストを複数リブログしてた。そこから雪だるま式にリアクションが増えたわけである。これにより、自分のブログのフォロワーも増加した。増加といってもその日に十人くらい、その後日に数人ずつ程度のペースだが。ちなみに先の人気アカウントにもフォローされていた。\nしかし、正直あまりうれしくないし、逆に困る。「ある誰かが自分の投稿を見ている」ことを意識していると、書きにくいことが出てくるのである。画像のポストだけでみても、フォロワーにインフルエンサーとそのフォロワーがいると「何を投稿するか」について、これまで以上に他人を意識せざるを得なくなってしまうのである。それまでは「とにかく自分がポストしたいものをポストする」スタンスだったのに、他人にサービスするようなポストを挟んでしまうとか。実際その日以降、しばらくそんな状況が続いた。引き摺られてはいけない、と自覚しつつも、どこかで引き摺られてしまうのだ。\nで、この状況はストレスなのである。つまり楽しくないのである。楽しくないTumblrなんかやりなくない。自分が楽しむためにやっているんだから、プライオリティの優位をそっちに戻す必要がある。\u0026hellip;と、そのことを明確に言語化するためのこの投稿を書いた。\n実はこの件と前後して、先の方に書いたセンス抜群のアカウントからフォローしてもらった。これは嬉しかったね。俺のポストはそんなにリブログしてもらってないけど、たまにリブログしてもらうとやはり反響がすごい。まぁこの反響ってのも良し悪しだけどね、まったく反応がないと寂しいけどデカすぎても疲れる、さっき書いたように、よくない影響受けることがあるからね。まぁこれって、リアルライフで人混みに出ると疲れるのと同じことだと思う。\n  で、最終的に言いたいことは。\nリアルライフでもSNSでも、「自分の周囲に誰がいるか」の影響は非常に大きいのだ、と。\n人間は誰でもエネルギーを持っている。エネルギーは、良くも悪くも他者に影響を与える。ある人間が、良いエネルギーを放出している集団の中にいればおのずとよい影響を受ける。逆もまた然りである。リアルライフだとそのことを如実に実感するが、ネット上でもそれは同様だ。実際物事はそう単純ではないから、他者からの影響の方向や質はモザイクのように絡み合っているイメージではあるが\u0026hellip;\nTwitterとかFacebookみたいにガチで言葉の応酬をするようなSNSは当然その傾向が強いと思うが、Tumblrのように非常に関係性が薄いSNSでもそういうことがあるんだな、と今更ながら実感した次第。\n結論としては、Tumblrではいくつかのアカウントを本当にリスペクトしているけれど、自分の軸をずらさずにかつ一定の距離を保つ姿勢を貫くのが、長く楽しむコツだね。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/sns-influence/","summary":"SNSって誰をフォローするかも大きいけど誰にフォローされるか、も相当影響でかいんだなと思う。\nもともとSNS嫌いだからほとんどやってないけど、Tumblrは例外で、ここしばらく依存症に近いくらい使っている。全然使っていなかった時期もあるんだけどね。今は諸事情によりヘビーユーザー。\n当初はフォロワー僅か、だったが逆に好き勝手なことが書けた。Tumblrってテキスト投稿には向いてないと思うけど、それすら気にせずに画像だろうが音声だろうがテキストだろうが、好きなように投稿する。それがTumblrの良さ。\n当初投稿するのは自分の写真が中心で、たまにテキストあり、リブログはあまりしていなかった。特にフォローしたいアカウントもなかったけどたまに癒し系とか懐かし系画像投稿したいから適当に複数アカウントフォローしてた。でも、楽しくはなかったんだよね。「たまにこっち系の画像ポストするのはいいけどそれメインでやりたいわけじゃないし、なんか違う気がするなぁ」と違和感を覚え始めて、フォロー解除した。\n  しかしその後、何がきっかけか覚えていないのだが、あるアカウントとその周辺アカウントをフォロー開始してから、めっちゃ楽しくなってしまった。それらのアカウントは毎日投稿しているけど、リブログせずにいられないような、何かしらカッコイイポストが必ずある。経由されたポストやソースをポストしたアカウントを追うとこれまたセンスが良くて、芋づる式に夢中でlike,reblogしてしまうのである。\nTumblrのすごいところは、オリジナルのポスト作成者じゃなくても、センスのいいポストで構成されたブログが甚大な価値を持つことだ。「あなたのセンスは素晴らしい、本当に尊敬する！」と叫びたくなるようなアカウントが複数存在する。まだ出会えていないブログもあるかもしれない。実際最近になっても、「こんなセンスいいブログがあったんだ！」と新たに発見することがある。（もちろんそんなときに直接メッセージを送ったりはしない。1%程度の例外はあるだろうが、Tumblrでは誰もそんなこと望んでいないのだから）\nいいポストを集めたブログは自然にいいブログになる。オリジナルの作者かどうか、の区別はもはや意味をなさなくなる。いいものを発見してコレクションする、そのエネルギーが、見る人にインスピレーションや刺激を与えるのだ。それがTumblrの良さ。（二度目）\nこのことに気づいてから、俺は夢中になってしまった。Tumblr自体はずっと前からやっているのに、こんなに楽しいと感じたのは初めてといってもいい。\n  以上は「誰をフォローするか」による影響の話。ここから先、「誰にフォローされるか」について書いてみる。\n少し前のある日、これまで細々とした件数だった、零細アカウントの俺の通知が飛躍的に伸びた。たまに特定のポストのリアクションが増加することはあったが、その日は過去にない規模の反響だった。「何かあったか？」と追ってみると、ある人気アカウントが自分のポストを複数リブログしてた。そこから雪だるま式にリアクションが増えたわけである。これにより、自分のブログのフォロワーも増加した。増加といってもその日に十人くらい、その後日に数人ずつ程度のペースだが。ちなみに先の人気アカウントにもフォローされていた。\nしかし、正直あまりうれしくないし、逆に困る。「ある誰かが自分の投稿を見ている」ことを意識していると、書きにくいことが出てくるのである。画像のポストだけでみても、フォロワーにインフルエンサーとそのフォロワーがいると「何を投稿するか」について、これまで以上に他人を意識せざるを得なくなってしまうのである。それまでは「とにかく自分がポストしたいものをポストする」スタンスだったのに、他人にサービスするようなポストを挟んでしまうとか。実際その日以降、しばらくそんな状況が続いた。引き摺られてはいけない、と自覚しつつも、どこかで引き摺られてしまうのだ。\nで、この状況はストレスなのである。つまり楽しくないのである。楽しくないTumblrなんかやりなくない。自分が楽しむためにやっているんだから、プライオリティの優位をそっちに戻す必要がある。\u0026hellip;と、そのことを明確に言語化するためのこの投稿を書いた。\n実はこの件と前後して、先の方に書いたセンス抜群のアカウントからフォローしてもらった。これは嬉しかったね。俺のポストはそんなにリブログしてもらってないけど、たまにリブログしてもらうとやはり反響がすごい。まぁこの反響ってのも良し悪しだけどね、まったく反応がないと寂しいけどデカすぎても疲れる、さっき書いたように、よくない影響受けることがあるからね。まぁこれって、リアルライフで人混みに出ると疲れるのと同じことだと思う。\n  で、最終的に言いたいことは。\nリアルライフでもSNSでも、「自分の周囲に誰がいるか」の影響は非常に大きいのだ、と。\n人間は誰でもエネルギーを持っている。エネルギーは、良くも悪くも他者に影響を与える。ある人間が、良いエネルギーを放出している集団の中にいればおのずとよい影響を受ける。逆もまた然りである。リアルライフだとそのことを如実に実感するが、ネット上でもそれは同様だ。実際物事はそう単純ではないから、他者からの影響の方向や質はモザイクのように絡み合っているイメージではあるが\u0026hellip;\nTwitterとかFacebookみたいにガチで言葉の応酬をするようなSNSは当然その傾向が強いと思うが、Tumblrのように非常に関係性が薄いSNSでもそういうことがあるんだな、と今更ながら実感した次第。\n結論としては、Tumblrではいくつかのアカウントを本当にリスペクトしているけれど、自分の軸をずらさずにかつ一定の距離を保つ姿勢を貫くのが、長く楽しむコツだね。","title":"Tumblrについて、ひとり言"},{"content":"前回投稿でAWS CodePipelineのクロスアカウント設定（前半）ではリソース配布元のアカウントAの内容中心に書いた。後半は配布先となるアカウントBの設定内容を書いていく。\n前回投稿\nAWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-1）\n繰り返しになるけれども、前提条件をおさらいとして記載。\nやりたいこと\nAWSの異なるアカウント間で、CodePipelineによりCodeDeployからec2インスタンスにリソースをデプロイする。ソースはリソース配布側のCodeCommit。この記事では配布元を開発環境/アカウントA、配布先を検証環境/アカウントBとして話を進める。 主な参考ページ\n他のリソースを使用するパイプラインを CodePipeline で作成するAWSアカウント\n 主な構成要素 これも前回書いているが、こっちにも書いておかないとわけわからなくなるので再掲。\n1-資材配布元（アカウントA）\n① CodeCommitリポジトリ（ec2にローカルリポジトリを作成〜資材格納）\n② KMSキー (両方のアカウントにアクセス許可する)\n③ S3バケット (アカウントBにアクセス許可するバケットポリシーを付与）\n④ CodePipelineが使用するサービスロール\n⑤ CodePipleline定義（コンソールで作成したパイプライン定義JSONをCLIから更新）\n 2-資材配布先（アカウントB）\n① CodeDeploy定義（アプリケーション/デプロイメントグループ）\n② ec2用のIAMロール（CodeDeployがアカウントAのKMSキー、S3にアクセスするためのポリシーを付与）\n③ ②のIAMロールをアタッチしたデプロイ先ec2\n④ クロスアカウント用サービスロール（CodeDeployとS3操作にassumeする）\n 上記アイテムを作成済みとして、作業概要は前回記事に記載した。以降、アカウントB側で用意するアイテムの内容を書く。\n2-① CodeDeploy定義\nアカウントBのコンソールにて、アプリケーションとデプロイメントグループを作成する。詳細は割愛。\n2-② ec2用のIAMロール\nKMSとS3用のインラインポリシーを作成する。AWS参考ページでは2つに分けていたが統合しても問題ないと思う。\nKMS用インラインポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:DescribeKey\u0026#34;, \u0026#34;kms:GenerateDataKey*\u0026#34;, \u0026#34;kms:Encrypt\u0026#34;, \u0026#34;kms:ReEncrypt*\u0026#34;, \u0026#34;kms:Decrypt\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:kms:us-east-1:[アカウントAのID]:key/[Key ID]\u0026#34; #KMSのARN ] } ] }  S3用インラインポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:Get*\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::[アカウントAのS3バケット名]/*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::[アカウントAのS3バケット名]\u0026#34; ] } ] }  2-④ クロスアカウントデプロイ用IAMロール\nサービスをCodeDeployとしてロールを作成する。この時アカウントAにassumeする前提で以下設定を行う。以下図の矢印箇所にアカウントAのIDを入力して次へ進む。これ以降は通常のロール作成時と同じ。\n デプロイ用ロール信頼ポリシーのJSONは以下のようになる。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::[アカウントAのID]:root\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Condition\u0026#34;: {} }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;codedeploy.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] }  デプロイ用メインのカスタムポリシー。CodeDeployのパーミッションを定義。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;codedeploy:CreateDeployment\u0026#34;, \u0026#34;codedeploy:GetDeployment\u0026#34;, \u0026#34;codedeploy:GetDeploymentConfig\u0026#34;, \u0026#34;codedeploy:GetApplicationRevision\u0026#34;, \u0026#34;codedeploy:RegisterApplicationRevision\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] }  デプロイ用インラインポリシー。S3とCodeCommitのパーミッション定義。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject*\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:PutObjectAcl\u0026#34;, \u0026#34;codecommit:ListBranches\u0026#34;, \u0026#34;codecommit:ListRepositories\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::[S3バケット名]/*\u0026#34; ] } ] }  これとは別にec2周りのポリシーも割り当てる。検証時は取り急ぎマネージドのAmazonEC2ReadOnlyAccessでもアタッチしておけばいい。\n これでやっとアイテムが出揃った。ここまで来たら、前回投稿の分も重複するがアカウントAの環境にて以下実行。（2. までは前回までの段階で完了しているとして、3.以降を実施）\n コンソールで単体アカウント用にパイプラインを作成 そのJSON定義を取得してクロスアカウント向けに編集 パイプラインをアップデート  $ aws codepipeline update-pipeline --cli-input-json file://[パイプライン名].json  アップデートしたパイプラインをスタート  $ aws codepipeline start-pipeline-execution --name [パイプライン名]  特にエラーが出なければパイプラインは走っているが、その先でコケることはよくあるのでコンソール画面から状況を確認する。アカウントAのマネジメントコンソール画面から全体の状況は把握できる。デプロイステージの詳細はアカウントBのコンソールからしか見れない。\nというわけで、果てしなく続くと思われた長い旅路がようやく終わりましたよ。しかしいいかげんに普通の旅にも出たいもんだ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/aws-crossaccount-pipeline-2/","summary":"前回投稿でAWS CodePipelineのクロスアカウント設定（前半）ではリソース配布元のアカウントAの内容中心に書いた。後半は配布先となるアカウントBの設定内容を書いていく。\n前回投稿\nAWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-1）\n繰り返しになるけれども、前提条件をおさらいとして記載。\nやりたいこと\nAWSの異なるアカウント間で、CodePipelineによりCodeDeployからec2インスタンスにリソースをデプロイする。ソースはリソース配布側のCodeCommit。この記事では配布元を開発環境/アカウントA、配布先を検証環境/アカウントBとして話を進める。 主な参考ページ\n他のリソースを使用するパイプラインを CodePipeline で作成するAWSアカウント\n 主な構成要素 これも前回書いているが、こっちにも書いておかないとわけわからなくなるので再掲。\n1-資材配布元（アカウントA）\n① CodeCommitリポジトリ（ec2にローカルリポジトリを作成〜資材格納）\n② KMSキー (両方のアカウントにアクセス許可する)\n③ S3バケット (アカウントBにアクセス許可するバケットポリシーを付与）\n④ CodePipelineが使用するサービスロール\n⑤ CodePipleline定義（コンソールで作成したパイプライン定義JSONをCLIから更新）\n 2-資材配布先（アカウントB）\n① CodeDeploy定義（アプリケーション/デプロイメントグループ）\n② ec2用のIAMロール（CodeDeployがアカウントAのKMSキー、S3にアクセスするためのポリシーを付与）\n③ ②のIAMロールをアタッチしたデプロイ先ec2\n④ クロスアカウント用サービスロール（CodeDeployとS3操作にassumeする）\n 上記アイテムを作成済みとして、作業概要は前回記事に記載した。以降、アカウントB側で用意するアイテムの内容を書く。\n2-① CodeDeploy定義\nアカウントBのコンソールにて、アプリケーションとデプロイメントグループを作成する。詳細は割愛。\n2-② ec2用のIAMロール\nKMSとS3用のインラインポリシーを作成する。AWS参考ページでは2つに分けていたが統合しても問題ないと思う。\nKMS用インラインポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:DescribeKey\u0026#34;, \u0026#34;kms:GenerateDataKey*\u0026#34;, \u0026#34;kms:Encrypt\u0026#34;, \u0026#34;kms:ReEncrypt*\u0026#34;, \u0026#34;kms:Decrypt\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:kms:us-east-1:[アカウントAのID]:key/[Key ID]\u0026#34; #KMSのARN ] } ] }  S3用インラインポリシー","title":"AWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-2）"},{"content":"前回投稿ではパイプラインなしでAWS クロスアカウントデプロイをやった。次はパイプラインを使ってやってみる。長くなるので前半/後半に分ける。\n やりたいこと\nAWSの異なるアカウント間で、CodePipelineによりCodeDeployからec2インスタンスにリソースをデプロイする。ソースはリソース配布側のCodeCommit。この記事では配布元を開発環境/アカウントA、配布先を検証環境/アカウントBとして話を進める。（ec2はオートスケールもなくただ単に配布するだけなので単一アカウントだったら簡単な話なんだが、アカウント跨ぐとなるとめっちゃ面倒くさい\u0026hellip;）\n 主な参考ページ\n他のリソースを使用するパイプラインを CodePipeline で作成するAWSアカウント\n 基本的にこのページの通りにやればOK。アカウントA側で一度単一アカウント用の適当なパイプラインを作成して、そのJSON定義を取得。それをクロスアカウント用に編集してCLIからアップデートする。ちなみに上記リンクは日本語版だが機械翻訳の文章がまともな日本語ではなくイラッとくるので、ほぼオリジナルの英語版を参考にした。\n参考までに、以下クラメソさんの記事。当初これのBuildをDeployに置き換えてやってみたが失敗した。不足か誤りがあるんだろうがいきなりやったこともありわけがわからなすぎて頓挫。先述のAWS公式の方がやりたいことに近かったため仕切り直しした。\nクロスアカウントCodeBuild + パイプライン例\nCodePipelineでアカウントをまたいだパイプラインを作成してみる\n 制約事項\n クロスアカウントのパイプラインはマネジメントコンソールから作成不可のため、aws cliから作成/更新する CodeDeployの定義とデプロイ先のec2は同一アカウントであること クロスアカウントでパイプラインを組む場合、アーティファクト格納用S3バケットの暗号化キーはKMSを使用する（AWS デフォルトの暗号化キーはNG）   主な構成要素 2アカウント間で各種アイテムを用意することになり、混乱しがちなのでまとめておく。前回投稿では配布先となるアカウントB側にS3バケットがある構成だったが、今回は逆。ただし構成的にはこちらの方が自然かと思う。\n1-資材配布元（アカウントA）\n① CodeCommitリポジトリ（ec2にローカルリポジトリを作成〜資材格納）\n② KMSキー (両方のアカウントにアクセス許可する)\n③ S3バケット (アカウントBにアクセス許可するバケットポリシーを付与）\n④ CodePipelineが使用するサービスロール\n⑤ CodePipleline定義（コンソールで作成したパイプライン定義JSONをCLIから更新）\nJSON取得コマンド\n$ aws codepipeline get-pipeline --name [パイプライン名] \u0026gt; [パイプライン名].json  2-資材配布先（アカウントB）\n① CodeDeploy定義（アプリケーション/デプロイメントグループ）\n② ec2用のIAMロール（CodeDeployがアカウントAのKMSキー、S3にアクセスするためのポリシーを付与）\n③ ②のIAMロールをアタッチしたデプロイ先ec2\n④ クロスアカウント用サービスロール（CodeDeployとS3操作にassumeする）\n 作業概要 上記各リソースを作成済として、以下の作業を行う。\nアカウントAの作業用端末またはec2にログイン。1-⑤のパイプライン定義JSONを適当なパスに配置し、パイプラインをアップデートする\n$ cd /path/to/json $ aws codepipeline update-pipeline --cli-input-json file://[パイプライン名].json  アップデートしたパイプラインを実行する\n$ aws codepipeline start-pipeline-execution --name [パイプライン名]  アカウントBでは特に作業なし。デプロイステータスが成功になったら、ec2に資材がデプロイされていることを確認する。\nクロスアカウントパイプラインの処理中の見え方\nアカウントAのマネジメントコンソール：パイプライン全体の処理状況は見える。デプロイステージの詳細は見れない。\nアカウントBのコンソール : デプロイの詳細が見れる\n 各種アイテムのサンプル AWS公式でも基本内容は網羅されているが自分用メモとしてここにも載せておく。\nアカウントA側アイテム\n1-② KMSキーポリシー\nアーティファクト用S3バケットの暗号化キーポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;[key-policy-name]\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Enable IAM User Permissions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::[アカウントAのID]:root\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;kms:*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;Allow access for Key Administrators\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;[KMSの暗号化キーの管理ユーザのARN]\u0026#34; #アカウントA側のキーのオーナーを指定 }, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:Create*\u0026#34;, \u0026#34;kms:Describe*\u0026#34;, \u0026#34;kms:Enable*\u0026#34;, \u0026#34;kms:List*\u0026#34;, \u0026#34;kms:Put*\u0026#34;, \u0026#34;kms:Update*\u0026#34;, \u0026#34;kms:Revoke*\u0026#34;, \u0026#34;kms:Disable*\u0026#34;, \u0026#34;kms:Get*\u0026#34;, \u0026#34;kms:Delete*\u0026#34;, \u0026#34;kms:TagResource\u0026#34;, \u0026#34;kms:UntagResource\u0026#34;, \u0026#34;kms:ScheduleKeyDeletion\u0026#34;, \u0026#34;kms:CancelKeyDeletion\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;Allow use of the key\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: [ \u0026#34;[アカウントAのパイプライン用サービスロールのARN]\u0026#34;, #(注1) \u0026#34;arn:aws:iam::[アカウントBのID]:root\u0026#34; ] }, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:Encrypt\u0026#34;, \u0026#34;kms:Decrypt\u0026#34;, \u0026#34;kms:ReEncrypt*\u0026#34;, \u0026#34;kms:GenerateDataKey*\u0026#34;, \u0026#34;kms:DescribeKey\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;Allow attachment of persistent resources\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: [ \u0026#34;[アカウントAのパイプライン用サービスロールのARN]\u0026#34;, #(注1) \u0026#34;arn:aws:iam::[アカウントBのID]:root\u0026#34; ] }, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:CreateGrant\u0026#34;, \u0026#34;kms:ListGrants\u0026#34;, \u0026#34;kms:RevokeGrant\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;Bool\u0026#34;: { \u0026#34;kms:GrantIsForAWSResource\u0026#34;: \u0026#34;true\u0026#34; } } } ] } (注1) 構文\narn:aws:iam::[アカウントAのID]:role/[パイプラインロール名]\n 1-③ S3バケットポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;SSEAndSSLPolicy\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;DenyUnEncryptedObjectUploads\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::[S3バケット名]/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringNotEquals\u0026#34;: { \u0026#34;s3:x-amz-server-side-encryption\u0026#34;: \u0026#34;aws:kms\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;DenyInsecureConnections\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::[S3バケット名]/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;Bool\u0026#34;: { \u0026#34;aws:SecureTransport\u0026#34;: false } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::[アカウントBのID]:root\u0026#34; }, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:Get*\u0026#34;, \u0026#34;s3:Put*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::[S3バケット名]/*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::[アカウントBのID]:root\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::[S3バケット名]\u0026#34; } ] }  1-④ CodePipelineが使用するサービスロール(IAM)\nこのロールには以下のポリシーを割り当てる。1.はロール作成前に作成可能。コンソールからロール作成する時に選択可能なサービスにCodePipelineがないので一旦CodeDeployで作成して、後から信頼ポリシー編集した。\n 通常のCodePipeline作業用ポリシー アカウントBのassume用インラインポリシー 信頼ポリシー（編集）  以下CodePipeline作業用ポリシー。AWSが自動で付与するポリシーは他のパーミッションも多く含まれているがそこから削って最小限にしたのがこれ。autoscalingは使わないんだけど一応残す。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Action\u0026#34;: [ \u0026#34;iam:PassRole\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEqualsIfExists\u0026#34;: { \u0026#34;iam:PassedToService\u0026#34;: [ \u0026#34;ec2.amazonaws.com\u0026#34; ] } } }, { \u0026#34;Action\u0026#34;: [ \u0026#34;codecommit:CancelUploadArchive\u0026#34;, \u0026#34;codecommit:GetBranch\u0026#34;, \u0026#34;codecommit:GetCommit\u0026#34;, \u0026#34;codecommit:GetUploadArchiveStatus\u0026#34;, \u0026#34;codecommit:UploadArchive\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; }, { \u0026#34;Action\u0026#34;: [ \u0026#34;codedeploy:CreateDeployment\u0026#34;, \u0026#34;codedeploy:GetApplication\u0026#34;, \u0026#34;codedeploy:GetApplicationRevision\u0026#34;, \u0026#34;codedeploy:GetDeployment\u0026#34;, \u0026#34;codedeploy:GetDeploymentConfig\u0026#34;, \u0026#34;codedeploy:RegisterApplicationRevision\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; }, { \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:*\u0026#34;, \u0026#34;elasticloadbalancing:*\u0026#34;, \u0026#34;autoscaling:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;s3:*\u0026#34;, \u0026#34;tag:*\u0026#34;, \u0026#34;logs:*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; } ] }  アカウントBのassume用インラインポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:iam::[アカウントBのID]:role/*\u0026#34; ] } }  信頼ポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: [ \u0026#34;codepipeline.amazonaws.com\u0026#34;, \u0026#34;codedeploy.amazonaws.com\u0026#34;, \u0026#34;ec2.amazonaws.com\u0026#34; ] }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] }  1-⑤ CodePiplelineのJSON定義\n冒頭のAWS公式ページにもポイントは記載されているが、今回のケースでまとめたのがこれ。繰り返しになるが、「1.コンソールで単体アカウント用にパイプラインを作成 2. そのJSON定義を取得してクロスアカウント向けに編集 3. パイプラインをアップデート」という流れになる。最初にパイプラインを作成するときにCodeDeploy用定義が必要なため、事前にアカウントA内で適当なCodeDeployアプリケーション/デプロイメントグループのペアを用意しておく。\n以下のJSON後半でアカウントB側のアイテム定義名をいくつか記載しており、当然アカウントB側に実体が存在する前提だが、編集時点では存在していなくても構わない。\n{ \u0026#34;pipeline\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;A_crossdeploy_pipeline\u0026#34;, \u0026#34;roleArn\u0026#34;: \u0026#34;arn:aws:iam::[アカウントAのID]:role/[クロスアカウントパイプライン用IAMロール名]\u0026#34;, \u0026#34;artifactStore\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;S3\u0026#34;, \u0026#34;location\u0026#34;: \u0026#34;[S3バケット名]\u0026#34; \u0026#34;encryptionKey\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;arn:aws:kms:us-east-1:[アカウントAのID]:key/[キーのID]\u0026#34;, #KMSキーのARN \u0026#34;type\u0026#34;: \u0026#34;KMS\u0026#34; }, \u0026#34;stages\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Source\u0026#34;, \u0026#34;actions\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Source\u0026#34;, \u0026#34;actionTypeId\u0026#34;: { \u0026#34;category\u0026#34;: \u0026#34;Source\u0026#34;, \u0026#34;owner\u0026#34;: \u0026#34;AWS\u0026#34;, \u0026#34;provider\u0026#34;: \u0026#34;CodeCommit\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1\u0026#34; }, \u0026#34;runOrder\u0026#34;: 1, \u0026#34;configuration\u0026#34;: { \u0026#34;BranchName\u0026#34;: \u0026#34;master\u0026#34;, \u0026#34;OutputArtifactFormat\u0026#34;: \u0026#34;CODE_ZIP\u0026#34;, \u0026#34;PollForSourceChanges\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;RepositoryName\u0026#34;: \u0026#34;[ソースリポジトリ名]\u0026#34; }, \u0026#34;outputArtifacts\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;SourceArtifact\u0026#34; } ], \u0026#34;roleArn\u0026#34; : \u0026#34;arn:aws:iam::[アカウントAのID]:role/[クロスアカウントパイプライン用IAMロール名]\u0026#34;, #冒頭で指定したIAMと同じ \u0026#34;inputArtifacts\u0026#34;: [], \u0026#34;region\u0026#34;: \u0026#34;ap-northeast-1\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;SourceVariables\u0026#34; } ] }, { \u0026#34;name\u0026#34;: \u0026#34;Deploy\u0026#34;, \u0026#34;actions\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;ExternalDeploy\u0026#34;, #Deploy --＞ ExternalDeployに変更 \u0026#34;actionTypeId\u0026#34;: { \u0026#34;category\u0026#34;: \u0026#34;Deploy\u0026#34;, \u0026#34;owner\u0026#34;: \u0026#34;AWS\u0026#34;, \u0026#34;provider\u0026#34;: \u0026#34;CodeDeploy\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1\u0026#34; }, \u0026#34;runOrder\u0026#34;: 1, \u0026#34;configuration\u0026#34;: { \u0026#34;ApplicationName\u0026#34;: \u0026#34;[アカウントBのコードデプロイアプリケーション名]\u0026#34;, \u0026#34;DeploymentGroupName\u0026#34;: \u0026#34;[アカウントBのコードデプロイデプロイメントグループ名]\u0026#34; }, \u0026#34;outputArtifacts\u0026#34;: [], \u0026#34;inputArtifacts\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;SourceArtifact\u0026#34; } ], \u0026#34;roleArn\u0026#34; : \u0026#34;arn:aws:iam::[アカウントBのID]:role/[アカウントBのクロスデプロイ用IAMロール名]\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-northeast-1\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;DeployVariables\u0026#34; } ] } ], \u0026#34;version\u0026#34;: 1 } }  やっとここまできた\u0026hellip;長かった。しかしまだ道は続く。次回、アカウントB側の設定内容を書く。\n続き\nAWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-2）\n","permalink":"https://ecnedaced-seirots.github.io/post/a/aws-crossaccount-pipeline-1/","summary":"前回投稿ではパイプラインなしでAWS クロスアカウントデプロイをやった。次はパイプラインを使ってやってみる。長くなるので前半/後半に分ける。\n やりたいこと\nAWSの異なるアカウント間で、CodePipelineによりCodeDeployからec2インスタンスにリソースをデプロイする。ソースはリソース配布側のCodeCommit。この記事では配布元を開発環境/アカウントA、配布先を検証環境/アカウントBとして話を進める。（ec2はオートスケールもなくただ単に配布するだけなので単一アカウントだったら簡単な話なんだが、アカウント跨ぐとなるとめっちゃ面倒くさい\u0026hellip;）\n 主な参考ページ\n他のリソースを使用するパイプラインを CodePipeline で作成するAWSアカウント\n 基本的にこのページの通りにやればOK。アカウントA側で一度単一アカウント用の適当なパイプラインを作成して、そのJSON定義を取得。それをクロスアカウント用に編集してCLIからアップデートする。ちなみに上記リンクは日本語版だが機械翻訳の文章がまともな日本語ではなくイラッとくるので、ほぼオリジナルの英語版を参考にした。\n参考までに、以下クラメソさんの記事。当初これのBuildをDeployに置き換えてやってみたが失敗した。不足か誤りがあるんだろうがいきなりやったこともありわけがわからなすぎて頓挫。先述のAWS公式の方がやりたいことに近かったため仕切り直しした。\nクロスアカウントCodeBuild + パイプライン例\nCodePipelineでアカウントをまたいだパイプラインを作成してみる\n 制約事項\n クロスアカウントのパイプラインはマネジメントコンソールから作成不可のため、aws cliから作成/更新する CodeDeployの定義とデプロイ先のec2は同一アカウントであること クロスアカウントでパイプラインを組む場合、アーティファクト格納用S3バケットの暗号化キーはKMSを使用する（AWS デフォルトの暗号化キーはNG）   主な構成要素 2アカウント間で各種アイテムを用意することになり、混乱しがちなのでまとめておく。前回投稿では配布先となるアカウントB側にS3バケットがある構成だったが、今回は逆。ただし構成的にはこちらの方が自然かと思う。\n1-資材配布元（アカウントA）\n① CodeCommitリポジトリ（ec2にローカルリポジトリを作成〜資材格納）\n② KMSキー (両方のアカウントにアクセス許可する)\n③ S3バケット (アカウントBにアクセス許可するバケットポリシーを付与）\n④ CodePipelineが使用するサービスロール\n⑤ CodePipleline定義（コンソールで作成したパイプライン定義JSONをCLIから更新）\nJSON取得コマンド\n$ aws codepipeline get-pipeline --name [パイプライン名] \u0026gt; [パイプライン名].json  2-資材配布先（アカウントB）\n① CodeDeploy定義（アプリケーション/デプロイメントグループ）\n② ec2用のIAMロール（CodeDeployがアカウントAのKMSキー、S3にアクセスするためのポリシーを付与）\n③ ②のIAMロールをアタッチしたデプロイ先ec2\n④ クロスアカウント用サービスロール（CodeDeployとS3操作にassumeする）\n 作業概要 上記各リソースを作成済として、以下の作業を行う。\nアカウントAの作業用端末またはec2にログイン。1-⑤のパイプライン定義JSONを適当なパスに配置し、パイプラインをアップデートする\n$ cd /path/to/json $ aws codepipeline update-pipeline --cli-input-json file://[パイプライン名].","title":"AWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-1）"},{"content":"AWS環境で、クロスアカウントでCI/CDしたい。とりあえずBuildフェーズはいらなくてDeployだけでいい。Deployの実行はパイプラインあり/なし両方可能。どちらも単一アカウント内なら複雑な設定もなく比較的容易にできることはわかっているが、クロスアカウントとなると何かと面倒だ。でもやってみる。ここではまずはパイプラインなしとする。\n 参考\n異なる AWS アカウントでアプリケーションをデプロイする\n（上記ページにリンクあり。assumeロールの設定は以下参考）\nIAM チュートリアル: AWS アカウント間の IAM ロールを使用したアクセスの委任\n 環境前提 配布元となるAWS開発環境(Dev)にCodeCommitのローカルリポジトリがあり、そこから別アカウントの検証環境(Stg)にデプロイする。その先には本番環境がある想定だが構成は同じになるはず。\n① 配布元(Dev)\n② 配布先(Stg)\n概要 ①配布元のアカウントから②配布先のec2にデプロイ可能とするため、②配布先アカウント側で①アカウントのassumeを可能とするIAMロールを作成する。（ロールAとする）① 配布元アカウント側でロールAにassumeし、デプロイを実行する。\n基本的に必要となるのはIAM周りの設定であり、ネットワーク系の特別な実装は必要ない。\n 作業内容   配布先②アカウントにて、配置用のS3バケットを作成する。IAMロールのポリシーでバケットへのアクセス権限を定義するため、バケットポリシーは設定しなくても問題なし。(注1)\n  配布先②アカウントにて、①がassumeするためのロールAを作成する。\n  ロールAで定義する内容 (1) 信頼ポリシーで②のアカウントIDを指定してassumeを許可する。このときrootか②側のIAMロールどちらかを指定する。\nrootに設定した場合は、①アカウントでデプロイを実行するユーザのグループにassume可能とするインラインポリシーを適用する。\nIAMに設定した場合は、①アカウントでデプロイを実行するec2にこのIAMロールを適用する。実行環境がec2の場合はこれでよいが、クライアント端末の場合はrootにする。\n インラインポリシー例 (①アカウントで設定) デプロイ実行ユーザが所属するグループの画面を開き、[アクセス許可] タブ \u0026ndash;\u0026gt; [アクセス許可の追加] \u0026ndash;\u0026gt; [インラインポリシーの作成] [JSON] タブ選択\n以下の内容を設定する。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:iam::②配布先のアカウントID:role/ロールA\u0026#34; } }  (2) ①のアカウントが資材配置用のS3にアクセスするための権限を定義したポリシーを適用する。ちゃんと書いてないけど以下にcodedeploy, ec2の操作権限も追加する。codedeployの権限は何が必要かわからないのでとりあえず全許可にしておいた。ECSへのデプロイだとec2のterminate権限が必要みたいだが、今回の場合ec2は参照のみでOKだと思う。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:GetBucketLocation\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::staging-app\u0026#34; #検証環境の資材格納バケット名 }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::staging-app/*\u0026#34; } ] }  ②配布先アカウントにて、deployのアプリケーションとデプロイメントグループを作成する。詳細は割愛。   ①配布元アカウントのec2（または同アカウントのcredentialsをセットした端末）にログインし、ロールAにスイッチする。ちなみにマネジメントコンソールでもスイッチして作業可能だが、deployのpushコマンドがCLIでしかできないため、ここではCLI前提で話を進める。  この時先で作成したロールAにスイッチするため、以下のコマンドを実行する。\n$ aws sts assume-role --role-arn \u0026quot;②配布先のアカウントID:role/ロールA\u0026quot; --role-session-name \u0026quot;deployment-test\u0026quot;  すると以下の形式の認証情報が出力される。\n{ \u0026#34;Credentials\u0026#34;: { \u0026#34;AccessKeyId\u0026#34;: \u0026#34;[access key id]\u0026#34; \u0026#34;SecretAccessKey\u0026#34;: \u0026#34;[secret access key id]\u0026#34;, \u0026#34;SessionToken\u0026#34;: \u0026#34;[token id]\u0026#34;, \u0026#34;Expiration\u0026#34;: \u0026#34;2021-09-20T15:08:00Z\u0026#34; } }  上記を環境変数にセットする。Windowsの場合はexportをsetに変更する。\n$ export AWS_ACCESS_KEY_ID=[access key id] $ export AWS_SECRET_ACCESS_KEY=[secret access key id] $ export AWS_SESSION_TOKEN=[token id]  これでセッション保持期間の間（expireの時刻)は②アカウントのロールAの権限で作業が可能となる。セッション時間はデフォルトで1時間だが、伸ばしたい場合は--duration-secondsオプションを使う。（2時間なら7200、3時間なら10800と指定。ロールAの最大セッション期間がそれに応じた時間に設定されている前提）\n デプロイ実行  最初にやる時はデプロイ前にaws s3 cpを実行して、対象S3バケットへ読み書き可能かチェックしておくとよい。\nCLIでpush [オプション]を実行し、S3に資材を格納する。この時 3.で作成したアプリケーション名を指定する。（これによりただ単にS3に資材を配置するのではなく、資材をアプリケーションのリビジョンと関連付けることになる）sourceはここではCodeCommitのローカルリポジトリパスを指定しているが、指定するのはappspec.ymlを配置したディレクトリとなる。\n$ aws deploy push ¥ --application-name [aplication-name] ¥ --s3-location s3://[staging-app]/[staging-app-key] ¥ --ignore-hidden-files ¥ --source /path/to/source  pushが成功すると資材がzip形式で格納される。ターミナル上ではE-Tagを含む実行コマンド情報が標準出力される。詳細は割愛するがこれを元にcreate-deploymentにてデプロイを実行する。この時 3.で作成したデプロイメントグループを指定する。成功すれば②配布先となるec2にS3から資材が配置される。ちなみにpushはコンソールから実行できないが、デプロイは可能である。しかしそのために実行画面を切り替えるのも面倒なので（コンソールでもassumeする）、ここは引き続きCLIでやる方が自然かと。\n (注1) 配布元①アカウントにバケットを作成してもよいが、また追加の設定が必要となる。今回は配布先②に作成した。\n その他ポイント 最初deployのコマンドは通ったがその先で失敗した。この時コンソール上では以下のエラーが表示されていた。\n The overall deployment failed because too many individual instances failed deployment, too few healthy instances are available for deployment, or some instances in your deployment group are experiencing problems.\n  これだけではわからないのでログを確認してみたところ、こんなエラーが繰り返し吐かれていた。\n/var/log/aws/codedeploy-agent/codedeploy-agent.log\n InstanceAgent::Plugins::CodeDeployPlugin::CommandPoller: Missing credentials - please check if this instance was started with an IAM instance profile\n  確かに配布先ec2にはIAMロールをアタッチしていなかったため、インスタンスプロファイルが存在しない。するとcodedepoloyエージェントが上記のログを吐くわけだ。配布先のec2にインスタンスプロファイルを割り当てるため、別途IAMロールを作成してIAMロールをアタッチしたところ成功した。\nIAMをアタッチしても同じエラーが出る場合、エージェントを再起動してみる。候補が表示されなかったりエラーになったりしてIAMのアタッチ自体が不可能な場合は、インスタンスを一旦停止して再試行してみる。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/cross-account-codedeploy/","summary":"AWS環境で、クロスアカウントでCI/CDしたい。とりあえずBuildフェーズはいらなくてDeployだけでいい。Deployの実行はパイプラインあり/なし両方可能。どちらも単一アカウント内なら複雑な設定もなく比較的容易にできることはわかっているが、クロスアカウントとなると何かと面倒だ。でもやってみる。ここではまずはパイプラインなしとする。\n 参考\n異なる AWS アカウントでアプリケーションをデプロイする\n（上記ページにリンクあり。assumeロールの設定は以下参考）\nIAM チュートリアル: AWS アカウント間の IAM ロールを使用したアクセスの委任\n 環境前提 配布元となるAWS開発環境(Dev)にCodeCommitのローカルリポジトリがあり、そこから別アカウントの検証環境(Stg)にデプロイする。その先には本番環境がある想定だが構成は同じになるはず。\n① 配布元(Dev)\n② 配布先(Stg)\n概要 ①配布元のアカウントから②配布先のec2にデプロイ可能とするため、②配布先アカウント側で①アカウントのassumeを可能とするIAMロールを作成する。（ロールAとする）① 配布元アカウント側でロールAにassumeし、デプロイを実行する。\n基本的に必要となるのはIAM周りの設定であり、ネットワーク系の特別な実装は必要ない。\n 作業内容   配布先②アカウントにて、配置用のS3バケットを作成する。IAMロールのポリシーでバケットへのアクセス権限を定義するため、バケットポリシーは設定しなくても問題なし。(注1)\n  配布先②アカウントにて、①がassumeするためのロールAを作成する。\n  ロールAで定義する内容 (1) 信頼ポリシーで②のアカウントIDを指定してassumeを許可する。このときrootか②側のIAMロールどちらかを指定する。\nrootに設定した場合は、①アカウントでデプロイを実行するユーザのグループにassume可能とするインラインポリシーを適用する。\nIAMに設定した場合は、①アカウントでデプロイを実行するec2にこのIAMロールを適用する。実行環境がec2の場合はこれでよいが、クライアント端末の場合はrootにする。\n インラインポリシー例 (①アカウントで設定) デプロイ実行ユーザが所属するグループの画面を開き、[アクセス許可] タブ \u0026ndash;\u0026gt; [アクセス許可の追加] \u0026ndash;\u0026gt; [インラインポリシーの作成] [JSON] タブ選択\n以下の内容を設定する。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:iam::②配布先のアカウントID:role/ロールA\u0026#34; } }  (2) ①のアカウントが資材配置用のS3にアクセスするための権限を定義したポリシーを適用する。ちゃんと書いてないけど以下にcodedeploy, ec2の操作権限も追加する。codedeployの権限は何が必要かわからないのでとりあえず全許可にしておいた。ECSへのデプロイだとec2のterminate権限が必要みたいだが、今回の場合ec2は参照のみでOKだと思う。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:GetBucketLocation\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::staging-app\u0026#34; #検証環境の資材格納バケット名 }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::staging-app/*\u0026#34; } ] }  ②配布先アカウントにて、deployのアプリケーションとデプロイメントグループを作成する。詳細は割愛。   ①配布元アカウントのec2（または同アカウントのcredentialsをセットした端末）にログインし、ロールAにスイッチする。ちなみにマネジメントコンソールでもスイッチして作業可能だが、deployのpushコマンドがCLIでしかできないため、ここではCLI前提で話を進める。  この時先で作成したロールAにスイッチするため、以下のコマンドを実行する。","title":"AWS CodeDeployでクロスアカウントデプロイの実行（パイプラインなし）"},{"content":"かつてブラウザで全画面キャプチャしたい時はChromeにアドオンを入れて使っていたがこのアドオンはキャプチャしたデータをどこかに送信しているという話をどこかで読んで、ちょっとなぁ、と思った。しかし最近になってChromeでもFirefoxでもアドオンなしで全画面キャプチャが可能になっていることを知った。自宅で見るブラウザはほぼFirefoxでChromeは滅多に使わないが、職場では事情が変わったりするので両方書いておく。\nFirefoxの場合 F12キーで開発ツール画面を表示する。ツール画面右上のカメラアイコンをクリック。これだけ。素晴らしい。画像はデフォルトでDwonloadディレクトリに保存される。\n\u0026hellip;が、画面左側に小さな字でさりげなく「画像が大きすぎたため、xxxxxのサイズに切り抜きました」と言われている。画面が長すぎると途中で切られてしまうわけだ。結果的には以下のようになった。矢印の箇所は実際にここで画面が切れている。自分の投稿記事でやってみたんだけどまぁ実際この記事は長すぎるね。\nChromeの場合 Chromeでやる場合は一手間増える。\nWindows  Ctrl + Shift + I 同時押しで開発ツール画面を表示 Ctrl + Shift + P 同時押しで入力欄を表示させる 「full」と入力してreturn。少し待つとDwonloadディレクトリに保存される。  Mac  command + option + I 同時押しで開発ツール画面を表示 command + Shift + P同時押しで入力欄を表示させる 「full」と入力してreturn。少し待つとDwonloadディレクトリに保存される。\n（デフォルト保存先）  手間といっても大したことじゃないが、なにせものぐさなんで。それでもアドオンなしで全画面キャプチャ可能になったのはありがたい。\nしかしここでもやはり画面が長すぎておかしなことになっている。途中で一回途切れて（矢印箇所）、再度記事の初めから出力されるというループに陥っている。ま、とにかくFirefoxでもChromeでも長すぎるとダメつうことだ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/browser-capture-all/","summary":"かつてブラウザで全画面キャプチャしたい時はChromeにアドオンを入れて使っていたがこのアドオンはキャプチャしたデータをどこかに送信しているという話をどこかで読んで、ちょっとなぁ、と思った。しかし最近になってChromeでもFirefoxでもアドオンなしで全画面キャプチャが可能になっていることを知った。自宅で見るブラウザはほぼFirefoxでChromeは滅多に使わないが、職場では事情が変わったりするので両方書いておく。\nFirefoxの場合 F12キーで開発ツール画面を表示する。ツール画面右上のカメラアイコンをクリック。これだけ。素晴らしい。画像はデフォルトでDwonloadディレクトリに保存される。\n\u0026hellip;が、画面左側に小さな字でさりげなく「画像が大きすぎたため、xxxxxのサイズに切り抜きました」と言われている。画面が長すぎると途中で切られてしまうわけだ。結果的には以下のようになった。矢印の箇所は実際にここで画面が切れている。自分の投稿記事でやってみたんだけどまぁ実際この記事は長すぎるね。\nChromeの場合 Chromeでやる場合は一手間増える。\nWindows  Ctrl + Shift + I 同時押しで開発ツール画面を表示 Ctrl + Shift + P 同時押しで入力欄を表示させる 「full」と入力してreturn。少し待つとDwonloadディレクトリに保存される。  Mac  command + option + I 同時押しで開発ツール画面を表示 command + Shift + P同時押しで入力欄を表示させる 「full」と入力してreturn。少し待つとDwonloadディレクトリに保存される。\n（デフォルト保存先）  手間といっても大したことじゃないが、なにせものぐさなんで。それでもアドオンなしで全画面キャプチャ可能になったのはありがたい。\nしかしここでもやはり画面が長すぎておかしなことになっている。途中で一回途切れて（矢印箇所）、再度記事の初めから出力されるというループに陥っている。ま、とにかくFirefoxでもChromeでも長すぎるとダメつうことだ。","title":"Firefox/Chromeでアドオンなし全画面キャプチャ"},{"content":" 私的にMacで必須のショートカットを3つ挙げるとしたらこんなところかな。\n  フルスクリーン解除 control+ command + F\n  アプリケーションの強制終了 command + option + esc\n  スクリーンショット command + shift + 3\n   それにしてもフルスクリーンて、あれ何のためにあるん？意図的にフルスクリーンにすることなくて変な風にキーボード触ってしまった時になっちまうんだけど、迷惑極まりない\u0026hellip;\n 追記\nもうひとつ迷惑なショートカット思い出したから追加。ターミナル画面が分割されるやつ。command + D同時押しでなってしまうらしい。絶対使わんのに。戻すには、command + Shift + D。3選といいつつ、思い出したらまた書くかもな\u0026hellip;\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/mac-shortcut/","summary":" 私的にMacで必須のショートカットを3つ挙げるとしたらこんなところかな。\n  フルスクリーン解除 control+ command + F\n  アプリケーションの強制終了 command + option + esc\n  スクリーンショット command + shift + 3\n   それにしてもフルスクリーンて、あれ何のためにあるん？意図的にフルスクリーンにすることなくて変な風にキーボード触ってしまった時になっちまうんだけど、迷惑極まりない\u0026hellip;\n 追記\nもうひとつ迷惑なショートカット思い出したから追加。ターミナル画面が分割されるやつ。command + D同時押しでなってしまうらしい。絶対使わんのに。戻すには、command + Shift + D。3選といいつつ、思い出したらまた書くかもな\u0026hellip;\n ","title":"Macで必須のショートカット3選"},{"content":"サクラエディタで半角スペースを可視化したい。環境が変わって入れ直した時とか都度やり直す羽目になるからメモ。\nメニューから[設定] 〜 [タイプ別設定] を選択。\n 「カラー」タブ 半角空白 「色分け/表示」にチェック  ","permalink":"https://ecnedaced-seirots.github.io/post/a/sakura/","summary":"サクラエディタで半角スペースを可視化したい。環境が変わって入れ直した時とか都度やり直す羽目になるからメモ。\nメニューから[設定] 〜 [タイプ別設定] を選択。\n 「カラー」タブ 半角空白 「色分け/表示」にチェック  ","title":"サクラエディタで半角スペースを可視化"},{"content":"小ネタでもいいからどんどんポストしたいと思っているけどそれもなかなかできないもんだな。写真だけ。2018年4月の東京・井の頭公園。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/inokashira-park/","summary":"小ネタでもいいからどんどんポストしたいと思っているけどそれもなかなかできないもんだな。写真だけ。2018年4月の東京・井の頭公園。\n ","title":"井の頭公園 - 2018年4月"},{"content":"AWS EKSでPodからログを送信する場合、Container Insightsを組み込んでFluentdかFluent Bitを利用するのが一般的と思われる。そしてFluent BitよりFluentdの方がメジャーなのでまずはそこから入る事例が多いと想像する。しかし、元々組み込みLinux用に開発されて軽量リソースで動作するFluent Bitの方がコンテナログ送信に向いていると思う。ということで、この記事ではFluent Bitに焦点を当てる。\n 参照\nFluent Bit ドキュメント（設定詳細は画面左「DATA PIPELINE」配下のメニュー参照）\nFluent Bit Documentation\nContainer Insights全般\nAmazon EKS と Kubernetes での Container Insights のセットアップ\nFluent Bit on Container Insights\nCloudWatch Logs へログを送信する DaemonSet として Fluent Bit を設定する\nサンプルマニフェスト\nfluent-bit-compatible.yaml\n※AWSがサンプルとして提供しているFluent BitのマニフェストはFluent Bit最適化用とFluentd互換用がある。今回は過去にFluentd使用事例があることから、Fluentd互換用マニフェストをDLしてカスタマイズした。\n 共通マニフェスト例 クラスタの全般的な設定と、アプリ個別のケースでマニフェストを二つに分けた。AWS公式では基本となるEKSクラスタの定義をコマンドでセットしているが、運用の際はマニフェストに落とし込むのが普通だと思う。以下のようなマニフェストを共通用として作成し、個別のマニフェストから参照させる。EKSクラスタ名はdata:cluster.nameで指定している。\nfluentbit-cluster.yaml\napiVersion: v1 kind: ConfigMap metadata: name: fluentbit-cluster namespace: amazon-cloudwatch selfLink: /api/v1/namespaces/amazone-cloudwatch/configmaps/fluentbit-cluster data: cluster.name: EKS-SAMPLE-CLUSTER log.region: ap-northeast-1 read.head: \u0026#34;On\u0026#34; read.tail: \u0026#34;Off\u0026#34; --- apiVersion: v1 kind: ServiceAccount metadata: name: fluent-bit namespace: amazon-cloudwatch --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: fluent-bit-role rules: - nonResourceURLs: - /metrics verbs: - get - apiGroups: [\u0026#34;\u0026#34;] resources: - namespaces - pods - pods/logs verbs: [\u0026#34;get\u0026#34;, \u0026#34;list\u0026#34;, \u0026#34;watch\u0026#34;] --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: fluent-bit-role-binding roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: fluent-bit-role subjects: - kind: ServiceAccount name: fluent-bit namespace: amazon-cloudwatch  個別マニフェスト例 「個別のマニフェスト」というのはアプリの種類が複数存在して、各種別ごとに送信先（ロググループ/ログストリーム）を振り分けたいケースを想定している。しかしAWS公式サンプルをそのまま使うと要件的に期待値にならない。現状ネットにわかりやすい事例がなく大分迷ったが、最終的に以下のような形に落とした。詳細は後述。\n最初に骨組みを説明すると、前半がFluent Bitの設定であるConfigMap、後半がワーカーノード上で起動するDaemonSetの定義となっている。冒頭の[SERVICE]で全体共通の設定を行う。@INCLUDEで3種類のConfig名を指定しているが名称は適当でよい。各Config内に[INPUT] [FILTER] [OUTPUT] を定義していく。\n confの種類 containers.conf\nfluentbit, cloudwatch-agentやアプリ個別ログを定義。簡素化のため対象を絞っているが、aws-node, kube-proxy, corednsのログを送信する場合もここに含める。\nkube-systemd.conf\ndocker,kubeletのログを定義。\nhost.conf\nOS上のログ（基本的に/var/log/配下の各種ログ）を定義。簡素化のためここではmessagesのみ定義している。他に送信したい種別は同様に設定する。\nparsers.conf\nログフォーマットのパースの定義\n fluentbit-sample-app.yaml\napiVersion: v1 kind: ConfigMap metadata: name: fluent-bit-config namespace: amazon-cloudwatch labels: k8s-app: fluent-bit-sample data: fluent-bit.conf: |[SERVICE] Flush 5 Log_Level info Daemon off Parsers_File parsers.conf storage.path /var/fluent-bit/state/flb-storage/ storage.sync normal storage.checksum off storage.backlog.mem_limit 5M @INCLUDE containers.conf @INCLUDE kube-systemd.conf @INCLUDE host.conf # containers.confの定義 containers.conf: |[INPUT] Name tail Tag fluentbit.* Path /var/log/containers/fluentbit* Parser docker DB /var/fluent-bit/state/flb_log.db Mem_Buf_Limit 5MB Skip_Long_Lines On Refresh_Interval 10 Read_from_Head ${READ_FROM_HEAD} [INPUT] Name tail Tag cloudwatch-agent.* Path /var/log/containers/cloudwatch-agent* Docker_Mode On Docker_Mode_Flush 5 Docker_Mode_Parser cwagent_firstline Parser docker DB /var/fluent-bit/state/flb_cwagent.db Mem_Buf_Limit 5MB Skip_Long_Lines On Refresh_Interval 10 Read_from_Head ${READ_FROM_HEAD} [INPUT] Name tail Tag sample-app.* Path /var/log/containers/sample-app* Parser docker DB /var/fluent-bit/state/flb_sample-app.db Mem_Buf_Limit 5MB Skip_Long_Lines On Refresh_Interval 10 Read_from_Head ${READ_FROM_HEAD} # 各INPUTに対応するFILTERを定義する [FILTER] Name kubernetes Match fluentbit.* Kube_URL ${MASTER_URL} Kube_Tag_Prefix fluentbit.var.log.containers. Merge_Log On Merge_Log_Key log_processed K8S-Logging.Parser On K8S-Logging.Exclude Off Annotations Off [FILTER] Name kubernetes Match cloudwatch-agent.* Kube_URL ${MASTER_URL} Kube_Tag_Prefix cloudwatch-agent.var.log.containers. Merge_Log On Merge_Log_Key log_processed K8S-Logging.Parser On K8S-Logging.Exclude Off Annotations Off [FILTER] Name kubernetes Match sample-app.* Kube_URL ${MASTER_URL} Kube_Tag_Prefix sample-app.var.log.containers. Merge_Log On Merge_Log_Key log_processed K8S-Logging.Parser On K8S-Logging.Exclude Off Annotations Off # アイテムの変換や不要なメタデータ送信抑止を定義 [FILTER] Name nest Match * Operation lift Nested_under kubernetes Add_prefix Nested. [FILTER] Name modify Match * Rename Nested.docker_id Docker.container_id [FILTER] Name nest Match * Operation nest Wildcard Nested.* Nested_under kubernetes Remove_prefix Nested. [FILTER] Name nest Match * Operation nest Wildcard Docker.* Nested_under docker Remove_prefix Docker. [FILTER] Name nest Match * Operation lift Nested_under kubernetes Add_prefix Kube. [FILTER] Name modify Match * Remove Kube.container_hash  Remove Kube.container_image Remove Kube.pod_id [FILTER] Name nest Match * Operation nest Wildcard Kube.* Nested_under Kubernetes Remove_prefix Kube. # 送信時の定義 # ロググループ名例：/eks/stg/sample-app_fluentbit # ログストリーム名例：ip-10-1-2-3.ap-northeast-1.compute.internal_[Pod名]_[ネームスペース]_[コンテナ名] # $(tag[4])とした場合、上記のようなkubeのタグ定義が投入され、ユニークなログストリーム名になる。 [OUTPUT] Name cloudwatch Match fluentbit.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_fluentbit log_stream_name ${HOST_NODE_NAME}_$(tag[4]) auto_create_group true extra_user_agent container-insights Retry_Limit 5 [OUTPUT] Name cloudwatch Match cloudwatch-agent.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_cwagent log_stream_name ${HOST_NODE_NAME}_$(tag[4]) auto_create_group true extra_user_agent container-insights Retry_Limit 5 # 個別アプリログ送信用定義 [OUTPUT] Name cloudwatch Match sample-app.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_application log_stream_name ${HOST_NODE_NAME}_$(tag[4]) auto_create_group true extra_user_agent container-insights Retry_Limit 5 # docker,kubenetesログ定義 kube-systemd.conf: |[INPUT] Name systemd Tag dockerlog.systemd.* Systemd_Filter _SYSTEMD_UNIT=docker.service DB /var/fluent-bit/state/systemd.db Path /var/log/journal Read_From_Head ${READ_FROM_HEAD} [INPUT] Name systemd Tag kubelet.systemd.* Systemd_Filter _SYSTEMD_UNIT=kubelet.service DB /var/fluent-bit/state/systemd.db Path /var/log/journal Read_From_Head ${READ_FROM_HEAD} [FILTER] Name modify Match dockerlog.systemd.* Rename _HOSTNAME hostname Rename _SYSTEMD_UNIT systemd_unit Rename MESSAGE message Remove_regex ^((?!hostname|systemd_unit|message).)*$ [FILTER] Name modify Match kubelet.systemd.* Rename _HOSTNAME hostname Rename _SYSTEMD_UNIT systemd_unit Rename MESSAGE message Remove_regex ^((?!hostname|systemd_unit|message).)*$ [OUTPUT] Name cloudwatch Match kubelet.systemd.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_docker log_stream_name ${HOST_NODE_NAME}_$(tag[2]) auto_create_group true extra_user_agent container-insight [OUTPUT] Name cloudwatch Match kubelet.systemd.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_kubelet log_stream_name ${HOST_NODE_NAME}_$(tag[2]) auto_create_group true extra_user_agent container-insight # messages等、OSのログ定義 host-log.conf: | [INPUT] Name tail Tag host.messages Path /var/log/messages Parser syslog DB /var/fluent-bit/state/flb_messages.db Mem_Buf_Limit 5MB Skip_Long_Lines On Refresh_Interval 10 Read_from_Head ${READ_FROM_HEAD} # host.confの[OUTPUT]定義は、複数のINPUTがあっても1つでよい。 # $(tag[1]) にはこの場合messagesが入る。 [OUTPUT] Name cloudwatch Match host.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_$(tag[1]) log_stream_name ${HOST_NODE_NAME}_$(tag[1]) auto_create_group true extra_user_agent container-insights Retry _Limit 5 parsers.conf: |[PARSER] Name docker Format json Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%LZ [PARSER] Name syslog-rfc5424 Format regex Regex ^(?\u0026lt;time\u0026gt;[^ ]* {1.2}[^ ]* [^ ]*) (?\u0026lt;host\u0026gt;[^ ]*) (?\u0026lt;ident\u0026gt;[a-zA-Z0-9_¥/¥.¥-]*) (?:¥[?\u0026lt;pid\u0026gt;[-0-9]+)¥])?(?:[^¥:]*¥:)? * (?\u0026lt;message\u0026gt;.*)$ Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%L Time_Strict Off [PARSER] Name container_firstline Format regex Regex (?\u0026lt;log\u0026gt;(?\u0026lt;=\u0026#34;log\u0026#34;:\u0026#34;)\\S(?!\\.).*?)(?\u0026lt;!\\\\)\u0026#34;.*(?\u0026lt;stream\u0026gt;(?\u0026lt;=\u0026#34;stream\u0026#34;:\u0026#34;).*?)\u0026#34;.*(?\u0026lt;time\u0026gt;\\d{4}-\\d{1,2}-\\d{1,2}T\\d{2}:\\d{2}:\\d{2}\\.\\w*).*(?=}) Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%LZ [PARSER] Name cwagent_firstline Format regex Regex (?\u0026lt;log\u0026gt;(?\u0026lt;=\u0026#34;log\u0026#34;:\u0026#34;)\\d{4}[\\/-]\\d{1,2}[\\/-]\\d{1,2}[ T]\\d{2}:\\d{2}:\\d{2}(?!\\.).*?)(?\u0026lt;!\\\\)\u0026#34;.*(?\u0026lt;stream\u0026gt;(?\u0026lt;=\u0026#34;stream\u0026#34;:\u0026#34;).*?)\u0026#34;.*(?\u0026lt;time\u0026gt;\\d{4}-\\d{1,2}-\\d{1,2}T\\d{2}:\\d{2}:\\d{2}\\.\\w*).*(?=}) Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%LZ --- apiVersion: apps/v1 kind: DaemonSet metadata: name: fluent-bit-sample namespace: amazon-cloudwatch labels: k8s-app: fluent-bit-sample version: v1 kubernetes.io/cluster-service: \u0026#34;true\u0026#34; spec: selector: matchLabels: k8s-app: fluent-bit-sample template: metadata: labels: k8s-app: fluent-bit-sample version: v1 kubernetes.io/cluster-service: \u0026#34;true\u0026#34; spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: nodelabel operator: In values: - STG-NODELABEL-APP-001 containers: - name: fluent-bit-sample image: amazon/aws-for-fluent-bit:2.12.0 imagePullPolicy: Always env: - name: AWS_REGION valueFrom: configMapKeyRef: name: fluentbit-cluster key: logs.region - name: CLUSTER_NAME valueFrom: configMapKeyRef: name: fluentbit-cluster key: cluster.name - name: READ_FROM_HEAD valueFrom: configMapKeyRef: name: fluentbit-cluster key: read.head - name: READ_FROM_TAIL valueFrom: configMapKeyRef: name: fluentbit-cluster key: read.tail - name: HOST_NODE_NAME valueFrom: fieldRef: fieldPath: spec.nodeName - name: CI_VERSION value: \u0026#34;k8s/1.3.8\u0026#34; # これ以降独自に設定追加。設定項目はユースケースに合わせてください。 - name: ENVIRONMENT value: \u0026#34;stg\u0026#34; - name: NODEGROUP value: \u0026#34;sample-app\u0026#34; - name: MASTER_URL value: \u0026#34;https://kubernetes.default.svc:443\u0026#34; resources: limits: cpu: 200m memory: 200Mi requests: cpu: 200m memory: 100Mi volumeMounts: # Please don\u0026#39;t change below read-only permissions - name: fluentbitstate mountPath: /var/fluent-bit/state - name: varlog mountPath: /var/log readOnly: true - name: varlibdockercontainers mountPath: /var/lib/docker/containers readOnly: true - name: fluent-bit-config mountPath: /fluent-bit/etc/ - name: runlogjournal mountPath: /run/log/journal readOnly: true - name: dmesg mountPath: /var/log/dmesg readOnly: true terminationGracePeriodSeconds: 90 volumes: - name: fluentbitstate hostPath: path: /var/fluent-bit/state - name: varlog hostPath: path: /var/log - name: varlibdockercontainers hostPath: path: /var/lib/docker/containers - name: fluent-bit-config configMap: name: fluent-bit-config - name: runlogjournal hostPath: path: /run/log/journal - name: dmesg hostPath: path: /var/log/dmesg serviceAccountName: fluent-bit tolerations: - key: node-role.kubernetes.io/master operator: Exists effect: NoSchedule - operator: \u0026#34;Exists\u0026#34; effect: \u0026#34;NoExecute\u0026#34; - operator: \u0026#34;Exists\u0026#34; effect: \u0026#34;NoSchedule\u0026#34;  補足説明 imageパスの指定\n上記ではコンテナイメージをインターネットを通って都度落とすようになっているが、業務利用時はECRに格納してプライベートな通信で完結させるのが望ましい。ECRに格納した場合は以下のように指定する。\nimage: [AWS-AccoundID].dkr.ecr.ap-northeast-1.amazon.com/[repo-name]:2.12.0  nodeAffinityで起動するノードを指定\n今回の事例では、sample-appのPodが起動するワーカーノード上にsample-appログ送信用のDaemonSetを起動させる必要がある。そのためnodeAffinityを定義する。EKSノードグループのラベルにkey:nodelabel values:STG-SAMPLE-APPを設定している前提の場合以下の様になる。sample-app用のマニフェストにも同様の記述をする。\n spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: nodelabel operator: In values: - STG-SAMPLE-APP  停止時のGracePeriod\nDaemonSetがKillシグナル受信後に削除されるまでの猶予時間を指定。公式サンプル10秒だと、コンテナログを送信しきる前に削除されてしまう可能性がある。ここでは余裕を持たせて90秒。\nterminationGracePeriodSeconds: 90  syslogのPARSER\nAWS公式の設定だとTime_FormatがダメらしきエラーがでるのでFluent Bit公式の例を適用した。Fluent Bit公式ではsyslogではなくsyslog-rfc5424。ではINPUTのParserはsyslogではなくsyslog-rfc5424とするのが正ではないか？と思ったが、そうすると動作しない。謎だが深追いはしない。Time_StrictはOffにしておく。しかしそれでもまだエラーになるので調べると、Regexの正規表現が原因らしいのでそこも直した。参照サイトは失念。\n DaemonSetの起動〜ログ送信\n今回cloudwatch-agentについては触れていないが、cloudwatch-agentネームスペースが存在している状態でマニフェストをapplyする。この時点ではノードグループは停止中でもよい。\n$ kubectl apply -f fluentbit-cluster.yaml $ kubectl apply -f fluentbit-sample-app.yaml  ノードグループが起動すると、各種ログがCloudWatchLogsに送信される。アプリ用マニフェストをapplyすればアプリログも送信される。\nあとresourceのcpuはデフォルトが500mになっていたが、そこまで割り当てなくてもちゃんと動作する。よほどのことがなければ100mでもいい気がする。メモリもFlunetdに比べて全然余裕。さすが軽量版。その他細かいチューニング項目もあるにはあるのだが、これ以上の長文は避けたいのでまた別の機会に投稿しようと思う。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/fluentbit/","summary":"AWS EKSでPodからログを送信する場合、Container Insightsを組み込んでFluentdかFluent Bitを利用するのが一般的と思われる。そしてFluent BitよりFluentdの方がメジャーなのでまずはそこから入る事例が多いと想像する。しかし、元々組み込みLinux用に開発されて軽量リソースで動作するFluent Bitの方がコンテナログ送信に向いていると思う。ということで、この記事ではFluent Bitに焦点を当てる。\n 参照\nFluent Bit ドキュメント（設定詳細は画面左「DATA PIPELINE」配下のメニュー参照）\nFluent Bit Documentation\nContainer Insights全般\nAmazon EKS と Kubernetes での Container Insights のセットアップ\nFluent Bit on Container Insights\nCloudWatch Logs へログを送信する DaemonSet として Fluent Bit を設定する\nサンプルマニフェスト\nfluent-bit-compatible.yaml\n※AWSがサンプルとして提供しているFluent BitのマニフェストはFluent Bit最適化用とFluentd互換用がある。今回は過去にFluentd使用事例があることから、Fluentd互換用マニフェストをDLしてカスタマイズした。\n 共通マニフェスト例 クラスタの全般的な設定と、アプリ個別のケースでマニフェストを二つに分けた。AWS公式では基本となるEKSクラスタの定義をコマンドでセットしているが、運用の際はマニフェストに落とし込むのが普通だと思う。以下のようなマニフェストを共通用として作成し、個別のマニフェストから参照させる。EKSクラスタ名はdata:cluster.nameで指定している。\nfluentbit-cluster.yaml\napiVersion: v1 kind: ConfigMap metadata: name: fluentbit-cluster namespace: amazon-cloudwatch selfLink: /api/v1/namespaces/amazone-cloudwatch/configmaps/fluentbit-cluster data: cluster.name: EKS-SAMPLE-CLUSTER log.region: ap-northeast-1 read.head: \u0026#34;On\u0026#34; read.tail: \u0026#34;Off\u0026#34; --- apiVersion: v1 kind: ServiceAccount metadata: name: fluent-bit namespace: amazon-cloudwatch --- apiVersion: rbac.","title":"EKS Container InsightsのFluent Bit設定"},{"content":"マークダウン記法の参考リンク。取り急ぎこれくらいあればいいかな。\n  Markdown 早見表 \u0026amp; 詳細\n  かんたんMarkdownの記法\n  Markdown記法 チートシート\n  GitHub Markdownの「シンタックスハイライト」に対応している言語一覧\n   ","permalink":"https://ecnedaced-seirots.github.io/post/a/markdown/","summary":"マークダウン記法の参考リンク。取り急ぎこれくらいあればいいかな。\n  Markdown 早見表 \u0026amp; 詳細\n  かんたんMarkdownの記法\n  Markdown記法 チートシート\n  GitHub Markdownの「シンタックスハイライト」に対応している言語一覧\n   ","title":"マークダウン記法"},{"content":"とりあえず最初の投稿。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/first/","summary":"とりあえず最初の投稿。\n ","title":"最初の投稿"}]