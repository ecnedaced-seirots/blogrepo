[{"content":"簡単そうとなめていると罠にはまりがちなAWS CodeDeployについて、いくつか覚書。\n 単純化しているが以下のサンプルを元にする。\nappspec.yml\nversion: 0.0 os: linux files: - source: /opt/script  #ディレクトリ自体を配布 destination: /opt/script - source: /opt/conf/server.conf  #特定のファイルを配布 destination: /opt/conf file_exists_behavior: OVERWRITE  #既存ファイルの上書き指定 permissions: - object: /opt/script  #/opt/script配下のディレクトリすべて指定したパーミッションになる pattern: \u0026#34;**\u0026#34; owner: root group: root mode: 755 type: - directory - object: /opt/script pattern: \u0026#34;*.sh\u0026#34; owner: root group: root mode: 755 type: - file - object: /opt/conf  #/opt/script配下のshファイルはすべて指定したパーミッションになる pattern: \u0026#34;**\u0026#34; owner: root group: root mode: 755 type: - directory - object: /opt/conf  #/opt/conf内のserver.confに対するパーミッションを指定 pattern: \u0026#34;server.conf\u0026#34; owner: root group: root mode: 644 type: - file hooks: AfterInstall: - location: ./deploy_task  #hookスクリプトファイルを相対パスで指定 timeout: 300  1.filesセクションの記述 appspec.ymlのfilesセクションがわかっているようでわかっていなかった。ひとつのappspec.ymlに複数のパターンがあると気をつけていても間違える。\nfiles\nsource: ディレクトリ配布の場合はディレクトリ名を、個別ファイルの場合はファイル名を指定。\ndestination: ディレクトリ名を指定。\ndestinationではファイル名は指定しない。（これ重要）\n 2. CodeDeployの上書きオプション OSに最初から入っている既存のファイルやリビジョンに加える前から存在しているファイルを配布したい場合、デフォルトだとalready exists.と言われてエラーになる。\n  The deployment failed because a specified file already exists at this location\n  CodeDeployエージェント 1.3.2以降のバージョンであれば、appspec.ymlのfilesセクションにfile_exists_behaviorオプションを指定すれば期待値になる。\nfiles: - source: /opt/script destination: /opt/script - source: /opt/conf/server.conf destination: /opt/conf file_exists_behavior: OVERWRITE  #既存リソースに対する動作を上書きとして指定  file_exists_behaviorに指定可能な値は DISALLOW|OVERWRITE|RETAIN のどれか。詳細は以下参考。\n参考\nAppSpecの「files」セクション\n 3. デプロイ後のファイルタイムスタンプ問題 現状の仕様により、CodePipelineでソースアクションとしてCodeCommitをソースにした場合、ファイルのタイムスタンプを取得できないという問題がある。何もしないとデプロイ後のタイムスタンプが1979年12月29日になってしまう。これを是正するため、以下のhookスクリプトによりデプロイ時点の時刻をタイムスタンプとしてセットする。\nミドルウェアの設定ファイルを配布する場合は、この後プロセス再起動の処理を書くこともできる。\ndeploy_task\n#!/bin/bash  touch /opt/script/* touch /opt/conf/*  4. AMIから復旧させたインスタンスのリビジョン 過去のインスタンスで実行した既存のデプロイは、teriminate後にAMIから復旧させたインスタンスでもリビジョン対象として認識される。このためfile_exists_behaviorがなくてもデプロイは可能である。（しかしその後の変更時にエラーを回避したければ、つけておく方が安心）\n 5. リビジョン対象資材削除時の対応 検索したが意外に情報がない。ほぼ皆無だ。以下、仕方ないので自分で検証して判明した結果より。\n(1) ディレクトリ内の資材一部の削除 リポジトリ内の対象資材をGit上から削除する。コミット/pushするとデプロイ時にその資材は削除された状態になる。サンプルymlの例で言うと、/opt/script内に複数のスクリプトがあるとして、その中の一つを削除したければGit上でdeleteし、appspec.ymlは変更なしでよい。\n(2) filesセクションで特定のファイルを削除する appspec.ymlのfilesセクションから対象のsource/destination行を削除する。permissionセクションからも削除。サンプルymlからserver.confを削除する場合、以下2行を削除する。\n- source: /opt/conf/server.conf destination: /opt/conf  さらに以下も削除。\n- object: /opt/conf pattern: \u0026#34;server.conf\u0026#34; owner: root group: root mode: 644 type: - file  ただし、これを実行すると「対象のファイルだけリビジョン対象外としてディレクトリは残す」ことができない。（ディレクトリの階層の状況にもよる）デプロイで期待値にならない部分は手動で対応するしかなさそうである。\n  ","permalink":"https://ecnedaced-seirots.github.io/post/b/aws-codedeploy-tips/","summary":"\u003cp\u003e簡単そうとなめていると罠にはまりがちなAWS CodeDeployについて、いくつか覚書。\u003c/p\u003e","title":"AWS CodeDeploy備忘録"},{"content":"村上龍著「愛と幻想のファシズム」より。\n  こいつらは簡単にだまされる。飢えているからだ。疲れて、参っている奴らは、たとえ嘘だとわかっていても暖かい光景に飢えているのだ。飢餓や混乱の経験がなく、いつも見慣れている風景が一瞬にして殺戮の廃墟と化すことがあると知らない奴らは、弱い。気付かない。暖かい心や言葉や光景は永遠のものだと信じていて、人間も風景もあっという間に変わってしまうのだと気付かない。\n  俺がヒューマニズムとセンチメンタリズムを敵視する理由はこの引用にも表現されている。\n 反吐が出そうな偽善民主主義ファシズムに覆われた、糞みたいな世界。こんな世界で奴隷ではない生き方で生きようとしたら、それこそ鈴原冬二のごとく、快楽とともに極限まで獲物を狙い、敵を見据えて戦う意志がなけりゃいけない。\n ","permalink":"https://ecnedaced-seirots.github.io/post/b/ryu-quotes-8/","summary":"\u003cp\u003e村上龍著「愛と幻想のファシズム」より。\u003c/p\u003e","title":"「愛と幻想のファシズム」より(6)"},{"content":"Go言語におけるif文の基本覚書。\n 今回も細かい話は抜きにして、サンプル構文。\nif_1.go\npackage main import \u0026#34;fmt\u0026#34; func main() { num := 1 if num \u0026gt; 0 { fmt.Println(\u0026#34;正の数です。\u0026#34;) } //変数定義と条件式を1行で記述してもよい  if num := 1; num \u0026gt; 0 { fmt.Println(\u0026#34;これも正の数です。\u0026#34;) } }  結果\n正の数です。 これも正の数です。  if_2.go\npackage main import \u0026#34;fmt\u0026#34; func main() { if 1 == 1 { fmt.Println(\u0026#34;番号は1です。\u0026#34;) } if true { fmt.Println(\u0026#34;trueです。\u0026#34;) } if false { fmt.Println(\u0026#34;falseです。\u0026#34;) } if !true { fmt.Println(\u0026#34;trueじゃないです。\u0026#34;) } if !false { fmt.Println(\u0026#34;falseじゃないです。ということはtrueです。\u0026#34;) } }  結果。trueの場合のみ出力が発生している。\n番号は1です。 trueです。 falseじゃないです。ということはtrueです。  Pythonに置き換えると。\nif.py\ndef main(): num = 1 if num \u0026gt; 0: print(\u0026#34;正の数です。\u0026#34;) if 1 == 1: print(\u0026#34;番号は1です。\u0026#34;) if True: print(\u0026#34;Trueです。\u0026#34;) if False: print(\u0026#34;Falseです。\u0026#34;) if not True: print(\u0026#34;Trueじゃないです。\u0026#34;) if not False: print(\u0026#34;Falseじゃないです。ということはTrueです。\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: main()  結果\n正の数です。 番号は1です。 Trueです。 Falseじゃないです。ということはTrueです。  参考\n【Go入門】if文による条件分岐とtrue, false\n  ","permalink":"https://ecnedaced-seirots.github.io/post/b/golang-init-if/","summary":"\u003cp\u003eGo言語におけるif文の基本覚書。\u003c/p\u003e","title":"Go入門(8) - if文の基本"},{"content":"画像処理ライブラリのOpenCVをいじってみようと思った。OpenCVがやりたいというより、Python + 画像処理なら両方好きだからモチベーションを維持できそうと思ったのだ。\n Macにインストールする。インストール方法が複数あり、その時点でどれを選んでいいか分からずつまづく派が多いらしい。とりあえずpipがおすすめらしいのでそれでいく。\n$ pip3 install opencv-python : : $ pip3 freeze boto3==1.18.63 botocore==1.21.63 Jinja2==2.11.2 jmespath==0.10.0 MarkupSafe==1.1.1 numpy==1.21.4 #numpyも一緒に入る opencv-python==4.5.5.62 pandas==1.3.4 python-dateutil==2.8.2 (snip)  適当なディレクトリに画像ファイルと以下コードを格納する。\ninit.py\nimport cv2 img = cv2.imread(\u0026#39;img_01.png\u0026#39;) #イメージファイルを指定 cv2.imshow(\u0026#39;Yellow\u0026#39;, img) #ウィンドウ名とイメージファイルを指定 cv2.waitKey(0) #これを記述することで、ファイルオープンの状態が継続する cv2.destroyAllWindows() #キーボード入力があった時点で終了  上記はカレントディレクトリにファイルが存在する前提。それ以外の場合は絶対パスか相対パスで指定する。実行すると以下のように画像が開く。何かキーボート入力すると閉じる。\n 何もしてないに等しいが、今日はここまで。\n参考\n【初心者向け】PythonとOpenCVで画像処理を体験してみよう\n ","permalink":"https://ecnedaced-seirots.github.io/post/b/python-opencv-1/","summary":"\u003cp\u003e画像処理ライブラリのOpenCVをいじってみようと思った。OpenCVがやりたいというより、Python + 画像処理なら両方好きだからモチベーションを維持できそうと思ったのだ。\u003c/p\u003e","title":"PythonでOpenCV始めてみる"},{"content":"Goのmap操作続き。range, 追加やdeleteなど。\n 要素の追加。\npackage main import \u0026#34;fmt\u0026#34; func main() { city := map[string]int{ \u0026#34;NY\u0026#34;: 100, \u0026#34;London\u0026#34;: 200, \u0026#34;Tokyo\u0026#34;: 300, } fmt.Println(city) fmt.Println(city[\u0026#34;London\u0026#34;]) //key \u0026#34;London\u0026#34;の値出力  fmt.Println(city[\u0026#34;Bangkok\u0026#34;]) //要素がないkeyの値は0  v, ok := city[\u0026#34;Bangkok\u0026#34;] //\u0026#34;Bangkok\u0026#34;の値と真偽を確認  fmt.Println(v) fmt.Println(ok) city[\u0026#34;Bangkok\u0026#34;] = 400 //要素\u0026#34;Bangkok\u0026#34;を追加  //要素と値の真偽を取得し、trueの場合に処理を実行  if v, ok := city[\u0026#34;Bangkok\u0026#34;]; ok { fmt.Println(v) } }  結果\nmap[London:200 NY:100 Tokyo:300] 200 0 0 false 400  rangeを使ってloop処理。\npackage main import \u0026#34;fmt\u0026#34; func main() { city := map[string]int{ \u0026#34;NY\u0026#34;: 100, \u0026#34;London\u0026#34;: 200, \u0026#34;Tokyo\u0026#34;: 300, } //keyにBangkokを追加  city[\u0026#34;Bangkok\u0026#34;] = 400 //rangeでループ処理してkey:valueを出力  for k, v := range city { fmt.Println(k, v) } }  結果\nBangkok 400 NY 100 London 200 Tokyo 300  要素の削除。\npackage main import \u0026#34;fmt\u0026#34; func main() { city := map[string]int{ \u0026#34;NY\u0026#34;: 100, \u0026#34;Tokyo\u0026#34;: 300, } fmt.Println(city) //\u0026#34;NY\u0026#34;を削除  delete(city, \u0026#34;NY\u0026#34;) fmt.Println(city) //要素と値の真偽を取得し、trueの場合に削除処理を実行  if v, ok := city[\u0026#34;Tokyo\u0026#34;]; ok { fmt.Println(\u0026#34;num:\u0026#34;, v) delete(city, \u0026#34;Tokyo\u0026#34;) } fmt.Println(city) //空のmapが出力される }  結果\nmap[NY:100 Tokyo:300] map[Tokyo:300] num: 300 map[]  Pythonに置き換えると。\ndict2.py\ndef main(): city = {\u0026#34;NY\u0026#34;: 100, \u0026#34;Tokyo\u0026#34;: 300} print(city) # 辞書に要素を追加 city[\u0026#34;Bangkok\u0026#34;] = 400 print(city) # popで要素を削除 print(city.pop(\u0026#34;NY\u0026#34;)) print(city) # clearで辞書データを削除 city.clear() print(city) if __name__ == \u0026#34;__main__\u0026#34;: main()  結果\n{'NY': 100, 'Tokyo': 300} {'NY': 100, 'Tokyo': 300, 'Bangkok': 400} 100 {'Tokyo': 300, 'Bangkok': 400} {}  参考\n【Go入門】mapの操作 – 要素の追加, range, delete\n  ","permalink":"https://ecnedaced-seirots.github.io/post/b/golang-init-map-2/","summary":"\u003cp\u003eGoのmap操作続き。range, 追加やdeleteなど。\u003c/p\u003e","title":"Go入門(7) - mapのrange,deleteなど"},{"content":"「コインロッカーベイビーズ」(村上龍）の英語翻訳版 “Coin Locker Babies\u0026quot;より、クライマックスに近づくあたりのシーン。\n キクとアネモネが小笠原の孤島からやってきた真夏のTokyoで、中古で購入したバイクに乗って高速道路を走るところ。すごくかっこよくて、かつ非常に重要なシーンなのだが、なんと英語版は以下赤字snipとしている箇所が抜けている！\n  Nothing ever changes, he thought. Everbodys' still trying to break out of themselves, hoping for that new wind to blow through and shake their hearts awake. (snip) But for us, for all the babies who slept their first sleep in those muggy boxes, who head that sound, the only sound there was until the air first touched our skin \u0026ndash; the sound of our mothers' hearts\u0026ndash;nothing ever changes. How could it? How could any of us forget \u0026ndash; a sign that came to us in the dark, endlessly, ceaselessly, wiht just one message, over and over and over again? \u0026hellip;\n    何一つ変わっていない、誰もが胸を切り開き新しい風を受けて自分の心臓の音を響かせたいと願っている、渋滞する高速道路をフルスロットルですり抜け疾走するバイクライダーのように生きたいのだ、俺は跳び続ける、ハシは歌い続けるだろう、夏の柔らかな箱で眠る赤ん坊、俺達はすべてあの音を聞いた、空気に触れるまで聴き続けたのは母親の心臓の鼓動だ。一瞬も休みなく送られてきたその信号を忘れてはならない。信号の意味はただ一つだ。\n  (snip)部分に相当するのは下原文の赤字箇所である。その後に続くセンテンスも、意味としては原文とほぼ同等だが若干表現が異なる。それは翻訳のスタイルだからいいとして、ここは削除しないで欲しかったなぁ、キクが「ハシは歌い続けるだろう」とつぶやくこの部分を知っているか知らないかで、この後に続くクライマックスの受け止め方が相当ブレる。（俺は、つまりキクはハシがTokyoで歌い続けることを確信した上で破壊物質のダチュラをばら撒いたという関係性を、原文を読んでやっと呑み込めた）\n そして、端折られているのはここだけじゃない。英語版を読み終わってから原文のラスト十数ページだけ読んだところ、数ページ分まるごと抜けていた！ハシが病院のNevaを訪ねて、そこで拉致られるあたりの数ページが。どうりで、話の展開についていけなかったわけだよ。（小説後半はハシの妄想シーンが多く占めていたから、展開がわけがわからないのはそういうもんだと軽く流してた。）うーん、数ページ削除ってさすがに乱暴すぎないか。\n全体通すと他にもカットシーンがあるんだろうな、映画をTVで放映する際にいくつかカットされたりする、あれと同じだ。いや、翻訳版はそういうのがあるってのは知っていたけど、冒頭の箇所はすごく重要なセンテンスだから端折らないで欲しかったな（2度目）、翻訳者の意向か編集側の意向か知らないけど。\n \u0026hellip;て、まぁこれについては若干モヤモヤ感があるものの、英語版の「コインロッカーベイビーズ」を読んですげぇよかったと思う、日本語の原文より刺さったからね、強烈に痺れる文章が何箇所かあった、英語で読むと日本語より集中するし、言葉が頭に入ってくる回路が違うから、日本語で読むのとは別の快楽・喜びがあるんだな。こんな時、長文読解鍛えておいてよかったとつくづく思う。\nしかし実は出だしは鈍くてなかなか進まなくて、完読に3ヶ月くらいかかるんじゃないかと思ってた。去年12月中旬に読み始めて先週半ばに読了したけど、当初はまさか1ヶ月ちょいで読み終わるとは思っていなかった。最後の方はめっちゃスパートかけた、やればできるじゃん、俺。\n野暮なことは語りたくないからゴチャゴチャ言わないけど、英語読解の復習も兼ねて今後もちょっとずつ引用していこうと思う。\n ","permalink":"https://ecnedaced-seirots.github.io/post/b/ryu-quotes-7/","summary":"\u003cp\u003e「コインロッカーベイビーズ」(村上龍）の英語翻訳版 “Coin Locker Babies\u0026quot;より、クライマックスに近づくあたりのシーン。\u003c/p\u003e","title":"Coin Locker Babies-2, Ryu Murakami"},{"content":"AWS Lambdaは関数が呼び出されると自動でCloudWatch Logsにログを吐く。このログの監視についてベストプラクティスを考えてみた。\nこれまでやってきた検証では、Lambdaとは無関係のロググループにエラー出力させて、そのログのサブスクリプションフィルタのターゲットにログ監視用Lambda関数を指定している。一方、Lambda自体のログを監視するには若干捻りが必要そうである。\n 以下記事のように、適当なLambda関数のログにサブスクリプションフィルタを設定してエラー検知 ＆ SNS連携でメッセージ通知させること自体は問題ない。\nCloudWatch Logsの特定文字を検知してログ内容を通知するLambda Function\n 一応、実際に試してみた。\n Lambda① 適当な処理を実行 Lambda② ログ監視用関数。SNSと連携してメール送信  Lambda①のログにサブスクを設定。ターゲットはLambda②とする。これだけなら動作は想定内で、Lambda①でエラーログを1回発生させたら、Lambda②により通知メールが1回送信された。\n しかしLambda①も監視用の関数の場合は注意が必要である。例えばその関数がアラーム監視に紐付いている場合の挙動を想定すると：\n-＞Lambda①にエラー要因がなければ、アラームトリガー発生時は設定したSNSに連携され、ログにはエラーが出ない。（ログ監視通知は飛ばない）\nここまではいいとして、気をつけたいのはLambda①にエラー要因がある状態でトリガー発生した場合:\n-＞ Lambdaログにエラーが吐き出され、サブスクが検知 -＞ ログ監視通知のLambdaが起動し、通知を送信する。\nアラーム監視自体で大量にトリガーが発生した場合、Lambdaのログエラーもそれに準じて高騰することになり、2倍に大量通知が飛ぶことになる。やってはいけないレベルではないかもしれないが、ソリューションは検討しておく必要がある。\nそして、Lambda①がログ監視用関数の場合はそれ自体にLambdaをターゲットとするサブスクを設定してはいけない。\n  無限の呼び出しループが作成されるため、ログ配布関数のロググループにサブスクライブすることは避けてください。\n AWS Lambdaでのロギングのベストプラクティス\n つまり、Lambda②のログはLambdaと連携させての監視はできない。他のターゲットなら可能かは不明。どちらにしろ、logsのサブスクは直接SNSに連携できないし、これだけのためにKinesis他のソリューションを採用するのも大袈裟だ。いや、どうしてもっていうなら他の仕組みを実装するしかないけど、自動通知が必須でなければ運用回避でもいいわけで。そんな中以下の記事を目にして、一瞬ハッとした。\n  エラー出力をする前に、なんのために必要なのか考えないといけない\nよく自分も陥りがちなのは、「色々な例外がありそうだからとりあえずERROR出力をする」といったパターンです。とりあえず設定したログレベルは、一度リリースされると改修による不具合発生のリスクや、リソースの都合でななかな変更できない事が多いと思います。\n本当に検知や対処が必要なものであればERROR出力は必要です。しかし、ERROR通知を受けた後何もしないのであれば、通知する必要はないのかもしれません。実装の時点で、検知したエラーを元に何をしたいのかを考慮した上で適切なログレベルをつける事が大切です。\n Serverless時代のシステム監視、ノイズ通知だらけな日々を経験しての反省点\n 発想の転換。自分も「とにかくエラーは通知しなければいけない」と思い込んでいたふしがある。ちょっとクールダウンして再検討しよう。\n ","permalink":"https://ecnedaced-seirots.github.io/post/b/aws-lambda-log-monitoring/","summary":"\u003cp\u003eAWS Lambdaは関数が呼び出されると自動でCloudWatch Logsにログを吐く。このログの監視についてベストプラクティスを考えてみた。\u003c/p\u003e","title":"AWS Lambdaのログ監視方法を考えてみる"},{"content":"TerraformでNAT Gatewayを作る。EKS Fargateの検証する時に、EKSリソースと一緒に自動生成したいからだ。\n ちなみに手動作成の手順は以下。\nAWS NATゲートウェイの作成と設定\n NATゲートウェイを作るだけなら、以下コードだけでよい。\nnat.tf\n########################################### # EIP ########################################### resource \u0026quot;aws_eip\u0026quot; \u0026quot;poc_eip\u0026quot; { vpc = true } ########################################### # NAT Gateway ########################################### resource \u0026quot;aws_nat_gateway\u0026quot; \u0026quot;nat_gw\u0026quot; { allocation_id = aws_eip.poc_eip.id subnet_id = var.public-a tags = { Name = \u0026quot;NAT-for-PoC\u0026quot; } # To ensure proper ordering, it is recommended to add an explicit dependency # on the Internet Gateway for the VPC. # depends_on = [aws_internet_gateway.example] }  先にEIPを作ってNATゲートウェイに割り当てている。このEIPはリソースに関連付けている限りは課金対象外だが、関連付けリソースから外れると課金対象になる。このためNATゲートウェイ削除時にはEIPもリリースしないといけないが、忘れがちなので要注意である。Terraformで作成するならTerraform destroy時に一緒にリリースされるはずだから安心だ。（しかし未検証）\n で、上記をapplyするとEIPとNATゲートウェイが作成される。しかし実際に使用できるようにするにはルートテーブルの設定が必要なのである。これが、よくわからなくてハマった。当初はaws_route_table_associationで設定可能か？と思って試してみた。しかしドキュメントを見ると設定可能なのはインターネットゲートウェイかサブネットIDのみで、NATゲートウェイは含まれていない。それでも無理矢理コードを書いてapplyしてみたら、無効なパラメータなんだよボケ！と怒られた。\nError: error creating Route Table (rtb-1234567890123445) Association: InvalidParameterValue: invalid value for parameter gateway-id: nat-02d182b4d52eb6aa7 status code: 400, request id: ae4cb491-23d6-41e8-b7ef-e01983cabef8 (snip)  しばし思いを馳せて、NATゲートウェイの関連付けはaws_route_table_associationではなくroute_tableでやればいいらしいのはなんとなく分かった。しかしドキュメントを読んでも設定項目がわからん\u0026hellip;\nTerraform - route_table\n そこで、ルートテーブルの設定をマネコンから手動で実施して、その状態をimportして探ってみた。importするため以下のような最低限のtfコードを用意してimportコマンドを実行する。\nrt-prv.tf\nresource \u0026quot;aws_route_table\u0026quot; \u0026quot;rt_prv\u0026quot; { }  $ terraform import aws_route_table.rt_prv rtb-1234567890123445  実行後のtfstateを確認する。以下は対象ルートテーブルの辺りだけ抜粋。\n{ \u0026quot;mode\u0026quot;: \u0026quot;managed\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;aws_route_table\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;rt_prv\u0026quot;, \u0026quot;provider\u0026quot;: \u0026quot;provider[\\\u0026quot;registry.terraform.io/hashicorp/aws\\\u0026quot;]\u0026quot;, \u0026quot;instances\u0026quot;: [ { \u0026quot;schema_version\u0026quot;: 0, \u0026quot;attributes\u0026quot;: { \u0026quot;arn\u0026quot;: \u0026quot;arn:aws:ec2:ap-northeast-1:0123456789010:route-table/rtb-1234567890123445\u0026quot;, \u0026quot;id\u0026quot;: \u0026quot;rtb-1234567890123445\u0026quot;, \u0026quot;owner_id\u0026quot;: \u0026quot;0123456789010\u0026quot;, \u0026quot;propagating_vgws\u0026quot;: [], \u0026quot;route\u0026quot;: [ { \u0026quot;carrier_gateway_id\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;cidr_block\u0026quot;: \u0026quot;0.0.0.0/0\u0026quot;, \u0026quot;destination_prefix_list_id\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;egress_only_gateway_id\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;gateway_id\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;instance_id\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;ipv6_cidr_block\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;local_gateway_id\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;nat_gateway_id\u0026quot;: \u0026quot;nat-02d182b4d52eb6aa7\u0026quot;, \u0026quot;network_interface_id\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;transit_gateway_id\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;vpc_endpoint_id\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;vpc_peering_connection_id\u0026quot;: \u0026quot;\u0026quot; } ], \u0026quot;tags\u0026quot;: { \u0026quot;Name\u0026quot;: \u0026quot;dev-private-rt\u0026quot; }, \u0026quot;tags_all\u0026quot;: { \u0026quot;Name\u0026quot;: \u0026quot;dev-private-rt\u0026quot; }, \u0026quot;timeouts\u0026quot;: { \u0026quot;create\u0026quot;: null, \u0026quot;delete\u0026quot;: null, \u0026quot;update\u0026quot;: null }, \u0026quot;vpc_id\u0026quot;: \u0026quot;vpc-1234567890123445\u0026quot; }, \u0026quot;sensitive_attributes\u0026quot;: [], \u0026quot;private\u0026quot;: (snip)  上記の値を参考にroute_tableでNATゲートウェイの関連付けができそうではある。しかしここで、今更ではあるがふと気がついた。\nもともと今回使っているサブネットやルートテーブルはTerraform外で作成したものである。既存の管理外ルートテーブルを下手にTerraformで操作して干渉させるのはNGじゃないかと。そして、importを実行した時点でTerraform管理下になってしまっているが、確認したかっただけなので管理下に置くつもりはないのである。(なので、今後のTerraform作業はこのtfstateから干渉されないパスで実行する）\n ネットワーク周りもすべてTerraformで作成したものであれば使い終わったらすべてdestroyで問題ないが、そうでないとなかなか厄介だ。かといってそのために今からコード追加したり書き換えるのも面倒だ。\nで、考えた挙句、ルートテーブル関連付けだけは手動でやることにした。本来は全自動でやりたいが、現状はNATゲートウェイ作成とEKSクラスタ作成を2段階で分割する必要がある。なかなか、思い通りにはいかない。まぁこういうジレンマは、TerraformだろうがCFnだろうがついて回る。試行錯誤でやっていくしかない。\n ところで自分はこれまでTerraformインポートは構成の確認のために使っていたが、こういう目的で使うこともあるのか。備忘録。\nTerraform import機能を使って既存のVPCとサブネットをTerraformで管理できるようにする\n ","permalink":"https://ecnedaced-seirots.github.io/post/b/terraform-nat-gateway/","summary":"\u003cp\u003eTerraformでNAT Gatewayを作る。EKS Fargateの検証する時に、EKSリソースと一緒に自動生成したいからだ。\u003c/p\u003e","title":"TerraformでNATゲートウェイを作成する"},{"content":"Goのmapはkey:valueの配列で構成されており、Pythonの辞書に似ている。ほぼ辞書と同等の使い方ができるようだが、若干挙動が異なる。\n map定義の構文は以下の通り。\nmap[keyの型名]値の型名{key: value, key: value, ..., key: value}  map1.go\npackage main import \u0026#34;fmt\u0026#34; func main() { //mapの基本  city := map[string]int{\u0026#34;NY\u0026#34;: 100, \u0026#34;London\u0026#34;: 200, \u0026#34;Tokyo\u0026#34;: 300, \u0026#34;Bangkok\u0026#34;: 400} fmt.Println(city) }  結果\n出力の順番は保証されない（記述した順番通りに出力されない）。\nmap[Bangkok:400 London:200 NY:100 Tokyo:300]  次にkeyの値を出力、valueの変更、key:valueの追加など。\nmap2.go\npackage main import \u0026#34;fmt\u0026#34; func main() { city := map[string]int{\u0026#34;NY\u0026#34;: 100, \u0026#34;London\u0026#34;: 200, \u0026#34;Tokyo\u0026#34;: 300, \u0026#34;Bangkok\u0026#34;: 400} fmt.Println(city) //map[Bangkok:400 London:200 NY:100 Tokyo:300]  //指定したkeyの値を出力  fmt.Println(city[\u0026#34;Tokyo\u0026#34;]) //300  //指定したkeyの値を変更  city[\u0026#34;Tokyo\u0026#34;] = 500 fmt.Println(city[\u0026#34;Tokyo\u0026#34;]) //500  //key:valueを新たに追加 \tcity[\u0026#34;Buenos Aires\u0026#34;] = 600 fmt.Println(city) //map[Bangkok:400 Buenos Aires:600 London:200 NY:100 Tokyo:500]  }  空のmapを作成してkey:valueを追加。配列を初期化して値を追加していくとかありがちだからいつか使う、かも。\nmap3.go\npackage main import \u0026#34;fmt\u0026#34; func main() { //makeで空のmap作成後、key:valueを追加  city2 := make(map[string]int) city2[\u0026#34;Paris\u0026#34;] = 700 fmt.Println(city2) //map[Paris:700]  }  次に、存在しないkey指定時の動作など。\nmap4.go\npackage main import \u0026#34;fmt\u0026#34; func main() { city := map[string]int{\u0026#34;NY\u0026#34;: 100, \u0026#34;London\u0026#34;: 200, \u0026#34;Tokyo\u0026#34;: 300, \u0026#34;Bangkok\u0026#34;: 400} fmt.Println(city) //valueがないkeyを指定すると:  fmt.Println(city[\u0026#34;L.A\u0026#34;]) //指定したkeyのvalueと、存在有無を出力。値が存在する場合:  v, isOk := city[\u0026#34;London\u0026#34;] fmt.Println(v, isOk) //値が存在しない場合:  v2, isOk2 := city[\u0026#34;L.A\u0026#34;] fmt.Println(v2, isOk2) }  結果\nmap[Bangkok:400 London:200 NY:100 Tokyo:300] 0 200 true 0 false  最後に、Python置き換えの例。\ndict.py\ndef main(): # 辞書定義 city = {\u0026#34;NY\u0026#34;: 100, \u0026#34;London\u0026#34;: 200, \u0026#34;Tokyo\u0026#34;: 300, \u0026#34;Bangkok\u0026#34;: 400} print(city) #{\u0026#39;NY\u0026#39;: 100, \u0026#39;London\u0026#39;: 200, \u0026#39;Tokyo\u0026#39;: 300, \u0026#39;Bangkok\u0026#39;: 400} # 指定したkeyの値を出力 print(city[ \u0026#34;London\u0026#34;]) #200 # 指定したkeyの値を変更 city[ \u0026#34;Tokyo\u0026#34;] = 500 print(city[ \u0026#34;Tokyo\u0026#34;]) #500 # key:valueを新たに追加 city[\u0026#34;Buenos Aires\u0026#34;] = 600 print(city) #{\u0026#39;NY\u0026#39;: 100, \u0026#39;London\u0026#39;: 200, \u0026#39;Tokyo\u0026#39;: 500, \u0026#39;Bangkok\u0026#39;: 400, \u0026#39;Buenos Aires\u0026#39;: 600} # 存在しないkeyを指定 print(city[ \u0026#34;L.A\u0026#34;]) #KeyError: \u0026#39;L.A\u0026#39; if __name__ == \u0026#34;__main__\u0026#34;: main()  参考\n【Go入門】mapの基本\n  ","permalink":"https://ecnedaced-seirots.github.io/post/b/golang-init-map/","summary":"\u003cp\u003eGoのmapはkey:valueの配列で構成されており、Pythonの辞書に似ている。ほぼ辞書と同等の使い方ができるようだが、若干挙動が異なる。\u003c/p\u003e","title":"Go入門(6) - mapの基本"},{"content":"Macで、特定の拡張子がつくファイルを開く時のデフォルトアプリケーションを設定したい時。例えばスクリプト系は一律mi.appとしたいが、最近始めたGoはまだ設定されていない。\n 未設定のファイルを１つ選択し、「情報を見る」(⌘ + I)を開いて以下のように設定する。\n 2番目の画像で、「続ける」を押下。設定後は「このアプリケーションで開く」が「mi.app（デフォルト）」となり、次回からxxx.goはすべてmiで開くことができる。\n どうということもないネタなんだが、すぐ忘れるんだなこれが。\n  ","permalink":"https://ecnedaced-seirots.github.io/post/b/mac-files-setting/","summary":"\u003cp\u003eMacで、特定の拡張子がつくファイルを開く時のデフォルトアプリケーションを設定したい時。例えばスクリプト系は一律mi.appとしたいが、最近始めたGoはまだ設定されていない。\u003c/p\u003e","title":"Macでファイルをデフォルトで開くアプリを設定"},{"content":"「コインロッカーベイビーズ」(村上龍）の英語翻訳版 \u0026ldquo;Coin Locker Babies\u0026quot;より。\n  he had leaned the things: one was that all the pain stopped when you stopped fighting death; and the other was that as long as you could still hear your heart beating, you had to keep fighting back.\n \u0026ldquo;Coin Locker Babies\u0026rdquo; by Ryu Murakmi(page 474)\n  ","permalink":"https://ecnedaced-seirots.github.io/post/b/ryu-quotes-6/","summary":"\u003cp\u003e「コインロッカーベイビーズ」(村上龍）の英語翻訳版 \u0026ldquo;Coin Locker Babies\u0026quot;より。\u003c/p\u003e","title":"Coin Locker Babies-1, Ryu Murakami"},{"content":"Go言語におけるfor文の基本覚書。\n 細かい話は抜きにして、サンプル構文。\nfor.go\npackage main import \u0026#34;fmt\u0026#34; func main() { //初期値をインクリメント  for i := 0; i \u0026lt;= 10; i++ { fmt.Println(i) } fmt.Println(\u0026#34;----------\u0026#34;) //配列の値をループ  city := []string{\u0026#34;NY\u0026#34;, \u0026#34;London\u0026#34;, \u0026#34;Bangkok\u0026#34;, \u0026#34;Tokyo\u0026#34;} for i := 0; i \u0026lt; len(city); i++ { fmt.Println(city[i]) } }  結果\n$ go run for.go 0 1 2 3 4 5 6 7 8 9 10 ---------- NY London Bangkok Tokyo  Pythonの場合 Pythonではインクリメント/デクリメント演算子が使用できないため、代替となるコードで記述する。while文なら累算代入で似たような処理ができるが、for文でやるとすればrangeを使うことになる。一方、Goにはwhile文がない。\ndef main(): for i in range(11): print(i) print('-----------') city = ['NY', 'London', 'Bangkok', 'Tokyo'] for i in city: print(i) if __name__ == \u0026quot;__main__\u0026quot;: main()  実行結果はGoのコードと同じ。\n 参考\n【Go入門】loop処理 – for文の基本 \nGo言語 for文のサンプル(break/continue)\n【Python入門】インクリメント演算子は使えない!?対処法まとめ\n ","permalink":"https://ecnedaced-seirots.github.io/post/b/golang-init-for/","summary":"\u003cp\u003eGo言語におけるfor文の基本覚書。\u003c/p\u003e","title":"Go入門(5) - for文の基本"},{"content":"Goの時刻扱いについて。しかし日付時刻の扱いを網羅すると果てしない旅路になるので、今回は触りだけ、現在時刻を出力。\n Goにおいて時刻はロケーション情報を持つtime構造体に格納される。timeで定義済みロケーションはtime.UTCと、time.Localの２つ。それ以外のロケーションを呼び出すには一手間必要で、例えば正式にJSTの時刻を定義するならこうするとかあるけれども、日付時刻の扱いを網羅すると(ry \u0026hellip;なので今回はスキップ。\ntime1.go\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { //現在時刻をUTCで出力  fmt.Println(\u0026#34;UTCの現在時刻：\u0026#34;, time.Now().UTC()) //ローカルの現在時刻を出力  fmt.Println(\u0026#34;JSTの現在時刻：\u0026#34;, time.Now().Local()) }  出力結果\n$ go run time1.go UTCの現在時刻： 2022-01-16 07:49:06.70495 +0000 UTC JSTの現在時刻： 2022-01-16 16:49:06.705033 +0900 JST  次に、UNIXタイムスタンプの値を出力してみる。さらにデータ型を出力させる。\ntime2.go\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;time\u0026quot; ) func main() { //時刻定義を変数に格納 t1 := time.Now().UTC() t2 := time.Now().Local() t3 := time.Now().Unix() //通常の時刻で値と型を出力 fmt.Println(\u0026quot;UTCの現在時刻:\u0026quot;,t1) fmt.Printf(\u0026quot;%T\\n\u0026quot;, t1) fmt.Println(\u0026quot;JSTの現在時刻:\u0026quot;,t2) fmt.Printf(\u0026quot;%T\\n\u0026quot;, t2) //UNIXタイムスタンプの値と型を出力 fmt.Println(\u0026quot;UNIXタイムスタンプ:\u0026quot;,t3) fmt.Printf(\u0026quot;%T\\n\u0026quot;, t3) }  出力結果。UNIXタイムスタンプはint64で、他はtime.Timeであると分かる。\n$ go run time2.go UTCの現在時刻: 2022-01-16 07:55:54.772297 +0000 UTC time.Time JSTの現在時刻: 2022-01-16 16:55:54.772298 +0900 JST time.Time UNIXタイムスタンプ: 1642319754 int64  最後にUNIXタイムスタンプをTime型に変換してみる。\ntime3.go\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { //UNIXタイムスタンプをTime型に変換し、値と型を出力。  t := time.Unix(1642319638, 0) fmt.Println(t.Format(\u0026#34;2006-01-02 15:04:05\u0026#34;)) //2022-01-16 16:53:58  fmt.Printf(\u0026#34;%T\\n\u0026#34;, t) //time.Time }  時刻出力/変換、タイムゾーンの問題はどの言語でも避けて通れない手強い敵なのだが、こればっかりやってもいられないので、まぁボチボチやっていこう。\n参考\nGo言語の時刻演算パッケージ「time」の使い方メモ\n[Go] Unix タイムスタンプを Time 型のデータに変換する\n【Go入門】型（type）を調べる – %T と Printf() \n ","permalink":"https://ecnedaced-seirots.github.io/post/b/golang-init-time/","summary":"\u003cp\u003eGoの時刻扱いについて。しかし日付時刻の扱いを網羅すると果てしない旅路になるので、今回は触りだけ、現在時刻を出力。\u003c/p\u003e","title":"Go入門(4) - 現在時刻の出力"},{"content":"Goには配列と似た「スライス(Slice)」というデータ構造の概念がある。要素数の指定が不要で、配列より柔軟にデータを扱うことができる。\n スライスの宣言 var 配列名 []型名 var 配列名 []型名 = []型名{要素a, 要素b,...}  スライスの使用例 slice1.go\npackage main import \u0026#34;fmt\u0026#34; func main() { //短縮系でスライスnumを定義  num := []int{1, 2, 3, 4, 5, 6, 7, 8, 9} //[1 2 3 4 5 6 7 8 9]  fmt.Println(num) }  特定の要素を取得するにはスライス名[インデックス値]となり、他の言語と変わりない。\nslice2.go\npackage main import \u0026#34;fmt\u0026#34; func main() { num := []int{1, 2, 3, 4, 5, 6, 7, 8, 9} //すべての要素を出力  fmt.Println(num) //[1 2 3 4 5 6 7 8 9]  //インデックスを指定して特定の要素を取得して出力  fmt.Println(num[2]) //3  //要素の値を変更  num[6] = 7000 fmt.Println(num) //[1 2 3 4 5 6 7000 8 9]  }  以下は要素の範囲を指定したり、値を追加する例。\nslice3.go\npackage main import \u0026#34;fmt\u0026#34; func main() { num := []int{1, 2, 3, 4, 5, 6, 7, 8, 9} //すべての要素を出力  fmt.Println(num) //[1 2 3 4 5 6 7 8 9]  //インデックス範囲の開始・終了地点を指定  fmt.Println(num[3:6]) //[4 5 6]  //インデックスの終了地点のみ指定  fmt.Println(num[:6]) //[1 2 3 4 5 6]  //インデックスの開始地点のみ指定  fmt.Println(num[6:]) //[7 8 9]  //要素に値を追加  num = append(num, 10, 11, 12, 100) fmt.Println(num) //[1 2 3 4 5 6 7 8 9 10 11 12 100]  //セミコロンで全要素を対象とする  fmt.Println(num[:]) //[1 2 3 4 5 6 7 8 9 10 11 12 100]  }  Pythonの場合 若干順番はずれているが、以下Pythonの例。Pythonにはsliceの概念がないのでlist。かつ、要素の型宣言が省略されている。\nlist.py\ndef main(): num = [1, 2, 3, 4, 5, 6, 7, 8, 9] print(num) # 要素の範囲指定 print(num[2:6]) print(num[:6]) print(num[6:]) # 要素に値を追加 num.append(10) num.append(11) num.append(12) num.append(100) print(num) # 要素の値を変更 num[6] = 7000 print(num[:]) if __name__ == \u0026#34;__main__\u0026#34;: main()  出力結果\n$ python3 list.py [1, 2, 3, 4, 5, 6, 7, 8, 9] [3, 4, 5, 6] [1, 2, 3, 4, 5, 6] [7, 8, 9] [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 100] [1, 2, 3, 4, 5, 6, 7000, 8, 9, 10, 11, 12, 100]  ちなみにPythonではnum.append(10,11,12,100)のような記述は以下のエラーになり、NGである。このため上記のように逐一個別に指定する必要がある。これについてはGoの方がちょっと便利。\nTypeError: list.append() takes exactly one argument (4 given)  参考\n【Go入門】スライス（Slice）の基本 \n ","permalink":"https://ecnedaced-seirots.github.io/post/b/golang-init-slice/","summary":"\u003cp\u003eGoには配列と似た「スライス(Slice)」というデータ構造の概念がある。要素数の指定が不要で、配列より柔軟にデータを扱うことができる。\u003c/p\u003e","title":"Go入門(3) - スライス(Slice)の扱い"},{"content":"Goの配列は要素数を宣言する。宣言した数を超える要素は格納できない。少ない分には可能。Goは配列よりスライスの方がよく使われるらしい。\n 配列の基本 配列の宣言はvar 配列名[要素数]型名 の形で行う。値の格納と同時に宣言する場合は、波括弧に要素を格納する。\narray.go\npackage main import \u0026#34;fmt\u0026#34; func main() { //配列の変数宣言 + 角括弧[]の中に格納するデータ数 + データの型名を記述  var num [5]int num[0] = 1000 num[1] = 2000 num[2] = 3000 num[3] = 4000 num[4] = 5000 fmt.Println(num) //要素の値を代入して宣言する。  //配列の変数宣言 + イコール + 要素数と型名 + 波括弧{}内に要素の値を格納。  var city [5]string = [5]string{\u0026#34;NY\u0026#34;, \u0026#34;Paris\u0026#34;, \u0026#34;London\u0026#34;, \u0026#34;Sydney\u0026#34;, \u0026#34;Tokyo\u0026#34;} fmt.Println(city) }  結果\n$ go run array.go [1000 2000 3000 4000 5000] [NY Paris London Sydney Tokyo]  要素数の増減 先述の通り、宣言した数を超える要素は格納できないが、少ない分には可能。要素の数が足りていなくても宣言した要素数は保持される。\narray2.go\npackage main import \u0026#34;fmt\u0026#34; func main() { //宣言した要素数より多い要素の格納は不可。  //宣言した要素数より少ない要素数の格納は可能。  var city [5]string = [5]string{\u0026#34;NY\u0026#34;, \u0026#34;London\u0026#34;, \u0026#34;Sydney\u0026#34;, \u0026#34;Tokyo\u0026#34;} fmt.Println(city) //配列の要素数を出力  //この場合実際に格納した数ではなく宣言した数を出力する  fmt.Println(len(city)) }  結果\n$ go run array2.go [NY London Sydney Tokyo ] 5  配列の要素へのアクセス 以下のように記述して配列の要素を取得できる。\n変数名 := 配列名[インデックス値] 例\nc0 := city[0]  array3.go\npackage main import \u0026#34;fmt\u0026#34; func main() { var city [5]string = [5]string{\u0026#34;NY\u0026#34;, \u0026#34;Paris\u0026#34;, \u0026#34;London\u0026#34;, \u0026#34;Sydney\u0026#34;, \u0026#34;Tokyo\u0026#34;} //配列の要素すべて出力  fmt.Println(city) //配列の要素を取得して変数に格納  c0 := city[0] c1 := city[1] c2 := city[2] c3 := city[3] c4 := city[4] //個別の要素を出力  fmt.Println(c0) fmt.Println(c1) fmt.Println(c2) fmt.Println(c3) fmt.Println(c4) }  結果\n$ go run array3.go [NY Paris London Sydney Tokyo] NY Paris London Sydney Tokyo  参考\n【Go入門】配列（Array）の宣言と要素へのアクセス\n ","permalink":"https://ecnedaced-seirots.github.io/post/b/golang-init-array/","summary":"\u003cp\u003eGoの配列は要素数を宣言する。宣言した数を超える要素は格納できない。少ない分には可能。Goは配列よりスライスの方がよく使われるらしい。\u003c/p\u003e","title":"Go入門(2) - 配列の扱い"},{"content":"Go言語の学習を始めることにした。シンプルで学びやすい。セミコロンは使わない。try-catchがサポートされていない。:=をよく使う。とのことだ。\n Goインストール まずはbrewでMacにインストール。\n$ brew install go $ go version go version go1.17.5 darwin/amd64  最初のコード 何はなくともHello World、ということで以下のファイルを作成。\ninitial.go\npackage main import \u0026#34;fmt\u0026#34; func main(){ fmt.Println(\u0026#34;Hello World\u0026#34;) }  それぞれのコンポーネントの役割は以下の通り。importするパッケージ名は他の言語と異なりダブルクォーテーションで囲む。\npackage 所属パッケージ名 import \u0026#34;利用パッケージ名\u0026#34; func 関数名() { 処理コード }  プログラムを実行するには、go run /path/to/[ファイル名].go とする。\n$ go run initial.go Hello World  変数の宣言 (1) 変数の型を宣言後、関数内で変数の値を定義。\nvar msg string msg = \u0026quot;Hello World\u0026quot; #関数内に記述  (2) 変数の型宣言と変数の値定義（初期化）を同時に行う\nvar msg string = \u0026quot;Hello World\u0026quot;  (3) 変数の短縮宣言\nこれは関数の内部でのみ使用可能。グローバル変数は(1)(2)の記述で対応する。\nmsg := \u0026quot;Hello World\u0026quot; #関数内に記述  initial1.go\npackage main import \u0026quot;fmt\u0026quot; //(1)の記述 var msg string func main(){ msg = \u0026quot;Hello World\u0026quot; fmt.Println(msg) }  initial2.go\npackage main import \u0026quot;fmt\u0026quot; //(2)の記述 var msg string = \u0026quot;Hello World\u0026quot; func main(){ fmt.Println(msg) }  initial3.go\npackage main import \u0026quot;fmt\u0026quot; //(3)の短縮型で記述 func main(){ msg := \u0026quot;Hello World\u0026quot; fmt.Println(msg) }  実行結果はすべて最初のinitial.goと同様となる。\n 参考\nGolang 入門 #1 【Go入門】Go言語でHello World! – パッケージとインポート\n ","permalink":"https://ecnedaced-seirots.github.io/post/b/golang-init-install/","summary":"\u003cp\u003eGo言語の学習を始めることにした。シンプルで学びやすい。セミコロンは使わない。try-catchがサポートされていない。\u003ccode\u003e:=\u003c/code\u003eをよく使う。とのことだ。\u003c/p\u003e","title":"Go入門(1) - 変数の定義"},{"content":" But Anemone had finally seen through all this talk; all Sachiko\u0026rsquo;s trips and lovers and \u0026ldquo;experiences\u0026rdquo; amounted to the same thing: boredom.\n \u0026ldquo;Coin Locker Babies\u0026rdquo; by Ryu Murakami\n boredom: 退屈、倦怠\n ","permalink":"https://ecnedaced-seirots.github.io/post/b/english-boredom/","summary":"\u003cblockquote\u003e\n\u003cp\u003eBut Anemone had finally seen through all this talk; all Sachiko\u0026rsquo;s trips and lovers and \u0026ldquo;experiences\u0026rdquo; amounted to the same thing: boredom.\u003c/p\u003e\n\u003c/blockquote\u003e","title":"英語メモ - boredom"},{"content":"村上龍著「愛と幻想のファシズム」より\n  「ただ、彼らの、彼らというのは西欧民主主義国家を言ってるのですが、彼らの、恐ろしさというのは、とてもわかりにくいのです、というのは、彼らは、ヒューマニズムを実践しているからです、恐怖を全面に押し出して来ないからですよ」\n   「アメリカが見えませんか？」\n「ボンヤリしています」\n「たぶんね、アメリカ人自身にもアメリカは見えないかも知れませんよ」\n   小説「愛と幻想のファシズム」は1983年〜84年にかけて書かれた。龍氏は同じ頃、「アメリカン★ドリーム」というエッセイを連載していて、一冊の本になっている。これは龍氏のアメリカに対する鋭く深く、ポップな洞察がびっしり詰まった、最高に濃くてエキサイティングな書物。この2つの本を合わせ技で読むと、アメリカ、世界統一的政治システム、その中の日本\u0026hellip;といった関係性が浮かび上がってくる。小説の中の物語としての筋書きとは、別の何かが。\n今は遠い過去の歴史となった東西冷戦真っ只中の時代に書かれた小説だが、今でも通用する世界観が散りばめられているし、今この時代だからこそ鮮烈に迫ってくる表現が多々ある。2019年以前に読んでいたらなかったかもしれないけど。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/ryu-quotes-5/","summary":"\u003cp\u003e村上龍著「愛と幻想のファシズム」より\u003c/p\u003e","title":"「愛と幻想のファシズム」より(5) "},{"content":"過去記事でEKS FargateのPodを起動するところまでやってみた。今回はFargate PodからFluent Bit経由でCloudWatch Logsにログを送信してみる。\n EKS Fargateの関連記事\nEKS FargateクラスタをTerraformで作成する(1) \nEKS FargateクラスタをTerraformで作成する(2) \n Fargate + Fluent Bitの参考記事\nFluent Bit for Amazon EKS on AWS Fargate をリリース\nAmazon EKS on Fargate上のPodログをCloudWatchLogsに送信する\n EKSクラスタは過去記事同様にTerraformから自動作成とする。で、FluentBit対応に入るが、準備してからクラスタ作成したかったのでドキュメントとは若干順番が異なる。まず過去記事でFargate Pod用のIAMロールを作成したが、CWログ送信にあたって追加で権限が必要なため別途ポリシーを作成して対象ロールにアタッチする。\n# ポリシーファイルをDL。 $ curl -OL https://raw.githubusercontent.com/aws-samples/amazon-eks-fluent-logging-examples/mainline/examples/fargate/cloudwatchlogs/permissions.json # ポリシー作成 $ aws iam create-policy \\ --policy-name eks-fargate-fluent-bit-cloudwatch \\ --policy-document file://permissions.json # 既存のFargate Pod用ロールにポリシーをアタッチする。 $ aws iam attach-role-policy \\ --policy-arn arn:aws:iam::012345678910:policy/eks-fargate-fluent-bit-cloudwatch \\ --role-name AmazonEKSFargatePodExecutionRole  この後terraform applyでEKSクラスタを作成。この間に必要なマニフェストを用意。試行錯誤したが最終的にPoCに使ったマニフェストは以下2種。ファイル名や各種値は任意だが一部変更不可の値があるため注意。\n fargate-logging.yaml（ロギング専用Namespace及びConfigMapの定義） httpd-pod.yaml （Fargate用Namespace及びログ送信用Deploymentの定義）   fargate-logging.yaml\nkind: Namespace apiVersion: v1 metadata: name: aws-observability  #変更不可 labels: aws-observability: enabled --- kind: ConfigMap apiVersion: v1 metadata: name: aws-logging namespace: aws-observability  #変更不可 data: output.conf: |  #変更不可（他に設定可能な値もある） [OUTPUT] Name cloudwatch Match * region ap-northeast-1 log_group_name /aws/eks/fargate-fluent-bit log_stream_prefix fargate-pod-log- auto_create_group true  httpd-pod.yaml\nkind: Namespace apiVersion: v1 metadata: name: fargate-test  #Fargateプロファイルで設定している値 --- apiVersion: apps/v1 kind: Deployment metadata: name: httpd-pod  #任意名称 namespace: fargate-test  #Fargateプロファイルで設定している値 spec: selector: matchLabels: app: nginx replicas: 1 template: metadata: labels: app: nginx spec: containers: - name: main image: nginx ports: - containerPort: 80  クラスタ作成完了後、aws eks update-kubeconfig --name [your cluster name]を実行し、以下コマンドを実行する。\n#ログ送信定義をapply $ kubectl apply -f fargate-logging.yaml namespace/aws-observability created configmap/aws-logging created #Fargate Podを起動 $ kubectl apply -f httpd-pod.yaml namespace/fargate-test created deployment.apps/httpd-pod created #ConfigMapの確認 $ kubectl -n aws-observability get cm NAME DATA AGE aws-logging 1 32s kube-root-ca.crt 1 32s  ここからログ送信のためhttpリクエストを生成していく。ターミナルを3個開いて作業する。\n###ターミナル1 #deploymentをexposeする。 $ kubectl -n fargate-test expose deploy httpd-pod #コネクション生成 kubectl -n fargate-test port-forward svc/httpd-pod 8080:80 Forwarding from 127.0.0.1:8080 -\u0026gt; 80 Forwarding from [::1]:8080 -\u0026gt; 80 ###ターミナル2 #リクエスト送信。以下コマンドを何度か繰り返す。 $ curl localhost:8080 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; (snip) \u0026lt;p\u0026gt;For online documentation and support please refer to \u0026lt;a href=\u0026quot;http://nginx.org/\u0026quot;\u0026gt;nginx.org\u0026lt;/a\u0026gt;.\u0026lt;br/\u0026gt; Commercial support is available at \u0026lt;a href=\u0026quot;http://nginx.com/\u0026quot;\u0026gt;nginx.com\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;em\u0026gt;Thank you for using nginx.\u0026lt;/em\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; ###ターミナル3 #ローカルでログ確認 $ kubectl -n fargate-test logs deploy/httpd-pod -f (snip) 127.0.0.1 - - [10/Jan/2022:09:17:15 +0000] \u0026quot;GET / HTTP/1.1\u0026quot; 200 615 \u0026quot;-\u0026quot; \u0026quot;curl/7.64.1\u0026quot; \u0026quot;-\u0026quot; 127.0.0.1 - - [10/Jan/2022:09:17:47 +0000] \u0026quot;GET / HTTP/1.1\u0026quot; 200 615 \u0026quot;-\u0026quot; \u0026quot;curl/7.64.1\u0026quot; \u0026quot;-\u0026quot; 127.0.0.1 - - [10/Jan/2022:09:19:01 +0000] \u0026quot;GET / HTTP/1.1\u0026quot; 200 615 \u0026quot;-\u0026quot; \u0026quot;curl/7.64.1\u0026quot; \u0026quot;-\u0026quot;  マネコンを覗いてみると、CloudWatch Logsにログが送信されていることを確認できた。\n  しかし実際にはこのようにあっさり成功したのではなく、それなりに試行錯誤があった、変更不可の値を任意の名称に変えたりしてたから。以下はfargate-logging.yamlを2回目にapplyした時のエラー。初回はエラー出なかったんだよ。最初から言ってくれよ\u0026hellip;\n Error from server: error when creating \u0026ldquo;fargate-logging.yaml\u0026rdquo;: admission webhook \u0026ldquo;0500-amazon-eks-fargate-configmaps-admission.amazonaws.com\u0026rdquo; denied the request: fargate.conf is not valid. Please only provide output.conf, filters.conf, parsers.conf or flb_log_cw in the logging configmap\n  素直に公式ドキュメントの通りにしていればつまづくことはなかっただろう。まぁわかったからいいけどね。\nそれと設定が読み込まれていないと思われるケースではPod再起動してみたり。（しかし今回の場合は原因はこれじゃなかった）\n$ kubectl -n fargate-test rollout restart deploy httpd-pod  課題 今回はログストリームのプレフィックスを決め打ちにしているが、本来であれば通常のEKSのように、Kubernetes filterでPod名から拾うとかさせたいのである。FargateでのKubernetes filterは初期の頃はサポートされていなかったが、現在は使用できるようになった。今度やってみよう。\nAmazon EKS on AWS Fargate が Fluent Bit Kubernetes Filter のサポートを開始\n ちなみに通常のEKSのログ送信については以下参照\nEKS Container InsightsのFluent Bit設定\n ","permalink":"https://ecnedaced-seirots.github.io/post/b/eks-fargate-fluent-bit/","summary":"\u003cp\u003e過去記事でEKS FargateのPodを起動するところまでやってみた。今回はFargate PodからFluent Bit経由でCloudWatch Logsにログを送信してみる。\u003c/p\u003e","title":"EKS FargateからFluent BitでCloudWatchにログ送信する"},{"content":"小ネタ。AWSのNATゲートウェイは業務では利用することが多いし自分で作ったりもしていた。個人アカでは利用したことがなかったが、先日必要に迫られて作ってみた。\nというのは、Fargate-EKSクラスタを作成する際、FargateのPodが起動するノードはプライベートサブネットに配置する必要があるからだ。外に出る口がないとコントロールプレーンと通信できなくて起動しないんじゃないか？と予想したらやはりその通りだったので、起動途中で詰まっている間にチャチャッとNATゲートウェイを作ったら、サクッとPodが起動した。\n で、NATゲートウェイの作成自体は特に難しいことはなく、業務でやっていた記憶を辿ってなんとなくやったらできた。しかし後で参照できるように記録を残す。\nパブリックサブネットとプライベートサブネットは作成済みとして、大まかには以下の対応となる。\n NATゲートウェイを作成。パブリックサブネットに所属させる。 プライベートサブネットのルートテーブルに1.のNATゲートウェイを関連付ける。    プライベートサブネットのルートテーブルを編集する。\n これで、プライベートサブネット上のPod/インスタンスが外に出ていけるようになる。\n NATゲートウェイは課金対象なので、Fargateの検証が済んだらすかさず削除する。EKSクラスタはTerraformで作ったので、削除時もterraform destroyであっさり削除。楽ちんだな〜！\nではNATゲートウェイの作成も自動化すればいいじゃないかというと、マネコン操作でも1分でできてしまうので、このままでもいいやと思ってしまうんだな。でもせっかくだから次回はNATゲートウェイも一緒にTerraformで作ってしまおうかな？\n ","permalink":"https://ecnedaced-seirots.github.io/post/b/aws-create-nat-gateway/","summary":"\u003cp\u003e小ネタ。AWSのNATゲートウェイは業務では利用することが多いし自分で作ったりもしていた。個人アカでは利用したことがなかったが、先日必要に迫られて作ってみた。\u003c/p\u003e","title":"AWS NATゲートウェイの作成と設定"},{"content":"Terraformで、「AWS SNSトピックのサブスク + エンドポイントがメール」のパターンで、複数のメールアドレスを指定したかった。しかし、通常の記述方法だとエラーになってしまうのである。\nそれで調べてみたんだが、ほぼ情報が見当たらない。結論から言うと、以下記事参考にしたらできた。この例ではcountで繰り返し処理をしている。\nHow to add email subscribers to an AWS SNS topic with Terraform\n 参考記事によると、TerraformでSNSサブスクリプションのエンドポイントとしてメールがサポートされたのが、2021年初頭らしい。そのため、それまではこれまたトリッキーな記述をする必要があった模様。ちなみにアドレスが単体であればcoount処理をせずに通常の記述方法で作成可能である。\n以下、ほぼパクリだがコード例。delivery_policyはデフォルトでよければ設定必要なしと想定する。\n ################################################## # E-mail address definition ################################################## locals { emails = [\u0026quot;foo@example.com\u0026quot;,\u0026quot;bar@example.com\u0026quot;] } ################################################## # SNS topic ################################################## resource \u0026quot;aws_sns_topic\u0026quot; \u0026quot;sns_topic\u0026quot; { name = \u0026quot;sns-test-topic\u0026quot; display_name = \u0026quot;Notification Mail\u0026quot; # メールの差出人として表示される delivery_policy = jsonencode({ \u0026quot;http\u0026quot; : { \u0026quot;defaultHealthyRetryPolicy\u0026quot; : { \u0026quot;minDelayTarget\u0026quot; : 20, \u0026quot;maxDelayTarget\u0026quot; : 20, \u0026quot;numRetries\u0026quot; : 3, \u0026quot;numMaxDelayRetries\u0026quot; : 0, \u0026quot;numNoDelayRetries\u0026quot; : 0, \u0026quot;numMinDelayRetries\u0026quot; : 0, \u0026quot;backoffFunction\u0026quot; : \u0026quot;linear\u0026quot; }, \u0026quot;disableSubscriptionOverrides\u0026quot; : false, \u0026quot;defaultThrottlePolicy\u0026quot; : { \u0026quot;maxReceivesPerSecond\u0026quot; : 1 } } }) } ################################################## # SNS topic subscription(for multi e-mail address) ################################################## resource \u0026quot;aws_sns_topic_subscription\u0026quot; \u0026quot;sns_topic_subs\u0026quot; { count = length(local.emails) topic_arn = aws_sns_topic.sns_topic.arn protocol = \u0026quot;email\u0026quot; endpoint = local.emails[count.index] #ここでlocal変数のメールアドレスを参照 }  上記、endpoint = [\u0026quot;foo@example.com\u0026quot;,\u0026quot;bar@example.com\u0026quot;] でいいじゃないかと思ってそう書くと失敗する。「何でこれでダメなんだ！」となるが仕方ない。簡単そうに見える場所にも何かと罠が潜んでいるTerraformである。\n ","permalink":"https://ecnedaced-seirots.github.io/post/b/aws-sns-topic-multi-endpoint/","summary":"\u003cp\u003eTerraformで、「AWS SNSトピックのサブスク + エンドポイントがメール」のパターンで、複数のメールアドレスを指定したかった。しかし、通常の記述方法だとエラーになってしまうのである。\u003c/p\u003e","title":"TerraformのSNSサブスクリプションで複数メールアドレス指定"},{"content":"前回投稿の続き。Terraformから構築したEKSクラスタで、Fargate Podを起動してみる。\nEKS FargateクラスタをTerraformで作成する(1)\n この時点ではノードグループ、Fargateプロファイルを含めてEKSクラスタが構築完了した状態である。まずはupdate-kubeconfig実行して状態を確認。（kubectlのセットアップは割愛。前からあったv1.19で今回のクラスタのバージョンv1.21に対応していないが、一応動作した）\n $ aws eks update-kubeconfig --name eks-test-cluster $ kubectl get no NAME STATUS ROLES AGE VERSION ip-10-0-2-99.ap-northeast-1.compute.internal Ready \u0026lt;none\u0026gt; 19m v1.21.5-eks-bc4871b ip-10-0-3-18.ap-northeast-1.compute.internal Ready \u0026lt;none\u0026gt; 19m v1.21.5-eks-bc4871b $ kubectl get po -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system aws-node-6fp74 1/1 Running 0 19m kube-system aws-node-ncjhh 1/1 Running 0 19m kube-system coredns-76f4967988-7pr2d 1/1 Running 0 48m kube-system coredns-76f4967988-t4lmc 1/1 Running 0 48m kube-system kube-proxy-58kvx 1/1 Running 0 19m kube-system kube-proxy-pfw7j 1/1 Running 0 19m  ここまではいつもと同じ。最小限のノードに、システム系のPodが起動している。ではFargate Podを起動！\u0026hellip;の前に、前回の構築時にSelectorとしてNamespace[fargate-test]を指定しているため、fargate-testネームスペースが必要である。この時点では対象ネームスペースが存在しないため新規作成する。\n# 作業前のネームスペース確認 $ kubectl get namespace NAME STATUS AGE default Active 54m kube-node-lease Active 54m kube-public Active 54m kube-system Active 54m # ネームスペース fargate-testを作成 $ kubectl create namespace fargate-test namespace/fargate-test created # 確認 $ kubectl get namespace | grep fargate fargate-test Active 53s  ネームスペースが作成されたので、これを指定してFargate Podを起動する。マニフェストは何も用意していないからこんなんで。\n$ kubectl create deployment test-app --namespace fargate-test --image=nginx deployment.apps/test-app created  やっとRunningになった。\n$ kubectl get po -n fargate-test NAME READY STATUS RESTARTS AGE test-app-f8c9656cd-ph7vg 1/1 Running 0 96s  get noしてみると、Fargage専用ノードが起動しているのが確認できた。\n$ kubectl get no NAME STATUS ROLES AGE VERSION fargate-ip-10-0-2-10.ap-northeast-1.compute.internal Ready \u0026lt;none\u0026gt; 103s v1.21.2-eks-06eac09 ip-10-0-2-99.ap-northeast-1.compute.internal Ready \u0026lt;none\u0026gt; 31m v1.21.5-eks-bc4871b ip-10-0-3-18.ap-northeast-1.compute.internal Ready \u0026lt;none\u0026gt; 31m v1.21.5-eks-bc4871b  そういえば、get pods に-o wideつければ一回で確認可能だった。\n$ kubectl get po -n fargate-test -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES test-app-f8c9656cd-ph7vg 1/1 Running 0 5m7s 10.0.2.10 fargate-ip-10-0-2-10.ap-northeast-1.compute.internal \u0026lt;none\u0026gt; \u0026lt;none\u0026gt;  最後にPodのdescribe結果を載せておく。リソース割り当てらしき箇所、[CapacityProvisioned: 0.25vCPU 0.5GB]となっている。これがデフォルト値なんだろう。当然実運用に向けては適宜サイジングすることになる。\n$ kubectl describe po -n fargate-test test-app-f8c9656cd-ph7vg Name: test-app-f8c9656cd-ph7vg Namespace: fargate-test Priority: 2000001000 Priority Class Name: system-node-critical Node: fargate-ip-10-0-2-10.ap-northeast-1.compute.internal/10.0.2.10 Start Time: Mon, 03 Jan 2022 12:31:21 +0900 Labels: app=test-app eks.amazonaws.com/fargate-profile=test-profile pod-template-hash=f8c9656cd Annotations: CapacityProvisioned: 0.25vCPU 0.5GB Logging: LoggingDisabled: LOGGING_CONFIGMAP_NOT_FOUND kubernetes.io/psp: eks.privileged Status: Running IP: 10.0.2.10 IPs: IP: 10.0.2.10 Controlled By: ReplicaSet/test-app-f8c9656cd Containers: nginx: Container ID: containerd://30f18fbf447144fec406634651e8e7ba0651a285a814419b77bf8c4d1d317f44 Image: nginx Image ID: docker.io/library/nginx@sha256:0d17b565c37bcbd895e9d92315a05c1c3c9a29f762b011a10c54a66cd53c9b31 Port: \u0026lt;none\u0026gt; Host Port: \u0026lt;none\u0026gt; State: Running Started: Mon, 03 Jan 2022 12:31:30 +0900 Ready: True Restart Count: 0 Environment: \u0026lt;none\u0026gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-9c7kb (ro) Conditions: Type Status Initialized True Ready True ContainersReady True PodScheduled True Volumes: kube-api-access-9c7kb: Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: \u0026lt;nil\u0026gt; DownwardAPI: true QoS Class: BestEffort Node-Selectors: \u0026lt;none\u0026gt; Tolerations: node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning LoggingDisabled 14m fargate-scheduler Disabled logging because aws-logging configmap was not found. configmap \u0026quot;aws-logging\u0026quot; not found Normal Scheduled 13m fargate-scheduler Successfully assigned fargate-test/test-app-f8c9656cd-ph7vg to fargate-ip-10-0-2-10.ap-northeast-1.compute.internal Normal Pulling 13m kubelet, fargate-ip-10-0-2-10.ap-northeast-1.compute.internal Pulling image \u0026quot;nginx\u0026quot; Normal Pulled 13m kubelet, fargate-ip-10-0-2-10.ap-northeast-1.compute.internal Successfully pulled image \u0026quot;nginx\u0026quot; in 7.409339398s Normal Created 13m kubelet, fargate-ip-10-0-2-10.ap-northeast-1.compute.internal Created container nginx Normal Started 13m kubelet, fargate-ip-10-0-2-10.ap-northeast-1.compute.internal Started container nginx  ここまで確認できたのでPodを削除\n$ kubectl delete deployment test-app --namespace fargate-test  eksクラスタはterraform destroyで一気に削除した。\n$ time terraform destroy : : aws_eks_fargate_profile.fargate-test: Destroying... [id=eks-test-cluster:test-profile] aws_eks_node_group.eks-node: Destroying... [id=eks-test-cluster:eks-test-node] 6m6.166s  次回からは再びterraform applyでお気軽に検証できるもんな！\u0026hellip;と言いつつ、正直Fargateの有り難みってよくわからんな。\u0026hellip;ということがわかった検証であった。Podとノードは1:1と決まっていて処理が終わったらノードも消滅するとなれば、バッチ処理に向いていることくらいは想像がつくが。\n通常のEKSとFargateは共存可能なため、アプリの処理の特性によってそれぞれどちらを選択するのか、または1クラスタにおいて片方のみで運用するのか、その検討のために頭を使うことになる。やはり夢は見ちゃいけないのである。\n ","permalink":"https://ecnedaced-seirots.github.io/post/b/eks-fargate-by-terraform-2/","summary":"\u003cp\u003e前回投稿の続き。Terraformから構築したEKSクラスタで、Fargate Podを起動してみる。\u003c/p\u003e","title":"EKS FargateクラスタをTerraformで作成する(2)"},{"content":"一回EKSのFargateを試してみようと思っていたので、新年早々やってみた。せっかくなのでEKS+FargateプロファイルをTerraformから作成する。他の事例だとeksctlから構築するパターンが多いようだが、最近Terraformいじってるし、eksctl嫌いなもんで。（削除時にハマったこともあり）\n その前に Fargateのことをよく分かっていなかったので基本項目をあげておく。以下は2022年1月現在の仕様・制約事項。\n 「面倒なEC2の管理が不要！」と大っぴらに言われているが、Fargateでも最低限のノードグループは必要。 Fargate Pod用のノードが起動するサブネットはプライベートサブネットであること。 2.のPodがコントロールプレーンと通信するためVPC外へ出る必要がある。NATゲートウェイ/プロキシ/VPCエンドポイントいずれかの方式で外部への通信経路を確保する。 Fargateプロファイルを設定する。（大雑把に言うとここでFargateが動作する環境を定義する） FargateにおけるPodとノードの関係は常に1:1となる。（1ノードに複数のPodは起動できない） Fargate Pod専用のIAMロールが必要。（4.で指定） Fargateと通常のEKSワーカーノードの共存が可能。   実は 1.については知らなかったので、EKSクラスタ起動してFargateプロファイル設定すればPodが起動できるもんだと思っていた。EC2がいらないってウソやんけ\u0026hellip;。当初その辺りで躓いたのだが、余計な失敗ネタは置いといて成功パターンを書いておく。\n で、Terraformのコード載せる前に基本前提について。上記の制約があることから、最小限以下の構成を用意しておく。それらもTerraformで作るのであればそれでもいいが、自分はさすがに面倒見切れないので既存のアイテムを流用した。VPCはすでにある想定で：\n AZにまたがったパブリックサブネット AZにまたがったプライベートサブネット NATゲートウェイ（2.のサブネットが外部と通信するため） ①EKSクラスタ ②ノードグループ ③Fargate Pod用の各IAMロール ノードグループリモートアクセス用のセキュリティグループ EKSクラスタ用のセキュリティグループ ノードグループ用のssh key   Fargateだろうが何だろうが、これらの前提アイテムは別途構築しなければならないのである。「eksctlならよしなに作ってくれるから楽！」とか言ってても、PoCならともかく実運用時にeksctlでお任せ構築なんてあり得ないのである。夢は見させてくれないのである。\n IAMロールについて ①クラスタ②ノード用ロールは既存のを使用した。ちなみにそれぞれ必要なポリシーは、①はAmazonEKSClusterPolicy、②はAmazonEKSWorkerNodePolicy、AmazonEC2ContainerRegistryReadOnlyとなる。②については、PoC時は最小限の権限でよいが本来Podが必要とするサービスの権限をすべてポリシーに追加する。\n参考\nAmazon EKS クラスター の IAM ロール\nAmazon EKS ノード の IAM ロール\nFargate Pod用ロールはCLIから新規作成した。信頼ポリシー用JSONを用意してコマンド実行。\n eks-fargate-pods-policy.json（信頼ポリシー用JSON）\n{ \u0026quot;Version\u0026quot;: \u0026quot;2012-10-17\u0026quot;, \u0026quot;Statement\u0026quot;: { \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Principal\u0026quot;: { \u0026quot;Service\u0026quot;: \u0026quot;eks-fargate-pods.amazonaws.com\u0026quot; }, \u0026quot;Action\u0026quot;: \u0026quot;sts:AssumeRole\u0026quot; } }  # ロール作成 $ aws iam create-role \\ --role-name AmazonEKSFargatePodExecutionRole \\ --assume-role-policy-document file://eks-fargate-pods-policy.json # ロールにポリシーをアタッチ aws iam attach-role-policy \\ --role-name AmazonEKSFargatePodExecutionRole\\ --policy-arn \u0026quot;arn:aws:iam::aws:policy/AmazonEKSFargatePodExecutionRolePolicy\u0026quot;  Teraraformコード 以降、Terraformコード。今回、前提条件となるネットワーク環境、IAMロール等はTerraform外で作成済みのアイテムを指定している。\neks.tf\n############################################# # EKS Cluster ############################################# resource \u0026quot;aws_eks_cluster\u0026quot; \u0026quot;eks-cluster\u0026quot; { name = \u0026quot;eks-test-cluster\u0026quot; role_arn = var.cluster-role vpc_config { subnet_ids = [var.public-a, var.public-c] security_group_ids = [var.cluster-sg] } } output \u0026quot;endpoint\u0026quot; { value = aws_eks_cluster.eks-cluster.endpoint } output \u0026quot;kubeconfig-certificate-authority-data\u0026quot; { value = aws_eks_cluster.eks-cluster.certificate_authority[0].data } ############################################# # EKS Node Group ############################################# resource \u0026quot;aws_eks_node_group\u0026quot; \u0026quot;eks-node\u0026quot; { cluster_name = aws_eks_cluster.eks-cluster.name node_group_name = \u0026quot;eks-test-node\u0026quot; node_role_arn = var.node-role subnet_ids = [var.private-a, var.private-c] ami_type = \u0026quot;AL2_x86_64\u0026quot; instance_types = [\u0026quot;t3.small\u0026quot;] labels = { type = \u0026quot;fargate-test\u0026quot; } remote_access { ec2_ssh_key = var.keyname source_security_group_ids = [var.remote-sg] } scaling_config { desired_size = 2 max_size = 2 min_size = 2 } } ############################################# # EKS Fargate Profile ############################################# resource \u0026quot;aws_eks_fargate_profile\u0026quot; \u0026quot;fargate-test\u0026quot; { cluster_name = aws_eks_cluster.eks-cluster.name fargate_profile_name = \u0026quot;test-profile\u0026quot; pod_execution_role_arn = var.pod-role subnet_ids = [var.private-a, var.private-c] selector { namespace = \u0026quot;fargate-test\u0026quot; } }  以下、変数参照先のvariables.tf。最近のTerraform PoCではtfvarsを使っていたが、今回は単純なケースなのでこれ一本で行く。\nvariables.tf\n############################# # public subnet-a ############################# variable \u0026quot;public-a\u0026quot; { default = \u0026quot;subnet-xxxxxxxxxxxxxxxxx\u0026quot; } ############################# # public subnet-c ############################# variable \u0026quot;public-c\u0026quot; { default = \u0026quot;subnet-yyyyyyyyyyyyyyyyy\u0026quot; } ############################# # private subnet-a ############################# variable \u0026quot;private-a\u0026quot; { default = \u0026quot;subnet-wwwwwwwwwwwwwwwww\u0026quot; } ############################# # private subnet-c ############################# variable \u0026quot;private-c\u0026quot; { default = \u0026quot;subnet-zzzzzzzzzzzzzzzzz\u0026quot; } ############################# # cluster security group ############################# variable \u0026quot;cluster-sg\u0026quot; { default = \u0026quot;sg-xxxxxxxxxxxxxxxxx\u0026quot; } ############################# # eks node security group ############################# variable \u0026quot;remote-sg\u0026quot; { default = \u0026quot;sg-xxxxxxxxxxxxxxxxx\u0026quot; } ############################# # cluster IAM role ############################# variable \u0026quot;cluster-role\u0026quot; { default = \u0026quot;arn:aws:iam::012345678910:role/eks-cluster-role\u0026quot; } ############################# # node IAM role ############################# variable \u0026quot;node-role\u0026quot; { default = \u0026quot;arn:aws:iam::012345678910:role/eks-node-group-role\u0026quot; } ############################# # pod IAM role ############################# variable \u0026quot;pod-role\u0026quot; { default = \u0026quot;arn:aws:iam::012345678910:role/AmazonEKSFargatePodExecutionRole\u0026quot; } ############################# # eks node key ############################# variable \u0026quot;keyname\u0026quot; { default = \u0026quot;eks-workeernode-key\u0026quot; }  この状態で terraform apply したところ、十数分後にEKSクラスタ/ノードグループ/Fargateプロファイルの作成が完了した。\n 最後のFargate Profile -＞ [Pod selectors]は、Fargate上で実行させたいPodの条件が設定されている。上記の場合Namespaceに[fargate-test]を指定しているため、Kubernetes上のfargate-testネームスペースにおいてFarget Podが実行されるようになる。\n ではようやく、Fargate Podを起動してみる。\u0026hellip;といきたいが、長くなるので次回に持ち越し。\n 参考\nGetting started with AWS Fargate using Amazon EKS\n【AWS】 EKS on Fargate のクラスタを構築してみる\nEKS on Fargateの特徴、通常のEKSとの違いは何か？（第1回）\nAmazon Fargate for Amazon EKSを試してみた #reinvent\nなんとなく「Fargate for EKS」が分かった気になる？ ～ いろいろなギモンを調べてみた ～ #reinvent\n  続きは以下。\nEKS FargateクラスタをTerraformで作成する(2)\n","permalink":"https://ecnedaced-seirots.github.io/post/b/eks-fargate-by-terraform/","summary":"\u003cp\u003e一回EKSのFargateを試してみようと思っていたので、新年早々やってみた。せっかくなのでEKS+FargateプロファイルをTerraformから作成する。他の事例だとeksctlから構築するパターンが多いようだが、最近Terraformいじってるし、eksctl嫌いなもんで。（削除時にハマったこともあり）\u003c/p\u003e","title":"EKS FargateクラスタをTerraformで作成する(1)"},{"content":"今朝目覚めの前に、REST APIのリクエストURL記述について、これなら上手くいくとかいかないとか議論しているような夢を見た。\n31日の目覚め前にもTerraformコードが夢に登場した。（確かに気になっていた部分だったので31日はそのままPoCして記事に書いた）\n 夢に仕事関係のネタが登場することはたまにある、過去にもその時気になっているコードなどがフラッシュバック状態で登場することはあった。昔は「うわ、夢の中でまで\u0026hellip;やめてくれ！」と嫌な気分になったものだが、いつからか「脳が気になっている情報を整理しているんだろうな」と淡々と受け流すようになった。\nしかし今現在仕事でREST APIに関わる対応はしていないのに何故これが夢に現れたんだろう、と不思議に思った。それに関連して過去の同僚のことが思い浮かんだりしたので、本来の目的はその同僚を思い出すことだったのかもしれない。それでも意味不明だが、まぁいいや。\n 通常、朝方の目覚めの前は数十分程度のレム睡眠状態にあり、この時間帯に夢を見ているらしい。この時は「手続き記憶」の定着を行なっていると聞いた。手続き記憶とは、楽器の演奏やスポーツなどの身体的な動作の記憶を示す、と。ではプログラムのコードや仕事関連の事柄が朝方の夢に現れるのは、それも手続き記憶の種類に入るのだろうか、と思って軽く調べたところ、別の意味も判明した。\nレム睡眠時に見る夢は、前日（直近）に経験した出来事と過去の出来事の関連性を整理したり、記憶の定着や索引付けを行なっているらしい。それを知って納得した。\n  また，記憶と睡眠の関係において，ノンレム睡眠－レム睡眠は異なる働きをもっています。ノンレム睡眠は，深いノンレム睡眠（一晩の睡眠の前半に多い）では，「いやな記憶」を消去する働きがあります。一方，浅いノンレム睡眠（一晩の睡眠の後半：朝方に多い）は，手続き記憶を固定する働きがあります。手続き記憶とは，自転車の乗り方や，習字，スポーツの技術などを身につけることと理解してください。また，浅いノンレム睡眠には，昼間記憶したことと過去の記憶を結合する働きもあります。これは色々な記憶を相互に関連づけることです。\n  さらに。以下重要。\n  基本的な睡眠として，７時間半寝るとすると，前半では深いノンレム睡眠が出現し，後半で浅いノンレム睡眠が出現することを思い出してください。就床後，間も無い時にしっかり寝ないと，昼間に経験した恐怖などの「嫌な記憶（嫌な感覚）」が消えず，心が癒されません。また，３時間や４時間の短時間睡眠では，浅いノンレム睡眠が無くなり，昼間一生懸命練習したことが身につかず，また，色々な出来事の関連情報が記憶されません。更に，短時間睡眠では，朝方の長いレム睡眠がないので，記憶の定着や記憶の索引付けが出来なくなります。\n 第１回 「睡眠と記憶について／基本的な睡眠とは」\n 不快な記憶を忘却させ、生きていくために必要な情報は整理して記憶の定着に導く。睡眠のメカニズム、人間の脳の働き\u0026hellip;すげぇ！！\n ところで夢に過去（または現在）の同僚が登場するのは、その時どんな気分だったかにより意味合いが変わってくるそうだが、個人的には、爽快というわけでもないが不快な気分ではなく、どちらかと言えばプラス方向の気分であることが多い。その場合、自分の理想像として登場している意味があるとかないとか。\nま、今朝思い出した元同僚は確かにできる奴だった。しばらく前にも別の、過去に一緒に仕事をした相当キレる人物が夢に登場したことがあった。これは何を象徴しているのか\u0026hellip;。それにしても、一緒に仕事をした時期は数ヶ月程度で、しかも数えてみると約8年くらい昔なのだ。\nこういう事柄が夢に現れるということは、やはり自分にとって記憶に残しておくべき意味があると解釈すべき、なんだろうか。\n ","permalink":"https://ecnedaced-seirots.github.io/post/b/mind-hacks-rem-sleep/","summary":"\u003cp\u003e今朝目覚めの前に、REST APIのリクエストURL記述について、これなら上手くいくとかいかないとか議論しているような夢を見た。\u003c/p\u003e","title":"レム睡眠と夢と記憶"},{"content":"イベント監視通知のためにAWS Configを設定して検証したが、個人PoCであり普段は必要ないため削除しようと思った。微々たる金額だが課金対象だし。\nしかしマネコンから削除しようとしたところ、該当する操作内容が見当たらない。AWS Configはマネコンからは削除できない仕様らしい。\nCLIからであれば可能ということで、CLIからaws configを削除する。\n 削除前の確認 $ aws configservice describe-delivery-channels { \u0026quot;DeliveryChannels\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;s3BucketName\u0026quot;: \u0026quot;config-bucket-xxxxxxxxxxxxx\u0026quot; } ] } $ aws configservice describe-configuration-recorders { \u0026quot;ConfigurationRecorders\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;roleARN\u0026quot;: \u0026quot;arn:aws:iam::012345678910:role/aws-service-role/config.amazonaws.com/AWSServiceRoleForConfig\u0026quot;, \u0026quot;recordingGroup\u0026quot;: { \u0026quot;allSupported\u0026quot;: false, \u0026quot;includeGlobalResourceTypes\u0026quot;: false, \u0026quot;resourceTypes\u0026quot;: [ \u0026quot;AWS::EC2::Instance\u0026quot; ] } } ] }  削除実行 以下の順番で。先にconfiguration recorderを削除しないとエラーになる。\n$ aws configservice delete-configuration-recorder --configuration-recorder-name default $ aws configservice delete-delivery-channel --delivery-channel-name default  削除後の確認 $ aws configservice describe-delivery-channels { \u0026quot;DeliveryChannels\u0026quot;: [] } $ aws configservice describe-configuration-recorders { \u0026quot;ConfigurationRecorders\u0026quot;: [] }  参考\nAWSマネジメントコンソールから消せないAWS Configの設定をAWSCLIで綺麗にする方法\n  ","permalink":"https://ecnedaced-seirots.github.io/post/b/delete-aws-config/","summary":"\u003cp\u003eイベント監視通知のためにAWS Configを設定して検証したが、個人PoCであり普段は必要ないため削除しようと思った。微々たる金額だが課金対象だし。\u003c/p\u003e","title":"AWS ConfigをCLIから削除する"},{"content":"大晦日も淡々と自宅PoCをし、淡々と記事を書く。Terraform loop処理シリーズ、今回はEC2インスタンスに対するCloudWatch Alarmの作成をやってみる。\n最初は定数バージョンのサンプルから。EventBridgeでアラームを検知する想定のためalarm_actionsは設定しない。\n（補足）SNSと直接連携する場合は以下のように記述する。\nalarm_actions = [aws_sns_topic.sns.arn]  ################################################ # CloudWatch metric alarm # 定数版 ################################################ resource \u0026quot;aws_cloudwatch_metric_alarm\u0026quot; \u0026quot;alarm_001\u0026quot; { alarm_name = \u0026quot;ec2-alarm-cpu-001\u0026quot; comparison_operator = \u0026quot;GreaterThanThreshold\u0026quot; evaluation_periods = \u0026quot;1\u0026quot; metric_name = \u0026quot;CPUUtilization\u0026quot; namespace = \u0026quot;AWS/EC2\u0026quot; period = \u0026quot;60\u0026quot; statistic = \u0026quot;Average\u0026quot; threshold = \u0026quot;80\u0026quot; alarm_description = \u0026quot;CPU Usage Check Alarm\u0026quot; datapoints_to_alarm = \u0026quot;1\u0026quot; treat_missing_data = \u0026quot;missing\u0026quot; dimensions = { InstanceId = \u0026quot;i-xxxxxxxxxxxxxxxxx\u0026quot; } }  上記はインスタンスi-xxxxxxxxxxxxxxxxxに対するCPU使用率監視のアラームを作成する。しかし実際にはひとつのインスタンスに対してメモリ、ディスク、複数のプロセス監視等を行うだろう。（あーEC2面倒くせぇ\u0026hellip;）それらを繰り返し記述するのはありえないのでloopにする。\nちなみにここではTerraformで作成していないインスタンスを指定したのでインスタンスIDを直接指定しているが、インスタンスもTerraformで作成する場合は以下のように記述する。\n  dimensions = { InstanceId = aws_instance.instance_001.id }  以下がloopバージョン。インスタンスが複数ある場合、loopの固まりをその分追加で作成し、aws_instance.instance_002.id, aws_instance.instance_003.id \u0026hellip;など指定すればよいかと。EC2インスタンス側もloopで作成する場合はまた参照方法が異なってくるが、EC2はlookupで参照するのは不可能と思われる。他のアラーム用パラメータとEC2のloopの順番は一致しないはずだから。（上手く言い表せない）\n metric_alarm.tf\n################################################ # CloudWatch metric alarm # loop版 ################################################ resource \u0026quot;aws_cloudwatch_metric_alarm\u0026quot; \u0026quot;alarm_001\u0026quot; { for_each = var.ec2_alarm001_param_list alarm_name = lookup(each.value, \u0026quot;alarm_name\u0026quot;) comparison_operator = lookup(each.value, \u0026quot;comparison_operator\u0026quot;) evaluation_periods = \u0026quot;1\u0026quot; metric_name = lookup(each.value, \u0026quot;metric_name\u0026quot;) namespace = lookup(each.value, \u0026quot;namespace\u0026quot;) period = lookup(each.value, \u0026quot;period\u0026quot;) statistic = lookup(each.value, \u0026quot;statistic\u0026quot;) threshold = lookup(each.value, \u0026quot;threshold\u0026quot;) alarm_description = lookup(each.value, \u0026quot;alarm_description\u0026quot;) datapoints_to_alarm = \u0026quot;1\u0026quot; treat_missing_data = lookup(each.value, \u0026quot;treat_missing_data\u0026quot;) dimensions = { InstanceId = \u0026quot;i-xxxxxxxxxxxxxxxxx\u0026quot; } }  以下は参照する変数リストとなる。\nmetric_alarm.auto.tfvars\n########################################### # CloudWatch alarm vars ########################################### ec2_alarm001_param_list = { param1 = { alarm_name = \u0026quot;ec2-alarm-system-001\u0026quot; comparison_operator = \u0026quot;GreaterThanOrEqualToThreshold\u0026quot; metric_name = \u0026quot;StatusCheckFailed_System\u0026quot; namespace = \u0026quot;AWS/EC2\u0026quot; period = \u0026quot;300\u0026quot; statistic = \u0026quot;Maximum\u0026quot; threshold = \u0026quot;1\u0026quot; alarm_description = \u0026quot;Node Status Monitoring\u0026quot; treat_missing_data = \u0026quot;missing\u0026quot; } param2 = { alarm_name = \u0026quot;ec2-alarm-status-001\u0026quot; comparison_operator = \u0026quot;GreaterThanOrEqualToThreshold\u0026quot; metric_name = \u0026quot;StatusCheckFailed_Instance\u0026quot; namespace = \u0026quot;AWS/EC2\u0026quot; period = \u0026quot;300\u0026quot; statistic = \u0026quot;Maximum\u0026quot; threshold = \u0026quot;1\u0026quot; alarm_description = \u0026quot;Node Status Monitoring\u0026quot; treat_missing_data = \u0026quot;missing\u0026quot; } param3 = { alarm_name = \u0026quot;ec2-alarm-cpu-001\u0026quot; comparison_operator = \u0026quot;GreaterThanThreshold\u0026quot; metric_name = \u0026quot;CPUUtilization\u0026quot; namespace = \u0026quot;AWS/EC2\u0026quot; period = \u0026quot;60\u0026quot; statistic = \u0026quot;Average\u0026quot; threshold = \u0026quot;80\u0026quot; alarm_description = \u0026quot;CPU Usage Monitoring\u0026quot; treat_missing_data = \u0026quot;missing\u0026quot; } param4 = { alarm_name = \u0026quot;ec2-alarm-process-001\u0026quot; comparison_operator = \u0026quot;LessThanThreshold\u0026quot; metric_name = \u0026quot;procstat_lookup_pid_count\u0026quot; namespace = \u0026quot;Prosess\u0026quot; period = \u0026quot;60\u0026quot; statistic = \u0026quot;Average\u0026quot; threshold = \u0026quot;1\u0026quot; alarm_description = \u0026quot;Process Monitoring\u0026quot; treat_missing_data = \u0026quot;missing\u0026quot; } }  こんなやっつけコードだがあっさり期待値になった。\n  ちなみにこれはloop回数が4つ分だけだから手動で書いたが、実際にはもっと多くの監視項目が並ぶ。過去記事に書いたように変数リストを自動生成する仕組みを作った方がよい。\nTerraformのtfvarsファイルを自動生成する\n ということでこれまでTerraformのloop処理方式をいくつか探ってきたが、どのような構成にすべきかはそれなりに頭を捻る必要がある。構成というのは、全体的な範囲と、リソース毎の構成。tfコード本体と変数リストの組み合わせとか。loop処理にすべきかどうかはリソースの数にもよる。また、loopか否かによって参照するリソース側の記述も変わってくる。回答はひとつではないのである。\nまぁ頭を捻る場面があるからこそ、面白いとも言えるけど。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform-loop-example-6/","summary":"\u003cp\u003e大晦日も淡々と自宅PoCをし、淡々と記事を書く。Terraform loop処理シリーズ、今回はEC2インスタンスに対するCloudWatch Alarmの作成をやってみる。\u003c/p\u003e","title":"Terraform loop処理の応用編(5) - Metric Alarm"},{"content":"過去LGS（リーキーガット症候群:Leaky gut syndrome) に罹ったことがあるから、腸内の日和見菌が凶暴化するとどれほど身体と脳が破壊されるか身に染みてわかる。\nあの地獄を抜け出すのに、2年以上はかかった。しかし油断すればまた日和見菌が暴徒化する。\n日和見菌は憎らしくて厄介だが、人体は日和見菌なくして生存できないのも事実だ。だから目標は日和見菌の撲滅ではない。無害な菌に戻して共存するしかない。\n世の中の仕組みと全く同じ。この世はごく一部の悪玉菌、善玉菌と、大多数の日和見菌で成り立っている。今の世界も極限までに日和見菌が凶暴化した状況に見える。しかし日和見菌は撲滅対象ではない。\n 上記は約一年前、2020年11月19日に書いたメモ書き。たまたま発見した。ここで言っている「日和見菌」とは、99.99%の日本人のことである。\n  ","permalink":"https://ecnedaced-seirots.github.io/post/a/lgs/","summary":"\u003cp\u003e過去LGS（リーキーガット症候群:Leaky gut syndrome) に罹ったことがあるから、腸内の日和見菌が凶暴化するとどれほど身体と脳が破壊されるか身に染みてわかる。\u003c/p\u003e","title":"Non Title"},{"content":"Pythonライブラリをローカルインストールする必要に迫られて対応した記録。実行した環境はWindowsだが、Linuxでも同様らしい。\n pypi.orgにアクセスし、ライブラリ名で検索。対象のwhlファイルをダウンロードし、実行環境に配置する。tar.gz形式の場合もあるが、それもWindowsにインストール可能。\npypi.org\n 複数の参考記事によれば以下のようなコマンドが紹介されている。（pipのパスが通っていない場合はpy -m pip ...とする）\n\u0026gt; pip install [Pythonパッケージのパス]  しかしそのまま実行すると、pip freeze実行時の出力がおかしい。\n\u0026gt; pip install ./six-1.16.0-py2.py3-none-any.whl \u0026gt; pip freeze six @ file:///C:/Users/xxxxx/six-1.16.0-py2.py3-none-any.whl  一旦アンインストールして、--find-linksオプションを指定して再度インストール。\n\u0026gt; pip install --no-index --find-links=./six-1.16.0-py2.py3-none-any.whl six  上記コマンドにした場合、期待値になる。\n\u0026gt; pip freeze six==1.16.0  ","permalink":"https://ecnedaced-seirots.github.io/post/a/python-package-localinstall/","summary":"\u003cp\u003ePythonライブラリをローカルインストールする必要に迫られて対応した記録。実行した環境はWindowsだが、Linuxでも同様らしい。\u003c/p\u003e","title":"Pythonライブラリのローカルインストール方法"},{"content":"村上龍著「愛と幻想のファシズム」より\n  「危機が生じると、弱者がくっきりと浮かび上がるもんだ」\n   本当は人間には何の欲望もない。対象があるために欲望が発生するだけだ。もし、欲望の充足、つまり自らの欲望の消去、または消去の過程を、快楽と呼ぶのならば、グリズリーは、永遠の快楽と共に在るということになる。\n   俺は結局撃たなかった。そのグリズリーを中心とした完璧な世界の中で、自分のことを余計なものだと感じた。そんなことは初めてだった。ライフルを下げている自分をみじめだと思った。ライフルがなぜ必要かがわかった。人間はあまりにも不完全で、快楽の森林からはっきりと拒絶されているために、ライフルが必要なのだ。\n   ","permalink":"https://ecnedaced-seirots.github.io/post/a/ryu-quotes-4/","summary":"\u003cp\u003e村上龍著「愛と幻想のファシズム」より\u003c/p\u003e\n\u003cp\u003e \u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e「危機が生じると、弱者がくっきりと浮かび上がるもんだ」\u003c/p\u003e\n\u003c/blockquote\u003e","title":"「愛と幻想のファシズム」より(4)"},{"content":"AWS Lambdaでサイズがでかいリソースをアップロードすると、こんなメッセージが表示されてコードが見れないことがある。\n 日本語\n Lambda 関数「xxxxxx-function」のデプロイパッケージが大きすぎて、インラインコード編集を有効にできません。ただし、関数を呼び出すことはできます。\n  英語\n The deployment package of your Lambda function \u0026ldquo;xxxxxx-function\u0026rdquo; is too large to enable inline code editing. However, you can still invoke your function.\n  この時アップロードしたのは、関数自体は空ファイルなのだが（アップロードしてからインラインで記述するつもりだった）モジュールが相当重かったようだ。こういうのは、Lambdaで処理すべきじゃないんだな。EC2上じゃなくてLambdaでサクッと実行できればいいな〜て処理があったのだが、頓挫\u0026hellip;\nそれはしょうがないとして、大分過去に検証した関数をまた見たくなって覗いたら上記のメッセージが出てコードが見れないという事例があったからメモ。って、以下記事にある通りマネコン画面から簡単にエクスポートできるんだけど。\nコンソールで確認できないLambda関数のコードを確認する\n 画面右上のActionプルダウンから、\u0026ldquo;Export function\u0026quot;選択。（日本語「関数のエクスポート」）\n CLIだったらaws lambda get-functionでエクスポート可能。でもマネコンからの方が簡単だな。\n   ","permalink":"https://ecnedaced-seirots.github.io/post/a/lambda-function-export/","summary":"\u003cp\u003eAWS Lambdaでサイズがでかいリソースをアップロードすると、こんなメッセージが表示されてコードが見れないことがある。\u003c/p\u003e","title":"AWS Lambda関数をダウンロードする"},{"content":"過去に類似のテーマで、CloudTrailによるイベント監視 + 通知メールカスタマイズをしてみた。今回はイベントソースをAWS Configにしてみる。\n（10月頃から金太郎飴のように類似の検証を重ね重ねやっていて脳内パズル状態甚だしいが、やらないことには整理ができないもんだから）\nAWSイベント監視 - CloudTrail + EventBridge + Lambdaでメールカスタマイズ(2)\n EventBridgeのルールで変更を検知したいが、ConfigとEventBridgeのルールはそれぞれ独立している様子で、仕組みが今いち不明。基本的にConfigで設定するルールはコンプライアンスに沿っているかどうかをチェックするためのものであり、変更を検知する目的とは意味合いが違うみたいだ。これまでその辺もよくわかっていなかった。実を言うと今もよくわかってはいないが、何はともあれConfigを用意して試す。Configのルールはマネージドのルールから「ec2-instance-profile-attached」をつけておいた。S3バケット、IAMロールは自動で生成させた。\n 今回作成したリソース名称。\n   アイテム 名称     SNSトピック custom-event-notification   Lambda用IAMロール custom-event-mail-role   Lambda関数 config-event-function   eventルール config-change-notify-rule     eventルール(EventBridge)は、当初イベント内容を絞って試したが検知されなかったのでとりあえずAnyにした。\n{ \u0026#34;source\u0026#34;: [\u0026#34;aws.config\u0026#34;], \u0026#34;detail-type\u0026#34;: [\u0026#34;Config Configuration Item Change\u0026#34;] }  イベント内容を確認するため、最初は以下のLambdaコードでメールを飛ばしてみる。SNSトピックは環境変数で指定。\nimport json import boto3 import os print(\u0026#39;Loading function\u0026#39;) sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] def lambda_handler(event, context): type = event[\u0026#39;detail-type\u0026#39;] Msg = json.dumps(event) sub = \u0026#39;[AWS Config]\u0026#39; + str(type) client = boto3.client(\u0026#39;sns\u0026#39;) response = client.publish( TopicArn = sns_arn, Message = Msg, MessageStructure = \u0026#39;context\u0026#39;, Subject = sub ) return  EC2インスタンスにつけたIAMロールをデタッチしてイベントルールが検知すると、JSONデータが丸ごと送信された。これをJSONファイルとして保存し、解析する。\n\u0026gt;\u0026gt;\u0026gt; event_file = open('config_sample.json','r') \u0026gt;\u0026gt;\u0026gt; type(event_file) \u0026lt;class '_io.TextIOWrapper'\u0026gt; \u0026gt;\u0026gt;\u0026gt; event = json.load(event_file) \u0026gt;\u0026gt;\u0026gt; msg = json.dumps(event, indent=3) #JSONを見やすく整形する \u0026gt;\u0026gt;\u0026gt; print(msg) { \u0026quot;version\u0026quot;: \u0026quot;0\u0026quot;, \u0026quot;id\u0026quot;: \u0026quot;07cedb49-ed89-6b1f-3ef7-b02fch9ae318\u0026quot;, \u0026quot;detail-type\u0026quot;: \u0026quot;Config Configuration Item Change\u0026quot;, \u0026quot;source\u0026quot;: \u0026quot;aws.config\u0026quot;, \u0026quot;account\u0026quot;: \u0026quot;012345678910\u0026quot;, \u0026quot;time\u0026quot;: \u0026quot;2021-12-26T04:36:35Z\u0026quot;, \u0026quot;region\u0026quot;: \u0026quot;ap-northeast-1\u0026quot;, \u0026quot;resources\u0026quot;: [ \u0026quot;arn:aws:ec2:ap-northeast-1:012345678910:instance/i-xxxxxxxxxxxxxxxxx\u0026quot; ], \u0026quot;detail\u0026quot;: { \u0026quot;recordVersion\u0026quot;: \u0026quot;1.3\u0026quot;, \u0026quot;messageType\u0026quot;: \u0026quot;ConfigurationItemChangeNotification\u0026quot;, \u0026quot;configurationItemDiff\u0026quot;: { \u0026quot;changedProperties\u0026quot;: { \u0026quot;Configuration.IamInstanceProfile\u0026quot;: { \u0026quot;updatedValue\u0026quot;: { \u0026quot;arn\u0026quot;: \u0026quot;arn:aws:iam::012345678910:instance-profile/test-instance-role\u0026quot;, \u0026quot;id\u0026quot;: \u0026quot;AIPBIC67ZVZTAHPSHTWDM\u0026quot; }, \u0026quot;changeType\u0026quot;: \u0026quot;CREATE\u0026quot; } }, \u0026quot;changeType\u0026quot;: \u0026quot;UPDATE\u0026quot; }, (snip)  ちなみに実際に取得したevent生データは以下。（一部マスク実施）\n{'version': '0', 'id': '03696e62-00e3-a8c1-3d1d-854a5153b93e', 'detail-type': 'Config Configuration Item Change', 'source': 'aws.config', 'account': '012345678901', 'time': '2021-12-26T04:12:26Z', 'region': 'ap-northeast-1', 'resources': ['arn:aws:ec2:ap-northeast-1:012345678901:instance/i-xxxxxxxxxxxxxxxxx'], 'detail': {'recordVersion': '1.3', 'messageType': 'ConfigurationItemChangeNotification', 'configurationItemDiff': {'changedProperties': {'Configuration.IamInstanceProfile': {'previousValue': {'arn': 'arn:aws:iam::012345678901:instance-profile/system-role', 'id': 'AIPAQNBL2HJCF36XERVQR'}, 'changeType': 'DELETE'}}, 'changeType': 'UPDATE'}, 'notificationCreationTime': '2021-12-26T04:12:26.909Z', 'configurationItem': {'relatedEvents': [], 'relationships': [{'resourceId': 'eni-6v292a2739eb1c95h', 'resourceType': 'AWS::EC2::NetworkInterface', 'name': 'Contains NetworkInterface'}, {'resourceId': 'sg-02a83b08a8bw1379f', 'resourceType': 'AWS::EC2::SecurityGroup', 'name': 'Is associated with SecurityGroup'}, {'resourceId': 'subnet-0bw1xc364270607cb', 'resourceType': 'AWS::EC2::Subnet', 'name': 'Is contained in Subnet'}, {'resourceId': 'vol-027326eaebf1903f2', 'resourceType': 'AWS::EC2::Volume', 'name': 'Is attached to Volume'}, {'resourceId': 'vpc-1247b576cb69f93d3', 'resourceType': 'AWS::EC2::VPC', 'name': 'Is contained in Vpc'}], 'configuration': {'amiLaunchIndex': 0.0, 'imageId': 'ami-032s715c7f0f18cue', 'instanceId': 'i-xxxxxxxxxxxxxxxxx', 'instanceType': 't2.micro', 'keyName': 'My.pem', 'launchTime': '2021-12-19T02:43:42.000Z', 'monitoring': {'state': 'disabled'}, 'placement': {'availabilityZone': 'ap-northeast-1a', 'groupName': '', 'tenancy': 'default'}, 'privateDnsName': 'ip-10-0-0-80.ap-northeast-1.compute.internal', 'privateIpAddress': '10.0.0.80', 'productCodes': [], 'publicDnsName': '', 'state': {'code': 80.0, 'name': 'stopped'}, 'stateTransitionReason': 'User initiated (2021-12-19 14:36:10 GMT)', 'subnetId': 'subnet-0bw1xc364270607cb', 'vpcId': 'vpc-1247b576cb69f93d3', 'architecture': 'x86_64', 'blockDeviceMappings': [{'deviceName': '/dev/xvda', 'ebs': {'attachTime': '2020-08-22T09:55:48.000Z', 'deleteOnTermination': True, 'status': 'attached', 'volumeId': 'vol-027326eaebf1903f2'}}], 'clientToken': '', 'ebsOptimized': False, 'enaSupport': True, 'hypervisor': 'xen', 'elasticGpuAssociations': [], 'elasticInferenceAcceleratorAssociations': [], 'networkInterfaces': [{'attachment': {'attachTime': '2020-08-22T09:55:47.000Z', 'attachmentId': 'eni-attach-0d0b8282ec9760266', 'deleteOnTermination': True, 'deviceIndex': 0.0, 'status': 'attached', 'networkCardIndex': 0.0}, 'description': 'Primary network interface', 'groups': [{'groupName': 'dev-sg-mainte', 'groupId': 'sg-02a83b08a8bw1379f'}], 'ipv6Addresses': [], 'macAddress': '03:02:a0:fc:31:48', 'networkInterfaceId': 'eni-6v292a2739eb1c95h', 'ownerId': '012345678901', 'privateDnsName': 'ip-10-0-0-80.ap-northeast-1.compute.internal', 'privateIpAddress': '10.0.0.80', 'privateIpAddresses': [{'primary': True, 'privateDnsName': 'ip-10-0-0-80.ap-northeast-1.compute.internal', 'privateIpAddress': '10.0.0.80'}], 'sourceDestCheck': True, 'status': 'in-use', 'subnetId': 'subnet-0bw1xc364270607cb', 'vpcId': 'vpc-1247b576cb69f93d3', 'interfaceType': 'interface'}], 'rootDeviceName': '/dev/xvda', 'rootDeviceType': 'ebs', 'securityGroups': [{'groupName': 'dev-sg-mainte', 'groupId': 'sg-02a83b08a8bw1379f'}], 'sourceDestCheck': True, 'stateReason': {'code': 'Client.UserInitiatedShutdown', 'message': 'Client.UserInitiatedShutdown: User initiated shutdown'}, 'tags': [{'key': 'Name', 'value': 'terraform-kubectl'}], 'virtualizationType': 'hvm', 'cpuOptions': {'coreCount': 1.0, 'threadsPerCore': 1.0}, 'capacityReservationSpecification': {'capacityReservationPreference': 'open'}, 'hibernationOptions': {'configured': False}, 'licenses': [], 'metadataOptions': {'state': 'applied', 'httpTokens': 'optional', 'httpPutResponseHopLimit': 1.0, 'httpEndpoint': 'enabled'}, 'enclaveOptions': {'enabled': False}}, 'supplementaryConfiguration': {}, 'tags': {'Name': 'terraform-kubectl'}, 'configurationItemVersion': '1.3', 'configurationItemCaptureTime': '2021-12-26T04:12:25.750Z', 'configurationStateId': 1640491945750.0, 'awsAccountId': '012345678901', 'configurationItemStatus': 'OK', 'resourceType': 'AWS::EC2::Instance', 'resourceId': 'i-xxxxxxxxxxxxxxxxx', 'ARN': 'arn:aws:ec2:ap-northeast-1:012345678901:instance/i-xxxxxxxxxxxxxxxxx', 'awsRegion': 'ap-northeast-1', 'availabilityZone': 'ap-northeast-1a', 'configurationStateMd5Hash': '', 'resourceCreationTime': '2021-12-19T02:43:42.000Z'}}}  これで大分見やすくなるが、階層が深いためさらに掘りたい場合は以下のようにkey:valueを抽出する。\n\u0026gt;\u0026gt;\u0026gt; dtl = event['detail'] \u0026gt;\u0026gt;\u0026gt; for k,v in dtl.items(): \u0026gt;\u0026gt;\u0026gt; print(k,v)  その結果、以下のように項目を抽出して表示させることにした。コード内のコメント「# さらに通知内容の項目を抽出」以降のあたり。生データだと余計な情報がめっちゃあるけど、通知に必要な情報だけ送信できればいい。\nLambdaコード（カスタマイズ版）\nimport boto3 import json import os from botocore.exceptions import ClientError from datetime import datetime, timezone, timedelta from dateutil import parser print(\u0026#39;Loading function\u0026#39;) sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] def lambda_handler(event, context): data = event s = json.dumps(data) e = json.loads(s) print(e) # eventから詳細項目を抽出 dtl = e[\u0026#39;detail\u0026#39;] # さらに通知内容の項目を抽出 t = e[\u0026#39;time\u0026#39;] # 発生時刻 rce_type = dtl[\u0026#39;configurationItem\u0026#39;][\u0026#39;resourceType\u0026#39;] # リソースタイプ rce_arn = str(e[\u0026#39;resources\u0026#39;]) # リソースARN diff = str(dtl[\u0026#39;configurationItemDiff\u0026#39;]) # 変更内容 # 時刻変換前処理 JST = timezone(timedelta(hours=+9), \u0026#39;JST\u0026#39;) utcstr_parsed = parser.parse(t) ux_time = utcstr_parsed.timestamp() epoch = int(ux_time) # unixタイムスタンプをJSTに変換 dt = datetime.fromtimestamp(epoch).replace(tzinfo=timezone.utc).astimezone(tz=JST) # dtを整形 dt_str = dt.strftime(\u0026#39;%Y-%m-%d%H:%M:%S\u0026#39;) # 件名整形 subject_str = \u0026#34;検証環境 Config変更通知 - \u0026#34; + rce_type # メッセージ本文整形 fix_msg = \u0026#34;AWS Configで変更を検知しました\u0026#34; + \u0026#34;\\n\u0026#34; time_msg = \u0026#34;発生時刻(JST):\u0026#34; + \u0026#34;\\n\u0026#34; + dt_str type_msg = \u0026#34;リソースタイプ:\u0026#34; + \u0026#34;\\n\u0026#34; + rce_type arn_msg = \u0026#34;リソースARN:\u0026#34; \u0026#34;\\n\u0026#34; + rce_arn diff_msg =\u0026#34;変更内容:\u0026#34; \u0026#34;\\n\u0026#34; + diff msg = fix_msg + \u0026#34;\\n\\n\u0026#34; + time_msg + \u0026#34;\\n\\n\u0026#34; + type_msg + \u0026#34;\\n\\n\u0026#34; + arn_msg + \u0026#34;\\n\\n\u0026#34; + diff_msg + \u0026#34;\\n\\n\u0026#34; try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = msg, Subject = subject_str ) except Exception as e: print(e)  変更を加えても通知が来なくて「おかしいなー」と言いつつ、ゴニョゴニョやっているうちにカスタマイズ版の通知メールが届いた。EC2以外の変更でも通用するかわからんが、一応その前提で作ってはいる。ダメだったらまた考えよう。（イベント検知のためインスタンスのIAMロールの「デタッチ/アタッチ」を何度も繰り返してたら、変なエラーメッセージが出るようになった。スパム行為と見做されてしまったかもしれない）\n 追記\nConfigの「変更内容」にあたるJSONは、発生したイベントによってはさらにボリュームが増して内容がわかりにくくなる。メールでより内容を把握しやすくするのであれば、このJSONもインデントして表示させるとよい。\ndiff_tmp = dtl[\u0026#39;configurationItemDiff\u0026#39;] #この時点では辞書型 diff = json.dumps(diff_tmp, indent=3) #この時点でStringになる  このようにすると、上記サンプルメールの「変更内容」以下のメッセージがインデントされて見やすくなる。\n 以下参考記事。Configの監視はLambdaと直接連携するケースもあり、その場合eventの中身も変わってくるようだ。当然Lambdaコードの内容も変わるので注意。以下のなかでは、最初の記事がEventBridgeと連携する例となる。\n参考\nAWS Configの通知内容をLambdaで整形\n【AWS config】設定変更時のみ独自の形式で通知を送る\nAWS Config Rules カスタムルールを作成してみよう\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/aws-events-custom-mail-3/","summary":"\u003cp\u003e過去に類似のテーマで、CloudTrailによるイベント監視 + 通知メールカスタマイズをしてみた。今回はイベントソースをAWS Configにしてみる。\u003c/p\u003e","title":"AWSイベント監視 - Config + EventBridge + Lambdaでメールカスタマイズ"},{"content":"I miss the aiport and airplane vibes.\n  \u0026hellip;ということで飛行機専門（＋乗り物系）のTumblrブログのリンク並べてみた。\n 以下は2021年暮れ時点でactive。微妙なのもあるが。\n take flight. So Nice Cars airviation Aviation Lover   以下はnon active。\n StopDreaming.StartFlying Airbus A380 L-AEROPORT Wan Arief Lmran on Tumblr Fuckyeah Airplaness   Non activeであっても、ブログを消さないでくれているだけでもありがたい。世界の誰かの「めっちゃ好き！」が、誰かの活力になるんだもんな。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/aviation-blog/","summary":"\u003cp\u003eI miss the aiport and airplane vibes.\u003c/p\u003e","title":"飛行機画像ブログのリンク集"},{"content":"murmur：ぶつぶつ言う、不満をつぶやく\n類：grumble\n\u0026ldquo;Zazie in the Metro\u0026rdquo;(Raymond Queneau) / 地下鉄のザジ（レーモン・クノー）から拾ったが、他の英文小説にも割と頻繁に登場する単語。それだけ普遍的な行為ということか。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/english-murmur/","summary":"murmur：ぶつぶつ言う、不満をつぶやく\n類：grumble\n\u0026ldquo;Zazie in the Metro\u0026rdquo;(Raymond Queneau) / 地下鉄のザジ（レーモン・クノー）から拾ったが、他の英文小説にも割と頻繁に登場する単語。それだけ普遍的な行為ということか。\n ","title":"英語メモ - murmur"},{"content":"村上龍著「愛と幻想のファシズム」より\n  俺達は何も知らない。快楽もない。十万人の哀れな日本人が俺を恐れ、あがめるのは、俺が日本人の中では、生態系の情報と快楽を知っているからだ。\n   恐怖に勝てるのは興奮だけなんだよ\n   厳しさを知ってる奴だけが生き残るんだ、動物だって同じだよ、人間の残飯を漁る熊や狐はすぐに撃たれる、世の中が同じようにずっと続くと思ってる奴はすぐにくたばる、\n  ","permalink":"https://ecnedaced-seirots.github.io/post/a/ryu-quotes-3/","summary":"\u003cp\u003e村上龍著「愛と幻想のファシズム」より\u003c/p\u003e\n\u003cp\u003e \u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e俺達は何も知らない。快楽もない。十万人の哀れな日本人が俺を恐れ、あがめるのは、俺が日本人の中では、生態系の情報と快楽を知っているからだ。\u003c/p\u003e\n\u003c/blockquote\u003e","title":"「愛と幻想のファシズム」より(3)"},{"content":"CloudWatch Logsから、LmabdaでログをS3にエクスポートする。対象のロググループとバケット内の第一階層を引数で指定するようにした。今回の事例ではエクスポートの範囲は「前日0時〜実行当日の0時」となる。\n参考\nboto3 API Reference\nLambdaよりCloudWatchログをS3に保存方法紹介\n 今回の検証に使用したアイテム（個人メモ）    アイテム 名称     Lambda用IAMロール lambda_basic_execution   Lambda関数 log-export-function   S3バケット log-export-xxxxxxxx     Lambda用IAMロールの権限はlogsフルアクセスのみ。S3もいると思ってたがなくてもできた。バケットポリシー側で許可しているからか。S3バケット名は環境変数で指定した。\n S3バケットポリシー（log-export-xxxxxxxx）\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::log-export-xxxxxxxx\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::log-export-xxxxxxxx/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;s3:x-amz-acl\u0026#34;: \u0026#34;bucket-owner-full-control\u0026#34; } } } ] }  Lambdaコード(Python3.9)\nimport boto3 import collections from datetime import datetime, date, time, timedelta import os def lambda_handler(event, context): log_g = event.get('loggrp') key1 = event.get('key_name') # 日付情報取得 yesterday = datetime.combine(date.today()-timedelta(1),time()) today = datetime.combine(date.today(),time()) unix_start = datetime(1970,1,1) # 日付範囲指定。範囲は実行時点を基準としたUNIXタイムスタンプの日本時間(+9h) from_t = int((yesterday-unix_start).total_seconds() * 1000) to_t = int((today-unix_start).total_seconds() * 1000) # S3 bucket + prefix定義（bucket/key1/YYYY/mmDD） bucket = os.environ['S3_BUCKET'] key2 = yesterday.strftime(\u0026quot;%Y\u0026quot;) key3 = yesterday.strftime(\u0026quot;%m-%d\u0026quot;) s3_key = key1 + \u0026quot;/\u0026quot; + key2 + \u0026quot;/\u0026quot; + key3 try: logs = boto3.client('logs') response = logs.create_export_task( logGroupName = log_g, fromTime = from_t, to = to_t, destination = bucket, destinationPrefix = s3_key ) except Exception as e: print(e)  では、Lambda関数をCLIから実行してみる。ま、普通はEventBridge経由とかでやると思うけど。（でもEventBridgeって引数指定できるんかな？）\n--payloadオプションのロググループ名、S3バケットの最初の階層となるサービス種別（ここではEC2)を指定している。これはJSONなので、file://parameter.jsonなどとしてファイル指定でもよい。\n$ aws lambda invoke --function-name log-export-function \\ --payload '{ \u0026quot;loggrp\u0026quot; : \u0026quot;/ec2/var/log/messages\u0026quot;,\u0026quot;key_name\u0026quot; : \u0026quot;EC2\u0026quot; }' \\ --cli-binary-format raw-in-base64-out \\ response.json  実行すると、Prefixはできていたが中身は書き込みテスト用ファイルしかない。このコード上の仕様は、前日の00:00:00 から当日の00:00:00までをエクスポートの対象としている。指定したロググループのログは、実行した時点で定義された日付範囲に含まれていないためである。\n（つまり、12/18の日中にインスタンスを起動してログが送信されたとする。しかしエクスポート対象は前日の2021-12-17 00:00:00 〜 当日の2021-12-18 00:00:00までとなるため、この期間内にログがなければ対象は存在しないことになる）\nちなみに関数が実行されるEC2のタイムゾーンはUTC。Lamabaの環境変数でタイムゾーンをJSTにするのは非推奨らしいので、コード側で制御するのが望ましい、とのこと。タイムゾーンの問題を考え始めるといつも頭の中がジグソーパズル状態になる。\nLambda のタイムゾーンを環境変数TZで指定してはいけないっていう話\nAWS Lambda でのタイムゾーン変換\n  「コード内での時間は常に UTC で扱い、表示する段階でローカル時間に変換する」を意識していればいいかなと思います。\n  これを当てはめると、「コード内の基準はUTCとし、JSTとして処理する必要になった時点でJSTに変換する」と考えればいいか。\nところでPythonでのタイムゾーン変換で検索すると大抵上記リンクと同様にpytzを使ったコードが紹介されている。pytzを使えば簡単なのだが、それができない事情があったから以下のように別の方法でやった。今回のコードではまた別の方法になっているが\u0026hellip;、どこまでも執拗に追ってくるしつこい敵なので、一度タイムゾーン処理単体で記事を書こうかと思う。\nCloudWatchアラーム + SNSからのメール本文をカスタマイズする(3) \n 話がそれたが、翌日再試行して、今度は無事エクスポートが実行された。今回のコード上の指定では以下スクショの階層でログがアップロードされる。（長いランダム文字列のプレフィックス配下に複数のログストリームのプレフィックス、最後に圧縮ログファイル）\n しかし、引数にLambda自体のログを指定するとエクスポートされない。なぜなんだ〜！\u0026hellip;と思ったら、数時間後にリトライしたら期待値になった。試しにひとつログをDLして中身を覗いてみる。\n$ gunzip -c 000000.gz 2021-12-18T09:30:45.236Z START RequestId: 4880df55-4576-4ccd-8edc-daecb18b0686 Version: $LATEST  このログは、マネコンの画面上ではJST（実際にLambdaを実行した時刻の日本時間）となっている。\n2021-12-18T18:30:45.236+09:00 #Timestamp列の値 START RequestId: 4880df55-4576-4ccd-8edc-daecb18b0686 Version: $LATEST  うーん、これでいいのか？コード内でJSTに変換しているけど、逆にしなくていいのか？脳内パズル。\n\u0026hellip;だが、Lambda関数が実行されるUTCのTZから、エクスポート対象のログ範囲をUTCのTZで指定すると、実際にログが吐き出されたJSTの時刻とは異なる日付範囲になる。だから関数でJSTに変換するのは正しい、と捉えてよい気がする。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatchlogs-export/","summary":"CloudWatch Logsから、LmabdaでログをS3にエクスポートする。対象のロググループとバケット内の第一階層を引数で指定するようにした。今回の事例ではエクスポートの範囲は「前日0時〜実行当日の0時」となる。\n参考\nboto3 API Reference\nLambdaよりCloudWatchログをS3に保存方法紹介\n 今回の検証に使用したアイテム（個人メモ）    アイテム 名称     Lambda用IAMロール lambda_basic_execution   Lambda関数 log-export-function   S3バケット log-export-xxxxxxxx     Lambda用IAMロールの権限はlogsフルアクセスのみ。S3もいると思ってたがなくてもできた。バケットポリシー側で許可しているからか。S3バケット名は環境変数で指定した。\n S3バケットポリシー（log-export-xxxxxxxx）\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::log-export-xxxxxxxx\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::log-export-xxxxxxxx/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;s3:x-amz-acl\u0026#34;: \u0026#34;bucket-owner-full-control\u0026#34; } } } ] }  Lambdaコード(Python3.","title":"CloudWatch LogsからS3にエクスポート(Lambda/Python)"},{"content":"村上龍著「愛と幻想のファシズム」より\n  強者は嫌われない。ゴミのような人間達は、強者と同化したがるのだ。\n   馬の臓物も、猪の肉も、からだを腹の底から暖める。野生の肉は血管を拡げるのだ。俺達は湧き出すように汗をかく。\n   「その婆さんは、よく晴れた日に、二人の孫を連れて、山菜を採りに行ったんだ、そして虎に襲われた、ばあさんは棘のついた木の枝で虎の注意をそらしながら、飛びかかって、虎の耳を食いちぎったんだそうだ、そのばあさんのコメントは中国でも有名になった、圧倒的に強い敵にギリギリまで追いつめられた時、残された唯一の手段、それは戦うことだ、ばあさんは、そう言ったんだとさ」\n   「圧倒的に強い敵にギリギリまで追いつめられた時、残された唯一の手段、それは戦うことだ」\n","permalink":"https://ecnedaced-seirots.github.io/post/a/ryu-quotes-2/","summary":"\u003cp\u003e村上龍著「愛と幻想のファシズム」より\u003c/p\u003e\n\u003cp\u003e \u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e強者は嫌われない。ゴミのような人間達は、強者と同化したがるのだ。\u003c/p\u003e\n\u003c/blockquote\u003e","title":"「愛と幻想のファシズム」より(2)"},{"content":"何日か前に読了した、村上龍著「愛と幻想のファシズム」より。\n  「それで、人間というのは、他の動物でもそうだけど、嫌いなことをやり続けると拒絶反応を起こすんだ、病気になるんだよ、トウジお前IBMのセールスマンになれるか？」\n  「止めてくれ、死んじゃうよ」\n「そうだろ、とにかく人間は嫌いなことはできないようになっている、ところがだ、嫌いなことでもやる奴がいる」\n「いるな」\n「いるだろ？」\n「誰だ？」\n「好きなことが何なのか捜すのに疲れた奴、あきらめた連中だ、楽をしたいと思う奴らだよ、そいつらは、奴隷だ」\n「奴隷？」\n「俺は奴隷を信頼しない」\n「どうして？」\n「人を裏切るのは気分が悪いものだ、そうだよな、誰だって人を裏切るのは嫌いなはずだ、だから嫌いなことを普段やってないやつ、つまり奴隷じゃない奴は、とりあえず信頼できるんだ」\n   「（略）\u0026hellip;俺は快楽を知っている、狩猟の快楽は他の何よりもすごい、だが俺はその快楽を必死になって手に入れたんだ、あいつらは黙っていても手に入れることができる、努力して手に入れるものに価値があるのというのは、芸術家とスポーツ選手にだけ言えることで、貧乏人には当てはまらない、嘘なんだ」\n   「そうだ、俺はいやなんだ、俺は快楽主義者だからな、小さな快楽で我慢しろなんて言われて黙っているのがいやなんだ、\n  すっげぇ、いやもうこれ、この年になってもわかるよ、ビンビンくるよ、あぁ、そうなんだよ、本当にそうなんだよ。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/ryu-quotes-1/","summary":"\u003cp\u003e何日か前に読了した、村上龍著「愛と幻想のファシズム」より。\u003c/p\u003e\n\u003cp\u003e \u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e「それで、人間というのは、他の動物でもそうだけど、嫌いなことをやり続けると拒絶反応を起こすんだ、病気になるんだよ、トウジお前IBMのセールスマンになれるか？」\u003c/p\u003e\n\u003c/blockquote\u003e","title":"「愛と幻想のファシズム」より(1)"},{"content":"あーあ、今日も、疲れた。気がついたら20時なんだもん、ひっでぇな。\nそして本来やるべきことの、半分もできていない。雑用の波が押し寄せる。言いたいことは多々あるが、ぶちまけ大会するわけにはいかない。このモヤモヤを一体どうしたらいいのか。\n  ま、でも今日も上手い寿司が食えたからな。寿司だ。寿司が今のオレのプライドを支えてるんだ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/life-1214/","summary":"あーあ、今日も、疲れた。気がついたら20時なんだもん、ひっでぇな。\nそして本来やるべきことの、半分もできていない。雑用の波が押し寄せる。言いたいことは多々あるが、ぶちまけ大会するわけにはいかない。このモヤモヤを一体どうしたらいいのか。\n  ま、でも今日も上手い寿司が食えたからな。寿司だ。寿司が今のオレのプライドを支えてるんだ。","title":"Non title"},{"content":"今日のTerraform loopネタはLambda関数作成。ログ監視の一貫なので、CloudWatchLogsのロググループとサブスクリプションフィルタ作成も一緒にやる。\nこの例でのディレクトリ構成は以下の通り。lambda/upload配下のzipファイルはTerraformにより生成されたもので、初回は空である。\nwork_dir ├── config.tf #初期化ファイル ├── lambda │ ├── code │ │ ├── func001 │ │ │ └── lambda-func001.py │ │ ├── func002 │ │ │ └── lambda-func002.py │ │ └── func003 │ │ └── lambda-func003.py │ └── upload │ ├── lambda-func001.zip │ ├── lambda-func002.zip │ └── lambda-func003.zip ├── lambda.auto.tfvars ├── lambda_cwl.tf ├── terraform.tfvars #regionのみ定義 └── variables.tf  最初に、すべて定数で記述したパターン。\nlambda_logs.tf（定数バージョン）\n################################################# # Lambda archive data ################################################# data \u0026quot;archive_file\u0026quot; \u0026quot;data-lambda-func001\u0026quot; { type = \u0026quot;zip\u0026quot; source_dir = \u0026quot;lambda/code/func001\u0026quot; output_path = \u0026quot;lambda/upload/lambda-func001.zip\u0026quot; } ################################################# # Lambda function ################################################# resource \u0026quot;aws_lambda_function\u0026quot; \u0026quot;lambda-func001\u0026quot; { filename = data.archive_file.data-lambda-func001.output_path function_name = \u0026quot;lambda-func001\u0026quot; role = \u0026quot;arn:aws:iam::012345678910:role/send-log-filter-role\u0026quot; handler = \u0026quot;lambda-func001.lambda_handler\u0026quot; source_code_hash = base64sha256(\u0026quot;lambda/upload/lambda-func001.zip\u0026quot;) timeout = 60 runtime = \u0026quot;python3.9\u0026quot; environment { variables = { \u0026quot;SNS_TOPIC_ARN\u0026quot; = \u0026quot;arn:aws:sns:ap-northeast-1:012345678910:log-monitor-topic\u0026quot; } } } ################################################# # Lambda Permission ################################################# resource \u0026quot;aws_lambda_permission\u0026quot; \u0026quot;func-perm001\u0026quot; { action = \u0026quot;lambda:InvokeFunction\u0026quot; function_name = aws_lambda_function.lambda-func001.arn principal = \u0026quot;logs.ap-northeast-1.amazonaws.com\u0026quot; source_arn = \u0026quot;arn:aws:logs:ap-northeast-1:012345678910:log-group:*:*\u0026quot; } ################################################# # CloudWatchLogs group ################################################# resource \u0026quot;aws_cloudwatch_log_group\u0026quot; \u0026quot;cwl-group001\u0026quot; { name = \u0026quot;log-group001\u0026quot; retention_in_days = \u0026quot;7\u0026quot; } ################################################# # CloudWatchLogs subscription filter ################################################# resource \u0026quot;aws_cloudwatch_log_subscription_filter\u0026quot; \u0026quot;cwl-subscription001\u0026quot; { name = \u0026quot;cwl-filter001\u0026quot; log_group_name = aws_cloudwatch_log_group.cwl-group001.name filter_pattern = \u0026quot;[( msg=\\\u0026quot;*error*\\\u0026quot; || msg=\\\u0026quot;*Error*\\\u0026quot; ) \u0026amp;\u0026amp; ( msg!=\\\u0026quot;*test*\\\u0026quot; \u0026amp;\u0026amp; msg!=\\\u0026quot;*Test*\\\u0026quot; \u0026amp;\u0026amp; msg!=\\\u0026quot;*TEST*\\\u0026quot; )]\u0026quot; destination_arn = aws_lambda_function.lambda-func001.arn }  これをapplyするとそれぞれ単体でリソースが作成される。次にloop処理の例。\nlambda_logs.tf（loopバージョン）\n################################################# # Lambda archive data ################################################# data \u0026quot;archive_file\u0026quot; \u0026quot;data-lambda-func\u0026quot; { for_each = var.lambda_param_list source_dir = lookup(each.value, \u0026quot;src_dir\u0026quot;) output_path = lookup(each.value, \u0026quot;out_path\u0026quot;) type = \u0026quot;zip\u0026quot; } ################################################# # Lambda function ################################################# resource \u0026quot;aws_lambda_function\u0026quot; \u0026quot;lambda-func\u0026quot; { for_each = var.lambda_param_list filename = lookup(each.value, \u0026quot;out_path\u0026quot;) function_name = lookup(each.value, \u0026quot;func_name\u0026quot;) role = var.lambda_role handler = \u0026quot;${lookup(each.value, \u0026quot;func_name\u0026quot;)}.lambda_handler\u0026quot; source_code_hash = base64sha256(\u0026quot;${lookup(each.value, \u0026quot;out_path\u0026quot;)}\u0026quot;) timeout = 60 runtime = \u0026quot;python3.9\u0026quot; environment { variables = { \u0026quot;SNS_TOPIC_ARN\u0026quot; = var.topic_arn } } } ################################################# # Lambda Permission ################################################# resource \u0026quot;aws_lambda_permission\u0026quot; \u0026quot;my-func-perm\u0026quot; { for_each = var.lambda_param_list action = \u0026quot;lambda:InvokeFunction\u0026quot; function_name = \u0026quot;arn:aws:lambda:ap-northeast-1:012345678910:function:${lookup(each.value, \u0026quot;func_name\u0026quot;)}\u0026quot; principal = \u0026quot;logs.ap-northeast-1.amazonaws.com\u0026quot; source_arn = var.src_arn } ################################################# # CloudWatchLogs group ################################################# resource \u0026quot;aws_cloudwatch_log_group\u0026quot; \u0026quot;cwl-group\u0026quot; { for_each = var.logs_param_list name = lookup(each.value, \u0026quot;log_grp\u0026quot;) retention_in_days = \u0026quot;7\u0026quot; } ################################################# # CloudWatchLogs subscription filter ################################################# resource \u0026quot;aws_cloudwatch_log_subscription_filter\u0026quot; \u0026quot;cwl-subscription\u0026quot; { for_each = var.logs_param_list name = lookup(each.value, \u0026quot;filter\u0026quot;) log_group_name = lookup(each.value, \u0026quot;log_grp\u0026quot;) filter_pattern = lookup(each.value, \u0026quot;pattern\u0026quot;) destination_arn = aws_lambda_function.lambda-func[\u0026quot;param1\u0026quot;].arn }  archive_fileによりTerraformがLambda用のzipファイルを生成してくれる。source_code_hashがzipのハッシュ値の差分をチェックして変更があればデプロイする。と、いうことだがこの記述だとコードを変更しなくても都度zipファイルが生成されてタイムスタンプが更新され、変更していなくても変更したと判断されてデプロイされる。デプロイされてもコードは同じだから害はないんだが、どうも納得がいかん。変更扱いにしたくなければarchive_fileのブロックを全部コメントしておくか、source_code_hashをコメントするか。どういう運用がいいんだろう？\nちなみに最初のapplyは比較対象のzipファイルがなくてエラーになるため、source_code_hashは初回のみコメントアウトしておく。\nsubscription filterで、Lambdaをloopで作ったのにここで単体で指定しているのは、こういう例もあるということで。この参照の場合は、logs_param_listにLambdaのARNの変数が存在しなくても問題ない。\nlambda.auto.tfvars（tfコードが参照する変数）\n################################################# # Lambda function loop vars ################################################# lambda_param_list = { param1 = { src_dir = \u0026quot;lambda/code/func001\u0026quot; out_path = \u0026quot;lambda/upload/lambda-func001.zip\u0026quot; func_name = \u0026quot;lambda-func001\u0026quot; } param2 = { src_dir = \u0026quot;lambda/code/func002\u0026quot; out_path = \u0026quot;lambda/upload/lambda-func002.zip\u0026quot; func_name = \u0026quot;lambda-func002\u0026quot; } param3 = { src_dir = \u0026quot;lambda/code/func003\u0026quot; out_path = \u0026quot;lambda/upload/lambda-func003.zip\u0026quot; func_name = \u0026quot;lambda-func003\u0026quot; } } ################################################# # Lambda function vars ################################################# lambda_role = \u0026quot;arn:aws:iam::012345678910:role/send-log-filter-role\u0026quot; topic_arn = \u0026quot;arn:aws:sns:ap-northeast-1:012345678910:log-monitor-topic\u0026quot; ################################################# # Lambda Permission vars ################################################# src_arn = \u0026quot;arn:aws:logs:ap-northeast-1:012345678910:log-group:*:*\u0026quot; ################################################# # CloudWatchLogs group \u0026amp; filter loop vars ################################################# logs_param_list = { param1 = { log_grp = \u0026quot;log-group001\u0026quot; filter = \u0026quot;logs-filter001\u0026quot; pattern = \u0026quot;[( msg=\\\u0026quot;*error*\\\u0026quot; || msg=\\\u0026quot;*Error*\\\u0026quot; ) \u0026amp;\u0026amp; ( msg!=\\\u0026quot;*test*\\\u0026quot; \u0026amp;\u0026amp; msg!=\\\u0026quot;*Test*\\\u0026quot; \u0026amp;\u0026amp; msg!=\\\u0026quot;*TEST*\\\u0026quot; )]\u0026quot; } param2 = { log_grp = \u0026quot;log-group002\u0026quot; filter = \u0026quot;logs-filter002\u0026quot; pattern = \u0026quot;[( msg=\\\u0026quot;*error*\\\u0026quot; || msg=\\\u0026quot;*ERROR*\\\u0026quot; ) \u0026amp;\u0026amp; ( msg!=\\\u0026quot;*test*\\\u0026quot; \u0026amp;\u0026amp; msg!=\\\u0026quot;*Test*\\\u0026quot; \u0026amp;\u0026amp; msg!=\\\u0026quot;*TEST*\\\u0026quot; )]\u0026quot; } param3 = { log_grp = \u0026quot;log-group003\u0026quot; filter = \u0026quot;logs-filter003\u0026quot; pattern = \u0026quot;[( msg=\\\u0026quot;*FAIL*\\\u0026quot; || msg=\\\u0026quot;*fail*\\\u0026quot; || msg=\\\u0026quot;*Fail*\\\u0026quot; ) \u0026amp;\u0026amp; ( msg!=\\\u0026quot;*test*\\\u0026quot; \u0026amp;\u0026amp; msg!=\\\u0026quot;*Test*\\\u0026quot; \u0026amp;\u0026amp; msg!=\\\u0026quot;*TEST*\\\u0026quot; )]\u0026quot; } }  フィルタパターンが汚なくて見るに耐えないがこればかりはどうしようもない\u0026hellip;\nvariables.tf（宣言のみ）\n################################## # main ################################## variable \u0026quot;region\u0026quot; { type = string description = \u0026quot;\u0026quot; } ################################## # lambda loop ################################## variable \u0026quot;lambda_param_list\u0026quot; { type = map(map(string)) description = \u0026quot;\u0026quot; } ################################## # lambda role ################################## variable \u0026quot;lambda_role\u0026quot; { type = string description = \u0026quot;\u0026quot; } ################################## # topic ################################## variable \u0026quot;topic_arn\u0026quot; { type = string description = \u0026quot;\u0026quot; } ################################## # lambda parmission ################################## variable \u0026quot;src_arn\u0026quot; { type = string description = \u0026quot;\u0026quot; } ################################## # logs loop ################################## variable \u0026quot;logs_param_list\u0026quot; { type = map(map(string)) description = \u0026quot;\u0026quot; }  これによりログ監視に必要なリソースが一気に作成される。最初にコード書くのは面倒だけど、やっぱり自動化の仕組み作っておくと楽だな。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform-loop-example-5/","summary":"今日のTerraform loopネタはLambda関数作成。ログ監視の一貫なので、CloudWatchLogsのロググループとサブスクリプションフィルタ作成も一緒にやる。\nこの例でのディレクトリ構成は以下の通り。lambda/upload配下のzipファイルはTerraformにより生成されたもので、初回は空である。\nwork_dir ├── config.tf #初期化ファイル ├── lambda │ ├── code │ │ ├── func001 │ │ │ └── lambda-func001.py │ │ ├── func002 │ │ │ └── lambda-func002.py │ │ └── func003 │ │ └── lambda-func003.py │ └── upload │ ├── lambda-func001.zip │ ├── lambda-func002.zip │ └── lambda-func003.zip ├── lambda.auto.tfvars ├── lambda_cwl.tf ├── terraform.tfvars #regionのみ定義 └── variables.tf  最初に、すべて定数で記述したパターン。\nlambda_logs.tf（定数バージョン）\n################################################# # Lambda archive data ################################################# data \u0026quot;archive_file\u0026quot; \u0026quot;data-lambda-func001\u0026quot; { type = \u0026quot;zip\u0026quot; source_dir = \u0026quot;lambda/code/func001\u0026quot; output_path = \u0026quot;lambda/upload/lambda-func001.","title":"Terraform loop処理の応用編(4) - Lambda"},{"content":"過去記事Terraform loop処理の応用編(2)で、AWS Code兄弟のリソースをTerraformのloop処理で作成した。それとは別に、CodePipelineのトリガーをEventBridgeルールにしたかったので追加処理を書いた。パイプラインの数だけ対応するルールを作成するため、これもloop処理で書く。Code兄弟の分も含めて全て同じtfファイルにまとめてもよいが、ここでは分割している。\n以下tfコード本体に、ルールとターゲットを作成する処理を書く。\nevent_rule.tf\n######################################## # EventBridge rule ######################################## resource \u0026quot;aws_cloudwatch_event_rule\u0026quot; \u0026quot;pln-rule\u0026quot; { for_each = var.events_param_list name = lookup(each.value, \u0026quot;name\u0026quot;) description = \u0026quot;Start the pipeline when detect CodeCommit repository state change.\u0026quot; event_pattern = \u0026lt;\u0026lt;-EOT { \u0026quot;source\u0026quot;: [\u0026quot;aws.codecommit\u0026quot;], \u0026quot;detail-type\u0026quot;: [\u0026quot;CodeCommit Repository State Change\u0026quot;], \u0026quot;resources\u0026quot;: [\u0026quot;arn:aws:codecommit:ap-northeast-1:012345678910:${lookup(each.value, \u0026quot;repo_name\u0026quot;)}\u0026quot;], \u0026quot;detail\u0026quot;: { \u0026quot;event\u0026quot;: [\u0026quot;referenceCreated\u0026quot;, \u0026quot;referenceUpdated\u0026quot;], \u0026quot;referenceType\u0026quot;: [\u0026quot;branch\u0026quot;], \u0026quot;referenceName\u0026quot; : [\u0026quot;master\u0026quot;] } } EOT } ######################################## # EventBridge target ######################################## resource \u0026quot;aws_cloudwatch_event_target\u0026quot; \u0026quot;pln-rule\u0026quot; { for_each = var.events_param_list rule = lookup(each.value, \u0026quot;name\u0026quot;) arn = lookup(each.value, \u0026quot;pipeline\u0026quot;) role_arn = var.events_role depends_on = [aws_cloudwatch_event_rule.pln-rule] }  当初event_patternのJSONはJSONファイルを外出しにしてファイル名指定でいくつもりだった。が、loop処理で回すのができなかった。いくつか試したのだが\u0026hellip;。パターンとしては可変になるのがCodeCommitリポジトリ名だけなので、そこをloopで回せばいけるんじゃないかと思いヒアドキュメントでやったらできた。このような場合JSONファイルをルールの数だけ用意するより、ヒアドキュメントの方が意外と楽だ。\nJSON定義の一部。以下の\u0026quot;repo_name\u0026quot;に対して、変数リストから取り出したCodeCommitリポジトリ名が格納される。\n\u0026quot;resources\u0026quot;: [\u0026quot;arn:aws:codecommit:ap-northeast-1:012345678910:${lookup(each.value, \u0026quot;repo_name\u0026quot;)}\u0026quot;],  loop処理が参照する変数リストは以下の通り。\n rule.auto.tfvars\n################### # rule vars ################### events_param_list = { param1 = { name = \u0026quot;cicd-event001\u0026quot; pipeline = \u0026quot;arn:aws:codepipeline:ap-northeast-1:012345678910:pipeline001\u0026quot; repo_name = \u0026quot;repo001\u0026quot; } param2 = { name = \u0026quot;cicd-event002\u0026quot; pipeline = \u0026quot;arn:aws:codepipeline:ap-northeast-1:012345678910:pipeline002\u0026quot; repo_name = \u0026quot;repo002\u0026quot; } param3 = { name = \u0026quot;cicd-event003\u0026quot; pipeline = \u0026quot;arn:aws:codepipeline:ap-northeast-1:012345678910:pipeline003\u0026quot; repo_name = \u0026quot;repo003\u0026quot; } } ################### # Events role ################### events_role = \u0026quot;arn:aws:iam::012345678910:role/codepipeline-exe-role\u0026quot;  上記ルールだけapplyした結果、成功。CICDリソース作成用のtfコードも含めて実行した結果も、成功。\nちなみにイベントルールを別途作成しない場合、パイプラインに紐付くルールが自動で生成される。ルールを実行するためのIAMロールも、ルールと1:1で個別に自動生成される。親切と言えば親切だが、そんなにボコボコ作られてもなー、と思った。このIAMロールはリソースとして指定したCodePipelineを実行するだけだから、リソースを* にすればひとつで事足りる。各アイテムの名称も管理下におきたい。\n\u0026hellip;ということで、ここでは自動生成ではなく別途ルールを作成したけれども、そこまでこだわらないのであれば自動生成でもいいだろう。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform-loop-example-4/","summary":"過去記事Terraform loop処理の応用編(2)で、AWS Code兄弟のリソースをTerraformのloop処理で作成した。それとは別に、CodePipelineのトリガーをEventBridgeルールにしたかったので追加処理を書いた。パイプラインの数だけ対応するルールを作成するため、これもloop処理で書く。Code兄弟の分も含めて全て同じtfファイルにまとめてもよいが、ここでは分割している。\n以下tfコード本体に、ルールとターゲットを作成する処理を書く。\nevent_rule.tf\n######################################## # EventBridge rule ######################################## resource \u0026quot;aws_cloudwatch_event_rule\u0026quot; \u0026quot;pln-rule\u0026quot; { for_each = var.events_param_list name = lookup(each.value, \u0026quot;name\u0026quot;) description = \u0026quot;Start the pipeline when detect CodeCommit repository state change.\u0026quot; event_pattern = \u0026lt;\u0026lt;-EOT { \u0026quot;source\u0026quot;: [\u0026quot;aws.codecommit\u0026quot;], \u0026quot;detail-type\u0026quot;: [\u0026quot;CodeCommit Repository State Change\u0026quot;], \u0026quot;resources\u0026quot;: [\u0026quot;arn:aws:codecommit:ap-northeast-1:012345678910:${lookup(each.value, \u0026quot;repo_name\u0026quot;)}\u0026quot;], \u0026quot;detail\u0026quot;: { \u0026quot;event\u0026quot;: [\u0026quot;referenceCreated\u0026quot;, \u0026quot;referenceUpdated\u0026quot;], \u0026quot;referenceType\u0026quot;: [\u0026quot;branch\u0026quot;], \u0026quot;referenceName\u0026quot; : [\u0026quot;master\u0026quot;] } } EOT } ######################################## # EventBridge target ######################################## resource \u0026quot;aws_cloudwatch_event_target\u0026quot; \u0026quot;pln-rule\u0026quot; { for_each = var.","title":"Terraform loop処理の応用編(3) - Event rule"},{"content":"\u0026ldquo;SNS\u0026quot;は\u0026quot;Social Networking Service\u0026quot;の略だ。この言葉の上では、プラットフォーム自体がサービスなのだ。しかし、そこに参加した途端に、自分自身が他者にサービスせざるを得なくなる。俗に言う、フォロバとかいいね返しとか、そういうことだ。\nそういうのは嫌いだ、しかしそこに参加している限り、鍵垢でもない限り、その渦から完全に逃れることはできない、この、人付き合いが嫌いな俺様であってもだ、しかし嫌いなものは嫌いなんだ、反応に対していちいち反応してたら自分のやりたいことができないし、余計にエネルギーを使うことになる。つまり、反応した相手の投稿をチェックするという作業自体が余剰作業なのだ、他人にサービスするためにやってるんじゃないからね。\nこれは、SNSの面倒で嫌いな部分だが、いいこともある、「反応に対する反応」により、センスがいいナイスなアカウントを発見することも多々あるからだ。tumblrの場合、ナイスなポストがあればreblogするし、この人は光る何かを持っている、とピピっときたらフォローせざるを得ない。相手が素晴らしいセンスの持ち主だと、サービスを通り越して夢中になってしまうこともある。\n  でも最近疲れてきたな、夢中になりすぎて疲れたのか、疲れたから夢中になれなくなったのか知らんが、あまり楽しくない。結局「お付き合い」の比重が多くなると、本来の目的からずれてしまうんだ、リアルワールドでやることのプライオリティが上がっているせいもあるな。\nしかしよく考えると、SNSとの付き合いなんてそれくらいか、それより低程度がいいのである、本来は。リアルワールドで重要なことが多いほど、SNSにかまけていられる時間やエネルギーは減る。つまり、「あんまり楽しくない」程度に捉えている方が自然なのである。\nそういう意味では、俺もやっと自然に戻れたんだろうか。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/sns/","summary":"\u0026ldquo;SNS\u0026quot;は\u0026quot;Social Networking Service\u0026quot;の略だ。この言葉の上では、プラットフォーム自体がサービスなのだ。しかし、そこに参加した途端に、自分自身が他者にサービスせざるを得なくなる。俗に言う、フォロバとかいいね返しとか、そういうことだ。\nそういうのは嫌いだ、しかしそこに参加している限り、鍵垢でもない限り、その渦から完全に逃れることはできない、この、人付き合いが嫌いな俺様であってもだ、しかし嫌いなものは嫌いなんだ、反応に対していちいち反応してたら自分のやりたいことができないし、余計にエネルギーを使うことになる。つまり、反応した相手の投稿をチェックするという作業自体が余剰作業なのだ、他人にサービスするためにやってるんじゃないからね。\nこれは、SNSの面倒で嫌いな部分だが、いいこともある、「反応に対する反応」により、センスがいいナイスなアカウントを発見することも多々あるからだ。tumblrの場合、ナイスなポストがあればreblogするし、この人は光る何かを持っている、とピピっときたらフォローせざるを得ない。相手が素晴らしいセンスの持ち主だと、サービスを通り越して夢中になってしまうこともある。\n  でも最近疲れてきたな、夢中になりすぎて疲れたのか、疲れたから夢中になれなくなったのか知らんが、あまり楽しくない。結局「お付き合い」の比重が多くなると、本来の目的からずれてしまうんだ、リアルワールドでやることのプライオリティが上がっているせいもあるな。\nしかしよく考えると、SNSとの付き合いなんてそれくらいか、それより低程度がいいのである、本来は。リアルワールドで重要なことが多いほど、SNSにかまけていられる時間やエネルギーは減る。つまり、「あんまり楽しくない」程度に捉えている方が自然なのである。\nそういう意味では、俺もやっと自然に戻れたんだろうか。\n ","title":"ソーシャルな反応に対する反応とか"},{"content":"前回投稿Terraform loop処理の応用編 の続き。CodeDeployを作成するTerraformコードに、CodeCommit, CodePipelineを追加して通して作ってみる。\n cicd.tf\n#################################### # CodeCommit #################################### resource \u0026quot;aws_codecommit_repository\u0026quot; \u0026quot;codecommit_repos\u0026quot; { for_each = var.codecommit_param_list repository_name = lookup(each.value, \u0026quot;repository_name\u0026quot;) description = lookup(each.value, \u0026quot;description\u0026quot;) } #################################### # CodeDeploy Application #################################### resource \u0026quot;aws_codedeploy_app\u0026quot; \u0026quot;codedeploy\u0026quot; { for_each = var.deploy_param_list name = lookup(each.value, \u0026quot;name\u0026quot;) compute_platform = \u0026quot;Server\u0026quot; } #################################### # CodeDeploy Deployment Group #################################### resource \u0026quot;aws_codedeploy_deployment_group\u0026quot; \u0026quot;codedeploy_grp\u0026quot; { for_each = var.deploy_param_list app_name = lookup(each.value, \u0026quot;name\u0026quot;) deployment_group_name = lookup(each.value, \u0026quot;deployment_group_name\u0026quot;) depends_on = [aws_codedeploy_app.codedeploy] service_role_arn = var.deploy_role deployment_config_name = \u0026quot;CodeDeployDefault.AllAtOnce\u0026quot; ec2_tag_set { ec2_tag_filter { key = \u0026quot;Name\u0026quot; type = \u0026quot;KEY_AND_VALUE\u0026quot; value = lookup(each.value, \u0026quot;value\u0026quot;) } } deployment_style { deployment_option = \u0026quot;WITHOUT_TRAFFIC_CONTROL\u0026quot; deployment_type = \u0026quot;IN_PLACE\u0026quot; } auto_rollback_configuration { enabled = true events = [\u0026quot;DEPLOYMENT_FAILURE\u0026quot;] } } #################################### # CodePipeline #################################### resource \u0026quot;aws_codepipeline\u0026quot; \u0026quot;pipeline\u0026quot; { for_each = var.pipeline_param_list name = lookup(each.value, \u0026quot;name\u0026quot;) role_arn = var.pipeline_role artifact_store { location = var.bucket type = \u0026quot;S3\u0026quot; } stage { name = \u0026quot;Source\u0026quot; action { category = \u0026quot;Source\u0026quot; configuration = { BranchName = \u0026quot;master\u0026quot; PollForSourceChanges = \u0026quot;true\u0026quot; RepositoryName = lookup(each.value, \u0026quot;repository_name\u0026quot;) } input_artifacts = [] name = \u0026quot;Source\u0026quot; namespace = \u0026quot;SourceVariables\u0026quot; output_artifacts = [\u0026quot;SourceArtifact\u0026quot;] owner = \u0026quot;AWS\u0026quot; provider = \u0026quot;CodeCommit\u0026quot; region = var.region run_order = 1 version = \u0026quot;1\u0026quot; } } stage { name = \u0026quot;Deploy\u0026quot; action { category = \u0026quot;Deploy\u0026quot; configuration = { ApplicationName = lookup(each.value, \u0026quot;app_name\u0026quot;) DeploymentGroupName = lookup(each.value, \u0026quot;deployment_group_name\u0026quot;) } input_artifacts = [\u0026quot;SourceArtifact\u0026quot;] name = \u0026quot;Deploy\u0026quot; namespace = \u0026quot;DeployVariables\u0026quot; output_artifacts = [] owner = \u0026quot;AWS\u0026quot; provider = \u0026quot;CodeDeploy\u0026quot; region = var.region run_order = 1 version = \u0026quot;1\u0026quot; } } }  cicd.auto.tfvars\n######################################## # codecommit repos vars ######################################## codecommit_param_list = { param1 = { repository_name = \u0026quot;repo001\u0026quot; description = \u0026quot;desciption for repo001\u0026quot; } param2 = { repository_name = \u0026quot;repo002\u0026quot; description = \u0026quot;desciption for repo002\u0026quot; } param3 = { repository_name = \u0026quot;repo003\u0026quot; description = \u0026quot;desciption for repo003\u0026quot; } } ######################################## # codedeploy vars ######################################## deploy_param_list = { param1 = { name = \u0026quot;deploy_app001\u0026quot; deployment_group_name = \u0026quot;deploy_grp001\u0026quot; value = \u0026quot;ec2-tag001\u0026quot; } param2 = { name = \u0026quot;deploy_app002\u0026quot; deployment_group_name = \u0026quot;deploy_grp002\u0026quot; value = \u0026quot;ec2-tag002\u0026quot; } param3 = { name = \u0026quot;deploy_app003\u0026quot; deployment_group_name = \u0026quot;deploy_grp003\u0026quot; value = \u0026quot;ec2-tag003\u0026quot; } } ######################################## # codedeploy vars ######################################## pipeline_param_list = { param1 = { name = \u0026quot;pipeline001\u0026quot; app_name = \u0026quot;deploy_app001\u0026quot; deployment_group_name = \u0026quot;deploy_grp001\u0026quot; repository_name = \u0026quot;repo001\u0026quot; } param2 = { name = \u0026quot;pipeline002\u0026quot; app_name = \u0026quot;deploy_app002\u0026quot; deployment_group_name = \u0026quot;deploy_grp002\u0026quot; repository_name = \u0026quot;repo002\u0026quot; } param3 = { name = \u0026quot;pipeline003\u0026quot; app_name = \u0026quot;deploy_app003\u0026quot; deployment_group_name = \u0026quot;deploy_grp003\u0026quot; repository_name = \u0026quot;repo003\u0026quot; } } ######################################## # CI/CD IAM role vars ######################################## deploy_role = \u0026quot;arn:aws:iam::[aws-account-id]:role/CodeDeployRole\u0026quot; pipeline_role = \u0026quot;arn:aws:iam::[aws-account-id]:role/PipelineRole\u0026quot; ######################################## # S3 vars ######################################## bucket = \u0026quot;codepipeline-bucket-name\u0026quot;  variables.tf （宣言のみ）\n################# # main ################# variable \u0026quot;region\u0026quot; { type = string description = \u0026quot;\u0026quot; } ################# # IAM ################# variable \u0026quot;deploy_role\u0026quot; { type = string description = \u0026quot;\u0026quot; } variable \u0026quot;pipeline_role\u0026quot; { type = string description = \u0026quot;\u0026quot; } ################# # S3 ################# variable \u0026quot;bucket\u0026quot; { type = string description = \u0026quot;\u0026quot; } ################# # codecommit ################# variable \u0026quot;codecommit_param_list\u0026quot; { type = map(map(string)) description = \u0026quot;\u0026quot; } ################# # codedeploy ################# variable \u0026quot;deploy_param_list\u0026quot; { type = map(map(string)) description = \u0026quot;\u0026quot; } ################# # codepipeline ################# variable \u0026quot;pipeline_param_list\u0026quot; { type = map(map(string)) description = \u0026quot;\u0026quot; }  cicd.tfのPollForSourceChangesはトリガーの定義だが、EventBridgeルール経由でやるのが望ましいから本来はfalseにする想定。ルールを別途作成する必要があるが、それが面倒なので一旦trueにしておいた。（関連付けたルールが存在しない場合、勝手に作成される）\nこれで実行したところ、一応期待値になった。ルールは、各パイプラインとルールがペアになるように個別に作成する。ルールが使用するIAMロールは共通のひとつでよい。このIAMの権限はコードパイプラインをスタートするだけなのだが、リソースを*にして共通で使えばよい。\n ところでtfvarsでloop処理が参照するmap変数をサービス毎に分割しているが、分ける必要ないんじゃね？と思った。重複している値が複数あって、冗長だ。key名を適当に変えれば、同じparam_listで全部賄えそうな気がしてきた。次回の課題。\n 追記\n後日param_listを全部まとめるバージョンでやってみたところ、期待値になった。だからリソース毎に個別にリストを作成する必要はない。ただし、それは参照されるリストの要素の数が全部揃っている場合。\n例えばloopで作成するCodeCommitリポジトリの数が10でCodeDeploy、CodePipelineの数は8、とかだったら共通のリストにすると失敗する。このようなケースでは、CodeCommitのリストとCodeDeploy/CodePipeline用のリストは別に分ける必要がある。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform-loop-example-3/","summary":"前回投稿Terraform loop処理の応用編 の続き。CodeDeployを作成するTerraformコードに、CodeCommit, CodePipelineを追加して通して作ってみる。\n cicd.tf\n#################################### # CodeCommit #################################### resource \u0026quot;aws_codecommit_repository\u0026quot; \u0026quot;codecommit_repos\u0026quot; { for_each = var.codecommit_param_list repository_name = lookup(each.value, \u0026quot;repository_name\u0026quot;) description = lookup(each.value, \u0026quot;description\u0026quot;) } #################################### # CodeDeploy Application #################################### resource \u0026quot;aws_codedeploy_app\u0026quot; \u0026quot;codedeploy\u0026quot; { for_each = var.deploy_param_list name = lookup(each.value, \u0026quot;name\u0026quot;) compute_platform = \u0026quot;Server\u0026quot; } #################################### # CodeDeploy Deployment Group #################################### resource \u0026quot;aws_codedeploy_deployment_group\u0026quot; \u0026quot;codedeploy_grp\u0026quot; { for_each = var.deploy_param_list app_name = lookup(each.value, \u0026quot;name\u0026quot;) deployment_group_name = lookup(each.value, \u0026quot;deployment_group_name\u0026quot;) depends_on = [aws_codedeploy_app.codedeploy] service_role_arn = var.","title":"Terraform loop処理の応用編(2) - CI/CD"},{"content":"過去記事Terraform loop処理の超シンプルな例 の続き。loopで作成したTerraformリソースの参照方法を検証したらやはりハマったので記録書いておく。\n前回はCodeCommitリポジトリを作成したが、今回はそれ抜きでCodeDeployのリソースを作成した。CodeDeployは (1)アプリケーションと、(2)デプロイメントグループの2つのリソースを作成する。(2)は(1)に依存している。\n作業ディレクトリ構成\nwork_dir ├── cicd.auto.tfvars ├── cicd.tf ├── config.tf #初期化用config ├── terraform.tfvars #regionのみ定義 └── variables.tf  cicd.tf （リソース作成用コード）\n#################################### # CodeDeploy Application #################################### resource \u0026quot;aws_codedeploy_app\u0026quot; \u0026quot;codedeploy\u0026quot; { for_each = var.deploy_param_list name = lookup(each.value, \u0026quot;name\u0026quot;) compute_platform = \u0026quot;Server\u0026quot; } #################################### # CodeDeploy Deployment Group #################################### resource \u0026quot;aws_codedeploy_deployment_group\u0026quot; \u0026quot;codedeploy_grp\u0026quot; { for_each = var.deploy_param_list app_name = lookup(each.value, \u0026quot;name\u0026quot;) deployment_group_name = lookup(each.value, \u0026quot;deployment_group_name\u0026quot;) service_role_arn = var.deploy_role deployment_config_name = \u0026quot;CodeDeployDefault.AllAtOnce\u0026quot; ec2_tag_set { ec2_tag_filter { key = \u0026quot;Name\u0026quot; type = \u0026quot;KEY_AND_VALUE\u0026quot; value = lookup(each.value, \u0026quot;value\u0026quot;) } } deployment_style { deployment_option = \u0026quot;WITHOUT_TRAFFIC_CONTROL\u0026quot; deployment_type = \u0026quot;IN_PLACE\u0026quot; } auto_rollback_configuration { enabled = true events = [\u0026quot;DEPLOYMENT_FAILURE\u0026quot;] } }  cicd.auto.tfvars（cicd.tfが参照する変数）\n######################################## # codedeploy vars ######################################## deploy_param_list = { param1 = { name = \u0026quot;deploy_app001\u0026quot; deployment_group_name = \u0026quot;deploy_grp001\u0026quot; value = \u0026quot;ec2-tag001\u0026quot; } param2 = { name = \u0026quot;deploy_app002\u0026quot; deployment_group_name = \u0026quot;deploy_grp002\u0026quot; value = \u0026quot;ec2-tag002\u0026quot; } param3 = { name = \u0026quot;deploy_app003\u0026quot; deployment_group_name = \u0026quot;deploy_grp003\u0026quot; value = \u0026quot;ec2-tag003\u0026quot; } } ######################################## # CodeDeploy IAM role var ######################################## deploy_role = \u0026quot;arn:aws:iam::[my-account-id]:role/CodeDeployRole\u0026quot;  variables.tf （宣言のみ行う）\n################# # main ################# variable \u0026quot;region\u0026quot; { type = string description = \u0026quot;\u0026quot; } ################# # IAM ################# variable \u0026quot;deploy_role\u0026quot; { type = string description = \u0026quot;\u0026quot; } ################# # codedeploy ################# variable \u0026quot;deploy_param_list\u0026quot; { type = map(map(string)) description = \u0026quot;\u0026quot; }  この状態で、plan実行時はエラーなし。しかしapplyしたところ、以下のエラーになった。参照するアプリケーション\u0026quot;deploy_app001\u0026quot;がないよ、と。\n No application found for name: deploy_app001\n  この時点でマネコンから確認すると、アプリケーションは出来ているが配下のデプロイメントグループが存在しない状態。実際にはdeploy_app00*は作成されているのだが、terraform実行時にうまく参照できていないらしい。当初、特別な記述をしなくてもTerraformがよしなにやってくれるもんだと思っていたんだけどなぁ。\n│ Error: Error creating CodeDeploy deployment group: ApplicationDoesNotExistException: No application found for name: deploy_app001 │ │ with aws_codedeploy_deployment_group.codedeploy_grp[\u0026quot;param1\u0026quot;], │ on cicd.tf line 16, in resource \u0026quot;aws_codedeploy_deployment_group\u0026quot; \u0026quot;codedeploy_grp\u0026quot;: │ 16: resource \u0026quot;aws_codedeploy_deployment_group\u0026quot; \u0026quot;codedeploy_grp\u0026quot; { │   この後でもう一回applyすると、今度はデプロイメントグループ（deploy_app00*）が作成された。しかし初回にエラーになるのはよろしくない。ありがちな事象だから何らかのソリューションはあるだろう、と調べる。\n 以下はツールGraphvizにより出力した、この時点におけるTerraformリソースの依存関係を表したグラフ。aws_codedeploy_appとaws_codedeploy_deployment_groupが並列になっていて、互いに関連を持たないように見える。（記事では削っているが実はCodeCommitの記述も含まれているため、グラフに表現されている）\n Terraformの依存関係の定義には「暗黙的な依存関係定義」と「明示的な依存関係定義」の2種類がある。後者は、前者が利用できないケースで使用するべき、とのこと。\n暗黙的な依存関係定義は、公式ドキュメントにもよく登場する role_arn = aws_iam_role.role001.arnといった記述で、意識せずとも普段から書いているやつ。今回みたく参照リソースがloopの場合、個別の値はaws_codedeploy_app.codedeploy[\u0026quot;param1\u0026quot;].idのような記述になるが、参照する側もloopだからこの方式では書けない。\n 一方、明示的な依存関係はdepends_onを利用する。\ndepends_on = [aws_iam_role.role001]  以下の記事を読むとloop処理の場合は別の記述方法が要るようなこと書いてあった。面倒くさそうだなぁ〜、と引いてしまう。（こちらはloop処理をcountで実行）\nTerraformリソース間の依存関係を確認する\nしかし以下フォーラムによれば、for_eachの場合これだけでいけそうではある。\nFor_each depends_on\nと、いうことでやってみる。一旦destroyしてクリーンにしてから、cicd.tfにdepends_on = [aws_codedeploy_app.codedeploy] 1行を追記。\nこの時点で、グラフを出力すると以下の通りに変化した。一応参照関係が描かれているように見える。\n 再びapplyしたところ成功。loop処理でも、for_eachはdepends_on記述だけでOKと判明した。やれやれ。\n 更新版のcicd.tf\n#################################### # CodeDeploy Application #################################### resource \u0026quot;aws_codedeploy_app\u0026quot; \u0026quot;codedeploy\u0026quot; { for_each = var.deploy_param_list name = lookup(each.value, \u0026quot;name\u0026quot;) compute_platform = \u0026quot;Server\u0026quot; } #################################### # CodeDeploy Deployment Group #################################### resource \u0026quot;aws_codedeploy_deployment_group\u0026quot; \u0026quot;codedeploy_grp\u0026quot; { for_each = var.deploy_param_list app_name = lookup(each.value, \u0026quot;name\u0026quot;) deployment_group_name = lookup(each.value, \u0026quot;deployment_group_name\u0026quot;) depends_on = [aws_codedeploy_app.codedeploy] service_role_arn = var.deploy_role deployment_config_name = \u0026quot;CodeDeployDefault.AllAtOnce\u0026quot; ec2_tag_set { ec2_tag_filter { key = \u0026quot;Name\u0026quot; type = \u0026quot;KEY_AND_VALUE\u0026quot; value = lookup(each.value, \u0026quot;value\u0026quot;) } } deployment_style { deployment_option = \u0026quot;WITHOUT_TRAFFIC_CONTROL\u0026quot; deployment_type = \u0026quot;IN_PLACE\u0026quot; } auto_rollback_configuration { enabled = true events = [\u0026quot;DEPLOYMENT_FAILURE\u0026quot;] } }  ちなみにec2_tag_filterは、apply実行時に指定したタグを持つEC2インスタンスが存在しなくても成功する。あとはこれに、前半にCodeCommit, 後半にCodePipelineを追加して、一気にCI/CDリソース作成目指したい。\n 余談：Graphvizインストール 参照した記事に記載があって気になったので入れてみた。本来はdot言語で記述したテキストデータをグラフで表現してくれるもので、terraform以外でも使える。現状深掘りしてる余裕はないけど別の機会に遊んでみよう。\nテキストデータをグラフ画像に変換するツール「Graphviz」ことはじめ\nGraphvizとdot言語でグラフを描く方法のまとめ\n $ brew install graphviz （すっげぇ膨大な依存関係ライブラリが一緒に入ってくる...） $ dot -V dot - graphviz version 2.49.3 (20211023.0002)  Terraform作業ディレクトリ内で、以下のようなコマンドを実行してグラフを出力する。\n$ terraform graph | dot -Tpng \u0026gt; cicd_graph.png  ","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform-loop-example-2/","summary":"過去記事Terraform loop処理の超シンプルな例 の続き。loopで作成したTerraformリソースの参照方法を検証したらやはりハマったので記録書いておく。\n前回はCodeCommitリポジトリを作成したが、今回はそれ抜きでCodeDeployのリソースを作成した。CodeDeployは (1)アプリケーションと、(2)デプロイメントグループの2つのリソースを作成する。(2)は(1)に依存している。\n作業ディレクトリ構成\nwork_dir ├── cicd.auto.tfvars ├── cicd.tf ├── config.tf #初期化用config ├── terraform.tfvars #regionのみ定義 └── variables.tf  cicd.tf （リソース作成用コード）\n#################################### # CodeDeploy Application #################################### resource \u0026quot;aws_codedeploy_app\u0026quot; \u0026quot;codedeploy\u0026quot; { for_each = var.deploy_param_list name = lookup(each.value, \u0026quot;name\u0026quot;) compute_platform = \u0026quot;Server\u0026quot; } #################################### # CodeDeploy Deployment Group #################################### resource \u0026quot;aws_codedeploy_deployment_group\u0026quot; \u0026quot;codedeploy_grp\u0026quot; { for_each = var.deploy_param_list app_name = lookup(each.value, \u0026quot;name\u0026quot;) deployment_group_name = lookup(each.value, \u0026quot;deployment_group_name\u0026quot;) service_role_arn = var.deploy_role deployment_config_name = \u0026quot;CodeDeployDefault.AllAtOnce\u0026quot; ec2_tag_set { ec2_tag_filter { key = \u0026quot;Name\u0026quot; type = \u0026quot;KEY_AND_VALUE\u0026quot; value = lookup(each.","title":"Terraform loop処理の応用編"},{"content":"過去記事からの派生案件で、Terraformで使うtfvarsファイルについて、繰り返しデータを多数投入する想定のため、これを自動生成したいと考えた。\nTerraform loop処理の超シンプルな例 \nPython - Jinja2テンプレートで連続データを処理したい\n 実際に使用するファイル群は過去記事に記載しているがこんな想定で。（もちろん実際は他にもいろいろ必要）自動生成したいのは、以下の*印をつけたcodecommit.auto.tfvarsである。（この時点では手動で値を記述したもの）\nwork_dir/ ├── codecommit.auto.tfvars * ├── codecommit.tf ├── config.tf ├── terraform.tfvars ├── variables.tf └── vpc.tf  これとは別に、tfvars自動生成作業用ディレクトリの作業前はこの状態。以下3つのファイルを用意する。codecommit.tmplはテンプレートとなる。このファイル名はスクリプトから呼び出すので名称に注意。対象のAWSリソースによって変えるが、tfファイルの名称に合わせておけばよい。\nscript_dir/ ├── codecommit.tmpl ├── create_vars.py └── data.csv  codecommit.tmpl\n param{{ num }} = { repository_name = \u0026quot;{{ repo_name }}\u0026quot; description = \u0026quot;{{ des }}\u0026quot; }  data.csv （今回の例ではヘッダーありの前提）\nnum,repo_name,des 1,\u0026quot;my-repo001\u0026quot;,\u0026quot;my-repo001の説明\u0026quot; 2,\u0026quot;my-repo002\u0026quot;,\u0026quot;my-repo002の説明\u0026quot; 3,\u0026quot;my-repo003\u0026quot;,\u0026quot;my-repo003の説明\u0026quot;  create_vars.py\nimport sys import pandas as pd from jinja2 import Environment, FileSystemLoader def main(): # テンプレート読み込み env = Environment(loader=FileSystemLoader(\u0026#39;./\u0026#39;, encoding=\u0026#39;utf8\u0026#39;)) tmpl = env.get_template(template) # CSV読み込み df = pd.read_csv(\u0026#34;data.csv\u0026#34;, encoding=\u0026#39;utf-8\u0026#39;, header=0 ) # CSVデータをJSONに変換 df.to_json(\u0026#39;data.json\u0026#39;) df_js = pd.read_json(\u0026#34;data.json\u0026#34;) # 代入処理。テンプレートにデータを投入後、変数ファイル(xxx.auto.vars)に書き出す。 def loop(): pre = n + \u0026#39;_param_list = {\u0026#39; + \u0026#39;\\n\u0026#39; end = \u0026#39;}\u0026#39;+ \u0026#39;\\n\u0026#39; with open(varsfile, \u0026#39;w\u0026#39;) as f: f.write(pre) for i in range(len(df_js)): data = df_js.iloc[i] config = tmpl.render(data) f.write(config) f.write(\u0026#39;\\n\u0026#39;) f.write(end) loop() if __name__ == \u0026#34;__main__\u0026#34;: args = sys.argv if len(args) == 2: n = args[1] template = n + \u0026#39;.tmpl\u0026#39; varsfile = n + \u0026#39;.auto.tfvars\u0026#39; main() else: print (\u0026#39;Usage: Specify one of AWS resource name. e.g. s3,iam,cloudwatch...etc.\u0026#39;) sys.exit()  CSVファイルのヘッダー列の値と、xxxx.tmplファイル内の代入箇所の値は一致させる。すると代入処理時に特に指定しなくてもうまいことやってくれる。pandasのヘッダー行の扱いがよくわからなくてはまったが、一応上記で期待値になった。CSV読み込み時はheaderを指定しなくても勝手に判断してこれもうまいことやってくれるらしいが、一応作法としてheader=0を指定。\nヘッダーあり・なしで挙動が変わり、認識させるために複数の方法があるが、あれこれ考えるの面倒だから、CSVにヘッダ入れておくのが一番簡単だろうと思った。ちなみに当初はこんな記述にしてた。namesがカラム名となるのだが、これを定数ではなく自動で取得したいというモチベーションにより、結果的に上記の通りになった。\n変更前のCSV読み込み処理（この時点ではCSVのヘッダーなし）\n# CSV読み込み df = pd.read_csv(\u0026#34;data.csv\u0026#34;, encoding=\u0026#39;utf-8\u0026#39;, names=(\u0026#34;num\u0026#34;,\u0026#34;repo_name\u0026#34;,\u0026#34;des\u0026#34;) )  CSVのヘッダ仕様については以下参考にした。\nCSVファイルから読み込みを行うには（pandas編）\nread_csv でヘッダあり・なしCSVの読み込み\n 代入処理ではループの都度ファイルに書き出している。当初、一度値を全部配列に格納してそれを書き出そうかと思ったが、フォーマットが崩れるからそれを整形したりとか面倒だからやめた。\n繰り返し代入処理の部分は以下記事が参考になった。助かった。\n【jinja2】テンプレートエンジンでデータの連続差し込み\n 実行時は引数として作成対象のAWSリソース名を指定する。テンプレート（今回の場合codecommit.tmpl）のファイル名に合わせる。ここで指定した値が[リソース名].auto.tfvarsのリソース名になる。\n$ python3 create_vars.py codecommit  生成されたcodecommit.auto.tfvars。\ncodecommit_param_list = { param1 = { repository_name = \u0026quot;my-repo001\u0026quot; description = \u0026quot;my-repo001の説明\u0026quot; } param2 = { repository_name = \u0026quot;my-repo002\u0026quot; description = \u0026quot;my-repo002の説明\u0026quot; } param3 = { repository_name = \u0026quot;my-repo003\u0026quot; description = \u0026quot;my-repo003の説明\u0026quot; } }  tfvars生成後は不要となるが、参考までに中間地点で生成されたJSONの中身。\ndata.json\n{\u0026#34;num\u0026#34;:{\u0026#34;0\u0026#34;:1,\u0026#34;1\u0026#34;:2,\u0026#34;2\u0026#34;:3},\u0026#34;repo_name\u0026#34;:{\u0026#34;0\u0026#34;:\u0026#34;my-repo001\u0026#34;,\u0026#34;1\u0026#34;:\u0026#34;my-repo002\u0026#34;,\u0026#34;2\u0026#34;:\u0026#34;my-repo003\u0026#34;},\u0026#34;des\u0026#34;:{\u0026#34;0\u0026#34;:\u0026#34;my-repo001\\u306e\\u8aac\\u660e\u0026#34;,\u0026#34;1\u0026#34;:\u0026#34;my-repo002\\u306e\\u8aac\\u660e\u0026#34;,\u0026#34;2\u0026#34;:\u0026#34;my-repo003\\u306e\\u8aac\\u660e\u0026#34;}}  こんな短いコードだがめっちゃ紆余曲折した。まーでも、これでひと安心。これはサンプルだから3アイテムだけだけど、AWSリソースの単位で十数個とか数十個とかアイテムがあって、さらにそれが複数重なったら手動で記述なんてやってられない。いや、3アイテムだけでも十分面倒だし、ミスる可能性ありありだ。\n今回のやり方はAWSリソース毎にCSVを分けて作っていく必要あるけど、それくらいならいいだろう。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform_auto_create_tfvars/","summary":"過去記事からの派生案件で、Terraformで使うtfvarsファイルについて、繰り返しデータを多数投入する想定のため、これを自動生成したいと考えた。\nTerraform loop処理の超シンプルな例 \nPython - Jinja2テンプレートで連続データを処理したい\n 実際に使用するファイル群は過去記事に記載しているがこんな想定で。（もちろん実際は他にもいろいろ必要）自動生成したいのは、以下の*印をつけたcodecommit.auto.tfvarsである。（この時点では手動で値を記述したもの）\nwork_dir/ ├── codecommit.auto.tfvars * ├── codecommit.tf ├── config.tf ├── terraform.tfvars ├── variables.tf └── vpc.tf  これとは別に、tfvars自動生成作業用ディレクトリの作業前はこの状態。以下3つのファイルを用意する。codecommit.tmplはテンプレートとなる。このファイル名はスクリプトから呼び出すので名称に注意。対象のAWSリソースによって変えるが、tfファイルの名称に合わせておけばよい。\nscript_dir/ ├── codecommit.tmpl ├── create_vars.py └── data.csv  codecommit.tmpl\n param{{ num }} = { repository_name = \u0026quot;{{ repo_name }}\u0026quot; description = \u0026quot;{{ des }}\u0026quot; }  data.csv （今回の例ではヘッダーありの前提）\nnum,repo_name,des 1,\u0026quot;my-repo001\u0026quot;,\u0026quot;my-repo001の説明\u0026quot; 2,\u0026quot;my-repo002\u0026quot;,\u0026quot;my-repo002の説明\u0026quot; 3,\u0026quot;my-repo003\u0026quot;,\u0026quot;my-repo003の説明\u0026quot;  create_vars.py\nimport sys import pandas as pd from jinja2 import Environment, FileSystemLoader def main(): # テンプレート読み込み env = Environment(loader=FileSystemLoader(\u0026#39;.","title":"Terraformのtfvarsファイルを自動生成する"},{"content":" Some say luck is when preparation meets opportunity.\n - Once Upon a Time in Hollywood\u0026quot;の小説版 (Quentin Tarantino) より。\n わかる、その発想好きだ。リアルワールドにおいてシャロン・テートを斬殺したチャールズ・マンソンのモノローグとして登場する言葉ってのがアレだけど\u0026hellip;\n個人的な経験からしても、preparation（準備）はopportunity（好機）を引き寄せるのは実感として理解できる。だから “preparation gets opportunity” とも言えるんじゃないか？\n   ","permalink":"https://ecnedaced-seirots.github.io/post/a/quotes-tarantino-movie-1/","summary":" Some say luck is when preparation meets opportunity.\n - Once Upon a Time in Hollywood\u0026quot;の小説版 (Quentin Tarantino) より。\n わかる、その発想好きだ。リアルワールドにおいてシャロン・テートを斬殺したチャールズ・マンソンのモノローグとして登場する言葉ってのがアレだけど\u0026hellip;\n個人的な経験からしても、preparation（準備）はopportunity（好機）を引き寄せるのは実感として理解できる。だから “preparation gets opportunity” とも言えるんじゃないか？\n   ","title":"Quotes - タランティーノ小説より(1)"},{"content":"Jinja2テンプレートで連続データを処理したい。元データはCSVとかで。いや、Jinja2でなくてもいいかもしれないけど、ちょっと思いつかないな\u0026hellip;\nとりあえず参考リンク。最初のリンクは、CSVをJSONに変換しているんだよな、CSVのままでやりたいんだけど。しかし例は分かりやすい。\n  【jinja2】テンプレートエンジンでデータの連続差し込み PythonのテンプレートエンジンJinja2を使ってみた   ","permalink":"https://ecnedaced-seirots.github.io/post/a/jinja2-python/","summary":"Jinja2テンプレートで連続データを処理したい。元データはCSVとかで。いや、Jinja2でなくてもいいかもしれないけど、ちょっと思いつかないな\u0026hellip;\nとりあえず参考リンク。最初のリンクは、CSVをJSONに変換しているんだよな、CSVのままでやりたいんだけど。しかし例は分かりやすい。\n  【jinja2】テンプレートエンジンでデータの連続差し込み PythonのテンプレートエンジンJinja2を使ってみた   ","title":"Python - Jinja2テンプレートで連続データを処理したい"},{"content":"前回投稿で言及したTerraformのループ処理を、めっちゃシンプルなパターンでやってみた。\n前回投稿\nTerraform loop処理のリンク集\n参考記事\nTerraformで配列をloopする時はfor_eachを使った方がいい\n やったこと Terraformのセットアップは割愛。作業ディレクトリには以下のtfコードがある。\nwork_dir/ ├── codecommit.tf ├── init.tf ├── variables.tf └── vpc.tf  以下は初期化ファイル。terraform init で初期化実行すみである。VPCも別途サクッと作ってある。ひとりPoCだからremote_stateにする必要もないのだが、なんとなくtfstateをS3に保管するためbackendの定義がある。\ninit.tf\nterraform { required_providers { aws = { source = \u0026quot;hashicorp/aws\u0026quot; version = \u0026quot;3.66.0\u0026quot; } } } terraform { required_version = \u0026quot;1.0.11\u0026quot; backend \u0026quot;s3\u0026quot; { bucket = \u0026quot;my-terraform-poc-repository\u0026quot; key = \u0026quot;poc/poc.tfstate\u0026quot; region = \u0026quot;ap-northeast-1\u0026quot; } }  で、肝心のloop処理。最初なので脳に優しく、超シンプルなパターンでいく。CodeCommitリポジトリの作成はパラメータが少ないので、参考記事を参照し、これで試した。他にもパラメータが少ないやつならなんでもいいけど。今回セットする値はrepository_nameとdescriptionの2点だけ。\nvariable.tf\nvariable \u0026quot;codecommit_param_list\u0026quot; { type = map(map(string)) default = { param1 = { repository_name = \u0026quot;repo001\u0026quot; description = \u0026quot;desciption for repo001\u0026quot; } param2 = { repository_name = \u0026quot;repo002\u0026quot; description = \u0026quot;desciption for repo002\u0026quot; } param3 = { repository_name = \u0026quot;repo003\u0026quot; description = \u0026quot;desciption for repo003\u0026quot; } } }  codecommit.tf\nresource \u0026quot;aws_codecommit_repository\u0026quot; \u0026quot;codecommit_repos\u0026quot; { for_each = var.codecommit_param_list repository_name = lookup(each.value, \u0026quot;repository_name\u0026quot;) description = lookup(each.value, \u0026quot;description\u0026quot;)  codecommit.tfの\u0026quot;codecommit_repos\u0026quot;は任意の名称。2行目、for_eachでvariables.tfのcodecommit_param_listを呼び出している。今回の場合はリポジトリ名がrepo001, repo002\u0026hellip;となる。この状態でplanを実行すると以下の出力になる。\n: Terraform will perform the following actions: # aws_codecommit_repository.codecommit_repos[\u0026quot;param1\u0026quot;] will be created + resource \u0026quot;aws_codecommit_repository\u0026quot; \u0026quot;codecommit_repos\u0026quot; { + arn = (known after apply) + clone_url_http = (known after apply) + clone_url_ssh = (known after apply) + description = \u0026quot;desciption for repo001\u0026quot; + id = (known after apply) + repository_id = (known after apply) + repository_name = \u0026quot;repo001\u0026quot; + tags_all = (known after apply) } # aws_codecommit_repository.codecommit_repos[\u0026quot;param2\u0026quot;] will be created + resource \u0026quot;aws_codecommit_repository\u0026quot; \u0026quot;codecommit_repos\u0026quot; { + arn = (known after apply) + clone_url_http = (known after apply) + clone_url_ssh = (known after apply) + description = \u0026quot;desciption for repo002\u0026quot; + id = (known after apply) + repository_id = (known after apply) + repository_name = \u0026quot;repo002\u0026quot; + tags_all = (known after apply) } (repo003も同様） Plan: 3 to add, 0 to change, 0 to destroy.  terraform applyを実行。期待値になった。（repo003だけ時間がずれているのは、1点間違いがあってやり直したから）\n やれることはわかったのでこいつ達は削除する。\nリポジトリを削除する。しかしいきなりdestroyすると別途作ったvpcまで消えてしまう。同じ階層にvpc.tfがあるのでそれはそのまま、codecommit.tfを作業ディレクトリから退避。この状態でapplyするとcodecommitリポジトリは消えてvpcは残る。以下でやっていることはapplyでもdestroyなので注意。\n$ terraform apply : aws_codecommit_repository.codecommit_repos[\u0026quot;param3\u0026quot;]: Destroying... [id=repo003] aws_codecommit_repository.codecommit_repos[\u0026quot;param1\u0026quot;]: Destroying... [id=repo001] aws_codecommit_repository.codecommit_repos[\u0026quot;param2\u0026quot;]: Destroying... [id=repo002] aws_codecommit_repository.codecommit_repos[\u0026quot;param1\u0026quot;]: Destruction complete after 0s aws_codecommit_repository.codecommit_repos[\u0026quot;param3\u0026quot;]: Destruction complete after 0s aws_codecommit_repository.codecommit_repos[\u0026quot;param2\u0026quot;]: Destruction complete after 0s Apply complete! Resources: 0 added, 0 changed, 3 destroyed.  課題 コツは掴めたけど、コード本体に書く値がvariablesに移動しただけという気もする。パラメータが増えるほど、結局variablesが肥大化することになる。変数定義を分割できないか？\n この課題については、変数定義をさらにtfvarsに外出しすることで解決可能。変数定義ファイルが増えることにはなるが、1ファイルが肥大化するよりいい。今回やった分だけでいうと、以下の構成になる。\nwork_dir/ ├── codecommit.auto.tfvars ├── codecommit.tf ├── config.tf ├── terraform.tfvars ├── variables.tf └── vpc.tf  xxxxx.auto.tfvarsに個別に分割した要素の値を記述すると、apply実行時に自動で呼び出される。\ncodecommit.tfはこれまでと同じ。\nvariables.tfには値は記述せず、宣言だけ記述する。\nterraform.tfvarsにはリージョンなど全てに共通の値、IAMなど他のリソースから共通で参照されるリソースの値を記述。\nvariables.tf\n# main variable \u0026quot;region\u0026quot; { type = string description = \u0026quot;\u0026quot; } # codecommit variable \u0026quot;codecommit_param_list\u0026quot; { type = map(map(string)) description = \u0026quot;\u0026quot; }  codecommit.auto.tfvars\n# codecommit repos definition codecommit_param_list = { param1 = { repository_name = \u0026quot;repo004\u0026quot; description = \u0026quot;desciption for repo004\u0026quot; } param2 = { repository_name = \u0026quot;repo005\u0026quot; description = \u0026quot;desciption for repo005\u0026quot; } param3 = { repository_name = \u0026quot;repo006\u0026quot; description = \u0026quot;desciption for repo006\u0026quot; } }  terraform.tfvars\nregion = \u0026quot;ap-northeast-1\u0026quot;  codecommit.auto.tfvarsは例なのでこれだけだが、例えばネットワーク周り、アプリ系リソース、監視、ジョブ等の大枠に分割して、その枠毎にtfvarsを用意すれば小回りが効く構成になるんじゃないかと。て、なんかloop処理のことを書くつもりが変数周りのネタメインになった気がする。ま、いいか。\n 課題2 loopで作成したリソースの参照方法はどうすればいいのか？が気になって調査してみた。今回だと、Terraformで作成したCodeCommitリポジトリ名をCodePipeline作成時のコードで参照するケースとか。リポジトリrepo001を参照するなら以下の記述になる。\ncodecommit_repository.codecommit_repos[\u0026quot;param1\u0026quot;].id  参照名はcodecommit_repository.codecommit_repos[\u0026quot;param1\u0026quot;].repository_nameではないことに注意。それはいいとして、CodePipeline自体もloopで作成するとしたらこの記述は使えないから、結局同じtfvarsの値を参照して作ることになるかな。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform-loop-example/","summary":"前回投稿で言及したTerraformのループ処理を、めっちゃシンプルなパターンでやってみた。\n前回投稿\nTerraform loop処理のリンク集\n参考記事\nTerraformで配列をloopする時はfor_eachを使った方がいい\n やったこと Terraformのセットアップは割愛。作業ディレクトリには以下のtfコードがある。\nwork_dir/ ├── codecommit.tf ├── init.tf ├── variables.tf └── vpc.tf  以下は初期化ファイル。terraform init で初期化実行すみである。VPCも別途サクッと作ってある。ひとりPoCだからremote_stateにする必要もないのだが、なんとなくtfstateをS3に保管するためbackendの定義がある。\ninit.tf\nterraform { required_providers { aws = { source = \u0026quot;hashicorp/aws\u0026quot; version = \u0026quot;3.66.0\u0026quot; } } } terraform { required_version = \u0026quot;1.0.11\u0026quot; backend \u0026quot;s3\u0026quot; { bucket = \u0026quot;my-terraform-poc-repository\u0026quot; key = \u0026quot;poc/poc.tfstate\u0026quot; region = \u0026quot;ap-northeast-1\u0026quot; } }  で、肝心のloop処理。最初なので脳に優しく、超シンプルなパターンでいく。CodeCommitリポジトリの作成はパラメータが少ないので、参考記事を参照し、これで試した。他にもパラメータが少ないやつならなんでもいいけど。今回セットする値はrepository_nameとdescriptionの2点だけ。\nvariable.tf\nvariable \u0026quot;codecommit_param_list\u0026quot; { type = map(map(string)) default = { param1 = { repository_name = \u0026quot;repo001\u0026quot; description = \u0026quot;desciption for repo001\u0026quot; } param2 = { repository_name = \u0026quot;repo002\u0026quot; description = \u0026quot;desciption for repo002\u0026quot; } param3 = { repository_name = \u0026quot;repo003\u0026quot; description = \u0026quot;desciption for repo003\u0026quot; } } }  codecommit.","title":"Terraform loop処理の超シンプルな例"},{"content":"Terraformでループ処理ってどうするんだっけ\u0026hellip;と調べたらいろいろ出てきた。読んでも全然頭に入らないがとりあえず参考リンクをメモ。パッと見る限りcountよりfor_eachの方がお勧め？ひとつのリソースに2個以上のパラメータをセットする場合は以下記事の「for_eachを使った書き方（その2）」を参考にすればいいかな。\n  for_eachを知らずにcountを使って作成したところ、追加や削除の際に色々と意図しない挙動になったので、回避策について備忘録を残しておきたいと思います。\n  Terraformで配列をloopする時はfor_eachを使った方がいい   以下もちゃんと読めば有益そうなのだが、マニアックすぎて理解が追いつかない。\n Terraformでのloop処理の書き方（for, for_each, count） Terraformのループ処理(for_each,for)について Terraformでimportを使う理由とfor_eachをつかったリソース定義に実リソースをimportする方法   これはcountを使う方法。多分使わないけど比較用にメモ。\n Terraformで超サクッとループでリソースを用意する方法   上記記事のリンクにあったこっちの記事の方にピピっときた。IntelliJでTerraformね、これはやってみよう。仕事じゃ使えないけど。\n 新記法対応！ IntelliJ IDEAを使ってTerraformを書いてみた   IntelliJはさておき、久しぶりに使ってみたらプロバイダの記述方法が変わっていてハマった。今現在は以下の方式で書く。\nterraform { required_providers { aws = { source = \u0026quot;hashicorp/aws\u0026quot; version = \u0026quot;3.66.0\u0026quot; } } }  以下記事に最近変わった細かい規則とかいろいろ書いてある。ロックファイルとか面倒くせぇな、なくていいのに。\u0026hellip;と思ったが、ドキュメント読む限り気にしなくてよさげ。\n Terraform職人再入門2020   ","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform-loop-memo/","summary":"Terraformでループ処理ってどうするんだっけ\u0026hellip;と調べたらいろいろ出てきた。読んでも全然頭に入らないがとりあえず参考リンクをメモ。パッと見る限りcountよりfor_eachの方がお勧め？ひとつのリソースに2個以上のパラメータをセットする場合は以下記事の「for_eachを使った書き方（その2）」を参考にすればいいかな。\n  for_eachを知らずにcountを使って作成したところ、追加や削除の際に色々と意図しない挙動になったので、回避策について備忘録を残しておきたいと思います。\n  Terraformで配列をloopする時はfor_eachを使った方がいい   以下もちゃんと読めば有益そうなのだが、マニアックすぎて理解が追いつかない。\n Terraformでのloop処理の書き方（for, for_each, count） Terraformのループ処理(for_each,for)について Terraformでimportを使う理由とfor_eachをつかったリソース定義に実リソースをimportする方法   これはcountを使う方法。多分使わないけど比較用にメモ。\n Terraformで超サクッとループでリソースを用意する方法   上記記事のリンクにあったこっちの記事の方にピピっときた。IntelliJでTerraformね、これはやってみよう。仕事じゃ使えないけど。\n 新記法対応！ IntelliJ IDEAを使ってTerraformを書いてみた   IntelliJはさておき、久しぶりに使ってみたらプロバイダの記述方法が変わっていてハマった。今現在は以下の方式で書く。\nterraform { required_providers { aws = { source = \u0026quot;hashicorp/aws\u0026quot; version = \u0026quot;3.66.0\u0026quot; } } }  以下記事に最近変わった細かい規則とかいろいろ書いてある。ロックファイルとか面倒くせぇな、なくていいのに。\u0026hellip;と思ったが、ドキュメント読む限り気にしなくてよさげ。\n Terraform職人再入門2020   ","title":"Terraform loop処理のリンク集"},{"content":"以下過去記事の続き。この時はメール本文がJSON生データで送信された。これを、人間が状況を判別可能な状態までもっていきたい。\nAWSイベント監視 - CloudTrail + EventBridge + Lambdaでメールカスタマイズ\n とういことで、再度検証。使用したAWS各種サービスのリソースは前回と同様で、Lambda関数のコードだけ入れ替え。何度も同じようなことをやっていて何がなんだか分からなくなっているがもうヤケクソ。\n lambda_function.py （イベント監視メール通知用）\nimport boto3 import json import os import re from botocore.exceptions import ClientError from datetime import datetime, timezone, timedelta from dateutil import parser print(\u0026#39;Loading function\u0026#39;) sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] def lambda_handler(event, context): data = event s = json.dumps(data) e = json.loads(s) print(e) # eventから項目を抽出 dtl = e[\u0026#39;detail\u0026#39;] #詳細(detail)を定義 e_type = e[\u0026#39;detail-type\u0026#39;] # イベントタイプ 例：\u0026#39;AWS API Call via CloudTrail\u0026#39; t = e[\u0026#39;time\u0026#39;] # 発生時刻 evt_name = dtl[\u0026#39;eventName\u0026#39;] # イベント名 例：DeleteBucket evt_src = dtl[\u0026#39;eventSource\u0026#39;] # イベントソース 例：s3.amazonaws.com evt_usr = dtl[\u0026#39;userIdentity\u0026#39;][\u0026#39;arn\u0026#39;] # 実行ユーザ 例：arn:aws:iam::012345678910:user/hoge_user evt_ip = dtl[\u0026#39;sourceIPAddress\u0026#39;] # ソースIPアドレス #123.123.123.123 # 時刻変換 JST = timezone(timedelta(hours=+9), \u0026#39;JST\u0026#39;) utcstr_parsed = parser.parse(t) ux_time = utcstr_parsed.timestamp() epoch = int(ux_time) # unixタイムスタンプをJSTに変換。dtはこの時点でdatetime.datetime型 dt = datetime.fromtimestamp(epoch).replace(tzinfo=timezone.utc).astimezone(tz=JST) # dtを整形 dt_str = dt.strftime(\u0026#39;%Y-%m-%d%H:%M:%S\u0026#39;) # イベントリクエスト 例：{\u0026#39;bucketName\u0026#39;: \u0026#39;hoge-test-bucket-0001\u0026#39;, \u0026#39;Host\u0026#39;: \u0026#39;s3-ap-northeast-1.amazonaws.com\u0026#39;} evt_req_d = e[\u0026#39;detail\u0026#39;][\u0026#39;requestParameters\u0026#39;] req_str = json.dumps(evt_req_d) evt_req = re.sub(r\u0026#34;[{}\\\u0026#34;]\u0026#34;, \u0026#34;\u0026#34;, req_str) # 件名整形 subject_str = \u0026#34;本番環境イベント監視 \u0026#34; + evt_name + \u0026#34; - \u0026#34; + evt_src # メッセージ本文整形 fix_msg = \u0026#34;以下のイベントが発生しました\u0026#34; + \u0026#34;\\n\u0026#34; type_msg = \u0026#34;イベントタイプ:\u0026#34; + \u0026#34;\\n\u0026#34; + e_type time_msg = \u0026#34;発生時刻(JST):\u0026#34; + \u0026#34;\\n\u0026#34; + dt_str ename_msg = \u0026#34;イベント名:\u0026#34; + \u0026#34;\\n\u0026#34; + evt_name esrc_msg =\u0026#34;イベントソース:\u0026#34; \u0026#34;\\n\u0026#34; + evt_src ereq_msg =\u0026#34;イベントリクエスト:\u0026#34; \u0026#34;\\n\u0026#34; + evt_req eusr_msg =\u0026#34;実行ユーザ:\u0026#34; \u0026#34;\\n\u0026#34; + evt_usr eip_msg =\u0026#34;ソースIPアドレス:\u0026#34; \u0026#34;\\n\u0026#34; + evt_ip msg = fix_msg + \u0026#34;\\n\\n\u0026#34; + type_msg + \u0026#34;\\n\\n\u0026#34; + time_msg + \u0026#34;\\n\\n\u0026#34; + ename_msg + \u0026#34;\\n\\n\u0026#34; + esrc_msg + \u0026#34;\\n\\n\u0026#34; + ereq_msg + \u0026#34;\\n\\n\u0026#34; + eusr_msg + \u0026#34;\\n\\n\u0026#34; + eip_msg try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = msg, Subject = subject_str ) except Exception as e: print(e)  テスト用にサンプルデータを貼り付けて、エラーが出ない状態にまでもっていった。これでもういいかと思ったがやはりちゃんとしたメールが届くのが見たい\u0026hellip;ということで、再びCloudTrailを有効にしてイベントを発生させることにした。前回無効にしたCloudTrailログ用の残骸バケットが残っていたのでそれを削除したら、まさにその行為がイベントとして検知され、メールが届いた。よしよし。\n 上記はテストデータ残骸の内容が表示されているが、実際のイベント発生時のメールも別途ちゃんと届いている。上記画面では「APIタイプ」が含まれているがこれはいらないと判断したため、この後コードから削除した。\n ちなみに、JSON生データからkey:valueの抽出を行うときはこんなんでやった。JSONデータをファイルに保存してから：\n\u0026gt;\u0026gt;\u0026gt; import json \u0026gt;\u0026gt;\u0026gt; event_file = open('event_msg_sample.json','r') \u0026gt;\u0026gt;\u0026gt; event = json.load(event_file) \u0026gt;\u0026gt;\u0026gt; for k,v in event.items(): ... print(k,v)  （追記）以下でもよい。先にこれをやって、階層が深くて分かりにくい場合は上記を併用すればいいかと。\n\u0026gt;\u0026gt;\u0026gt; msg = json.dumps(event, indent=3) \u0026gt;\u0026gt;\u0026gt; print(msg)  ","permalink":"https://ecnedaced-seirots.github.io/post/a/aws-events-custom-mail-2/","summary":"以下過去記事の続き。この時はメール本文がJSON生データで送信された。これを、人間が状況を判別可能な状態までもっていきたい。\nAWSイベント監視 - CloudTrail + EventBridge + Lambdaでメールカスタマイズ\n とういことで、再度検証。使用したAWS各種サービスのリソースは前回と同様で、Lambda関数のコードだけ入れ替え。何度も同じようなことをやっていて何がなんだか分からなくなっているがもうヤケクソ。\n lambda_function.py （イベント監視メール通知用）\nimport boto3 import json import os import re from botocore.exceptions import ClientError from datetime import datetime, timezone, timedelta from dateutil import parser print(\u0026#39;Loading function\u0026#39;) sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] def lambda_handler(event, context): data = event s = json.dumps(data) e = json.loads(s) print(e) # eventから項目を抽出 dtl = e[\u0026#39;detail\u0026#39;] #詳細(detail)を定義 e_type = e[\u0026#39;detail-type\u0026#39;] # イベントタイプ 例：\u0026#39;AWS API Call via CloudTrail\u0026#39; t = e[\u0026#39;time\u0026#39;] # 発生時刻 evt_name = dtl[\u0026#39;eventName\u0026#39;] # イベント名 例：DeleteBucket evt_src = dtl[\u0026#39;eventSource\u0026#39;] # イベントソース 例：s3.","title":"AWSイベント監視 - CloudTrail + EventBridge + Lambdaでメールカスタマイズ(2)"},{"content":"表題のテーマ、過去にもCloudWatchアラーム通知メールのカスタマイズについて書いたが、表示時刻がUTCなのでJSTに変換しようと考えた。\n 過去記事\nCloudWatchアラーム + SNSからのメール本文をカスタマイズする(2)\nCloudWatchアラーム + SNSからのメール件名をカスタマイズする\n CloudWatchアラームから渡されるeventの、元データの時刻表示は例えば'2021-10-24T09:35:10Z\u0026rsquo;となっている。これをJSTにするのに手っ取り早いのはpytzを使う方法だが、諸事情により標準ライブラリの範囲でやる必要がある。\nで、試行錯誤。当初datetime型にしてからJSTに変換しようとしたがいいやり方が見つからなかったため「unixタイムスタンプに変換後、JSTに変換」とすることにした。\nfrom datetime import datetime, timezone, timedelta from dateutil import parser JST = timezone(timedelta(hours=+9), 'JST') utcstr = '2021-10-24T09:35:10Z' utcstr_parsed = parser.parse(utcstr) #UNIXタイムスタンプに変換 ux_time = utcstr_parsed.timestamp() #int型にする epoch = int(ux_time) #JSTに変換 dt = datetime.fromtimestamp(epoch).replace(tzinfo=timezone.utc).astimezone(tz=JST) print(dt) 2021-10-25 03:35:10+09:00  当初JSTに変換した後の時間が変だ+18時間になってる何故だ、と悩んだが、拠点にした時間から+18時間になるのはおそらく実行環境がJSTだから。UTCの環境でやれば+9時間になるんだろう。くそ、こんなことで数時間週末を無駄にした。俺の休息時間はいつなんだ？\nともあれ、修正したのが以下。コメントの「時刻変換」と、「件名に投入するアラーム名を抽出」を追加した。前回はメール件名規則を「任意の文字列 + 発生契機 + 対象リソース(dimention)」としていたが、発生契機はいらないから代わりにアラーム名にした。\n lambda_function.py （時刻表示JSTバージョン）\nimport boto3 import json import os import re from botocore.exceptions import ClientError from datetime import datetime, timezone, timedelta from dateutil import parser print(\u0026#39;Loading function\u0026#39;) sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] def lambda_handler(event, context): data = event s = json.dumps(data) e = json.loads(s) print(e) # eventから項目を抽出 t = e[\u0026#39;time\u0026#39;] trig = e[\u0026#39;detail-type\u0026#39;] alarm = e[\u0026#39;resources\u0026#39;] # 時刻変換 JST = timezone(timedelta(hours=+9), \u0026#39;JST\u0026#39;) utcstr_parsed = parser.parse(t) ux_time = utcstr_parsed.timestamp() epoch = int(ux_time) # unixタイムスタンプをJSTに変換。dtはこの時点でdatetime.datetime型 dt = datetime.fromtimestamp(epoch).replace(tzinfo=timezone.utc).astimezone(tz=JST) # dtを整形 dt_str = dt.strftime(\u0026#39;%Y-%m-%d%H:%M:%S\u0026#39;) # 件名に投入するアラーム名を抽出 alm_list = alarm[0].split(\u0026#39;:\u0026#39;) alm_name = alm_list[-1] # 「理由」となる詳細抽出 reason = e[\u0026#39;detail\u0026#39;][\u0026#39;state\u0026#39;][\u0026#39;reason\u0026#39;] # リソース（ここではインスタンスID)を抽出し、文字列整形 resource = e[\u0026#39;detail\u0026#39;][\u0026#39;configuration\u0026#39;][\u0026#39;metrics\u0026#39;][0][\u0026#39;metricStat\u0026#39;][\u0026#39;metric\u0026#39;][\u0026#39;dimensions\u0026#39;] res_str = json.dumps(resource) res = re.sub(r\u0026#34;[{}\\\u0026#34;]\u0026#34;, \u0026#34;\u0026#34;, res_str) # 件名整形 subject_str = \u0026#34;本番環境アラーム \u0026#34; + alm_name + \u0026#34; - \u0026#34; + res # メッセージ本文整形 fix_msg = \u0026#34;以下のアラームが発生しました\u0026#34; + \u0026#34;\\n\u0026#34; trig_msg = \u0026#34;発生契機:\u0026#34; + \u0026#34;\\n\u0026#34; + trig time_msg = \u0026#34;発生時刻(JST):\u0026#34; + \u0026#34;\\n\u0026#34; + dt_str alm_msg = \u0026#34;アラームARN:\u0026#34; + \u0026#34;\\n\u0026#34; + alarm[0] res_msg =\u0026#34;対象リソース:\u0026#34; \u0026#34;\\n\u0026#34; + res dtl_msg =\u0026#34;理由:\u0026#34; \u0026#34;\\n\u0026#34; + reason msg = fix_msg + \u0026#34;\\n\\n\u0026#34; + trig_msg + \u0026#34;\\n\\n\u0026#34; + time_msg + \u0026#34;\\n\\n\u0026#34; + alm_msg + \u0026#34;\\n\\n\u0026#34; + res_msg + \u0026#34;\\n\\n\u0026#34; + dtl_msg try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = msg, Subject = subject_str ) except Exception as e: print(e)  上記コードにてLambdaを再デプロイしてec2インスタンスでCPU負荷発生させたところ、一応期待値となるメールが届いた。画面下の「理由」に記載の時刻はUTCとなっているが、「発生時刻(JST)」は日本時刻表記である。（ほぼ実際にCPU負荷をかけた時間）\n  参考\n[Python]UNIX秒(UTC)をISO8601(JST)に変換する\nPythonで日付をunixtimeに変換する方法【初心者向け】\n まぁこんなことやったところで誰も感謝もしてくれないがね。映画\u0026quot;Taxi Driver\u0026quot;のトラヴィスの気持ちも分かるってもんだ。（\u0026hellip;若干くされ気分）\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatch-alarm-lambda-3/","summary":"表題のテーマ、過去にもCloudWatchアラーム通知メールのカスタマイズについて書いたが、表示時刻がUTCなのでJSTに変換しようと考えた。\n 過去記事\nCloudWatchアラーム + SNSからのメール本文をカスタマイズする(2)\nCloudWatchアラーム + SNSからのメール件名をカスタマイズする\n CloudWatchアラームから渡されるeventの、元データの時刻表示は例えば'2021-10-24T09:35:10Z\u0026rsquo;となっている。これをJSTにするのに手っ取り早いのはpytzを使う方法だが、諸事情により標準ライブラリの範囲でやる必要がある。\nで、試行錯誤。当初datetime型にしてからJSTに変換しようとしたがいいやり方が見つからなかったため「unixタイムスタンプに変換後、JSTに変換」とすることにした。\nfrom datetime import datetime, timezone, timedelta from dateutil import parser JST = timezone(timedelta(hours=+9), 'JST') utcstr = '2021-10-24T09:35:10Z' utcstr_parsed = parser.parse(utcstr) #UNIXタイムスタンプに変換 ux_time = utcstr_parsed.timestamp() #int型にする epoch = int(ux_time) #JSTに変換 dt = datetime.fromtimestamp(epoch).replace(tzinfo=timezone.utc).astimezone(tz=JST) print(dt) 2021-10-25 03:35:10+09:00  当初JSTに変換した後の時間が変だ+18時間になってる何故だ、と悩んだが、拠点にした時間から+18時間になるのはおそらく実行環境がJSTだから。UTCの環境でやれば+9時間になるんだろう。くそ、こんなことで数時間週末を無駄にした。俺の休息時間はいつなんだ？\nともあれ、修正したのが以下。コメントの「時刻変換」と、「件名に投入するアラーム名を抽出」を追加した。前回はメール件名規則を「任意の文字列 + 発生契機 + 対象リソース(dimention)」としていたが、発生契機はいらないから代わりにアラーム名にした。\n lambda_function.py （時刻表示JSTバージョン）\nimport boto3 import json import os import re from botocore.exceptions import ClientError from datetime import datetime, timezone, timedelta from dateutil import parser print(\u0026#39;Loading function\u0026#39;) sns_arn = os.","title":"CloudWatchアラーム + SNSからのメール本文をカスタマイズする(3)"},{"content":"into the bargain = in addition\n\u0026ldquo;Zazie in the Metro\u0026rdquo;(Raymond Queneau) / 地下鉄のザジ（レーモン・クノー）より\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/english-into-the-bargain/","summary":"into the bargain = in addition\n\u0026ldquo;Zazie in the Metro\u0026rdquo;(Raymond Queneau) / 地下鉄のザジ（レーモン・クノー）より\n ","title":"英語メモ - into the bargain"},{"content":"表題の件、過去記事ではメール件名カスタマイズが主題だったが、メール本文を人間が判読可能なフォーマットにすべく、Lambdaコードを改良してみた。これがSNSに渡り、整形された本文がメール送信される想定である。前回はメール件名を環境変数にしたが今回はコード内から値を取り出している。\n類似の過去記事\nCloudWatchアラーム + SNSからのメール件名をカスタマイズする\n lambda_function.py\nimport boto3 import json import os import re from botocore.exceptions import ClientError print(\u0026#39;Loading function\u0026#39;) sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] def lambda_handler(event, context): data = event s = json.dumps(data) e = json.loads(s) print(e) # eventから項目を抽出 t = e[\u0026#39;time\u0026#39;] trig = e[\u0026#39;detail-type\u0026#39;] alarm = e[\u0026#39;resources\u0026#39;] #これはリスト。文字列にするにはalarm[0] # 「理由」となる詳細抽出 reason = e[\u0026#39;detail\u0026#39;][\u0026#39;state\u0026#39;][\u0026#39;reason\u0026#39;] # リソース（ここではインスタンスID)を抽出し、文字列整形 resource = e[\u0026#39;detail\u0026#39;][\u0026#39;configuration\u0026#39;][\u0026#39;metrics\u0026#39;][0][\u0026#39;metricStat\u0026#39;][\u0026#39;metric\u0026#39;][\u0026#39;dimensions\u0026#39;] res_str = json.dumps(resource) res = re.sub(r\u0026#34;[{}\\\u0026#34;]\u0026#34;, \u0026#34;\u0026#34;, res_str) # 件名整形 subject_str = \u0026#34;本番環境 - アラーム \u0026#34; + trig + \u0026#34; - \u0026#34; + res # メッセージ本文整形 fix_msg = \u0026#34;以下のアラームが発生しました\u0026#34; + \u0026#34;\\n\u0026#34; trig_msg = \u0026#34;発生契機:\u0026#34; + \u0026#34;\\n\u0026#34; + trig time_msg = \u0026#34;発生時刻:\u0026#34; + \u0026#34;\\n\u0026#34; + t alm_msg = \u0026#34;アラーム:\u0026#34; + \u0026#34;\\n\u0026#34; + alarm[0] res_msg =\u0026#34;対象リソース:\u0026#34; \u0026#34;\\n\u0026#34; + res dtl_msg =\u0026#34;理由:\u0026#34; \u0026#34;\\n\u0026#34; + reason msg = fix_msg + \u0026#34;\\n\\n\u0026#34; + trig_msg + \u0026#34;\\n\\n\u0026#34; + time_msg + \u0026#34;\\n\\n\u0026#34; + alm_msg + \u0026#34;\\n\\n\u0026#34; + res_msg + \u0026#34;\\n\\n\u0026#34; + dtl_msg try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = msg, Subject = subject_str ) except Exception as e: print(e)  マネコン上でテストしたらいくつかエラー出たので対処して、エラー出ないところまでもってきた。で、ec2インスタンスに負荷をかけてアラームステータスにしたが\u0026hellip;メールが届かない。あぁ。\n明日以降考えよ。\n 追記\n翌日Lambdaの画面からなんとなくEventBridgeルールのリンクを辿ったら、なんとルールがdisableになっていた！そりゃ何も起こらないわけだ。enableに変更して、改めてインスタンスで負荷をかけたところ、カスタムメールが届いた！大したことじゃないけど、こういうのはいつまでたっても嬉しいもんだ。\n  しかしよく見ると日付が変だ。Lambdaテスト用に使った過去データの値みたいだ。な、なんでこうなるんだ。でももう遅いから寝る\u0026hellip;\n 追記2\nさらにその翌日、テストデータ削除して再試行してみたところ、期待値となるまともなメールが届いた。\n 時間はUTC表記。これどうするかな。以下でやれるのはわかったけど。\n\u0026gt;\u0026gt;\u0026gt; from pytz import timezone \u0026gt;\u0026gt;\u0026gt; from dateutil import parser \u0026gt;\u0026gt;\u0026gt; time = \u0026quot;2021-11-03T10:17:51Z\u0026quot; \u0026gt;\u0026gt;\u0026gt; utc_string = time \u0026gt;\u0026gt;\u0026gt; jst_time = parser.parse(utc_string).astimezone(timezone('Asia/Tokyo')) \u0026gt;\u0026gt;\u0026gt; print(jst_time) 2021-11-03 19:17:51+09:00 参考\nPythonの UTC ⇔ JST、文字列(UTC) ⇒ JST の変換とかのメモ\n しかし、今日はもう寝たいんだ。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatch-alarm-lambda-2/","summary":"表題の件、過去記事ではメール件名カスタマイズが主題だったが、メール本文を人間が判読可能なフォーマットにすべく、Lambdaコードを改良してみた。これがSNSに渡り、整形された本文がメール送信される想定である。前回はメール件名を環境変数にしたが今回はコード内から値を取り出している。\n類似の過去記事\nCloudWatchアラーム + SNSからのメール件名をカスタマイズする\n lambda_function.py\nimport boto3 import json import os import re from botocore.exceptions import ClientError print(\u0026#39;Loading function\u0026#39;) sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] def lambda_handler(event, context): data = event s = json.dumps(data) e = json.loads(s) print(e) # eventから項目を抽出 t = e[\u0026#39;time\u0026#39;] trig = e[\u0026#39;detail-type\u0026#39;] alarm = e[\u0026#39;resources\u0026#39;] #これはリスト。文字列にするにはalarm[0] # 「理由」となる詳細抽出 reason = e[\u0026#39;detail\u0026#39;][\u0026#39;state\u0026#39;][\u0026#39;reason\u0026#39;] # リソース（ここではインスタンスID)を抽出し、文字列整形 resource = e[\u0026#39;detail\u0026#39;][\u0026#39;configuration\u0026#39;][\u0026#39;metrics\u0026#39;][0][\u0026#39;metricStat\u0026#39;][\u0026#39;metric\u0026#39;][\u0026#39;dimensions\u0026#39;] res_str = json.dumps(resource) res = re.sub(r\u0026#34;[{}\\\u0026#34;]\u0026#34;, \u0026#34;\u0026#34;, res_str) # 件名整形 subject_str = \u0026#34;本番環境 - アラーム \u0026#34; + trig + \u0026#34; - \u0026#34; + res # メッセージ本文整形 fix_msg = \u0026#34;以下のアラームが発生しました\u0026#34; + \u0026#34;\\n\u0026#34; trig_msg = \u0026#34;発生契機:\u0026#34; + \u0026#34;\\n\u0026#34; + trig time_msg = \u0026#34;発生時刻:\u0026#34; + \u0026#34;\\n\u0026#34; + t alm_msg = \u0026#34;アラーム:\u0026#34; + \u0026#34;\\n\u0026#34; + alarm[0] res_msg =\u0026#34;対象リソース:\u0026#34; \u0026#34;\\n\u0026#34; + res dtl_msg =\u0026#34;理由:\u0026#34; \u0026#34;\\n\u0026#34; + reason msg = fix_msg + \u0026#34;\\n\\n\u0026#34; + trig_msg + \u0026#34;\\n\\n\u0026#34; + time_msg + \u0026#34;\\n\\n\u0026#34; + alm_msg + \u0026#34;\\n\\n\u0026#34; + res_msg + \u0026#34;\\n\\n\u0026#34; + dtl_msg try: sns = boto3.","title":"CloudWatchアラーム + SNSからのメール本文をカスタマイズする(2)"},{"content":"表題の件、以下の過去記事に書いたが、この時点では送信される本文ががログメッセージだけとなっていて、通知メールとしては不十分なため本文もカスタマイズしてみた。\nCloudWatchLogsのログ監視 - サブスクリプションフィルタ + Lambdaでメール送信\n 各種設定は冒頭の過去記事と同様のため割愛するとして、コードは変更前・後両方載せておく。\n変更前：lambda_function.py(1)\nimport base64 import json import zlib import datetime import os import boto3 from botocore.exceptions import ClientError print(\u0026#39;Loading function\u0026#39;) def lambda_handler(event, context): data = zlib.decompress(base64.b64decode(event[\u0026#39;awslogs\u0026#39;][\u0026#39;data\u0026#39;]), 16+zlib.MAX_WBITS) data_json = json.loads(data) log_entire_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;], ensure_ascii=False)) log_entire_len = len(log_entire_json) print(log_entire_json) for i in range(log_entire_len): log_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;][i], ensure_ascii=False)) try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = log_json[\u0026#39;message\u0026#39;], Subject = os.environ[\u0026#39;ALARM_SUBJECT\u0026#39;] ) except Exception as e: print(e) 参考\nCloudWatch Logs を文字列検知してログ内容をメールを送信してみた サブスクリプションフィルター版\n 変更後：lambda_function.py(2)\nimport base64 import json import zlib import datetime import os import boto3 from botocore.exceptions import ClientError print(\u0026#39;Loading function\u0026#39;) def lambda_handler(event, context): data = zlib.decompress(base64.b64decode(event[\u0026#39;awslogs\u0026#39;][\u0026#39;data\u0026#39;]), 16+zlib.MAX_WBITS) data_json = json.loads(data) log_entire_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;], ensure_ascii=False)) log_entire_len = len(log_entire_json) print(log_entire_json) for i in range(log_entire_len): # ロググループ名取得 log_group = data_json[\u0026#39;logGroup\u0026#39;] # ログストリーム名取得 log_stm = data_json[\u0026#39;logStream\u0026#39;] # LogEvents取得 log_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;][i], ensure_ascii=False)) #UNIX時間→時刻/JST変換 datetime_utc = log_json[\u0026#39;timestamp\u0026#39;] / 1000.0 datetime_utc = datetime.datetime.fromtimestamp(datetime_utc).strftime(\u0026#39;%Y/%m/%d%H:%M:%S\u0026#39;) datetime_utc = datetime.datetime.strptime(datetime_utc, \u0026#39;%Y/%m/%d%H:%M:%S\u0026#39;) datetime_jst = datetime_utc + datetime.timedelta(hours = 9) # メール件名整形 subject_str = \u0026#34;本番環境 - ログアラート \u0026#34; + log_group # メッセージ本文整形 fix_msg = \u0026#34;以下のアラートが発生しました\u0026#34; + \u0026#34;\\n\u0026#34; log_group_msg = \u0026#34;ロググループ名:\u0026#34; + \u0026#34;\\n\u0026#34; + log_group log_stm_msg = \u0026#34;ログストリーム名:\u0026#34; + \u0026#34;\\n\u0026#34; + log_stm time_msg = \u0026#34;発生時刻:\u0026#34; + \u0026#34;\\n\u0026#34; + str(datetime_jst) log_msg = \u0026#34;メッセージ:\u0026#34; + \u0026#34;\\n\u0026#34; + log_json[\u0026#39;message\u0026#39;] msg = fix_msg + \u0026#34;\\n\\n\u0026#34; + log_group_msg + \u0026#34;\\n\\n\u0026#34; + log_stm_msg + \u0026#34;\\n\\n\u0026#34; + time_msg + \u0026#34;\\n\\n\u0026#34; + log_msg try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = msg, Subject = subject_str ) except Exception as e: print(e) 参考\n【AWS】CloudWatch Logsからシステムログをメール通知する。\n 改良後のコードでは本文整形の他、メール件名を環境変数決め打ちからコード内でeventの情報から取得、に変更している。ログ種別は多義に渡るしログ監視以外のメール送信もあるから、動的に対応できる方が望ましいということで。本文冒頭に決め打ちメッセージ追加と変数名を変えたくらいで基本は参考元とほぼ同じ。タイムスタンプ変換まで書いてもらって非常にありがたい。\n 最終的に、送信されたメールはこんな感じ。\n 参考サイトさんのおかげですんなりできて助かった。（2度目）ちなみに、当初自力で応用しようとしてハマってた。Logs(サブスクリプションフィルタ)からLambdaに渡されるデータ構造が不明だったからだ。しかし以下公式にちゃんとサンプルと説明があったということを、最後に知った。\nCloudWatch Logs サブスクリプションフィルターの使用\n 以下、データサンプルの抜粋\n{ \u0026#34;owner\u0026#34;: \u0026#34;111111111111\u0026#34;, \u0026#34;logGroup\u0026#34;: \u0026#34;CloudTrail\u0026#34;, \u0026#34;logStream\u0026#34;: \u0026#34;111111111111_CloudTrail_us-east-1\u0026#34;, \u0026#34;subscriptionFilters\u0026#34;: [ \u0026#34;Destination\u0026#34; ], \u0026#34;messageType\u0026#34;: \u0026#34;DATA_MESSAGE\u0026#34;, \u0026#34;logEvents\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;31953106606966983378809025079804211143289615424298221568\u0026#34;, \u0026#34;timestamp\u0026#34;: 1432826855000, \u0026#34;message\u0026#34;: \u0026#34;{\\\u0026#34;eventVersion\\\u0026#34;:\\\u0026#34;1.03\\\u0026#34;,\\\u0026#34;userIdentity\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;Root\\\u0026#34;}\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;31953106606966983378809025079804211143289615424298221569\u0026#34;, \u0026#34;timestamp\u0026#34;: 1432826855000, \u0026#34;message\u0026#34;: \u0026#34;{\\\u0026#34;eventVersion\\\u0026#34;:\\\u0026#34;1.03\\\u0026#34;,\\\u0026#34;userIdentity\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;Root\\\u0026#34;}\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;31953106606966983378809025079804211143289615424298221570\u0026#34;, \u0026#34;timestamp\u0026#34;: 1432826855000, \u0026#34;message\u0026#34;: \u0026#34;{\\\u0026#34;eventVersion\\\u0026#34;:\\\u0026#34;1.03\\\u0026#34;,\\\u0026#34;userIdentity\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;Root\\\u0026#34;}\u0026#34; } ] }  そして上記ページにたどり着いたのは以下記事のコメントによる。\ncloudwatchlogs -\u0026gt; lambda -\u0026gt; SNSを試してみた\n 先に記載したコードはこのコメントで言及されている「複数イベントへの対処」が行われているバージョンとなる。改めて、先駆者の方々のおかげで非常に助かった。（3度目）\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatchlogs-send-filter-mail-2/","summary":"表題の件、以下の過去記事に書いたが、この時点では送信される本文ががログメッセージだけとなっていて、通知メールとしては不十分なため本文もカスタマイズしてみた。\nCloudWatchLogsのログ監視 - サブスクリプションフィルタ + Lambdaでメール送信\n 各種設定は冒頭の過去記事と同様のため割愛するとして、コードは変更前・後両方載せておく。\n変更前：lambda_function.py(1)\nimport base64 import json import zlib import datetime import os import boto3 from botocore.exceptions import ClientError print(\u0026#39;Loading function\u0026#39;) def lambda_handler(event, context): data = zlib.decompress(base64.b64decode(event[\u0026#39;awslogs\u0026#39;][\u0026#39;data\u0026#39;]), 16+zlib.MAX_WBITS) data_json = json.loads(data) log_entire_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;], ensure_ascii=False)) log_entire_len = len(log_entire_json) print(log_entire_json) for i in range(log_entire_len): log_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;][i], ensure_ascii=False)) try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = log_json[\u0026#39;message\u0026#39;], Subject = os.","title":"CloudWatchLogsのログ監視 - サブスクリプションフィルタ + Lambdaでメール送信(2)"},{"content":"elaborate   複雑な、入り組んだ 精巧な、精密な 入念な、苦心の末の  他動詞としては「〜を詳しく調べる」\n Irvine Welshの\u0026quot;Trainspotting\u0026quot;読書中に登場した単語だと思うが、何ページかはもう覚えていない。\n  ","permalink":"https://ecnedaced-seirots.github.io/post/a/english-elaborate/","summary":"elaborate   複雑な、入り組んだ 精巧な、精密な 入念な、苦心の末の  他動詞としては「〜を詳しく調べる」\n Irvine Welshの\u0026quot;Trainspotting\u0026quot;読書中に登場した単語だと思うが、何ページかはもう覚えていない。\n  ","title":"英語メモ - elaborate"},{"content":"AWSで過去普通にやってた監視実装も、2,3年経つと（或いはそれより短い周期で）陳腐化する。以前は限られたサービスのリソース範囲でやれることをやっていればよかったが、今はSSM(Systems Manager)、Lambda、EventBridgeなどの「登場人物」が増えて、カスタマイズが可能になったからだ。やれることが増えた分、実装が複雑になる。その分チャレンジングな分野になって楽しめると言えないこともないが\u0026hellip;、時間が足りないんだ。頭痛ぇな、まったく。絡み合った糸をほぐすためにまとめてみる。\n監視の種別としては大枠としてノード監視、閾値監視、ログ監視、プロセス監視、イベント監視と想定する。それぞれの実装方式が若干異なってくるため整理したい。\n  監視方式大枠  ノード監視\nCloudWatchアラーム(ステータスチェック) ー＞ (EventBridgeルール) ー＞ Lambda ー＞ SNSトピック ー＞ メール送信  ※ハード障害等でインスタンスが落ちた時に発動される想定。手動で落とした時は発動しないので通知は来ない。\n閾値監視\nCloudWatchアラーム（閾値チェック） ー＞ (EventBridgeルール) ー＞ Lambda ー＞ SNSトピック ー＞ メール送信  ※EC2インスタンスのCPU使用率、ディスク使用率を想定。メモリ監視は別途カスタムメトリクスの実装がいる。\nログ監視\nCloudWatchLogsでログ出力（サブスクリプションフィルタキーワード検知）ー＞ Lambda ー＞ SNSトピック ー＞ メール送信  ※これだけEventBridgeを使用しない。\nプロセス監視\nEC2インスタンス上のプロセス数監視に相当する。検索すると「プロセス落ちていたらインスタンス再起動」アクションの事例が多いが、今回やりたいのはメール通知だけ。一応メモっておくけど。  CWエージェント + SSM + インスタンス停止、Lamabdaなし\nEC2上のプロセスを監視し自動復旧する\nCWエージェント + SSM + 自動再起動、Lamabdaなし\nAWSでプロセス監視を実装したい\nCWエージェント + Lamabda + SSM + 自動再起動\nEC2のプロセス監視と自動再起動\n procstat事例\n以下はSSMを使用せず、procstatプラグインを使用してプロセス監視する例。記事には監視設定以降の通知イベント事例はなし。\nCloudWatch Agent でProcstatプラグインの利用が可能になりました\nSSMを使わずCloudwatchでEC2上のプロセス監視をしてみる\n 以下は途中まで参照したところ（後半は有料サービスの案内）、アラームを作成するところまでわかりやすかった。であれば、閾値監視と同様にEBルールを挟んでLambdaをターゲットに指定 ー＞ SNSトピックに渡されてメール送信、でいけるはず。\nCloudWatchでプロセス監視する手順をLinuxとWindowsともに詳しく紹介\nイベント監視\nイベント発生 ー＞ (EventBridgeルール) ー＞ Lambda ー＞ SNSトピック ー＞ メール送信  ※1. 2. のアラームがイベントに置き換わるだけで、後続のフローは同様となる想定。\n  上記の中で、私的には4.のプロセス監視が一番面倒な気がする。プロセス監視の詳細は保留として、全体の登場人物を整理しておこう。\n 登場人物整理 整理したらこうなった。方式をどうするかによって変わる部分もあるが、今のところこの想定。すべての監視でLambdaを使うのは、メール件名や本文をカスタマイズしたいため。\n    ノード監視 閾値監視 ログ監視 プロセス監視 イベント監視     CloudWatchAlarm ● ● - ● -   CloudWatchLogs - - ● - -   SSM(Systems Manager) - - - ● -   EventBridge rule ● ● - ● ●   Lambda ● ● ● ● ●   SNS topic ● ● ● ● ●     次のステップとして、これらの各アイテムにおいて「共通化できるもの / 個別に作成するもの」に分類する必要がある。\n  その他メモ  メール件名のカスタマイズ\nメール件名のカスタマイズをLambdaの環境変数でやるかコード本体でやるか。\nイベントの中身を拾って詳細に設定するならLambdaコード内でやるしかないが、そんな体力はない。そもそもイベントの中身が元ネタによって異なるからメッセージ内容別に大幅な差分が発生するはず。やれなくもないがそんな体力は(ry)。となると、カッコ悪いかもしれないがほぼ決め打ちの値で環境変数にセット、でいく方がいい。   メッセージ本文のカスタマイズ\n① Lambdaコード内で実装\n② EventBridgeルールの入力トランスフォーマーで実装  ②を試したが期待値ならず。深追いしている時間はない。どっちにしろログ監視では本文をLambdaに渡しているからそっちに寄せる方がいい。ここでやってるマッピングがLambdaコードにも適用できるか検討しようと思ったが、スキーマレジストリとかよくわからん。\n aws configの通知をどうするか\nconfigのログはS3にしか飛ばせない。ログ監視ではなく、イベント監視でやる。検知を制御したい時はイベント検知無効化で対応とか。   Amazon CloudWatch Events を使用すると、AWS Config イベントのステータスで変更を検出し対応することができます。\n AWS Config でのログ記録とモニタリング\n Configの変更はCloudTrailにつながるから、下手すると監視が重複するかもしれない。が、考えてる時間が(ry) 以下はCloudTrailの設定で直接SNSを指定しているっぽいが、これもEventBridgeに渡す、に統一させた方がよさげ。\n CloudTrail が、新しいログファイルを Amazon S3 バケットに発行するときに通知を受け取ることができます。\n CloudTrail の Amazon SNS 通知の設定\n 以下は通知事例の記載はないが一応メモ\nAWSリソースの設定変更履歴を管理する「AWS Config」とは？実際に使用してみた\n  果てしない旅路。\n （追記）\nSSM(Systems Manager)は使わずにprocstatプラグインだけでもなんとかなりそう。SSMを使えばもっと楽になるらしいが、よくわかっていない。ちゃんと調べればいいんだが、時間がないんだ\u0026hellip;\n","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatch-monitoring-idea/","summary":"AWSで過去普通にやってた監視実装も、2,3年経つと（或いはそれより短い周期で）陳腐化する。以前は限られたサービスのリソース範囲でやれることをやっていればよかったが、今はSSM(Systems Manager)、Lambda、EventBridgeなどの「登場人物」が増えて、カスタマイズが可能になったからだ。やれることが増えた分、実装が複雑になる。その分チャレンジングな分野になって楽しめると言えないこともないが\u0026hellip;、時間が足りないんだ。頭痛ぇな、まったく。絡み合った糸をほぐすためにまとめてみる。\n監視の種別としては大枠としてノード監視、閾値監視、ログ監視、プロセス監視、イベント監視と想定する。それぞれの実装方式が若干異なってくるため整理したい。\n  監視方式大枠  ノード監視\nCloudWatchアラーム(ステータスチェック) ー＞ (EventBridgeルール) ー＞ Lambda ー＞ SNSトピック ー＞ メール送信  ※ハード障害等でインスタンスが落ちた時に発動される想定。手動で落とした時は発動しないので通知は来ない。\n閾値監視\nCloudWatchアラーム（閾値チェック） ー＞ (EventBridgeルール) ー＞ Lambda ー＞ SNSトピック ー＞ メール送信  ※EC2インスタンスのCPU使用率、ディスク使用率を想定。メモリ監視は別途カスタムメトリクスの実装がいる。\nログ監視\nCloudWatchLogsでログ出力（サブスクリプションフィルタキーワード検知）ー＞ Lambda ー＞ SNSトピック ー＞ メール送信  ※これだけEventBridgeを使用しない。\nプロセス監視\nEC2インスタンス上のプロセス数監視に相当する。検索すると「プロセス落ちていたらインスタンス再起動」アクションの事例が多いが、今回やりたいのはメール通知だけ。一応メモっておくけど。  CWエージェント + SSM + インスタンス停止、Lamabdaなし\nEC2上のプロセスを監視し自動復旧する\nCWエージェント + SSM + 自動再起動、Lamabdaなし\nAWSでプロセス監視を実装したい\nCWエージェント + Lamabda + SSM + 自動再起動\nEC2のプロセス監視と自動再起動\n procstat事例\n以下はSSMを使用せず、procstatプラグインを使用してプロセス監視する例。記事には監視設定以降の通知イベント事例はなし。\nCloudWatch Agent でProcstatプラグインの利用が可能になりました\nSSMを使わずCloudwatchでEC2上のプロセス監視をしてみる","title":"AWS監視の方式を整理したい"},{"content":"タウリンの効果。過去に見つけたネタをバラバラにメモっていたのをまとめておく。\n タウリンとは、一言で言うと。\nタウリンは分子量124の含硫アミノ酸。タンパク質の構成成分にはならないが、細胞内の遊離アミノ酸としてはグルタミンと並んでもっとも高濃度に存在し、かつグルタミンに類似する成分。またタウリンは脳内のアミノ酸の中では2番目に多く存在する。\nタウリンは疲れが溜まっていると多く消費される、年齢を重ねると減少、男性より女性が不足しがち、とも言われている。\nタウリンの効果としてはアセトアルデヒトの代謝促進による肝機能サポートがよく知られているが、記憶力や認知能力の改善、目の網膜の保護、便通の改善等、意外な効能もある様子。\nそんなタウリンの効果について、とりあえず箇条書きで。\n  神経伝達、海馬の増強や安定化をサポート。 記憶力に関与するグリア細胞の活性化を促進する。(注1) アルコールや有害物質から発生するアセトアルデヒトの代謝を促進する。 心筋を強くして疲労回復を促す。（ただし即効性はないらしい？） 心臓のポンプ作用を高めて筋肉により多くの血液を送り込み、持久力を高める。（ドイツの研究より） 細胞のミトコンドリアの数を増やす（ミトコンドリアのタンパク質合成に必須）(注2) 目の網膜や角膜を保護する。 腸管の抗炎症作用 血圧や血糖値のバランスをサポート。 肝臓・心臓の機能強化 胆汁を生成し、コレステロールや中性脂肪の代謝をコントロール インスリン分泌促進 便の水分を増やし、便秘を改善する。 ニューロンのカリウム除去をサポートし、ニューロンが過度に活発化することを防ぐ。 タウリンはレシチンと併用することで細胞の細胞膜を丈夫にし、細胞が正常な形状を保つようにサポートをする。 髪の毛の成長にも不可欠なタンパク質IGF-1(インスリン様成長因子)を増やす   (注1) 記憶を司ると言われる海馬にはグリア細胞が多く存在する。\nまた以下のように認知機能の改善を示す研究がある。\n 迷路試験（Y-maze test）と受動的回避試験（passive avoidance test）で、タウリンを摂取したマウスの認知機能が正常な状態に回復することが確認された。さらに、アルツハイマー病の症状である大脳皮質の炎症が抑えられたほか、脳の海馬から分泌されるアミロイドベータの量も減り、記憶力に深く関与するグリア細胞の活性化が促進されることが確認された。\n注目すべき特徴は、タウリンの脳機能改善効果がアルツハイマー病において選択的に表れるということだ。従来の治療薬物が正常のマウスでは脳機能の異常を来たしたのに対し、タウリンは正常のマウスで脳機能の異常を来たすことはなかった。タウリンの持つもう一つの特性は、タウリンが脳の血管壁を透過しやすいため、口から摂取しても脳にうまく吸収されることだ。別途の複雑な投与過程を経る必要がなく、飲料水などの食物からタウリンを摂っても効果が高い。\n タウリンがアルツハイマー病治療に有効だと判明\n(注2) 「ただしタウリンが細胞内のエネルギー生産組織であるミトコンドリアの数を増やすのは、タウリン サプリを継続的に数か月～半年ほど摂取した場合に限られます。」（参照リンクは消滅）\n タウリンを多く含む食材\n 貝・甲殻類（サザエ、牡蠣、帆立、蛤、あさり、しじみ、タコ、イカ、カニ等） ブリやカツオの血合い 鯵や鯖などの近海魚  タウリンを多く含む食材としてはタコ・イカのイメージが強かったのだが、ダントツで多いのは牡蠣だった。100g中1180mg。サザエの方が100g1500mgで含有量としては多いが、摂取量・摂取回数は一般的に考えて少ない。\n余談だが牡蠣は亜鉛も多く含んでいて、その亜鉛はグルタミン酸興奮毒性（神経細胞死の一因）から脳を守る機能を果たす。また、記憶を司る海馬には最高濃度の亜鉛が存在する。脳の海馬をサポートするタウリンと亜鉛を両方含む牡蠣は、最強ブレインフードだった！\nタウリンを多く含む食品一覧 ポイントは魚介類と血合肉\n タウリン摂取時の注意\n 食間・空腹時の摂取が有効。 アスピリンと併用しないこと。（薬理作用を増強させてしまうため余計な負担がかかる。バファリンは原材料としてアスピリンを含む）   \u0026hellip;と、万能選手的なタウリンではあるが、日本国内ではタウリン単体のサプリメントは販売されていない。このためタウリンのサプリはiHerbで時々購入しているが、在庫切れのことが多く割と入手困難ではある。日本の薬事法に規制があって、一回で購入可能な量・個数が制限されているから、まとめ買いもできないのだ。（おそらく鷲のマークの製薬会社の圧力）\niHerb独自ブランドのタウリンサプリが安価で嬉しいけど、数ヶ月前から在庫切れ状態が続いている。しょうがないから、今日別の高いやつをポチってしまった。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/healthcare-taurine/","summary":"タウリンの効果。過去に見つけたネタをバラバラにメモっていたのをまとめておく。\n タウリンとは、一言で言うと。\nタウリンは分子量124の含硫アミノ酸。タンパク質の構成成分にはならないが、細胞内の遊離アミノ酸としてはグルタミンと並んでもっとも高濃度に存在し、かつグルタミンに類似する成分。またタウリンは脳内のアミノ酸の中では2番目に多く存在する。\nタウリンは疲れが溜まっていると多く消費される、年齢を重ねると減少、男性より女性が不足しがち、とも言われている。\nタウリンの効果としてはアセトアルデヒトの代謝促進による肝機能サポートがよく知られているが、記憶力や認知能力の改善、目の網膜の保護、便通の改善等、意外な効能もある様子。\nそんなタウリンの効果について、とりあえず箇条書きで。\n  神経伝達、海馬の増強や安定化をサポート。 記憶力に関与するグリア細胞の活性化を促進する。(注1) アルコールや有害物質から発生するアセトアルデヒトの代謝を促進する。 心筋を強くして疲労回復を促す。（ただし即効性はないらしい？） 心臓のポンプ作用を高めて筋肉により多くの血液を送り込み、持久力を高める。（ドイツの研究より） 細胞のミトコンドリアの数を増やす（ミトコンドリアのタンパク質合成に必須）(注2) 目の網膜や角膜を保護する。 腸管の抗炎症作用 血圧や血糖値のバランスをサポート。 肝臓・心臓の機能強化 胆汁を生成し、コレステロールや中性脂肪の代謝をコントロール インスリン分泌促進 便の水分を増やし、便秘を改善する。 ニューロンのカリウム除去をサポートし、ニューロンが過度に活発化することを防ぐ。 タウリンはレシチンと併用することで細胞の細胞膜を丈夫にし、細胞が正常な形状を保つようにサポートをする。 髪の毛の成長にも不可欠なタンパク質IGF-1(インスリン様成長因子)を増やす   (注1) 記憶を司ると言われる海馬にはグリア細胞が多く存在する。\nまた以下のように認知機能の改善を示す研究がある。\n 迷路試験（Y-maze test）と受動的回避試験（passive avoidance test）で、タウリンを摂取したマウスの認知機能が正常な状態に回復することが確認された。さらに、アルツハイマー病の症状である大脳皮質の炎症が抑えられたほか、脳の海馬から分泌されるアミロイドベータの量も減り、記憶力に深く関与するグリア細胞の活性化が促進されることが確認された。\n注目すべき特徴は、タウリンの脳機能改善効果がアルツハイマー病において選択的に表れるということだ。従来の治療薬物が正常のマウスでは脳機能の異常を来たしたのに対し、タウリンは正常のマウスで脳機能の異常を来たすことはなかった。タウリンの持つもう一つの特性は、タウリンが脳の血管壁を透過しやすいため、口から摂取しても脳にうまく吸収されることだ。別途の複雑な投与過程を経る必要がなく、飲料水などの食物からタウリンを摂っても効果が高い。\n タウリンがアルツハイマー病治療に有効だと判明\n(注2) 「ただしタウリンが細胞内のエネルギー生産組織であるミトコンドリアの数を増やすのは、タウリン サプリを継続的に数か月～半年ほど摂取した場合に限られます。」（参照リンクは消滅）\n タウリンを多く含む食材\n 貝・甲殻類（サザエ、牡蠣、帆立、蛤、あさり、しじみ、タコ、イカ、カニ等） ブリやカツオの血合い 鯵や鯖などの近海魚  タウリンを多く含む食材としてはタコ・イカのイメージが強かったのだが、ダントツで多いのは牡蠣だった。100g中1180mg。サザエの方が100g1500mgで含有量としては多いが、摂取量・摂取回数は一般的に考えて少ない。\n余談だが牡蠣は亜鉛も多く含んでいて、その亜鉛はグルタミン酸興奮毒性（神経細胞死の一因）から脳を守る機能を果たす。また、記憶を司る海馬には最高濃度の亜鉛が存在する。脳の海馬をサポートするタウリンと亜鉛を両方含む牡蠣は、最強ブレインフードだった！\nタウリンを多く含む食品一覧 ポイントは魚介類と血合肉\n タウリン摂取時の注意\n 食間・空腹時の摂取が有効。 アスピリンと併用しないこと。（薬理作用を増強させてしまうため余計な負担がかかる。バファリンは原材料としてアスピリンを含む）   \u0026hellip;と、万能選手的なタウリンではあるが、日本国内ではタウリン単体のサプリメントは販売されていない。このためタウリンのサプリはiHerbで時々購入しているが、在庫切れのことが多く割と入手困難ではある。日本の薬事法に規制があって、一回で購入可能な量・個数が制限されているから、まとめ買いもできないのだ。（おそらく鷲のマークの製薬会社の圧力）\niHerb独自ブランドのタウリンサプリが安価で嬉しいけど、数ヶ月前から在庫切れ状態が続いている。しょうがないから、今日別の高いやつをポチってしまった。","title":"タウリン(taurine)の効能いろいろ"},{"content":"CloudWatchアラーム + SNSトピックでメール飛ばす時の件名を変更したい。ということで、過去記事 AWS EventBridge + SNSからのメール件名をカスタマイズする でイベントからのメール通知でやったことを、アラームに変えてやってみた。アラームのトリガーはEC2インスタンスCPU使用率閾値超えとする。\n ベースの参照は以下クラメソさんネタ。ただしこちらは本文のカスタマイズであり、件名は変えていない。またLambdaも使用していない。これに先の過去記事パターンを合体させてやってみた。\nCloudWatch アラームの通知メールを少しでも読みやすくしたい\n 処理概要  CloudWatchアラームのステータスがALARMに変わる。 Lambda関数起動 SNSに連携される メール通知   作業概要  SNSトピック作成〜サブスクライブ CloudWatchアラーム作成 Lambda関数作成（Lambda用IAMロールは既存流用） EventBridgeルール作成 EventBridgeルールのターゲットに3.のLambda関数を設定する 対象EC2インスタンスのCPU負荷を上げてアラームステータスにする メール通知確認   検証に使用したアイテム    アイテム 名称     SNSトピック alarm-notification-topic   CloudWatchアラーム CPU_Utilization_Test   Lambda関数 cw-alarm-sns-function   EventBridgeルール cw-alarm-rule    やったこと SNSトピック作成、Lambda関数作成は冒頭のリンク過去記事でもやったので省略。Lambda関数の環境変数でSNSトピック、メール件名を指定している。一応後半にスクショあり。\nCLIよりCloudWatchアラーム作成。少ない負荷でもアラームステータスになるように閾値は10%にしてある。\n$ aws cloudwatch put-metric-alarm --alarm-name \u0026quot;CPU_Utilization_Test\u0026quot; \\ --metric-name \u0026quot;CPUUtilization\u0026quot; \\ --namespace \u0026quot;AWS/EC2\u0026quot; \\ --statistic \u0026quot;Maximum\u0026quot; \\ --period 60 \\ --evaluation-periods 1 \\ --datapoints-to-alarm 1 \\ --threshold 10 \\ --comparison-operator \u0026quot;GreaterThanThreshold\u0026quot; \\ --dimensions \u0026quot;Name=InstanceId,Value=i-0xxxxxxxxxxx9\u0026quot;  EventBridgeルールの作成。以下の場合、\u0026ldquo;CPU_Utilization_\u0026ldquo;を含むアラームと関連付けられる\n$ AWSREGION=ap-northeast-1 $ AWSACCOUNT=my-account-id $ aws events put-rule --name \u0026quot;cw-alarm-rule\u0026quot; \\ --event-pattern \u0026quot;{\\\u0026quot;source\\\u0026quot;: [\\\u0026quot;aws.cloudwatch\\\u0026quot;],\\\u0026quot;detail-type\\\u0026quot;: [\\\u0026quot;CloudWatch Alarm State Change\\\u0026quot;],\\\u0026quot;resources\\\u0026quot;: [{\\\u0026quot;prefix\\\u0026quot;: \\\u0026quot;arn:aws:cloudwatch:${AWSREGION}:${AWSACCOUNT}:alarm:CPU_Utilization_\\\u0026quot;}],\\\u0026quot;detail\\\u0026quot;: {\\\u0026quot;state\\\u0026quot;: {\\\u0026quot;value\\\u0026quot;: [\\\u0026quot;ALARM\\\u0026quot;]}}}\u0026quot;  以下の様にルールが作成された。\n { \u0026quot;source\u0026quot;: [\u0026quot;aws.cloudwatch\u0026quot;], \u0026quot;detail-type\u0026quot;: [\u0026quot;CloudWatch Alarm State Change\u0026quot;], \u0026quot;resources\u0026quot;: [{ \u0026quot;prefix\u0026quot;: \u0026quot;arn:aws:cloudwatch:ap-northeast-1:0123456789102:alarm:CPU_Utilization_\u0026quot; }], \u0026quot;detail\u0026quot;: { \u0026quot;state\u0026quot;: { \u0026quot;value\u0026quot;: [\u0026quot;ALARM\u0026quot;] } } }  しかしこの段階ではまだターゲットが存在しない。前回はコマンドでターゲット指定したが、今回はマネコンからやった。対象のルールを選択して「Edit」ー＞ 「Select targets」で作成済みのLambda関数を指定して、「Update」\n すると、以下の様にLambda側のトリガーとして、セットしたルールが設定される。\n ここまでやったら、以下の流れでメール通知される、はず。\n① EC2インスタンスのCPU使用率を上げてアラーム発行させる ② EventBridgeルールでターゲットに指定したLambdaに渡される ③ Lambdaで設定したSNSに渡される\nちなみにCPU使用率UP時はこんなのをshellにしてバックグラウンドで複数実行させた。アラームの設定で閾値10%にしたが、これをt3.microマシン上で3回くらい同時に回せば軽く90%くらいになる。\nCNT=0; while [ $CNT -lt 100000 ]; do CNT=$(( CNT + 1 ));done\n 少し経つとアラームのステータスが変わって、カスタム件名のメールが届いた！しかし本文がひどい\u0026hellip;\n サンプルコードではMessage=json.dumps(event) としているから、JSONデータをそのまま吐き出しているだけ。本文をカスタマイズする場合はこのeventをいじる必要がある。冒頭のクラメソさんの事例もはっきりいって面倒くさそうだったが、コードでやるのも面倒だなぁ、何せサンデープログラマだから。\neventに相当するJSONデータ\n{\u0026#34;version\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;86fa8a3f-7470-8c16-ef56-aaba9821771e\u0026#34;, \u0026#34;detail-type\u0026#34;: \u0026#34;CloudWatch Alarm State Change\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;aws.cloudwatch\u0026#34;, \u0026#34;account\u0026#34;: \u0026#34;123456789101\u0026#34;, \u0026#34;time\u0026#34;: \u0026#34;2021-11-03T10:17:51Z\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-northeast-1\u0026#34;, \u0026#34;resources\u0026#34;: [\u0026#34;arn:aws:cloudwatch:ap-northeast-1:123456789101:alarm:CPU_Utilization_Test\u0026#34;], \u0026#34;detail\u0026#34;: {\u0026#34;alarmName\u0026#34;: \u0026#34;CPU_Utilization_Test\u0026#34;, \u0026#34;state\u0026#34;: {\u0026#34;value\u0026#34;: \u0026#34;ALARM\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;Threshold Crossed: 1 out of the last 1 datapoints [100.0 (03/11/21 10:11:00)] was greater than the threshold (10.0) (minimum 1 datapoint for OK -\u0026gt; ALARM transition).\u0026#34;, \u0026#34;reasonData\u0026#34;: \u0026#34;{\\\u0026#34;version\\\u0026#34;:\\\u0026#34;1.0\\\u0026#34;,\\\u0026#34;queryDate\\\u0026#34;:\\\u0026#34;2021-11-03T10:17:51.018+0000\\\u0026#34;,\\\u0026#34;startDate\\\u0026#34;:\\\u0026#34;2021-11-03T10:11:00.000+0000\\\u0026#34;,\\\u0026#34;statistic\\\u0026#34;:\\\u0026#34;Maximum\\\u0026#34;,\\\u0026#34;period\\\u0026#34;:60,\\\u0026#34;recentDatapoints\\\u0026#34;:[100.0],\\\u0026#34;threshold\\\u0026#34;:10.0,\\\u0026#34;evaluatedDatapoints\\\u0026#34;:[{\\\u0026#34;timestamp\\\u0026#34;:\\\u0026#34;2021-11-03T10:11:00.000+0000\\\u0026#34;,\\\u0026#34;sampleCount\\\u0026#34;:5.0,\\\u0026#34;value\\\u0026#34;:100.0}]}\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2021-11-03T10:17:51.020+0000\u0026#34;}, \u0026#34;previousState\u0026#34;: {\u0026#34;value\u0026#34;: \u0026#34;INSUFFICIENT_DATA\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;Insufficient Data: 1 datapoint was unknown.\u0026#34;, \u0026#34;reasonData\u0026#34;: \u0026#34;{\\\u0026#34;version\\\u0026#34;:\\\u0026#34;1.0\\\u0026#34;,\\\u0026#34;queryDate\\\u0026#34;:\\\u0026#34;2021-11-03T10:13:51.019+0000\\\u0026#34;,\\\u0026#34;statistic\\\u0026#34;:\\\u0026#34;Maximum\\\u0026#34;,\\\u0026#34;period\\\u0026#34;:60,\\\u0026#34;recentDatapoints\\\u0026#34;:[],\\\u0026#34;threshold\\\u0026#34;:10.0,\\\u0026#34;evaluatedDatapoints\\\u0026#34;:[{\\\u0026#34;timestamp\\\u0026#34;:\\\u0026#34;2021-11-03T10:13:00.000+0000\\\u0026#34;}]}\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2021-11-03T10:13:51.023+0000\u0026#34;}, \u0026#34;configuration\u0026#34;: {\u0026#34;metrics\u0026#34;: [{\u0026#34;id\u0026#34;: \u0026#34;4cbe7286-d70f-fcb9-4a0a-758612d568db\u0026#34;, \u0026#34;metricStat\u0026#34;: {\u0026#34;metric\u0026#34;: {\u0026#34;namespace\u0026#34;: \u0026#34;AWS/EC2\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;CPUUtilization\u0026#34;, \u0026#34;dimensions\u0026#34;: {\u0026#34;InstanceId\u0026#34;: \u0026#34;i-0b22a89b0bb3faf49\u0026#34;}}, \u0026#34;period\u0026#34;: 60, \u0026#34;stat\u0026#34;: \u0026#34;Maximum\u0026#34;}, \u0026#34;returnData\u0026#34;: true}]}}}  と、ここで別途最近実施した、特別カスタマイズをしないアラーム + SNS送信検証時のメールを見たら、英語のみとはいえこっちの方がまだ全然見やすい。そりゃわかりにくいけど、JSON生データよりマシ。もう本文はこれでいいんじゃね？という気もするんだが。件名も、アラーム名が件名に入るんだから識別・フィルタしやすいアラーム名にすればどうにかなりそうな気もする。\u0026hellip;と、減速気味になってきた。\n \u0026hellip;が！以下の補足事項を思い出した。アラーム単体では無効化・有効化の制御ができない。となると、やはりEventBridgに組み込む方がいいんだよな。うーむ\u0026hellip;。頭痛いから明日考えよう。明後日かもしれない。\n 補足 アラームを一時無効化したい場合は、Rule側で制御する。マネコンで対象のルールを選択して、「Distable/無効にする」ボタンを押下。（アラーム単体ではこの機能がない）\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatch-alarm-lambda/","summary":"CloudWatchアラーム + SNSトピックでメール飛ばす時の件名を変更したい。ということで、過去記事 AWS EventBridge + SNSからのメール件名をカスタマイズする でイベントからのメール通知でやったことを、アラームに変えてやってみた。アラームのトリガーはEC2インスタンスCPU使用率閾値超えとする。\n ベースの参照は以下クラメソさんネタ。ただしこちらは本文のカスタマイズであり、件名は変えていない。またLambdaも使用していない。これに先の過去記事パターンを合体させてやってみた。\nCloudWatch アラームの通知メールを少しでも読みやすくしたい\n 処理概要  CloudWatchアラームのステータスがALARMに変わる。 Lambda関数起動 SNSに連携される メール通知   作業概要  SNSトピック作成〜サブスクライブ CloudWatchアラーム作成 Lambda関数作成（Lambda用IAMロールは既存流用） EventBridgeルール作成 EventBridgeルールのターゲットに3.のLambda関数を設定する 対象EC2インスタンスのCPU負荷を上げてアラームステータスにする メール通知確認   検証に使用したアイテム    アイテム 名称     SNSトピック alarm-notification-topic   CloudWatchアラーム CPU_Utilization_Test   Lambda関数 cw-alarm-sns-function   EventBridgeルール cw-alarm-rule    やったこと SNSトピック作成、Lambda関数作成は冒頭のリンク過去記事でもやったので省略。Lambda関数の環境変数でSNSトピック、メール件名を指定している。一応後半にスクショあり。\nCLIよりCloudWatchアラーム作成。少ない負荷でもアラームステータスになるように閾値は10%にしてある。\n$ aws cloudwatch put-metric-alarm --alarm-name \u0026quot;CPU_Utilization_Test\u0026quot; \\ --metric-name \u0026quot;CPUUtilization\u0026quot; \\ --namespace \u0026quot;AWS/EC2\u0026quot; \\ --statistic \u0026quot;Maximum\u0026quot; \\ --period 60 \\ --evaluation-periods 1 \\ --datapoints-to-alarm 1 \\ --threshold 10 \\ --comparison-operator \u0026quot;GreaterThanThreshold\u0026quot; \\ --dimensions \u0026quot;Name=InstanceId,Value=i-0xxxxxxxxxxx9\u0026quot;  EventBridgeルールの作成。以下の場合、\u0026ldquo;CPU_Utilization_\u0026ldquo;を含むアラームと関連付けられる","title":"CloudWatchアラーム + SNSからのメール件名をカスタマイズする"},{"content":"職場とか、いろんなチーム・グループの中で、「この人がいてくれると安心」「いてくれるだけでいい」と思える人が稀にいる。本当に、稀に、だが。そういう人と、その他の人々の違いは一体何なのか、とモヤっと不思議に思っていた。若干解明できそうなのが、以下の記事。ここに書かれている要因だけではないと思うが、理由の一部としては納得できる。\n「いるだけでチームの雰囲気をよくする人」の口癖4つ。“ど” から始まるあの言葉がかなり使える\n （以降軽くNSFW画像あり。閲覧注意）\n 記事では「いるだけでチームの雰囲気をよくする人」の4つの要素を述べている。\n 「ちょうどよかった」悪い状況にある時でもポジティブに捉える 「ありがとう」を言う時に別途感謝の言葉を添える どの、どのように、どちらか、等「ど」ではじまる質問で相手の話を引き出す 「教えてください」で相手へのリスペクトの気持ちを表す   上記のうち、1.と2.は他の自己啓発系コンテンツでもよく目にする話なので割愛する。まぁ「感謝の言葉を出し惜しみしない」、これは確かに大事だよ、俺も実践してる。相手によるけどね。\n3.は、俺はこれは実践する気ないけど、要するに聞き上手になって相手の気分をよくしてやれ、つうことだ。\n  ハーバード大学の研究論文（2012年）によると、自分の話をしているとき、おいしい食事をするときや収入を得るときと同じように脳の報酬系という部位が活性化したことが、 約300人の脳をfMRIでスキャンした結果からわかったのだそう。私たちが聞き上手な人に好感を抱くのは、「自分の話をするのが好き！」という人間の本能を満たしてくれるからなのかもしれません。\n  「上手に質問をすれば共感力が上がり、相手に好感を抱かせることができる」につながる、と。俺は「聞き上手ボランティア」をやる気はさらさらないが、興味深いのは先の引用にある「自分の話をするのが好き！という人間の本能」だ。よくいるよな、人の話は全然聞かないで、延々と自分のことを話したがるやつ。（ま、経験上女に多いという傾向は、ある）\n俺は今までそういうやつのことを、ただ自己愛が強くて、その自己愛を充足させるために他人に自分話を押売りして聞かせているもんだと思っていた。しかし上記引用で、「自分の話をしているときに脳の報酬系が活性化する」というのを読んで「そうか！」とひらめいた。脳の報酬系とはドーパミンのことである。ドーパミンは快楽を司る神経伝達物質だ。つまり自分のことを話すのは、人類共通の快感だったのだ！\nまぁ確かに、自分だってそういう面があるのは認めるよ。よく「話を聞いてもらってスッキリした」って言うもんな。何で話すだけでスッキリするのかって、ちゃんと理由があったんだな。しかしこれも度がすぎると聞かされる相手が迷惑だし、みっともないという自覚はある。自分のことを延々と話す人は、その制御が効かなくて、自らの快感原則に従って暴走しているんだろう。プラス自己愛もあるだろうけどね、どっちにしろこの手の人間とは遠い距離を置きたいものである。相手だけ満足して、自分はエネルギー吸い取られるだけだからな\u0026hellip;\n  話が大分脱線した、本来の主旨に戻る。うまい質問の仕方。「ど」で始まる疑問符がキーらしいが、具体的には記事の引用を俺なりにアレンジすると以下のようになる。（仕事関連の想定じゃないとピンと来ないもんで\u0026hellip;）\n   キーワード 質問例     What ー＞「どう、どんな」 どんな理由でこの仕事を始めたんですか？   Who ー＞「どの人、どんな人」 どんな人と仕事してみたいですか？   When ー＞「どんなとき、どのタイミング」 どんなときに達成感を感じますか？   Where ー＞「どこに、どこで」 どこでその分野を学んだのですか？   Why ー＞「どうして」 どうしてその製品に人気が集中するんでしょうね？   Which ー＞「どれ、どっち」 どちらのアイデアが気に入りましたか？   How ー＞「どうやって、どのように」 どのようにしてその課題を解決したんですか？     自己愛満々野郎の自分話を聞かされるのはゴメンだが、まともな相手とのコミュニケーション手法としては頭の片隅においておこう。\n   人はだれでも、自分に助言を求めてくる人の見識を高く評価する\n（We all admire the wisdom of people who come to us for advice.）\n ー 19世紀のイギリスの作家 アーサー・ヘルプスの言葉\n 最後の「教えてください」。これは相手を間接的に褒める手法だそうだ。ほぉぉ。\n  ブリガム・ヤング大学助教授で、組織の対人関係を研究するケイティ・リルエンクイスト氏らは、「助言を求められることは、基本的に嬉しいことだ」と言います。 なぜなら、助言を求める行為には、暗黙に「あなたの考えや価値観を支持している」というメッセージが含まれるから。 「教えてください」とアドバイスを求めることは、相手を立てることと同様の意味をもつのです。\n  これはわかる気がするな、同じ助言の依頼でも「教えてくれくれ」的に無作法または横暴に聞かれると不愉快でしかないが、リスペクトの気持ちを込めた依頼は、相手の気分をよくすることができる。\nそこには「あなたは私が知らない知見/情報を持っていると思う、あなたのその知恵を私に分けて貰えたら非常にうれしい」という、メタメッセージが込められているんだ。そういうメッセージを受け取って悪い気分になる人間は滅多にいない。\n  まぁ自分今もいろいろ思うことがあってこの記事を書いているわけだが\u0026hellip;.、まったく関係なく、ふと別の言葉を思い出した。\n村上龍の小説「5分後の世界」に登場するミズノ少尉は、「絶対に最悪の事態を想像するな」と言った。俺はミズノ少尉のような器ではない。けど、ミズノ少尉のような存在をリスペクトするし、こういう人物と一緒に仕事ができたら嬉しいし、（それこそ、いてくれるだけでいい）少なくとも自分もミズノ少尉に近づけるように努めたいとは思う。\n 何か主旨が散逸してしまい、「いてくれるだけでいい人」の理由は解明されていない気がする。まぁ理由は他にもいろいろあるよね、ということで。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/skill-in-communication/","summary":"職場とか、いろんなチーム・グループの中で、「この人がいてくれると安心」「いてくれるだけでいい」と思える人が稀にいる。本当に、稀に、だが。そういう人と、その他の人々の違いは一体何なのか、とモヤっと不思議に思っていた。若干解明できそうなのが、以下の記事。ここに書かれている要因だけではないと思うが、理由の一部としては納得できる。\n「いるだけでチームの雰囲気をよくする人」の口癖4つ。“ど” から始まるあの言葉がかなり使える\n （以降軽くNSFW画像あり。閲覧注意）\n 記事では「いるだけでチームの雰囲気をよくする人」の4つの要素を述べている。\n 「ちょうどよかった」悪い状況にある時でもポジティブに捉える 「ありがとう」を言う時に別途感謝の言葉を添える どの、どのように、どちらか、等「ど」ではじまる質問で相手の話を引き出す 「教えてください」で相手へのリスペクトの気持ちを表す   上記のうち、1.と2.は他の自己啓発系コンテンツでもよく目にする話なので割愛する。まぁ「感謝の言葉を出し惜しみしない」、これは確かに大事だよ、俺も実践してる。相手によるけどね。\n3.は、俺はこれは実践する気ないけど、要するに聞き上手になって相手の気分をよくしてやれ、つうことだ。\n  ハーバード大学の研究論文（2012年）によると、自分の話をしているとき、おいしい食事をするときや収入を得るときと同じように脳の報酬系という部位が活性化したことが、 約300人の脳をfMRIでスキャンした結果からわかったのだそう。私たちが聞き上手な人に好感を抱くのは、「自分の話をするのが好き！」という人間の本能を満たしてくれるからなのかもしれません。\n  「上手に質問をすれば共感力が上がり、相手に好感を抱かせることができる」につながる、と。俺は「聞き上手ボランティア」をやる気はさらさらないが、興味深いのは先の引用にある「自分の話をするのが好き！という人間の本能」だ。よくいるよな、人の話は全然聞かないで、延々と自分のことを話したがるやつ。（ま、経験上女に多いという傾向は、ある）\n俺は今までそういうやつのことを、ただ自己愛が強くて、その自己愛を充足させるために他人に自分話を押売りして聞かせているもんだと思っていた。しかし上記引用で、「自分の話をしているときに脳の報酬系が活性化する」というのを読んで「そうか！」とひらめいた。脳の報酬系とはドーパミンのことである。ドーパミンは快楽を司る神経伝達物質だ。つまり自分のことを話すのは、人類共通の快感だったのだ！\nまぁ確かに、自分だってそういう面があるのは認めるよ。よく「話を聞いてもらってスッキリした」って言うもんな。何で話すだけでスッキリするのかって、ちゃんと理由があったんだな。しかしこれも度がすぎると聞かされる相手が迷惑だし、みっともないという自覚はある。自分のことを延々と話す人は、その制御が効かなくて、自らの快感原則に従って暴走しているんだろう。プラス自己愛もあるだろうけどね、どっちにしろこの手の人間とは遠い距離を置きたいものである。相手だけ満足して、自分はエネルギー吸い取られるだけだからな\u0026hellip;\n  話が大分脱線した、本来の主旨に戻る。うまい質問の仕方。「ど」で始まる疑問符がキーらしいが、具体的には記事の引用を俺なりにアレンジすると以下のようになる。（仕事関連の想定じゃないとピンと来ないもんで\u0026hellip;）\n   キーワード 質問例     What ー＞「どう、どんな」 どんな理由でこの仕事を始めたんですか？   Who ー＞「どの人、どんな人」 どんな人と仕事してみたいですか？   When ー＞「どんなとき、どのタイミング」 どんなときに達成感を感じますか？   Where ー＞「どこに、どこで」 どこでその分野を学んだのですか？   Why ー＞「どうして」 どうしてその製品に人気が集中するんでしょうね？   Which ー＞「どれ、どっち」 どちらのアイデアが気に入りましたか？   How ー＞「どうやって、どのように」 どのようにしてその課題を解決したんですか？     自己愛満々野郎の自分話を聞かされるのはゴメンだが、まともな相手とのコミュニケーション手法としては頭の片隅においておこう。","title":"「いてくれるだけでいい人」の理由"},{"content":"AWSでのログ監視メール送信はサブスクリプションフィルタ + Lambda + SNSを使用するのがスタンダード。みんなやっていそうなことだが未経験だったのでやってみた。基本参考にしたのは王道クラメソさんの記事だったが、ちょっとわかりにくいところがあったので他の記事も合わせて参照して若干やり方変えつつ検証した。\n今回はマネコン作業メインでやったが、CLIやTerraformなどAPI経由で実装する場合追加作業が発生するため注意が必要。(後述 補足事項に記載)\n 参考\n CloudWatch Logs を文字列検知してログ内容をメールを送信してみた サブスクリプションフィルター版 【AWS】CloudWatch Logsからシステムログをメール通知する。 CloudWatch Logs のサブスクリプションフィルタを使って特定文字列を検知したログをEメール通知する ※CLI実装例   以下は今後の参考用\n CloudWatchLogsの内容をフィルタリングしてLambdaで通知させたい ※除外キーワードをコードで記述する例 CloudWatchLogsからLambda経由でログメッセージを通知する ※Terraform実装例   処理概要  CWLにログが出力される CWLのサブスクリプションフィルタでキーワード検知 Lambda関数起動 SNSに連携される メール通知   作業概要  SNSトピック作成〜サブスクライブ Lambda用IAMロール作成 Lambda関数作成 ロググループ/ログストリーム作成 ロググループにサブスクリプションフィルタ作成 （配信先に3.のLambda関数を指定） テストログ送信〜メール通知確認  ※ログストリーム作成は検証時のみ。通常は自動生成される。\n 今回の検証に使用したアイテム（個人メモ）    アイテム 名称     SNSトピック log-monitor-topic   Lambda用IAMロール send-log-filter-role   Lambda関数 send-log-filter-function   サブスクリプションフィルタ send-log-filter     やったこと  SNSトピック作成〜サブスクライブ\n過去記事:AWS EventBridge + SNSからのメール件名をカスタマイズするに書いたので省略。ここではCLIでやってるけどマネコンでも特にハマるところはない。アクセスポリシーはデフォルトにした。   Lambda用IAMロール作成\nとりあえず以下のマネージドポリシーをアタッチ。   CloudEatchLogsFullAccess AmazonSNSFullAccess   Lambda関数作成\n(1) 参考ブログのコード貼り付け  import base64 import json import zlib import datetime import os import boto3 from botocore.exceptions import ClientError print(\u0026#39;Loading function\u0026#39;) def lambda_handler(event, context): data = zlib.decompress(base64.b64decode(event[\u0026#39;awslogs\u0026#39;][\u0026#39;data\u0026#39;]), 16+zlib.MAX_WBITS) data_json = json.loads(data) log_entire_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;], ensure_ascii=False)) log_entire_len = len(log_entire_json) print(log_entire_json) for i in range(log_entire_len): log_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;][i], ensure_ascii=False)) try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = log_json[\u0026#39;message\u0026#39;], Subject = os.environ[\u0026#39;ALARM_SUBJECT\u0026#39;] ) except Exception as e: print(e)  (2) 環境変数をセット(Configration/設定タブ ー＞ 左ペインのEnvironment variables/環境変数)\n   Key Value     SNS_TOPIC_ARN arn:aws:sns:ap-northeast-1:my-account-id:log-monitor-topic   CUSTOM_SUBJECT エラーログ送信テスト    ロググループ/ログストリーム作成\nマネコンから普通にできるので省略。   サブスクリプションフィルタ作成\nロググループの画面から作成する。   配信先として先に作成したLambda関数を指定する。ログフォーマットは当初OtherにしたがJSONでいいらしい。（まだよくわかっていない\u0026hellip;）\n 事前にメッセージを投入しておけばここでテストできる。メッセージが何もない場合はスキップ。\n 最後に[Start streaming]押下で完了。\n 作成後のサブスクリプションフィルタ。作成後に変更したい場合はマネコンからはできないため、CLIから設定する。詳細は後述の補足事項に記載。\n テストログ送信〜メール通知確認\nこのテストログ送信方法については、クラメソさんや他の記事ではCLIからput-log-eventsを実行しているが、正直面倒くさい。マネコンからやる方が簡単なのでここではその手順を記載。  対象のログストリーム画面から、[Actions(アクション)] ー＞ [Create log event（ログイベントの作成）]と遷移し、テストイベントを発行する。\n メール通知を確認。届いた！\n \u0026hellip;と、ここまで普通にできたっぽく書いているが、実際には何かとハマって手こずってしまった。当初メールが届かなくてね。複数の記事を参考にしているが、それぞれ微妙に手順や実装が異なるから、少しどこかをいじるとNGになったりする。\nメールが届かないのはSNSが原因と思ったけど（Lambdaでエラー出ていないから）、Lambda自体のログにテストイベントのメッセージが何も出力されていないことに気づいて、Lambdaがイベントを取得できていなくてSNSにメッセージが渡っていないことが原因とわかった。コードも若干入れ替えたり編集したりしたんで。自分は紆余曲折しておかしなことになったが、最初はクラメソさんのコードをそのまま使って手順通りにやればできるはず。応用はその後。\n 補足事項  サブスクリプション作成後の変更\nサブスク作成後はマネコンからは直接変更できないが、CLIで編集可能。aws logs put-subscripution-filterで同じサブスク名を指定すれば設定が上書きされる。  $ aws logs put-subscription-filter ¥ --log-group-name [your log group name] ¥ --filter-name [your subscription filter name] ¥ --filter-pattern [your filter pattern] ¥ --destination-arn [your destination arn] ※今回の場合Lambda関数のARN  フィルタパターン編集\nフィルタパターンでOR条件するには、キーワード間はスペース区切りとし、各キーワードの先頭に?をつける。除外フィルタはまた別に必要で複雑になる。Lambda関数内で設定することも可能なので、要件に応じて検討。  フィルタパターンOR条件例\nこれを作成済みのサブスクに適用したい場合は、上記1.のCLIコマンドの--filter-patternオプションの値として指定すればよい。\n\u0026quot;?error ?Error ?ERROR ?fail ?Fail ?FAIL\u0026quot;  除外キーワードをセットするのはちょっと面倒で、こんな風になる。以下の場合、メッセージが\u0026quot;error event\u0026quot;の場合は検知され、\u0026ldquo;error test\u0026quot;の場合は検知されない。\n\u0026quot;[( msg=¥\u0026quot;*error*¥\u0026quot; || msg=¥\u0026quot;*Error*¥\u0026quot; ) \u0026amp;\u0026amp; ( msg!=¥\u0026quot;*test*¥\u0026quot; \u0026amp;\u0026amp; msg!=¥\u0026quot;*Test*¥\u0026quot; \u0026amp;\u0026amp; msg!=¥\u0026quot;*TEST*¥\u0026quot; )]\u0026quot;  Lambdaコード内で除外キーワード定義することも可能だが、検知キーワードと除外キーワードが別れるのもどうなんかと思うし、迷うところ。\n APIから実装する際の追加作業\nサブスクリプションフィルタ作成時、マネコンだと自動で付与される権限がCLIでは付与されないため、事前にLambda側で権限を追加する。--statement-idは適当な文字列でいいと思われる。多分。  $ aws lambda add-permission ¥ --function-name [your function name] ¥ --statement-id \u0026quot;your statement id\u0026quot; ¥ --principal \u0026quot;logs.ap-northeast-1.amazonaws.com\u0026quot; ¥ --action \u0026quot;lambda:InvokeFunction\u0026quot; ¥ --source-arn \u0026quot;arn:aws:logs:ap-northeast-1:[your account id]:log-group:*:*\u0026quot; ¥ --source-account [your account id]  TerraformやCFnから作成する場合も同じ作業が必要になるはずだから要注意。\n参考: add-permission\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatchlogs-send-filter-mail/","summary":"AWSでのログ監視メール送信はサブスクリプションフィルタ + Lambda + SNSを使用するのがスタンダード。みんなやっていそうなことだが未経験だったのでやってみた。基本参考にしたのは王道クラメソさんの記事だったが、ちょっとわかりにくいところがあったので他の記事も合わせて参照して若干やり方変えつつ検証した。\n今回はマネコン作業メインでやったが、CLIやTerraformなどAPI経由で実装する場合追加作業が発生するため注意が必要。(後述 補足事項に記載)\n 参考\n CloudWatch Logs を文字列検知してログ内容をメールを送信してみた サブスクリプションフィルター版 【AWS】CloudWatch Logsからシステムログをメール通知する。 CloudWatch Logs のサブスクリプションフィルタを使って特定文字列を検知したログをEメール通知する ※CLI実装例   以下は今後の参考用\n CloudWatchLogsの内容をフィルタリングしてLambdaで通知させたい ※除外キーワードをコードで記述する例 CloudWatchLogsからLambda経由でログメッセージを通知する ※Terraform実装例   処理概要  CWLにログが出力される CWLのサブスクリプションフィルタでキーワード検知 Lambda関数起動 SNSに連携される メール通知   作業概要  SNSトピック作成〜サブスクライブ Lambda用IAMロール作成 Lambda関数作成 ロググループ/ログストリーム作成 ロググループにサブスクリプションフィルタ作成 （配信先に3.のLambda関数を指定） テストログ送信〜メール通知確認  ※ログストリーム作成は検証時のみ。通常は自動生成される。\n 今回の検証に使用したアイテム（個人メモ）    アイテム 名称     SNSトピック log-monitor-topic   Lambda用IAMロール send-log-filter-role   Lambda関数 send-log-filter-function   サブスクリプションフィルタ send-log-filter     やったこと  SNSトピック作成〜サブスクライブ","title":"CloudWatchLogsのログ監視 - サブスクリプションフィルタ + Lambdaでメール送信"},{"content":"昨年の過去ツイのスレッドでちょっと気になるのを見つけたので、若干手を入れてここにまとめて書いておく。\n  暴力の加害者に対して被害者が好意を抱く「ストックホルム症候群」と567脳、マスク厨の心理は似てないか？側から見ると、あの人たちは自由や人権を奪われている今の状況を愛しているように見える。\nその裏では「認知的不協和の解消」が発生している可能性がある。これは、自分の内部の矛盾に一貫性を持たせようとする機能。「新しい生活様式」だの、自粛しろマスクつけろだの、不自由で不本意な状況を強いられているが、それを受け入れている自分に葛藤が生じているはずなのだ。\nだからマナーだの何だの言って正当化している。または無意識に自分を麻痺させている。どちらにしても認知に修正を加えて不協和（矛盾）を解消しようとしているわけで、つまり認知に歪みが発生している。だから苦痛さえ感じなくなっているのではないかと想像する。\nそれから、「沖縄から貧困がなくならない本当の理由」（樋口耕太郎著）からの引用なのだが、こういった自己防衛の心理も働いているかとも。\n 人間は激しい痛みを感じると、自分の感覚を鈍らせて自己防衛を図る性質があるが、それは絶望の耐え難い痛みを和らげるために、自分自身に打つ麻酔のようなものだ。\n  自分に麻酔を打って思考や身体感覚を麻痺させたり、自ら認知を歪ませれば、見かけ上は苦痛が和らぐ。しかし同時に生きる上でのあらゆる喜びもまた、感じることができなくなる。そして本来あるべき自分の自由と権利を、忘却の彼方に押しやっている。それは虚構の世界を生きているだけなのだ。\n  \u0026hellip;と、まぁ当時はこんなことを思いつくままに呟いてみたが、大半の世間のコロナ恐怖脳はここまで複雑な心理の綾などなく、自分で調べたり考察することもなくひたすら垂れ流される情報を鵜呑みにして怖いね怖いねと決まり文句を言ってるだけのように見える、それが世間の掟だから。\nもちろん、マスク・アルコール消毒・検温や在宅勤務を強制または半強制されることに疑問を抱くこともない。一切の疑問も抱かずに、受け入れているのだ。昼の外食時に周りから聞こえてくる会話を聞いていると呆れる、それなりに一流と呼ばれる企業に勤めていてある程度の地位についていそうな人たちが、そんな具合なのである。\nまぁ何にせよ、認知の歪みが生じていることは確か、40度近い真夏日に病気でもないのにマスクとか異常でしかないよ。\n それから「家庭内ストックホルム症候群」という言葉もある。児童虐待やDVを受けている被害者が、自分を虐待・無視などで苦しめる親や配偶者（多くの場合夫）に不満や憎しみを抱きつつも、見捨てられたらどうしようと、過剰な不安や恐怖心が芽生える。そこで無意識の内に親や配偶者が気に入られるように「良い子」「良い妻」を演じてしまう\u0026hellip;ということらしい。\nいやでもこれって別に、ストックホルム症候群という名称を持ち出すまでもなく、より普遍的な事象だと思うな、人間が暴力・抑圧・嫌がらせに対して自分の心を麻痺させて適応を試みる心理が働くのは、きっと人間のデフォルト機能なんだよ、悲しい機能だけど。\nDVの他に大学内の教授と生徒の間に発生する「アカハラ」、職場のパワハラでも同様の状態になるよね、理不尽なハラスメントを受けているのに、それを客観視できない状態にあると、相手に気に入られようとして相手に従い、相手の意に沿うように行動してしまうんだ。\nこれには2つの要因がある、生き延びるための生存本能と、他者に愛されたい、承認されたいという、ヒトとしての社会的本能。しかしそれで相手がハラスメントを辞めるかと言ったら逆だ、「こいつはいじめれば何でも言うことをきく」と思われてエスカレートするだけだ、全く本質的な解決にはならず、状況が悪化するだけなんだよ。\n  ここまでの文章は、今年2021年の1月に別のブログに投稿した内容を編集・加筆したものだ。そこに置いておいても塩漬けになるだけだからこっちに持ってきた。文章中に登場するツイは、とうにアカウント削除したので今は存在しない。「家庭内ストックホルム症候群」から先は今回追記したもの。主旨が途中からずれている気がするが、まぁ気にしない。\nTwitterなんか最低のクソメディアだと思うが、ふと思いついて書いたことでも後でこうして振り返って考察することもあるから、そういう意味では少しはやる価値あったかな。\n結局何が言いたいのかってね、多くの人間は、ハラスメントを受けている最中は、状況を客観視できないんだよ、かつ、生存本能と社会的本能のためにその状況に適応しようとして、自分を押し殺してハラスメントをする相手や周囲に従ったり、意に沿わない行動をとったりしがちなんだ。これは自覚しないといけないし、あらゆるハラスメントには声をあげ、全力で抵抗しなけりゃいけないんだ、それこそ、羊や奴隷ではなく、主権を持った人間として生きるために。\n  過去記事にも書いたDylan Thomasの詩の一部。本来の詩の主旨は違うけど、今のこの世界に対して、全く同じことを言いたいね。\n Do not go gentle into that good night,\nRage, rage against the dying of the light.\n  あぁまったく、俺はやっぱりこのまま死ぬわけにはいかねぇ、大人しく従ってちゃダメなんだ、激怒して、憤怒して、死にもの狂いで抵抗しなくちゃいけないんだ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/stockholm-syndrome/","summary":"昨年の過去ツイのスレッドでちょっと気になるのを見つけたので、若干手を入れてここにまとめて書いておく。\n  暴力の加害者に対して被害者が好意を抱く「ストックホルム症候群」と567脳、マスク厨の心理は似てないか？側から見ると、あの人たちは自由や人権を奪われている今の状況を愛しているように見える。\nその裏では「認知的不協和の解消」が発生している可能性がある。これは、自分の内部の矛盾に一貫性を持たせようとする機能。「新しい生活様式」だの、自粛しろマスクつけろだの、不自由で不本意な状況を強いられているが、それを受け入れている自分に葛藤が生じているはずなのだ。\nだからマナーだの何だの言って正当化している。または無意識に自分を麻痺させている。どちらにしても認知に修正を加えて不協和（矛盾）を解消しようとしているわけで、つまり認知に歪みが発生している。だから苦痛さえ感じなくなっているのではないかと想像する。\nそれから、「沖縄から貧困がなくならない本当の理由」（樋口耕太郎著）からの引用なのだが、こういった自己防衛の心理も働いているかとも。\n 人間は激しい痛みを感じると、自分の感覚を鈍らせて自己防衛を図る性質があるが、それは絶望の耐え難い痛みを和らげるために、自分自身に打つ麻酔のようなものだ。\n  自分に麻酔を打って思考や身体感覚を麻痺させたり、自ら認知を歪ませれば、見かけ上は苦痛が和らぐ。しかし同時に生きる上でのあらゆる喜びもまた、感じることができなくなる。そして本来あるべき自分の自由と権利を、忘却の彼方に押しやっている。それは虚構の世界を生きているだけなのだ。\n  \u0026hellip;と、まぁ当時はこんなことを思いつくままに呟いてみたが、大半の世間のコロナ恐怖脳はここまで複雑な心理の綾などなく、自分で調べたり考察することもなくひたすら垂れ流される情報を鵜呑みにして怖いね怖いねと決まり文句を言ってるだけのように見える、それが世間の掟だから。\nもちろん、マスク・アルコール消毒・検温や在宅勤務を強制または半強制されることに疑問を抱くこともない。一切の疑問も抱かずに、受け入れているのだ。昼の外食時に周りから聞こえてくる会話を聞いていると呆れる、それなりに一流と呼ばれる企業に勤めていてある程度の地位についていそうな人たちが、そんな具合なのである。\nまぁ何にせよ、認知の歪みが生じていることは確か、40度近い真夏日に病気でもないのにマスクとか異常でしかないよ。\n それから「家庭内ストックホルム症候群」という言葉もある。児童虐待やDVを受けている被害者が、自分を虐待・無視などで苦しめる親や配偶者（多くの場合夫）に不満や憎しみを抱きつつも、見捨てられたらどうしようと、過剰な不安や恐怖心が芽生える。そこで無意識の内に親や配偶者が気に入られるように「良い子」「良い妻」を演じてしまう\u0026hellip;ということらしい。\nいやでもこれって別に、ストックホルム症候群という名称を持ち出すまでもなく、より普遍的な事象だと思うな、人間が暴力・抑圧・嫌がらせに対して自分の心を麻痺させて適応を試みる心理が働くのは、きっと人間のデフォルト機能なんだよ、悲しい機能だけど。\nDVの他に大学内の教授と生徒の間に発生する「アカハラ」、職場のパワハラでも同様の状態になるよね、理不尽なハラスメントを受けているのに、それを客観視できない状態にあると、相手に気に入られようとして相手に従い、相手の意に沿うように行動してしまうんだ。\nこれには2つの要因がある、生き延びるための生存本能と、他者に愛されたい、承認されたいという、ヒトとしての社会的本能。しかしそれで相手がハラスメントを辞めるかと言ったら逆だ、「こいつはいじめれば何でも言うことをきく」と思われてエスカレートするだけだ、全く本質的な解決にはならず、状況が悪化するだけなんだよ。\n  ここまでの文章は、今年2021年の1月に別のブログに投稿した内容を編集・加筆したものだ。そこに置いておいても塩漬けになるだけだからこっちに持ってきた。文章中に登場するツイは、とうにアカウント削除したので今は存在しない。「家庭内ストックホルム症候群」から先は今回追記したもの。主旨が途中からずれている気がするが、まぁ気にしない。\nTwitterなんか最低のクソメディアだと思うが、ふと思いついて書いたことでも後でこうして振り返って考察することもあるから、そういう意味では少しはやる価値あったかな。\n結局何が言いたいのかってね、多くの人間は、ハラスメントを受けている最中は、状況を客観視できないんだよ、かつ、生存本能と社会的本能のためにその状況に適応しようとして、自分を押し殺してハラスメントをする相手や周囲に従ったり、意に沿わない行動をとったりしがちなんだ。これは自覚しないといけないし、あらゆるハラスメントには声をあげ、全力で抵抗しなけりゃいけないんだ、それこそ、羊や奴隷ではなく、主権を持った人間として生きるために。\n  過去記事にも書いたDylan Thomasの詩の一部。本来の詩の主旨は違うけど、今のこの世界に対して、全く同じことを言いたいね。\n Do not go gentle into that good night,\nRage, rage against the dying of the light.\n  あぁまったく、俺はやっぱりこのまま死ぬわけにはいかねぇ、大人しく従ってちゃダメなんだ、激怒して、憤怒して、死にもの狂いで抵抗しなくちゃいけないんだ。","title":"「ストックホルム症候群」の心理はヒトのデフォルト機能だった"},{"content":"Mac上のpython3。しばらく前にhomebrewと一緒に削除してしまったので入れ直した。\n$ brew install python3  $ which python3 /usr/local/bin/python3 $ python3 -V Python 3.9.7 $ pip3 -V pip 21.2.4 from /usr/local/lib/python3.9/site-packages/pip (python 3.9)  pythonだけで実行するとゴニョゴニョ言われる。\n$ python Your PYTHONPATH points to a site-packages dir for Python 3.x but you are running Python 2.x! PYTHONPATH is currently: \u0026quot;/usr/local/lib/python3.9/site-packages:\u0026quot; You should `unset PYTHONPATH` to fix this. $ unset PYTHONPATH  で、この後pythonを実行すると2系になってしまう。\n$ python WARNING: Python 2.7 is not recommended. This version is included in macOS for compatibility with legacy software. Future versions of macOS will not include Python 2.7. Instead, it is recommended that you transition to using 'python3' from within Terminal. Python 2.7.16 (default, Aug 30 2021, 14:43:11) [GCC Apple LLVM 12.0.5 (clang-1205.0.19.59.6) [+internal-os, ptrauth-isa=deploy on darwin Type \u0026quot;help\u0026quot;, \u0026quot;copyright\u0026quot;, \u0026quot;credits\u0026quot; or \u0026quot;license\u0026quot; for more information. \u0026gt;\u0026gt;\u0026gt;  python3を実行するにはpython3とタイプ。\n$ python3 Python 3.9.7 (default, Oct 13 2021, 06:45:31) [Clang 13.0.0 (clang-1300.0.29.3)] on darwin Type \u0026quot;help\u0026quot;, \u0026quot;copyright\u0026quot;, \u0026quot;credits\u0026quot; or \u0026quot;license\u0026quot; for more information. \u0026gt;\u0026gt;\u0026gt;  boto3が消えていたのでこれも再インストールした。\n$ pip3 install boto3 $ pip3 freeze boto3==1.18.63 botocore==1.21.63 Jinja2==2.11.2 jmespath==0.10.0 MarkupSafe==1.1.1 python-dateutil==2.8.2 PyYAML==5.3.1 s3transfer==0.5.0 six==1.16.0 urllib3==1.26.7  全く無関係に在りし日の記録。（2019年）\n  はるばるアルゼンチンから、こんなに大勢の人が日本に来てくれたんだよ、あの頃は。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/mac-python3-re-install/","summary":"Mac上のpython3。しばらく前にhomebrewと一緒に削除してしまったので入れ直した。\n$ brew install python3  $ which python3 /usr/local/bin/python3 $ python3 -V Python 3.9.7 $ pip3 -V pip 21.2.4 from /usr/local/lib/python3.9/site-packages/pip (python 3.9)  pythonだけで実行するとゴニョゴニョ言われる。\n$ python Your PYTHONPATH points to a site-packages dir for Python 3.x but you are running Python 2.x! PYTHONPATH is currently: \u0026quot;/usr/local/lib/python3.9/site-packages:\u0026quot; You should `unset PYTHONPATH` to fix this. $ unset PYTHONPATH  で、この後pythonを実行すると2系になってしまう。\n$ python WARNING: Python 2.7 is not recommended. This version is included in macOS for compatibility with legacy software.","title":"MacにPython3を再インストール"},{"content":"あー、マジやべぇ、息が詰まりそうだ、いろいろと、勘弁してくれよもう的な動きが多くてさ、めっちゃやり辛い。まじで、10月入ってからすげえやり辛くなった。鬱屈がたまってどうしようもねぇ。\nしばらく前から通勤時に英文小説読む余力もないし、Tumblrやり過ぎるとDVT症候群で頭痛と目眩がするし、イヤホンで大音量で音楽聴きすぎて耳がイカレそうだし、もう何を支えにしていいかわからないな、オレは生き延びることができるんだろうか？\nそりゃ仕事があるだけありがたい立場だってことは忘れちゃいけないけどね、もし今「戦争」状態じゃなかったらいつでも出ていけるんだからな、なにせ俺様能力高いからな。\n うん、そのつもりでやっていくしかねぇ。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/life-1027/","summary":"あー、マジやべぇ、息が詰まりそうだ、いろいろと、勘弁してくれよもう的な動きが多くてさ、めっちゃやり辛い。まじで、10月入ってからすげえやり辛くなった。鬱屈がたまってどうしようもねぇ。\nしばらく前から通勤時に英文小説読む余力もないし、Tumblrやり過ぎるとDVT症候群で頭痛と目眩がするし、イヤホンで大音量で音楽聴きすぎて耳がイカレそうだし、もう何を支えにしていいかわからないな、オレは生き延びることができるんだろうか？\nそりゃ仕事があるだけありがたい立場だってことは忘れちゃいけないけどね、もし今「戦争」状態じゃなかったらいつでも出ていけるんだからな、なにせ俺様能力高いからな。\n うん、そのつもりでやっていくしかねぇ。\n ","title":"ひとり言 - 10月27日"},{"content":"10月25日の明け方に見た夢。コンサート会場みたいなところ。そこはロンドンである。観客が大勢いて賑わっている。そしてノーマスク。「あぁ、マスク圧解禁されたのか！」と嬉しい。よく見ると数人はマスクしている、でもほぼノーマスク。あぁ。\n もうずっとリアル世界で不快なものしか見てないから、せめてここだけでも。これくらいいいだろ\u0026hellip;.\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/life-1025/","summary":"10月25日の明け方に見た夢。コンサート会場みたいなところ。そこはロンドンである。観客が大勢いて賑わっている。そしてノーマスク。「あぁ、マスク圧解禁されたのか！」と嬉しい。よく見ると数人はマスクしている、でもほぼノーマスク。あぁ。\n もうずっとリアル世界で不快なものしか見てないから、せめてここだけでも。これくらいいいだろ\u0026hellip;.\n ","title":"Eye Candyがいるんだ"},{"content":"表題の件、通知メールの件名はわかりやすいのにしたいよねというニーズに対応すべく、以下参考に試してみた。やったことはほぼこちらの記事の通り。\nAmazon SNS で送られる CloudWatch Events ルールの通知内容をカスタマイズする\n 上記の通りやっていけばできるんだけれど、整理するためにも自分用に記録残す。ちなみに2021年10月現在、CloudWatch EventsはEventBridgeになっている。移行期間中だからまだ違和感があるが、この記事では名称は「EventBridge」とする。それと後半で書いているが、今回の事例ではCloudTrailが有効になっていることが前提なので、現状無効の場合は有効にしておく。\n各種リソースに類似の名称が多くて混乱するので、これも自分用に整理。以下、今回作成したリソース名称。\n   アイテム 名称     SNSトピック custom-event-notification   Lambda用IAMロール custom-event-mail-role   Lambda関数 custom-mail-function   eventルール custom-mail-rule     ではここから作業内容の記録に入る。\nSNSトピック作成\n$ aws sns create-topic --name custom-event-notification  サブスク（サブスクリプション）作成\n$ aws sns subscribe --topic-arn arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification --protocol email --notification-endpoint [my mail address] { \u0026quot;SubscriptionArn\u0026quot;: \u0026quot;pending confirmation\u0026quot; }  指定したアドレスにメールが届くので、リンク押下してconfirmする。その後マネコンのSNS画面を見るとサブスクのステータスがconfirmedになっているはず。\nまたは、以下確認コマンド\n$ aws sns list-subscriptions-by-topic --topic-arn arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification  ここからLambdaの作業に入る。最初にLambda用のIAMロールを作成。以下の内容で信頼ポリシー用のJSONファイルを用意し、それを指定してロール作成実行。\ntrust-policy.json\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;lambda.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] }  $ aws iam create-role --role-name custom-event-mail-role --assume-role-policy-document file://trust-policy.json  ロールにAWSマネージドポリシーをアタッチ。\n$ aws iam attach-role-policy --role-name custom-event-mail-role --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole $ aws iam attach-role-policy --role-name custom-event-mail-role --policy-arn arn:aws:iam::aws:policy/AmazonSNSFullAccess  ここまでで、IAMロール完成。次に、以下内容のLambda関数のコードを用意する。\ncustom-mail.py\nimport boto3 import json import os sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] custom_subject = os.environ[\u0026#39;CUSTOM_SUBJECT\u0026#39;] def lambda_handler(event, context): print(sns_arn) client = boto3.client(\u0026#34;sns\u0026#34;) resp = client.publish(TargetArn=sns_arn, Message=json.dumps(event), Subject=custom_subject)  これをzipにする。\n$ zip custom-mail.zip custom-mail.py  IAMロールとzipファイルを指定してLambda関数を作成。\n$ aws lambda create-function --function-name custom-mail-function --role arn:aws:iam::my-account-id:role/custom-event-mail-role --runtime python3.8 --handler custom-mail.lambda_handler --zip-file fileb://custom-mail.zip  環境変数をセット。ここでSNSトピックARNと、送信したいメール件名を定義している。\n$ aws lambda update-function-configuration --function-name custom-mail-function --environment Variables='{SNS_TOPIC_ARN=\u0026quot;arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification\u0026quot;,CUSTOM_SUBJECT=\u0026quot;カスタムメールタイトル送信テスト\u0026quot;}'     変数名 値     SNS_TOPIC_ARN arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification   CUSTOM_SUBJECT カスタムメールタイトル送信テスト     トリガーとなるイベントルールを作成。本当はec2のCPU使用率のアラームでメール飛ばしたいがここは参考ページの通りにする。\nevent-pattern.json\n{ \u0026#34;source\u0026#34;: [ \u0026#34;aws.s3\u0026#34; ], \u0026#34;detail-type\u0026#34;: [ \u0026#34;AWS API Call via CloudTrail\u0026#34; ], \u0026#34;detail\u0026#34;: { \u0026#34;eventSource\u0026#34;: [ \u0026#34;s3.amazonaws.com\u0026#34; ], \u0026#34;eventName\u0026#34;: [ \u0026#34;CreateBucket\u0026#34;, \u0026#34;DeleteBucket\u0026#34; ] } }  eventsのルールを作成する。\n$ aws events put-rule --name custom-mail-rule --event-pattern file://event-pattern.json { \u0026quot;RuleArn\u0026quot;: \u0026quot;arn:aws:events:ap-northeast-1:my-account-id:rule/custom-mail-rule\u0026quot; }  Lambdaにルールの実行権限を追加。\n$ aws lambda add-permission --function-name custom-mail-function --statement-id 1 --principal events.amazonaws.com --action 'lambda:InvokeFunction' --source-arn arn:aws:events:ap-northeast-1:my-account-id:rule/custom-mail-rule { \u0026quot;Statement\u0026quot;: \u0026quot;{\\\u0026quot;Sid\\\u0026quot;:\\\u0026quot;1\\\u0026quot;,\\\u0026quot;Effect\\\u0026quot;:\\\u0026quot;Allow\\\u0026quot;,\\\u0026quot;Principal\\\u0026quot;:{\\\u0026quot;Service\\\u0026quot;:\\\u0026quot;events.amazonaws.com\\\u0026quot;},\\\u0026quot;Action\\\u0026quot;:\\\u0026quot;lambda:InvokeFunction\\\u0026quot;,\\\u0026quot;Resource\\\u0026quot;:\\\u0026quot;arn:aws:lambda:ap-northeast-1:my-account-id:function:custom-mail-function\\\u0026quot;,\\\u0026quot;Condition\\\u0026quot;:{\\\u0026quot;ArnLike\\\u0026quot;:{\\\u0026quot;AWS:SourceArn\\\u0026quot;:\\\u0026quot;arn:aws:events:ap-northeast-1:my-account-id:rule/custom-mail-rule\\\u0026quot;}}}\u0026quot; }  Lambda関数をルールのターゲットとしてセットする。\n$ aws events put-targets --rule custom-mail-rule --targets \u0026quot;Id\u0026quot;=\u0026quot;Target1\u0026quot;,\u0026quot;Arn\u0026quot;=\u0026quot;arn:aws:lambda:ap-northeast-1:my-account-id:function:custom-mail-function\u0026quot; { \u0026quot;FailedEntryCount\u0026quot;: 0, \u0026quot;FailedEntries\u0026quot;: [] }  バケットを作成して通知テスト\n$ aws s3 mb s3://custom-mail-sending-test-xxxx  \u0026hellip;しかしメール届かない。て、CloudTrailが無効になっているんだから当然である。で、CloudTrailを有効にしてから先ほど作成したバケットを消してみる。したら、\u0026hellip;設定した件名「カスタムメールタイトル送信テスト」で通知メールが届いた！\nLambda関数の画面ではトリガーがEventBridgeになっているが、移行期間中はカッコでCloudWatche Eventsも併記されるっぽい。\n Events側でもルールとLambda関数が紐付いていることがわかる。ちなみにこれはCloudWatche Eventsの画面から見ているが、同じルールがEventBridgeの画面にも存在するはずである。\n メール本文。JSONの生データそのまんま。「人間」の感覚としてはこんなん送られてもなぁ\u0026hellip;としか思えないが、\u0026ldquo;DeleteBucket\u0026quot;の記録があることは一応わかる。\n CloudTrailはもういらんので削除。\u0026hellip;で、SNSからのメールは件名カスタマイズできるのはわかったが、アラームと組み合わせるとなるとまた別の調整が必要。その辺がわからん。次回の課題。\n（追記）後日改良版にトライした\nイベント監視 メール本文カスタマイズ版\nAWSイベント監視 - CloudTrail + EventBridge + Lambdaでメールカスタマイズ(2)\nリソース監視 アラーム通知版\nCloudWatchアラーム + SNSからのメール件名をカスタマイズする \n 本文のカスタマイズ例。これはLambda使ってないけど、今回のコードをアレンジすればできるっぽいからそっちに寄せたい感じ。\nCloudWatch アラームの通知メールを少しでも読みやすくしたい\nEventBridgeって結局元CloudWatchEventsのことなんだが、まだよくわかっていないのでこの辺も調べておく。\nAmazon EventBridgeとは何か\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/aws-events-custom-mail/","summary":"表題の件、通知メールの件名はわかりやすいのにしたいよねというニーズに対応すべく、以下参考に試してみた。やったことはほぼこちらの記事の通り。\nAmazon SNS で送られる CloudWatch Events ルールの通知内容をカスタマイズする\n 上記の通りやっていけばできるんだけれど、整理するためにも自分用に記録残す。ちなみに2021年10月現在、CloudWatch EventsはEventBridgeになっている。移行期間中だからまだ違和感があるが、この記事では名称は「EventBridge」とする。それと後半で書いているが、今回の事例ではCloudTrailが有効になっていることが前提なので、現状無効の場合は有効にしておく。\n各種リソースに類似の名称が多くて混乱するので、これも自分用に整理。以下、今回作成したリソース名称。\n   アイテム 名称     SNSトピック custom-event-notification   Lambda用IAMロール custom-event-mail-role   Lambda関数 custom-mail-function   eventルール custom-mail-rule     ではここから作業内容の記録に入る。\nSNSトピック作成\n$ aws sns create-topic --name custom-event-notification  サブスク（サブスクリプション）作成\n$ aws sns subscribe --topic-arn arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification --protocol email --notification-endpoint [my mail address] { \u0026quot;SubscriptionArn\u0026quot;: \u0026quot;pending confirmation\u0026quot; }  指定したアドレスにメールが届くので、リンク押下してconfirmする。その後マネコンのSNS画面を見るとサブスクのステータスがconfirmedになっているはず。\nまたは、以下確認コマンド\n$ aws sns list-subscriptions-by-topic --topic-arn arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification  ここからLambdaの作業に入る。最初にLambda用のIAMロールを作成。以下の内容で信頼ポリシー用のJSONファイルを用意し、それを指定してロール作成実行。","title":"AWSイベント監視 - CloudTrail + EventBridge + Lambdaでメールカスタマイズ"},{"content":"CloudWatchLogsからS3へログをエクスポートする。基本的に以下の通りにやればできるのだが、説明が冗長だったりわかりにくいところがあるので自分用に書いておく。IAMユーザ作成の手順とかいらん。親切のつもりだろうけど、無駄に記事が長くなって読む気が失せる\u0026hellip;\nコンソールを使用してログデータを Amazon S3 にエクスポートする\n 概要。ログストリームのエクスポートはログストリームの画面ではなく、ロググループの画面から行う。事前にログエクスポート専用S3バケットを用意し、ドキュメントの通りにバケットポリシーを設定しておく。適当なランダム値のプレフィクスを作成し、バケットポリシーに反映する。\n バケットポリシーサンプル\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::my-app-logs\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; } }, { \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34; , \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::my-app-logs/sjh6dert3a/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;s3:x-amz-acl\u0026#34;: \u0026#34;bucket-owner-full-control\u0026#34; } }, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; } } ] }  上記前提条件が整った上で、以下実行する。カッコ内は英語表記の場合。\n 対象のログストリーム画面上で、「アクション」(Actions)のプルダウンから、「データをAmazon S3に エクスポート」(Export data to Amazon S3)を選択。 次画面でバケット名、作成しておいたS3のプレフィクス名、ログストリーム、時間の範囲指定を行い、「エクスポート」実行   エクスポート先のS3では確かzip化された状態で格納されていたと思う。\nドキュメント中の表現一部「ランダムに生成されたプレフィクス」、これがわかりにくかった。ログエクスポート先のS3にランダム文字列のプレフィクスが存在するのが望ましいようだ。なぜ普通の文字列ではなくランダム値が望ましいのかはよくわからん。「生成されたランダム文字列」と書かれているもんだから、どこで生成してるんだ？と混乱した。これは自分で適当に決めた値でよい。\n 上記に書いた作業はもちろん必要に応じてアドホック的に行う対応であり、定常的対応であればLambdaなりshellなりでバッチ化するのが普通だろう。しかしね、たかがログエクスポートだろ？て舐めちゃいけないよ、作り込みがいけてないせいで、処理に24時間以上かかる例があったんだから。（もちろん作ったのはオレじゃない）\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/cwl-s3-export/","summary":"CloudWatchLogsからS3へログをエクスポートする。基本的に以下の通りにやればできるのだが、説明が冗長だったりわかりにくいところがあるので自分用に書いておく。IAMユーザ作成の手順とかいらん。親切のつもりだろうけど、無駄に記事が長くなって読む気が失せる\u0026hellip;\nコンソールを使用してログデータを Amazon S3 にエクスポートする\n 概要。ログストリームのエクスポートはログストリームの画面ではなく、ロググループの画面から行う。事前にログエクスポート専用S3バケットを用意し、ドキュメントの通りにバケットポリシーを設定しておく。適当なランダム値のプレフィクスを作成し、バケットポリシーに反映する。\n バケットポリシーサンプル\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::my-app-logs\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; } }, { \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34; , \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::my-app-logs/sjh6dert3a/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;s3:x-amz-acl\u0026#34;: \u0026#34;bucket-owner-full-control\u0026#34; } }, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; } } ] }  上記前提条件が整った上で、以下実行する。カッコ内は英語表記の場合。\n 対象のログストリーム画面上で、「アクション」(Actions)のプルダウンから、「データをAmazon S3に エクスポート」(Export data to Amazon S3)を選択。 次画面でバケット名、作成しておいたS3のプレフィクス名、ログストリーム、時間の範囲指定を行い、「エクスポート」実行   エクスポート先のS3では確かzip化された状態で格納されていたと思う。\nドキュメント中の表現一部「ランダムに生成されたプレフィクス」、これがわかりにくかった。ログエクスポート先のS3にランダム文字列のプレフィクスが存在するのが望ましいようだ。なぜ普通の文字列ではなくランダム値が望ましいのかはよくわからん。「生成されたランダム文字列」と書かれているもんだから、どこで生成してるんだ？と混乱した。これは自分で適当に決めた値でよい。\n 上記に書いた作業はもちろん必要に応じてアドホック的に行う対応であり、定常的対応であればLambdaなりshellなりでバッチ化するのが普通だろう。しかしね、たかがログエクスポートだろ？て舐めちゃいけないよ、作り込みがいけてないせいで、処理に24時間以上かかる例があったんだから。（もちろん作ったのはオレじゃない）\n ","title":"CloudWatchLogsからS3へログをエクスポートする"},{"content":"GitHub ActionsでCIか。このブログについては今の時点でも不自由していないから無理にやらなくてもいい気がする、けど調べておこう。\nHugo + GitHub Pages + GitHub Actions で独自ドメインのウェブサイトを構築する\n  今日はとうとう電車の中で堂々と中指を突き立てた俺様であったが、週末くらいは心穏やかに過ごそう、ふぅ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/github-actions/","summary":"GitHub ActionsでCIか。このブログについては今の時点でも不自由していないから無理にやらなくてもいい気がする、けど調べておこう。\nHugo + GitHub Pages + GitHub Actions で独自ドメインのウェブサイトを構築する\n  今日はとうとう電車の中で堂々と中指を突き立てた俺様であったが、週末くらいは心穏やかに過ごそう、ふぅ。","title":"Github Actionsメモ"},{"content":"そして俺は相変わらず中指を1000本くらい突き立てたい気分の日々が継続中なのだ。日々アドレナリンが過剰放出されてしまい、心身によろしくない。けど怒りをそのままぶちまけるのは芸がないし、自分にとってプラスにならないからね、俺はプラスになることだけやりたいわけ、だから少しでも勉強になることを書く。\n \u0026ldquo;middle finger\u0026quot;って言ったらあれです、特別な意味を持つ「中指」。\n以下はすべて同じ意味。\u0026ldquo;the finger\u0026quot;でも同じ意味になるとは知らなかった。\n middle finger second finger the finger   侮蔑や怒りを示すジェスチャーとなる「中指を立てる」行為は以下の表現。\n give the middle finger give the finger   以下も同じ意味。知らなかった。でもどれだけポピュラーなんだろう？\n flip the bird fly the bird    しばらく前までは心の中だけで中指を突き立てていたが、最近もう耐えられなくなって物理的にも公の場で中指を立てている俺様なのだった。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/the-finger/","summary":"そして俺は相変わらず中指を1000本くらい突き立てたい気分の日々が継続中なのだ。日々アドレナリンが過剰放出されてしまい、心身によろしくない。けど怒りをそのままぶちまけるのは芸がないし、自分にとってプラスにならないからね、俺はプラスになることだけやりたいわけ、だから少しでも勉強になることを書く。\n \u0026ldquo;middle finger\u0026quot;って言ったらあれです、特別な意味を持つ「中指」。\n以下はすべて同じ意味。\u0026ldquo;the finger\u0026quot;でも同じ意味になるとは知らなかった。\n middle finger second finger the finger   侮蔑や怒りを示すジェスチャーとなる「中指を立てる」行為は以下の表現。\n give the middle finger give the finger   以下も同じ意味。知らなかった。でもどれだけポピュラーなんだろう？\n flip the bird fly the bird    しばらく前までは心の中だけで中指を突き立てていたが、最近もう耐えられなくなって物理的にも公の場で中指を立てている俺様なのだった。","title":"middle finger周辺の表現など"},{"content":"\u0026ldquo;rage\u0026quot;という英単語がある。名詞としては「激情、激怒、憤怒」、自動詞として「怒る、暴れる」という意味だ。これを知ったきっかけは、Tumblrで見かけた以下の引用だった。\n Do not go gentle into that good night.\nRage, rage against the dying of the light.\n  パッと見てすぐに意味は理解できなかったが何か心を捉えられた感があった。\u0026ldquo;rage\u0026quot;という単語を初めて見たので調べたところ、意味は先述の通り。\nこれはウェールズの詩人ディラン・トーマス(Dylan Thomas) の詩の一部である。でもTumblrの投稿にはOscar Wildeって書いたあったような記憶がある。それで最近までずっとこの引用元をOscar Wildeだと思い込んでいたんだから。間違いだったんだなあれは。\nそれはさておき、今日この詩について少し文献を調べてみたら、この引用に対して今までの自分の解釈が若干ズレていたことがわかった。以下は引用元の詩全体である。\n  Do not go gentle into that good night,\nOld age should burn and rage at close of day;\nRage, rage against the dying of the light.\nThough wise men at their end know dark is right,\nBecause their words had forked no lightning they\nDo not go gentle into that good night.\nGood men, the last wave by, crying how bright\nTheir frail deeds might have danced in a green bay,\nRage, rage against the dying of the light.\nWild men who caught and sang the sun in flight,\nAnd learn, too late, they grieved it on its way,\nDo not go gentle into that good night.\nGrave men, near death, who see with blinding sight\nBlind eyes could blaze like meteors and be gay,\nRage, rage against the dying of the light.\nAnd you, my father, there on the sad height,\nCurse, bless me now with your fierce tears, I pray.\nDo not go gentle into that good night.\nRage, rage against the dying of the light.\n (Dylan Thomas, Do Not Go Gentle Into That Good Night)\n  この詩は、ディランが死に瀕した父親へ向けて書いた詩である。（\u0026hellip;というのはもちろん拾った情報）\n詩を理解するのは難しい、言葉としての意味を理解するのと文脈を理解すること、さらにその裏に表現された暗喩を理解するのは別のことだ。しかも母国語以外で。\n俺の英語力はお粗末なので、言葉の意味と文脈はどうにか掴めても、その奥の本質までは手が届きそうで届かない。しかしこの時点で今までの自分の解釈がズレていたことに気づいた。\n俺はTumblrでこの引用を初めて目にしたとき、「大人しくなんかなるなよ、消えゆく灯りに激怒しろ、憤怒しろ」と文字通りの意味に捉えていた、作家がオスカー・ワイルドと思っていたせいもあり、今そこでまだエネルギーを保持して生きている人間が自分または他人をさらに奮い立たせる意図の言葉と解釈した。それで、何か心が「ザワザワッ」としたのである。そしてrageという単語を覚えたのである。\n  話変わって数ヶ月後、村上龍の「ピアッシング」を英語翻訳版で読む機会があった。そしてそこでrageという単語に再会した。コールガールのChiakiが妄想に取り憑かれた男Kawashimaに客として出会い、ふとしたきっかけでrageな状態に至る。そのシーンで、先の引用を真っ先に思い出した。ピピピッときたよね。\nその後また別の英文小説を読んだら、そこでも単語rageが登場してピピピッときた。言葉というものは、こういうプロセスを経て自分の内部に取り込まれていくのである。だからそのプロセスは、人の数だけバリエーションが存在する。\nで、話は戻って俺の英語力ではこの詩の奥深い意味を捉えるのは無理めだったので日本語訳を探してみたところ、素晴らしい翻訳があった。全部載せるのはアレなので一部だけ引用させてもらうと。\n  あんな風に「おやすみ」なんて言ってさっさと諦めるなよ\nもう若くなくたって，一日が人生が終わりそうなら，烈火のごとく怒り狂って，ギャアギャアそこで喚くんだ；\n太陽の光が薄れて消えていっても，死にものぐるいで抵抗しなきゃ\n Do Not Go Gentle Into That Night ディラン・トーマス (Dylan Thomas) より\n 全文はリンク先で読んでもらうとして、訳者ご本人が認めているようにかなり意訳色が強い翻訳である。しかし素晴らしい、最高だ。気持ちがストレートに伝わってくる。そしてこのリンク記事が2020年の大晦日に投稿され、「暗いニュースばかりが目立ったこの一年ですが，最後をこの力強い詩で締めくくりたい」と記されていることにもグッときた。泣けてくるぜ\u0026hellip;\n他の訳も発見したが、同じ原文がこうも異なる訳になるのかと驚く。どれが正しいということではないのだが、自分はやはり上のが一番だな。\n Do Not Go Gentle Into That Night （正当古典派訳）\natheistの意味は? – Do not go gentle into that good night （中庸派的訳）\n  話はあちこちに逸脱したが、この記事ではrageという単語がどのような経緯で自分に取り込まれたのかを書きたかったのである。何故書きたかったのか？まぁこうやって頭を整理しつつ記事を書くのも、一種のアンガー・マネジメントなのかもしれない。\n中指1000本突き立てても気が済まないくらいrageな日々を送っているが、整理して調べていく過程で先ほどの素晴らしい翻訳に出会うことができた。これは幸運の極みだよ、力強く美しい言葉は、人間に偉大な力を与えてくれるんだから。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/dylan-thomas/","summary":"\u0026ldquo;rage\u0026quot;という英単語がある。名詞としては「激情、激怒、憤怒」、自動詞として「怒る、暴れる」という意味だ。これを知ったきっかけは、Tumblrで見かけた以下の引用だった。\n Do not go gentle into that good night.\nRage, rage against the dying of the light.\n  パッと見てすぐに意味は理解できなかったが何か心を捉えられた感があった。\u0026ldquo;rage\u0026quot;という単語を初めて見たので調べたところ、意味は先述の通り。\nこれはウェールズの詩人ディラン・トーマス(Dylan Thomas) の詩の一部である。でもTumblrの投稿にはOscar Wildeって書いたあったような記憶がある。それで最近までずっとこの引用元をOscar Wildeだと思い込んでいたんだから。間違いだったんだなあれは。\nそれはさておき、今日この詩について少し文献を調べてみたら、この引用に対して今までの自分の解釈が若干ズレていたことがわかった。以下は引用元の詩全体である。\n  Do not go gentle into that good night,\nOld age should burn and rage at close of day;\nRage, rage against the dying of the light.\nThough wise men at their end know dark is right,\nBecause their words had forked no lightning they","title":"単語rageを覚えたきっかけはディラン・トーマスの詩だった"},{"content":"Mac OSで標準搭載されているdateコマンドはBSD版であり、Linux標準のGNU版と微妙に異なる。Linuxと実行結果が異なったり、使用できないオプションがあったりとか。それが困るから、自宅のMacでもGNU版のdateが使いたいのである。数年前に標準のdateを入れたのだが、その後Mac本体を買い替えたタイミングで消えてしまった。\n Mac OSでgnu/dateを使いたい場合、brewから入れる。install dateではなく、coreutilsとする。（他のGNU系コマンド一式が含まれる）\n$ brew install coreutils  /usr/local/bin/gdateにインストールされた。（正確にはシンボリックリンク）\nこのままだとコマンドがgdateなので、gdateを\u0026quot;date\u0026quot;で実行できるようにする。以下エイリアスを.bashrcに追記。\nalias date='/usr/local/bin/gdate'  やっとできた。以下は所定の日付時刻をエポックタイム(UNIXタイムスタンプ)に変換するコマンド。Mac版のdateだと使えないんだよこれが。\n$ date -d '2018/5/17 00:00:00' +'%s' 1526482800  参考\nMacでdateコマンドが違う件について\nUNIX時間に変換・UNIX時間を取得する方法\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/mac-installe-gdate/","summary":"Mac OSで標準搭載されているdateコマンドはBSD版であり、Linux標準のGNU版と微妙に異なる。Linuxと実行結果が異なったり、使用できないオプションがあったりとか。それが困るから、自宅のMacでもGNU版のdateが使いたいのである。数年前に標準のdateを入れたのだが、その後Mac本体を買い替えたタイミングで消えてしまった。\n Mac OSでgnu/dateを使いたい場合、brewから入れる。install dateではなく、coreutilsとする。（他のGNU系コマンド一式が含まれる）\n$ brew install coreutils  /usr/local/bin/gdateにインストールされた。（正確にはシンボリックリンク）\nこのままだとコマンドがgdateなので、gdateを\u0026quot;date\u0026quot;で実行できるようにする。以下エイリアスを.bashrcに追記。\nalias date='/usr/local/bin/gdate'  やっとできた。以下は所定の日付時刻をエポックタイム(UNIXタイムスタンプ)に変換するコマンド。Mac版のdateだと使えないんだよこれが。\n$ date -d '2018/5/17 00:00:00' +'%s' 1526482800  参考\nMacでdateコマンドが違う件について\nUNIX時間に変換・UNIX時間を取得する方法\n ","title":"MacにGNU版dateをインストール"},{"content":"AWS CLI v2でデフォルトになっているページャを無効化する方法は2種類ある。\n configで設定  ~/.aws/configに以下記載する。\n[default] cli_pager=  環境変数で設定  $ export AWS_PAGER=\u0026quot;\u0026quot;  1.の方が推奨されているようだが、k8s(Kubernetes)のPodの場合は、マニフェストのENVに2.の環境変数を書いておけば期待値になる。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/awscli-pager/","summary":"AWS CLI v2でデフォルトになっているページャを無効化する方法は2種類ある。\n configで設定  ~/.aws/configに以下記載する。\n[default] cli_pager=  環境変数で設定  $ export AWS_PAGER=\u0026quot;\u0026quot;  1.の方が推奨されているようだが、k8s(Kubernetes)のPodの場合は、マニフェストのENVに2.の環境変数を書いておけば期待値になる。\n ","title":"AWS CLIのページャを無効化する"},{"content":"AWSで、CloudWatchアラームのメッセージをSNSトピックかましてメール送信。昔からよくあるオーソドックスなパターンだが、しばらく縁がなかったので記憶がかすんでいる。過去に構築した時の記録を掘り返してみる。\n数年前、CloudFormation（CFn）で環境構築したのだが（主担当は別のメンバー）、CWアラーム作成はCFnで作るのに不向きということでAWS CLIで作成していた。何故CFnが不向きなのか、理由は何だったか思い出せない。以下の記事を見ると普通にCFnでアラーム作成しているから問題なさそうではあるのだが\u0026hellip;\nCloudFormationでCloudWatchAlermを作成する\n ここで、書いていてうっすら思い出した。過去事例ではオートスケールのアラームだったが、その場合は他のアラームと異なるのかもしれない。（つまりオートスケールのアラームはポリシーを別出しにする）確かASG（オートスケーリンググループ）自体もCFnで作るのは不向きということでCLIで作成してた。CFnだと勝手に変な名前付けられるから、って理由だったかな。しかしハッキリとは思い出せない。\nもやもや感が払拭しきれないが、とりあえず過去のメモ書きをのせておく。\n ここから。\nオートスケーリンググループのCloudWatchアラーム作成時のポイントは、先にSNSトピック、ポリシーを作成する。ポリシー作成のCLIを実行するとARNが出力されるので、その値を定義してアラームを作成する。SNSトピック自体はCFnで作成していた。サブスクリプション作成はコンソールからやったような。グダグダな記憶だが、メールアドレスをサブスクライブする時に手動での承認が発生するのは確か。（設定したメールアドレスに届いたメール内のリンクを押下すると承認が完了する）\nサブスクリプション承認は手動になるが、アラーム作成時に指定するのはトピックARN。承認しないと後続作業ができないわけではない、と思われる。（ただし承認対応は3日以内に実施すること）\n以下、ec2オートスケーリングのスケールアウト/インポリシー作成CLIの例。ec2のオートスケールってパターンもすでにオールドファッション化しているけど\u0026hellip;、数年前の事例なので。\nスケールアウトポリシー\n$ aws autoscaling put-scaling-policy \\ --auto-scaling-group-name test-web-asg \\ --policy-name test-web-scaleout-policy \\ --scaling-adjustment 2 \\ --adjustment-type ChangeInCapacity \\ --cooldown 300 \\ --region ap-northeast-1  スケールインポリシー\n$ aws autoscaling put-scaling-policy \\ --auto-scaling-group-name test-web-asg \\ --policy-name test-web-scalein-policy \\ --scaling-adjustment -2 \\ --adjustment-type ChangeInCapacity \\ --cooldown 600 \\ --region ap-northeast-1  この後、以下のCLIを実行。スケールアウトアラーム作成CLI例。--alarm-actions オプションで 先に作成しておいた$snstopic, $scaleoutpolicy の値を指定している。\nsnstopic=\u0026quot;arn:aws:sns:ap-northeast-1:[AWSアカウントID]:test-alert-mail\u0026quot; scaleoutpolicy=\u0026quot;arn:aws:autoscaling:ap-northeast-1:[AWSアカウントID]:scalingPolicy:[ランダム値]:autoScalingGroupName/test-web-asg:policyName/test-web-scaleout-policy\u0026quot; $ aws cloudwatch put-metric-alarm \\ --alarm-name \u0026quot;test-web-scaleout-alarm\u0026quot; \\ --alarm-description \u0026quot;Alarm when CPU exceeds 70%\u0026quot; \\ --metric-name CPUUtilization \\ --namespace AWS/EC2 \\ --statistic Average \\ --period 60 \\ --threshold 70 \\ --comparison-operator GreaterThanThreshold \\ --dimensions Name=AutoScalingGroupName,Value=\u0026quot;test-web-asg\u0026quot; \\ --evaluation-periods 4 \\ --alarm-actions $scaleoutpolicy $snstopic \\ --unit Percent \\ --region ap-northeast-1  スケールイン時のアラームも同様に作成する。\n 以下備忘録。静観対応をどうするか\nCloudWatch アラームのダウンタイム（特定期間の発報抑止）を Metric Math を使用して実現してみた\n","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatch-alarm-memo/","summary":"AWSで、CloudWatchアラームのメッセージをSNSトピックかましてメール送信。昔からよくあるオーソドックスなパターンだが、しばらく縁がなかったので記憶がかすんでいる。過去に構築した時の記録を掘り返してみる。\n数年前、CloudFormation（CFn）で環境構築したのだが（主担当は別のメンバー）、CWアラーム作成はCFnで作るのに不向きということでAWS CLIで作成していた。何故CFnが不向きなのか、理由は何だったか思い出せない。以下の記事を見ると普通にCFnでアラーム作成しているから問題なさそうではあるのだが\u0026hellip;\nCloudFormationでCloudWatchAlermを作成する\n ここで、書いていてうっすら思い出した。過去事例ではオートスケールのアラームだったが、その場合は他のアラームと異なるのかもしれない。（つまりオートスケールのアラームはポリシーを別出しにする）確かASG（オートスケーリンググループ）自体もCFnで作るのは不向きということでCLIで作成してた。CFnだと勝手に変な名前付けられるから、って理由だったかな。しかしハッキリとは思い出せない。\nもやもや感が払拭しきれないが、とりあえず過去のメモ書きをのせておく。\n ここから。\nオートスケーリンググループのCloudWatchアラーム作成時のポイントは、先にSNSトピック、ポリシーを作成する。ポリシー作成のCLIを実行するとARNが出力されるので、その値を定義してアラームを作成する。SNSトピック自体はCFnで作成していた。サブスクリプション作成はコンソールからやったような。グダグダな記憶だが、メールアドレスをサブスクライブする時に手動での承認が発生するのは確か。（設定したメールアドレスに届いたメール内のリンクを押下すると承認が完了する）\nサブスクリプション承認は手動になるが、アラーム作成時に指定するのはトピックARN。承認しないと後続作業ができないわけではない、と思われる。（ただし承認対応は3日以内に実施すること）\n以下、ec2オートスケーリングのスケールアウト/インポリシー作成CLIの例。ec2のオートスケールってパターンもすでにオールドファッション化しているけど\u0026hellip;、数年前の事例なので。\nスケールアウトポリシー\n$ aws autoscaling put-scaling-policy \\ --auto-scaling-group-name test-web-asg \\ --policy-name test-web-scaleout-policy \\ --scaling-adjustment 2 \\ --adjustment-type ChangeInCapacity \\ --cooldown 300 \\ --region ap-northeast-1  スケールインポリシー\n$ aws autoscaling put-scaling-policy \\ --auto-scaling-group-name test-web-asg \\ --policy-name test-web-scalein-policy \\ --scaling-adjustment -2 \\ --adjustment-type ChangeInCapacity \\ --cooldown 600 \\ --region ap-northeast-1  この後、以下のCLIを実行。スケールアウトアラーム作成CLI例。--alarm-actions オプションで 先に作成しておいた$snstopic, $scaleoutpolicy の値を指定している。\nsnstopic=\u0026quot;arn:aws:sns:ap-northeast-1:[AWSアカウントID]:test-alert-mail\u0026quot; scaleoutpolicy=\u0026quot;arn:aws:autoscaling:ap-northeast-1:[AWSアカウントID]:scalingPolicy:[ランダム値]:autoScalingGroupName/test-web-asg:policyName/test-web-scaleout-policy\u0026quot; $ aws cloudwatch put-metric-alarm \\ --alarm-name \u0026quot;test-web-scaleout-alarm\u0026quot; \\ --alarm-description \u0026quot;Alarm when CPU exceeds 70%\u0026quot; \\ --metric-name CPUUtilization \\ --namespace AWS/EC2 \\ --statistic Average \\ --period 60 \\ --threshold 70 \\ --comparison-operator GreaterThanThreshold \\ --dimensions Name=AutoScalingGroupName,Value=\u0026quot;test-web-asg\u0026quot; \\ --evaluation-periods 4 \\ --alarm-actions $scaleoutpolicy $snstopic \\ --unit Percent \\ --region ap-northeast-1  スケールイン時のアラームも同様に作成する。","title":"CloudWatchアラーム作成時のメモ（過去事例）"},{"content":"SNSって誰をフォローするかも大きいけど誰にフォローされるか、も相当影響でかいんだなと思う。\nもともとSNS嫌いだからほとんどやってないけど、Tumblrは例外で、ここしばらく依存症に近いくらい使っている。全然使っていなかった時期もあるんだけどね。今は諸事情によりヘビーユーザー。\n当初はフォロワー僅か、だったが逆に好き勝手なことが書けた。Tumblrってテキスト投稿には向いてないと思うけど、それすら気にせずに画像だろうが音声だろうがテキストだろうが、好きなように投稿する。それがTumblrの良さ。\n当初投稿するのは自分の写真が中心で、たまにテキストあり、リブログはあまりしていなかった。特にフォローしたいアカウントもなかったけどたまに癒し系とか懐かし系画像投稿したいから適当に複数アカウントフォローしてた。でも、楽しくはなかったんだよね。「たまにこっち系の画像ポストするのはいいけどそれメインでやりたいわけじゃないし、なんか違う気がするなぁ」と違和感を覚え始めて、フォロー解除した。\n  しかしその後、何がきっかけか覚えていないのだが、あるアカウントとその周辺アカウントをフォロー開始してから、めっちゃ楽しくなってしまった。それらのアカウントは毎日投稿しているけど、リブログせずにいられないような、何かしらカッコイイポストが必ずある。経由されたポストやソースをポストしたアカウントを追うとこれまたセンスが良くて、芋づる式に夢中でlike,reblogしてしまうのである。\nTumblrのすごいところは、オリジナルのポスト作成者じゃなくても、センスのいいポストで構成されたブログが甚大な価値を持つことだ。「あなたのセンスは素晴らしい、本当に尊敬する！」と叫びたくなるようなアカウントが複数存在する。まだ出会えていないブログもあるかもしれない。実際最近になっても、「こんなセンスいいブログがあったんだ！」と新たに発見することがある。（もちろんそんなときに直接メッセージを送ったりはしない。1%程度の例外はあるだろうが、Tumblrでは誰もそんなこと望んでいないのだから）\nいいポストを集めたブログは自然にいいブログになる。オリジナルの作者かどうか、の区別はもはや意味をなさなくなる。いいものを発見してコレクションする、そのエネルギーが、見る人にインスピレーションや刺激を与えるのだ。それがTumblrの良さ。（二度目）\nこのことに気づいてから、俺は夢中になってしまった。Tumblr自体はずっと前からやっているのに、こんなに楽しいと感じたのは初めてといってもいい。\n  以上は「誰をフォローするか」による影響の話。ここから先、「誰にフォローされるか」について書いてみる。\n少し前のある日、これまで細々とした件数だった、零細アカウントの俺の通知が飛躍的に伸びた。たまに特定のポストのリアクションが増加することはあったが、その日は過去にない規模の反響だった。「何かあったか？」と追ってみると、ある人気アカウントが自分のポストを複数リブログしてた。そこから雪だるま式にリアクションが増えたわけである。これにより、自分のブログのフォロワーも増加した。増加といってもその日に十人くらい、その後日に数人ずつ程度のペースだが。ちなみに先の人気アカウントにもフォローされていた。\nしかし、正直あまりうれしくないし、逆に困る。「ある誰かが自分の投稿を見ている」ことを意識していると、書きにくいことが出てくるのである。画像のポストだけでみても、フォロワーにインフルエンサーとそのフォロワーがいると「何を投稿するか」について、これまで以上に他人を意識せざるを得なくなってしまうのである。それまでは「とにかく自分がポストしたいものをポストする」スタンスだったのに、他人にサービスするようなポストを挟んでしまうとか。実際その日以降、しばらくそんな状況が続いた。引き摺られてはいけない、と自覚しつつも、どこかで引き摺られてしまうのだ。\nで、この状況はストレスなのである。つまり楽しくないのである。楽しくないTumblrなんかやりなくない。自分が楽しむためにやっているんだから、プライオリティの優位をそっちに戻す必要がある。\u0026hellip;と、そのことを明確に言語化するためのこの投稿を書いた。\n実はこの件と前後して、先の方に書いたセンス抜群のアカウントからフォローしてもらった。これは嬉しかったね。俺のポストはそんなにリブログしてもらってないけど、たまにリブログしてもらうとやはり反響がすごい。まぁこの反響ってのも良し悪しだけどね、まったく反応がないと寂しいけどデカすぎても疲れる、さっき書いたように、よくない影響受けることがあるからね。まぁこれって、リアルライフで人混みに出ると疲れるのと同じことだと思う。\n  で、最終的に言いたいことは。\nリアルライフでもSNSでも、「自分の周囲に誰がいるか」の影響は非常に大きいのだ、と。\n人間は誰でもエネルギーを持っている。エネルギーは、良くも悪くも他者に影響を与える。ある人間が、良いエネルギーを放出している集団の中にいればおのずとよい影響を受ける。逆もまた然りである。リアルライフだとそのことを如実に実感するが、ネット上でもそれは同様だ。実際物事はそう単純ではないから、他者からの影響の方向や質はモザイクのように絡み合っているイメージではあるが\u0026hellip;\nTwitterとかFacebookみたいにガチで言葉の応酬をするようなSNSは当然その傾向が強いと思うが、Tumblrのように非常に関係性が薄いSNSでもそういうことがあるんだな、と今更ながら実感した次第。\n結論としては、Tumblrではいくつかのアカウントを本当にリスペクトしているけれど、自分の軸をずらさずにかつ一定の距離を保つ姿勢を貫くのが、長く楽しむコツだね。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/sns-influence/","summary":"SNSって誰をフォローするかも大きいけど誰にフォローされるか、も相当影響でかいんだなと思う。\nもともとSNS嫌いだからほとんどやってないけど、Tumblrは例外で、ここしばらく依存症に近いくらい使っている。全然使っていなかった時期もあるんだけどね。今は諸事情によりヘビーユーザー。\n当初はフォロワー僅か、だったが逆に好き勝手なことが書けた。Tumblrってテキスト投稿には向いてないと思うけど、それすら気にせずに画像だろうが音声だろうがテキストだろうが、好きなように投稿する。それがTumblrの良さ。\n当初投稿するのは自分の写真が中心で、たまにテキストあり、リブログはあまりしていなかった。特にフォローしたいアカウントもなかったけどたまに癒し系とか懐かし系画像投稿したいから適当に複数アカウントフォローしてた。でも、楽しくはなかったんだよね。「たまにこっち系の画像ポストするのはいいけどそれメインでやりたいわけじゃないし、なんか違う気がするなぁ」と違和感を覚え始めて、フォロー解除した。\n  しかしその後、何がきっかけか覚えていないのだが、あるアカウントとその周辺アカウントをフォロー開始してから、めっちゃ楽しくなってしまった。それらのアカウントは毎日投稿しているけど、リブログせずにいられないような、何かしらカッコイイポストが必ずある。経由されたポストやソースをポストしたアカウントを追うとこれまたセンスが良くて、芋づる式に夢中でlike,reblogしてしまうのである。\nTumblrのすごいところは、オリジナルのポスト作成者じゃなくても、センスのいいポストで構成されたブログが甚大な価値を持つことだ。「あなたのセンスは素晴らしい、本当に尊敬する！」と叫びたくなるようなアカウントが複数存在する。まだ出会えていないブログもあるかもしれない。実際最近になっても、「こんなセンスいいブログがあったんだ！」と新たに発見することがある。（もちろんそんなときに直接メッセージを送ったりはしない。1%程度の例外はあるだろうが、Tumblrでは誰もそんなこと望んでいないのだから）\nいいポストを集めたブログは自然にいいブログになる。オリジナルの作者かどうか、の区別はもはや意味をなさなくなる。いいものを発見してコレクションする、そのエネルギーが、見る人にインスピレーションや刺激を与えるのだ。それがTumblrの良さ。（二度目）\nこのことに気づいてから、俺は夢中になってしまった。Tumblr自体はずっと前からやっているのに、こんなに楽しいと感じたのは初めてといってもいい。\n  以上は「誰をフォローするか」による影響の話。ここから先、「誰にフォローされるか」について書いてみる。\n少し前のある日、これまで細々とした件数だった、零細アカウントの俺の通知が飛躍的に伸びた。たまに特定のポストのリアクションが増加することはあったが、その日は過去にない規模の反響だった。「何かあったか？」と追ってみると、ある人気アカウントが自分のポストを複数リブログしてた。そこから雪だるま式にリアクションが増えたわけである。これにより、自分のブログのフォロワーも増加した。増加といってもその日に十人くらい、その後日に数人ずつ程度のペースだが。ちなみに先の人気アカウントにもフォローされていた。\nしかし、正直あまりうれしくないし、逆に困る。「ある誰かが自分の投稿を見ている」ことを意識していると、書きにくいことが出てくるのである。画像のポストだけでみても、フォロワーにインフルエンサーとそのフォロワーがいると「何を投稿するか」について、これまで以上に他人を意識せざるを得なくなってしまうのである。それまでは「とにかく自分がポストしたいものをポストする」スタンスだったのに、他人にサービスするようなポストを挟んでしまうとか。実際その日以降、しばらくそんな状況が続いた。引き摺られてはいけない、と自覚しつつも、どこかで引き摺られてしまうのだ。\nで、この状況はストレスなのである。つまり楽しくないのである。楽しくないTumblrなんかやりなくない。自分が楽しむためにやっているんだから、プライオリティの優位をそっちに戻す必要がある。\u0026hellip;と、そのことを明確に言語化するためのこの投稿を書いた。\n実はこの件と前後して、先の方に書いたセンス抜群のアカウントからフォローしてもらった。これは嬉しかったね。俺のポストはそんなにリブログしてもらってないけど、たまにリブログしてもらうとやはり反響がすごい。まぁこの反響ってのも良し悪しだけどね、まったく反応がないと寂しいけどデカすぎても疲れる、さっき書いたように、よくない影響受けることがあるからね。まぁこれって、リアルライフで人混みに出ると疲れるのと同じことだと思う。\n  で、最終的に言いたいことは。\nリアルライフでもSNSでも、「自分の周囲に誰がいるか」の影響は非常に大きいのだ、と。\n人間は誰でもエネルギーを持っている。エネルギーは、良くも悪くも他者に影響を与える。ある人間が、良いエネルギーを放出している集団の中にいればおのずとよい影響を受ける。逆もまた然りである。リアルライフだとそのことを如実に実感するが、ネット上でもそれは同様だ。実際物事はそう単純ではないから、他者からの影響の方向や質はモザイクのように絡み合っているイメージではあるが\u0026hellip;\nTwitterとかFacebookみたいにガチで言葉の応酬をするようなSNSは当然その傾向が強いと思うが、Tumblrのように非常に関係性が薄いSNSでもそういうことがあるんだな、と今更ながら実感した次第。\n結論としては、Tumblrではいくつかのアカウントを本当にリスペクトしているけれど、自分の軸をずらさずにかつ一定の距離を保つ姿勢を貫くのが、長く楽しむコツだね。","title":"Tumblrについて、ひとり言"},{"content":"前回投稿でAWS CodePipelineのクロスアカウント設定（前半）ではリソース配布元のアカウントAの内容中心に書いた。後半は配布先となるアカウントBの設定内容を書いていく。\n前回投稿\nAWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-1）\n繰り返しになるけれども、前提条件をおさらいとして記載。\nやりたいこと\nAWSの異なるアカウント間で、CodePipelineによりCodeDeployからec2インスタンスにリソースをデプロイする。ソースはリソース配布側のCodeCommit。この記事では配布元を開発環境/アカウントA、配布先を検証環境/アカウントBとして話を進める。 主な参考ページ\n他のリソースを使用するパイプラインを CodePipeline で作成するAWSアカウント\n 主な構成要素 これも前回書いているが、こっちにも書いておかないとわけわからなくなるので再掲。\n1-資材配布元（アカウントA）\n① CodeCommitリポジトリ（ec2にローカルリポジトリを作成〜資材格納）\n② KMSキー (両方のアカウントにアクセス許可する)\n③ S3バケット (アカウントBにアクセス許可するバケットポリシーを付与）\n④ CodePipelineが使用するサービスロール\n⑤ CodePipleline定義（コンソールで作成したパイプライン定義JSONをCLIから更新）\n 2-資材配布先（アカウントB）\n① CodeDeploy定義（アプリケーション/デプロイメントグループ）\n② ec2用のIAMロール（CodeDeployがアカウントAのKMSキー、S3にアクセスするためのポリシーを付与）\n③ ②のIAMロールをアタッチしたデプロイ先ec2\n④ クロスアカウント用サービスロール（CodeDeployとS3操作にassumeする）\n 上記アイテムを作成済みとして、作業概要は前回記事に記載した。以降、アカウントB側で用意するアイテムの内容を書く。\n2-① CodeDeploy定義\nアカウントBのコンソールにて、アプリケーションとデプロイメントグループを作成する。詳細は割愛。\n2-② ec2用のIAMロール\nKMSとS3用のインラインポリシーを作成する。AWS参考ページでは2つに分けていたが統合しても問題ないと思う。\nKMS用インラインポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:DescribeKey\u0026#34;, \u0026#34;kms:GenerateDataKey*\u0026#34;, \u0026#34;kms:Encrypt\u0026#34;, \u0026#34;kms:ReEncrypt*\u0026#34;, \u0026#34;kms:Decrypt\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:kms:us-east-1:[アカウントAのID]:key/[Key ID]\u0026#34; #KMSのARN ] } ] }  S3用インラインポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:Get*\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::[アカウントAのS3バケット名]/*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::[アカウントAのS3バケット名]\u0026#34; ] } ] }  2-④ クロスアカウントデプロイ用IAMロール\nサービスをCodeDeployとしてロールを作成する。この時アカウントAにassumeする前提で以下設定を行う。以下図の矢印箇所にアカウントAのIDを入力して次へ進む。これ以降は通常のロール作成時と同じ。\n デプロイ用ロール信頼ポリシーのJSONは以下のようになる。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::[アカウントAのID]:root\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Condition\u0026#34;: {} }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;codedeploy.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] }  デプロイ用メインのカスタムポリシー。CodeDeployのパーミッションを定義。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;codedeploy:CreateDeployment\u0026#34;, \u0026#34;codedeploy:GetDeployment\u0026#34;, \u0026#34;codedeploy:GetDeploymentConfig\u0026#34;, \u0026#34;codedeploy:GetApplicationRevision\u0026#34;, \u0026#34;codedeploy:RegisterApplicationRevision\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] }  デプロイ用インラインポリシー。S3とCodeCommitのパーミッション定義。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject*\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:PutObjectAcl\u0026#34;, \u0026#34;codecommit:ListBranches\u0026#34;, \u0026#34;codecommit:ListRepositories\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::[S3バケット名]/*\u0026#34; ] } ] }  これとは別にec2周りのポリシーも割り当てる。検証時は取り急ぎマネージドのAmazonEC2ReadOnlyAccessでもアタッチしておけばいい。\n これでやっとアイテムが出揃った。ここまで来たら、前回投稿の分も重複するがアカウントAの環境にて以下実行。（2. までは前回までの段階で完了しているとして、3.以降を実施）\n コンソールで単体アカウント用にパイプラインを作成 そのJSON定義を取得してクロスアカウント向けに編集 パイプラインをアップデート  $ aws codepipeline update-pipeline --cli-input-json file://[パイプライン名].json  アップデートしたパイプラインをスタート  $ aws codepipeline start-pipeline-execution --name [パイプライン名]  特にエラーが出なければパイプラインは走っているが、その先でコケることはよくあるのでコンソール画面から状況を確認する。アカウントAのマネジメントコンソール画面から全体の状況は把握できる。デプロイステージの詳細はアカウントBのコンソールからしか見れない。\nというわけで、果てしなく続くと思われた長い旅路がようやく終わりましたよ。しかしいいかげんに普通の旅にも出たいもんだ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/aws-crossaccount-pipeline-2/","summary":"前回投稿でAWS CodePipelineのクロスアカウント設定（前半）ではリソース配布元のアカウントAの内容中心に書いた。後半は配布先となるアカウントBの設定内容を書いていく。\n前回投稿\nAWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-1）\n繰り返しになるけれども、前提条件をおさらいとして記載。\nやりたいこと\nAWSの異なるアカウント間で、CodePipelineによりCodeDeployからec2インスタンスにリソースをデプロイする。ソースはリソース配布側のCodeCommit。この記事では配布元を開発環境/アカウントA、配布先を検証環境/アカウントBとして話を進める。 主な参考ページ\n他のリソースを使用するパイプラインを CodePipeline で作成するAWSアカウント\n 主な構成要素 これも前回書いているが、こっちにも書いておかないとわけわからなくなるので再掲。\n1-資材配布元（アカウントA）\n① CodeCommitリポジトリ（ec2にローカルリポジトリを作成〜資材格納）\n② KMSキー (両方のアカウントにアクセス許可する)\n③ S3バケット (アカウントBにアクセス許可するバケットポリシーを付与）\n④ CodePipelineが使用するサービスロール\n⑤ CodePipleline定義（コンソールで作成したパイプライン定義JSONをCLIから更新）\n 2-資材配布先（アカウントB）\n① CodeDeploy定義（アプリケーション/デプロイメントグループ）\n② ec2用のIAMロール（CodeDeployがアカウントAのKMSキー、S3にアクセスするためのポリシーを付与）\n③ ②のIAMロールをアタッチしたデプロイ先ec2\n④ クロスアカウント用サービスロール（CodeDeployとS3操作にassumeする）\n 上記アイテムを作成済みとして、作業概要は前回記事に記載した。以降、アカウントB側で用意するアイテムの内容を書く。\n2-① CodeDeploy定義\nアカウントBのコンソールにて、アプリケーションとデプロイメントグループを作成する。詳細は割愛。\n2-② ec2用のIAMロール\nKMSとS3用のインラインポリシーを作成する。AWS参考ページでは2つに分けていたが統合しても問題ないと思う。\nKMS用インラインポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:DescribeKey\u0026#34;, \u0026#34;kms:GenerateDataKey*\u0026#34;, \u0026#34;kms:Encrypt\u0026#34;, \u0026#34;kms:ReEncrypt*\u0026#34;, \u0026#34;kms:Decrypt\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:kms:us-east-1:[アカウントAのID]:key/[Key ID]\u0026#34; #KMSのARN ] } ] }  S3用インラインポリシー","title":"AWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-2）"},{"content":"前回投稿ではパイプラインなしでAWS クロスアカウントデプロイをやった。次はパイプラインを使ってやってみる。長くなるので前半/後半に分ける。\n やりたいこと\nAWSの異なるアカウント間で、CodePipelineによりCodeDeployからec2インスタンスにリソースをデプロイする。ソースはリソース配布側のCodeCommit。この記事では配布元を開発環境/アカウントA、配布先を検証環境/アカウントBとして話を進める。（ec2はオートスケールもなくただ単に配布するだけなので単一アカウントだったら簡単な話なんだが、アカウント跨ぐとなるとめっちゃ面倒くさい\u0026hellip;）\n 主な参考ページ\n他のリソースを使用するパイプラインを CodePipeline で作成するAWSアカウント\n 基本的にこのページの通りにやればOK。アカウントA側で一度単一アカウント用の適当なパイプラインを作成して、そのJSON定義を取得。それをクロスアカウント用に編集してCLIからアップデートする。ちなみに上記リンクは日本語版だが機械翻訳の文章がまともな日本語ではなくイラッとくるので、ほぼオリジナルの英語版を参考にした。\n参考までに、以下クラメソさんの記事。当初これのBuildをDeployに置き換えてやってみたが失敗した。不足か誤りがあるんだろうがいきなりやったこともありわけがわからなすぎて頓挫。先述のAWS公式の方がやりたいことに近かったため仕切り直しした。\nクロスアカウントCodeBuild + パイプライン例\nCodePipelineでアカウントをまたいだパイプラインを作成してみる\n 制約事項\n クロスアカウントのパイプラインはマネジメントコンソールから作成不可のため、aws cliから作成/更新する CodeDeployの定義とデプロイ先のec2は同一アカウントであること クロスアカウントでパイプラインを組む場合、アーティファクト格納用S3バケットの暗号化キーはKMSを使用する（AWS デフォルトの暗号化キーはNG）   主な構成要素 2アカウント間で各種アイテムを用意することになり、混乱しがちなのでまとめておく。前回投稿では配布先となるアカウントB側にS3バケットがある構成だったが、今回は逆。ただし構成的にはこちらの方が自然かと思う。\n1-資材配布元（アカウントA）\n① CodeCommitリポジトリ（ec2にローカルリポジトリを作成〜資材格納）\n② KMSキー (両方のアカウントにアクセス許可する)\n③ S3バケット (アカウントBにアクセス許可するバケットポリシーを付与）\n④ CodePipelineが使用するサービスロール\n⑤ CodePipleline定義（コンソールで作成したパイプライン定義JSONをCLIから更新）\nJSON取得コマンド\n$ aws codepipeline get-pipeline --name [パイプライン名] \u0026gt; [パイプライン名].json  2-資材配布先（アカウントB）\n① CodeDeploy定義（アプリケーション/デプロイメントグループ）\n② ec2用のIAMロール（CodeDeployがアカウントAのKMSキー、S3にアクセスするためのポリシーを付与）\n③ ②のIAMロールをアタッチしたデプロイ先ec2\n④ クロスアカウント用サービスロール（CodeDeployとS3操作にassumeする）\n 作業概要 上記各リソースを作成済として、以下の作業を行う。\nアカウントAの作業用端末またはec2にログイン。1-⑤のパイプライン定義JSONを適当なパスに配置し、パイプラインをアップデートする\n$ cd /path/to/json $ aws codepipeline update-pipeline --cli-input-json file://[パイプライン名].json  アップデートしたパイプラインを実行する\n$ aws codepipeline start-pipeline-execution --name [パイプライン名]  アカウントBでは特に作業なし。デプロイステータスが成功になったら、ec2に資材がデプロイされていることを確認する。\nクロスアカウントパイプラインの処理中の見え方\nアカウントAのマネジメントコンソール：パイプライン全体の処理状況は見える。デプロイステージの詳細は見れない。\nアカウントBのコンソール : デプロイの詳細が見れる\n 各種アイテムのサンプル AWS公式でも基本内容は網羅されているが自分用メモとしてここにも載せておく。\nアカウントA側アイテム\n1-② KMSキーポリシー\nアーティファクト用S3バケットの暗号化キーポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;[key-policy-name]\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Enable IAM User Permissions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::[アカウントAのID]:root\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;kms:*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;Allow access for Key Administrators\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;[KMSの暗号化キーの管理ユーザのARN]\u0026#34; #アカウントA側のキーのオーナーを指定 }, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:Create*\u0026#34;, \u0026#34;kms:Describe*\u0026#34;, \u0026#34;kms:Enable*\u0026#34;, \u0026#34;kms:List*\u0026#34;, \u0026#34;kms:Put*\u0026#34;, \u0026#34;kms:Update*\u0026#34;, \u0026#34;kms:Revoke*\u0026#34;, \u0026#34;kms:Disable*\u0026#34;, \u0026#34;kms:Get*\u0026#34;, \u0026#34;kms:Delete*\u0026#34;, \u0026#34;kms:TagResource\u0026#34;, \u0026#34;kms:UntagResource\u0026#34;, \u0026#34;kms:ScheduleKeyDeletion\u0026#34;, \u0026#34;kms:CancelKeyDeletion\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;Allow use of the key\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: [ \u0026#34;[アカウントAのパイプライン用サービスロールのARN]\u0026#34;, #(注1) \u0026#34;arn:aws:iam::[アカウントBのID]:root\u0026#34; ] }, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:Encrypt\u0026#34;, \u0026#34;kms:Decrypt\u0026#34;, \u0026#34;kms:ReEncrypt*\u0026#34;, \u0026#34;kms:GenerateDataKey*\u0026#34;, \u0026#34;kms:DescribeKey\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;Allow attachment of persistent resources\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: [ \u0026#34;[アカウントAのパイプライン用サービスロールのARN]\u0026#34;, #(注1) \u0026#34;arn:aws:iam::[アカウントBのID]:root\u0026#34; ] }, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:CreateGrant\u0026#34;, \u0026#34;kms:ListGrants\u0026#34;, \u0026#34;kms:RevokeGrant\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;Bool\u0026#34;: { \u0026#34;kms:GrantIsForAWSResource\u0026#34;: \u0026#34;true\u0026#34; } } } ] } (注1) 構文\narn:aws:iam::[アカウントAのID]:role/[パイプラインロール名]\n 1-③ S3バケットポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;SSEAndSSLPolicy\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;DenyUnEncryptedObjectUploads\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::[S3バケット名]/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringNotEquals\u0026#34;: { \u0026#34;s3:x-amz-server-side-encryption\u0026#34;: \u0026#34;aws:kms\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;DenyInsecureConnections\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::[S3バケット名]/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;Bool\u0026#34;: { \u0026#34;aws:SecureTransport\u0026#34;: false } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::[アカウントBのID]:root\u0026#34; }, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:Get*\u0026#34;, \u0026#34;s3:Put*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::[S3バケット名]/*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::[アカウントBのID]:root\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::[S3バケット名]\u0026#34; } ] }  1-④ CodePipelineが使用するサービスロール(IAM)\nこのロールには以下のポリシーを割り当てる。1.はロール作成前に作成可能。コンソールからロール作成する時に選択可能なサービスにCodePipelineがないので一旦CodeDeployで作成して、後から信頼ポリシー編集した。\n 通常のCodePipeline作業用ポリシー アカウントBのassume用インラインポリシー 信頼ポリシー（編集）  以下CodePipeline作業用ポリシー。AWSが自動で付与するポリシーは他のパーミッションも多く含まれているがそこから削って最小限にしたのがこれ。autoscalingは使わないんだけど一応残す。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Action\u0026#34;: [ \u0026#34;iam:PassRole\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEqualsIfExists\u0026#34;: { \u0026#34;iam:PassedToService\u0026#34;: [ \u0026#34;ec2.amazonaws.com\u0026#34; ] } } }, { \u0026#34;Action\u0026#34;: [ \u0026#34;codecommit:CancelUploadArchive\u0026#34;, \u0026#34;codecommit:GetBranch\u0026#34;, \u0026#34;codecommit:GetCommit\u0026#34;, \u0026#34;codecommit:GetUploadArchiveStatus\u0026#34;, \u0026#34;codecommit:UploadArchive\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; }, { \u0026#34;Action\u0026#34;: [ \u0026#34;codedeploy:CreateDeployment\u0026#34;, \u0026#34;codedeploy:GetApplication\u0026#34;, \u0026#34;codedeploy:GetApplicationRevision\u0026#34;, \u0026#34;codedeploy:GetDeployment\u0026#34;, \u0026#34;codedeploy:GetDeploymentConfig\u0026#34;, \u0026#34;codedeploy:RegisterApplicationRevision\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; }, { \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:*\u0026#34;, \u0026#34;elasticloadbalancing:*\u0026#34;, \u0026#34;autoscaling:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;s3:*\u0026#34;, \u0026#34;tag:*\u0026#34;, \u0026#34;logs:*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; } ] }  アカウントBのassume用インラインポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:iam::[アカウントBのID]:role/*\u0026#34; ] } }  信頼ポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: [ \u0026#34;codepipeline.amazonaws.com\u0026#34;, \u0026#34;codedeploy.amazonaws.com\u0026#34;, \u0026#34;ec2.amazonaws.com\u0026#34; ] }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] }  1-⑤ CodePiplelineのJSON定義\n冒頭のAWS公式ページにもポイントは記載されているが、今回のケースでまとめたのがこれ。繰り返しになるが、「1.コンソールで単体アカウント用にパイプラインを作成 2. そのJSON定義を取得してクロスアカウント向けに編集 3. パイプラインをアップデート」という流れになる。最初にパイプラインを作成するときにCodeDeploy用定義が必要なため、事前にアカウントA内で適当なCodeDeployアプリケーション/デプロイメントグループのペアを用意しておく。\n以下のJSON後半でアカウントB側のアイテム定義名をいくつか記載しており、当然アカウントB側に実体が存在する前提だが、編集時点では存在していなくても構わない。\n{ \u0026#34;pipeline\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;A_crossdeploy_pipeline\u0026#34;, \u0026#34;roleArn\u0026#34;: \u0026#34;arn:aws:iam::[アカウントAのID]:role/[クロスアカウントパイプライン用IAMロール名]\u0026#34;, \u0026#34;artifactStore\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;S3\u0026#34;, \u0026#34;location\u0026#34;: \u0026#34;[S3バケット名]\u0026#34; \u0026#34;encryptionKey\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;arn:aws:kms:us-east-1:[アカウントAのID]:key/[キーのID]\u0026#34;, #KMSキーのARN \u0026#34;type\u0026#34;: \u0026#34;KMS\u0026#34; }, \u0026#34;stages\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Source\u0026#34;, \u0026#34;actions\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Source\u0026#34;, \u0026#34;actionTypeId\u0026#34;: { \u0026#34;category\u0026#34;: \u0026#34;Source\u0026#34;, \u0026#34;owner\u0026#34;: \u0026#34;AWS\u0026#34;, \u0026#34;provider\u0026#34;: \u0026#34;CodeCommit\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1\u0026#34; }, \u0026#34;runOrder\u0026#34;: 1, \u0026#34;configuration\u0026#34;: { \u0026#34;BranchName\u0026#34;: \u0026#34;master\u0026#34;, \u0026#34;OutputArtifactFormat\u0026#34;: \u0026#34;CODE_ZIP\u0026#34;, \u0026#34;PollForSourceChanges\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;RepositoryName\u0026#34;: \u0026#34;[ソースリポジトリ名]\u0026#34; }, \u0026#34;outputArtifacts\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;SourceArtifact\u0026#34; } ], \u0026#34;roleArn\u0026#34; : \u0026#34;arn:aws:iam::[アカウントAのID]:role/[クロスアカウントパイプライン用IAMロール名]\u0026#34;, #冒頭で指定したIAMと同じ \u0026#34;inputArtifacts\u0026#34;: [], \u0026#34;region\u0026#34;: \u0026#34;ap-northeast-1\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;SourceVariables\u0026#34; } ] }, { \u0026#34;name\u0026#34;: \u0026#34;Deploy\u0026#34;, \u0026#34;actions\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;ExternalDeploy\u0026#34;, #Deploy --＞ ExternalDeployに変更 \u0026#34;actionTypeId\u0026#34;: { \u0026#34;category\u0026#34;: \u0026#34;Deploy\u0026#34;, \u0026#34;owner\u0026#34;: \u0026#34;AWS\u0026#34;, \u0026#34;provider\u0026#34;: \u0026#34;CodeDeploy\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1\u0026#34; }, \u0026#34;runOrder\u0026#34;: 1, \u0026#34;configuration\u0026#34;: { \u0026#34;ApplicationName\u0026#34;: \u0026#34;[アカウントBのコードデプロイアプリケーション名]\u0026#34;, \u0026#34;DeploymentGroupName\u0026#34;: \u0026#34;[アカウントBのコードデプロイデプロイメントグループ名]\u0026#34; }, \u0026#34;outputArtifacts\u0026#34;: [], \u0026#34;inputArtifacts\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;SourceArtifact\u0026#34; } ], \u0026#34;roleArn\u0026#34; : \u0026#34;arn:aws:iam::[アカウントBのID]:role/[アカウントBのクロスデプロイ用IAMロール名]\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-northeast-1\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;DeployVariables\u0026#34; } ] } ], \u0026#34;version\u0026#34;: 1 } }  やっとここまできた\u0026hellip;長かった。しかしまだ道は続く。次回、アカウントB側の設定内容を書く。\n続き\nAWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-2）\n","permalink":"https://ecnedaced-seirots.github.io/post/a/aws-crossaccount-pipeline-1/","summary":"前回投稿ではパイプラインなしでAWS クロスアカウントデプロイをやった。次はパイプラインを使ってやってみる。長くなるので前半/後半に分ける。\n やりたいこと\nAWSの異なるアカウント間で、CodePipelineによりCodeDeployからec2インスタンスにリソースをデプロイする。ソースはリソース配布側のCodeCommit。この記事では配布元を開発環境/アカウントA、配布先を検証環境/アカウントBとして話を進める。（ec2はオートスケールもなくただ単に配布するだけなので単一アカウントだったら簡単な話なんだが、アカウント跨ぐとなるとめっちゃ面倒くさい\u0026hellip;）\n 主な参考ページ\n他のリソースを使用するパイプラインを CodePipeline で作成するAWSアカウント\n 基本的にこのページの通りにやればOK。アカウントA側で一度単一アカウント用の適当なパイプラインを作成して、そのJSON定義を取得。それをクロスアカウント用に編集してCLIからアップデートする。ちなみに上記リンクは日本語版だが機械翻訳の文章がまともな日本語ではなくイラッとくるので、ほぼオリジナルの英語版を参考にした。\n参考までに、以下クラメソさんの記事。当初これのBuildをDeployに置き換えてやってみたが失敗した。不足か誤りがあるんだろうがいきなりやったこともありわけがわからなすぎて頓挫。先述のAWS公式の方がやりたいことに近かったため仕切り直しした。\nクロスアカウントCodeBuild + パイプライン例\nCodePipelineでアカウントをまたいだパイプラインを作成してみる\n 制約事項\n クロスアカウントのパイプラインはマネジメントコンソールから作成不可のため、aws cliから作成/更新する CodeDeployの定義とデプロイ先のec2は同一アカウントであること クロスアカウントでパイプラインを組む場合、アーティファクト格納用S3バケットの暗号化キーはKMSを使用する（AWS デフォルトの暗号化キーはNG）   主な構成要素 2アカウント間で各種アイテムを用意することになり、混乱しがちなのでまとめておく。前回投稿では配布先となるアカウントB側にS3バケットがある構成だったが、今回は逆。ただし構成的にはこちらの方が自然かと思う。\n1-資材配布元（アカウントA）\n① CodeCommitリポジトリ（ec2にローカルリポジトリを作成〜資材格納）\n② KMSキー (両方のアカウントにアクセス許可する)\n③ S3バケット (アカウントBにアクセス許可するバケットポリシーを付与）\n④ CodePipelineが使用するサービスロール\n⑤ CodePipleline定義（コンソールで作成したパイプライン定義JSONをCLIから更新）\nJSON取得コマンド\n$ aws codepipeline get-pipeline --name [パイプライン名] \u0026gt; [パイプライン名].json  2-資材配布先（アカウントB）\n① CodeDeploy定義（アプリケーション/デプロイメントグループ）\n② ec2用のIAMロール（CodeDeployがアカウントAのKMSキー、S3にアクセスするためのポリシーを付与）\n③ ②のIAMロールをアタッチしたデプロイ先ec2\n④ クロスアカウント用サービスロール（CodeDeployとS3操作にassumeする）\n 作業概要 上記各リソースを作成済として、以下の作業を行う。\nアカウントAの作業用端末またはec2にログイン。1-⑤のパイプライン定義JSONを適当なパスに配置し、パイプラインをアップデートする\n$ cd /path/to/json $ aws codepipeline update-pipeline --cli-input-json file://[パイプライン名].","title":"AWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-1）"},{"content":"AWS環境で、クロスアカウントでCI/CDしたい。とりあえずBuildフェーズはいらなくてDeployだけでいい。Deployの実行はパイプラインあり/なし両方可能。どちらも単一アカウント内なら複雑な設定もなく比較的容易にできることはわかっているが、クロスアカウントとなると何かと面倒だ。でもやってみる。ここではまずはパイプラインなしとする。\n 参考\n異なる AWS アカウントでアプリケーションをデプロイする\n（上記ページにリンクあり。assumeロールの設定は以下参考）\nIAM チュートリアル: AWS アカウント間の IAM ロールを使用したアクセスの委任\n 環境前提 配布元となるAWS開発環境(Dev)にCodeCommitのローカルリポジトリがあり、そこから別アカウントの検証環境(Stg)にデプロイする。その先には本番環境がある想定だが構成は同じになるはず。\n① 配布元(Dev)\n② 配布先(Stg)\n概要 ①配布元のアカウントから②配布先のec2にデプロイ可能とするため、②配布先アカウント側で①アカウントのassumeを可能とするIAMロールを作成する。（ロールAとする）① 配布元アカウント側でロールAにassumeし、デプロイを実行する。\n基本的に必要となるのはIAM周りの設定であり、ネットワーク系の特別な実装は必要ない。\n 作業内容   配布先②アカウントにて、配置用のS3バケットを作成する。IAMロールのポリシーでバケットへのアクセス権限を定義するため、バケットポリシーは設定しなくても問題なし。(注1)\n  配布先②アカウントにて、①がassumeするためのロールAを作成する。\n  ロールAで定義する内容 (1) 信頼ポリシーで②のアカウントIDを指定してassumeを許可する。このときrootか②側のIAMロールどちらかを指定する。\nrootに設定した場合は、①アカウントでデプロイを実行するユーザのグループにassume可能とするインラインポリシーを適用する。\nIAMに設定した場合は、①アカウントでデプロイを実行するec2にこのIAMロールを適用する。実行環境がec2の場合はこれでよいが、クライアント端末の場合はrootにする。\n インラインポリシー例 (①アカウントで設定) デプロイ実行ユーザが所属するグループの画面を開き、[アクセス許可] タブ \u0026ndash;\u0026gt; [アクセス許可の追加] \u0026ndash;\u0026gt; [インラインポリシーの作成] [JSON] タブ選択\n以下の内容を設定する。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:iam::②配布先のアカウントID:role/ロールA\u0026#34; } }  (2) ①のアカウントが資材配置用のS3にアクセスするための権限を定義したポリシーを適用する。ちゃんと書いてないけど以下にcodedeploy, ec2の操作権限も追加する。codedeployの権限は何が必要かわからないのでとりあえず全許可にしておいた。ECSへのデプロイだとec2のterminate権限が必要みたいだが、今回の場合ec2は参照のみでOKだと思う。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:GetBucketLocation\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::staging-app\u0026#34; #検証環境の資材格納バケット名 }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::staging-app/*\u0026#34; } ] }  ②配布先アカウントにて、deployのアプリケーションとデプロイメントグループを作成する。詳細は割愛。   ①配布元アカウントのec2（または同アカウントのcredentialsをセットした端末）にログインし、ロールAにスイッチする。ちなみにマネジメントコンソールでもスイッチして作業可能だが、deployのpushコマンドがCLIでしかできないため、ここではCLI前提で話を進める。  この時先で作成したロールAにスイッチするため、以下のコマンドを実行する。\n$ aws sts assume-role --role-arn \u0026quot;②配布先のアカウントID:role/ロールA\u0026quot; --role-session-name \u0026quot;deployment-test\u0026quot;  すると以下の形式の認証情報が出力される。\n{ \u0026#34;Credentials\u0026#34;: { \u0026#34;AccessKeyId\u0026#34;: \u0026#34;[access key id]\u0026#34; \u0026#34;SecretAccessKey\u0026#34;: \u0026#34;[secret access key id]\u0026#34;, \u0026#34;SessionToken\u0026#34;: \u0026#34;[token id]\u0026#34;, \u0026#34;Expiration\u0026#34;: \u0026#34;2021-09-20T15:08:00Z\u0026#34; } }  上記を環境変数にセットする。Windowsの場合はexportをsetに変更する。\n$ export AWS_ACCESS_KEY_ID=[access key id] $ export AWS_SECRET_ACCESS_KEY=[secret access key id] $ export AWS_SESSION_TOKEN=[token id]  これでセッション保持期間の間（expireの時刻)は②アカウントのロールAの権限で作業が可能となる。セッション時間はデフォルトで1時間だが、伸ばしたい場合は--duration-secondsオプションを使う。（2時間なら7200、3時間なら10800と指定。ロールAの最大セッション期間がそれに応じた時間に設定されている前提）\n デプロイ実行  最初にやる時はデプロイ前にaws s3 cpを実行して、対象S3バケットへ読み書き可能かチェックしておくとよい。\nCLIでpush [オプション]を実行し、S3に資材を格納する。この時 3.で作成したアプリケーション名を指定する。（これによりただ単にS3に資材を配置するのではなく、資材をアプリケーションのリビジョンと関連付けることになる）sourceはここではCodeCommitのローカルリポジトリパスを指定しているが、指定するのはappspec.ymlを配置したディレクトリとなる。\n$ aws deploy push ¥ --application-name [aplication-name] ¥ --s3-location s3://[staging-app]/[staging-app-key] ¥ --ignore-hidden-files ¥ --source /path/to/source  pushが成功すると資材がzip形式で格納される。ターミナル上ではE-Tagを含む実行コマンド情報が標準出力される。詳細は割愛するがこれを元にcreate-deploymentにてデプロイを実行する。この時 3.で作成したデプロイメントグループを指定する。成功すれば②配布先となるec2にS3から資材が配置される。ちなみにpushはコンソールから実行できないが、デプロイは可能である。しかしそのために実行画面を切り替えるのも面倒なので（コンソールでもassumeする）、ここは引き続きCLIでやる方が自然かと。\n (注1) 配布元①アカウントにバケットを作成してもよいが、また追加の設定が必要となる。今回は配布先②に作成した。\n その他ポイント 最初deployのコマンドは通ったがその先で失敗した。この時コンソール上では以下のエラーが表示されていた。\n The overall deployment failed because too many individual instances failed deployment, too few healthy instances are available for deployment, or some instances in your deployment group are experiencing problems.\n  これだけではわからないのでログを確認してみたところ、こんなエラーが繰り返し吐かれていた。\n/var/log/aws/codedeploy-agent/codedeploy-agent.log\n InstanceAgent::Plugins::CodeDeployPlugin::CommandPoller: Missing credentials - please check if this instance was started with an IAM instance profile\n  確かに配布先ec2にはIAMロールをアタッチしていなかったため、インスタンスプロファイルが存在しない。するとcodedepoloyエージェントが上記のログを吐くわけだ。配布先のec2にインスタンスプロファイルを割り当てるため、別途IAMロールを作成してIAMロールをアタッチしたところ成功した。\nIAMをアタッチしても同じエラーが出る場合、エージェントを再起動してみる。候補が表示されなかったりエラーになったりしてIAMのアタッチ自体が不可能な場合は、インスタンスを一旦停止して再試行してみる。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/cross-account-codedeploy/","summary":"AWS環境で、クロスアカウントでCI/CDしたい。とりあえずBuildフェーズはいらなくてDeployだけでいい。Deployの実行はパイプラインあり/なし両方可能。どちらも単一アカウント内なら複雑な設定もなく比較的容易にできることはわかっているが、クロスアカウントとなると何かと面倒だ。でもやってみる。ここではまずはパイプラインなしとする。\n 参考\n異なる AWS アカウントでアプリケーションをデプロイする\n（上記ページにリンクあり。assumeロールの設定は以下参考）\nIAM チュートリアル: AWS アカウント間の IAM ロールを使用したアクセスの委任\n 環境前提 配布元となるAWS開発環境(Dev)にCodeCommitのローカルリポジトリがあり、そこから別アカウントの検証環境(Stg)にデプロイする。その先には本番環境がある想定だが構成は同じになるはず。\n① 配布元(Dev)\n② 配布先(Stg)\n概要 ①配布元のアカウントから②配布先のec2にデプロイ可能とするため、②配布先アカウント側で①アカウントのassumeを可能とするIAMロールを作成する。（ロールAとする）① 配布元アカウント側でロールAにassumeし、デプロイを実行する。\n基本的に必要となるのはIAM周りの設定であり、ネットワーク系の特別な実装は必要ない。\n 作業内容   配布先②アカウントにて、配置用のS3バケットを作成する。IAMロールのポリシーでバケットへのアクセス権限を定義するため、バケットポリシーは設定しなくても問題なし。(注1)\n  配布先②アカウントにて、①がassumeするためのロールAを作成する。\n  ロールAで定義する内容 (1) 信頼ポリシーで②のアカウントIDを指定してassumeを許可する。このときrootか②側のIAMロールどちらかを指定する。\nrootに設定した場合は、①アカウントでデプロイを実行するユーザのグループにassume可能とするインラインポリシーを適用する。\nIAMに設定した場合は、①アカウントでデプロイを実行するec2にこのIAMロールを適用する。実行環境がec2の場合はこれでよいが、クライアント端末の場合はrootにする。\n インラインポリシー例 (①アカウントで設定) デプロイ実行ユーザが所属するグループの画面を開き、[アクセス許可] タブ \u0026ndash;\u0026gt; [アクセス許可の追加] \u0026ndash;\u0026gt; [インラインポリシーの作成] [JSON] タブ選択\n以下の内容を設定する。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:iam::②配布先のアカウントID:role/ロールA\u0026#34; } }  (2) ①のアカウントが資材配置用のS3にアクセスするための権限を定義したポリシーを適用する。ちゃんと書いてないけど以下にcodedeploy, ec2の操作権限も追加する。codedeployの権限は何が必要かわからないのでとりあえず全許可にしておいた。ECSへのデプロイだとec2のterminate権限が必要みたいだが、今回の場合ec2は参照のみでOKだと思う。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:GetBucketLocation\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::staging-app\u0026#34; #検証環境の資材格納バケット名 }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::staging-app/*\u0026#34; } ] }  ②配布先アカウントにて、deployのアプリケーションとデプロイメントグループを作成する。詳細は割愛。   ①配布元アカウントのec2（または同アカウントのcredentialsをセットした端末）にログインし、ロールAにスイッチする。ちなみにマネジメントコンソールでもスイッチして作業可能だが、deployのpushコマンドがCLIでしかできないため、ここではCLI前提で話を進める。  この時先で作成したロールAにスイッチするため、以下のコマンドを実行する。","title":"AWS CodeDeployでクロスアカウントデプロイの実行（パイプラインなし）"},{"content":"かつてブラウザで全画面キャプチャしたい時はChromeにアドオンを入れて使っていたがこのアドオンはキャプチャしたデータをどこかに送信しているという話をどこかで読んで、ちょっとなぁ、と思った。しかし最近になってChromeでもFirefoxでもアドオンなしで全画面キャプチャが可能になっていることを知った。自宅で見るブラウザはほぼFirefoxでChromeは滅多に使わないが、職場では事情が変わったりするので両方書いておく。\nFirefoxの場合 F12キーで開発ツール画面を表示する。ツール画面右上のカメラアイコンをクリック。これだけ。素晴らしい。画像はデフォルトでDwonloadディレクトリに保存される。\n\u0026hellip;が、画面左側に小さな字でさりげなく「画像が大きすぎたため、xxxxxのサイズに切り抜きました」と言われている。画面が長すぎると途中で切られてしまうわけだ。結果的には以下のようになった。矢印の箇所は実際にここで画面が切れている。自分の投稿記事でやってみたんだけどまぁ実際この記事は長すぎるね。\nChromeの場合 Chromeでやる場合は一手間増える。\nWindows  Ctrl + Shift + I 同時押しで開発ツール画面を表示 Ctrl + Shift + P 同時押しで入力欄を表示させる 「full」と入力してreturn。少し待つとDwonloadディレクトリに保存される。  Mac  command + option + I 同時押しで開発ツール画面を表示 command + Shift + P同時押しで入力欄を表示させる 「full」と入力してreturn。少し待つとDwonloadディレクトリに保存される。\n（デフォルト保存先）  手間といっても大したことじゃないが、なにせものぐさなんで。それでもアドオンなしで全画面キャプチャ可能になったのはありがたい。\nしかしここでもやはり画面が長すぎておかしなことになっている。途中で一回途切れて（矢印箇所）、再度記事の初めから出力されるというループに陥っている。ま、とにかくFirefoxでもChromeでも長すぎるとダメつうことだ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/browser-capture-all/","summary":"かつてブラウザで全画面キャプチャしたい時はChromeにアドオンを入れて使っていたがこのアドオンはキャプチャしたデータをどこかに送信しているという話をどこかで読んで、ちょっとなぁ、と思った。しかし最近になってChromeでもFirefoxでもアドオンなしで全画面キャプチャが可能になっていることを知った。自宅で見るブラウザはほぼFirefoxでChromeは滅多に使わないが、職場では事情が変わったりするので両方書いておく。\nFirefoxの場合 F12キーで開発ツール画面を表示する。ツール画面右上のカメラアイコンをクリック。これだけ。素晴らしい。画像はデフォルトでDwonloadディレクトリに保存される。\n\u0026hellip;が、画面左側に小さな字でさりげなく「画像が大きすぎたため、xxxxxのサイズに切り抜きました」と言われている。画面が長すぎると途中で切られてしまうわけだ。結果的には以下のようになった。矢印の箇所は実際にここで画面が切れている。自分の投稿記事でやってみたんだけどまぁ実際この記事は長すぎるね。\nChromeの場合 Chromeでやる場合は一手間増える。\nWindows  Ctrl + Shift + I 同時押しで開発ツール画面を表示 Ctrl + Shift + P 同時押しで入力欄を表示させる 「full」と入力してreturn。少し待つとDwonloadディレクトリに保存される。  Mac  command + option + I 同時押しで開発ツール画面を表示 command + Shift + P同時押しで入力欄を表示させる 「full」と入力してreturn。少し待つとDwonloadディレクトリに保存される。\n（デフォルト保存先）  手間といっても大したことじゃないが、なにせものぐさなんで。それでもアドオンなしで全画面キャプチャ可能になったのはありがたい。\nしかしここでもやはり画面が長すぎておかしなことになっている。途中で一回途切れて（矢印箇所）、再度記事の初めから出力されるというループに陥っている。ま、とにかくFirefoxでもChromeでも長すぎるとダメつうことだ。","title":"Firefox/Chromeでアドオンなし全画面キャプチャ"},{"content":" 私的にMacで必須のショートカットを3つ挙げるとしたらこんなところかな。\n  フルスクリーン解除 control+ command + F\n  アプリケーションの強制終了 command + option + esc\n  スクリーンショット command + shift + 3\n   それにしてもフルスクリーンて、あれ何のためにあるん？意図的にフルスクリーンにすることなくて変な風にキーボード触ってしまった時になっちまうんだけど、迷惑極まりない\u0026hellip;\n 追記\nもうひとつ迷惑なショートカット思い出したから追加。ターミナル画面が分割されるやつ。command + D同時押しでなってしまうらしい。絶対使わんのに。戻すには、command + Shift + D。3選といいつつ、思い出したらまた書くかもな\u0026hellip;\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/mac-shortcut/","summary":" 私的にMacで必須のショートカットを3つ挙げるとしたらこんなところかな。\n  フルスクリーン解除 control+ command + F\n  アプリケーションの強制終了 command + option + esc\n  スクリーンショット command + shift + 3\n   それにしてもフルスクリーンて、あれ何のためにあるん？意図的にフルスクリーンにすることなくて変な風にキーボード触ってしまった時になっちまうんだけど、迷惑極まりない\u0026hellip;\n 追記\nもうひとつ迷惑なショートカット思い出したから追加。ターミナル画面が分割されるやつ。command + D同時押しでなってしまうらしい。絶対使わんのに。戻すには、command + Shift + D。3選といいつつ、思い出したらまた書くかもな\u0026hellip;\n ","title":"Macで必須のショートカット3選"},{"content":"サクラエディタで半角スペースを可視化したい。環境が変わって入れ直した時とか都度やり直す羽目になるからメモ。\nメニューから[設定] 〜 [タイプ別設定] を選択。\n 「カラー」タブ 半角空白 「色分け/表示」にチェック  ","permalink":"https://ecnedaced-seirots.github.io/post/a/sakura/","summary":"サクラエディタで半角スペースを可視化したい。環境が変わって入れ直した時とか都度やり直す羽目になるからメモ。\nメニューから[設定] 〜 [タイプ別設定] を選択。\n 「カラー」タブ 半角空白 「色分け/表示」にチェック  ","title":"サクラエディタで半角スペースを可視化"},{"content":"小ネタでもいいからどんどんポストしたいと思っているけどそれもなかなかできないもんだな。写真だけ。2018年4月の東京・井の頭公園。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/inokashira-park/","summary":"小ネタでもいいからどんどんポストしたいと思っているけどそれもなかなかできないもんだな。写真だけ。2018年4月の東京・井の頭公園。\n ","title":"井の頭公園 - 2018年4月"},{"content":"AWS EKSでPodからログを送信する場合、Container Insightsを組み込んでFluentdかFluent Bitを利用するのが一般的と思われる。そしてFluent BitよりFluentdの方がメジャーなのでまずはそこから入る事例が多いと想像する。\nしかし、元々組み込みLinux用に開発されて軽量リソースで動作するFluent Bitの方がコンテナログ送信に向いていると思う。ということで、この記事ではFluent Bitに焦点を当てる。\n 参照\nFluent Bit ドキュメント（設定詳細は画面左「DATA PIPELINE」配下のメニュー参照）\nFluent Bit Documentation\nContainer Insights全般\nAmazon EKS と Kubernetes での Container Insights のセットアップ\nFluent Bit on Container Insights\nCloudWatch Logs へログを送信する DaemonSet として Fluent Bit を設定する\nサンプルマニフェスト\nfluent-bit-compatible.yaml\n※AWSがサンプルとして提供しているFluent BitのマニフェストはFluent Bit最適化用とFluentd互換用がある。今回は過去にFluentd使用事例があることから、Fluentd互換用マニフェストをDLしてカスタマイズした。\n 共通マニフェスト例 クラスタの全般的な設定と、アプリ個別のケースでマニフェストを二つに分けた。AWS公式では基本となるEKSクラスタの定義をコマンドでセットしているが、運用の際はマニフェストに落とし込むのが普通だと思う。以下のようなマニフェストを共通用として作成し、個別のマニフェストから参照させる。EKSクラスタ名はdata:cluster.nameで指定している。\nfluentbit-cluster.yaml\napiVersion: v1 kind: ConfigMap metadata: name: fluentbit-cluster namespace: amazon-cloudwatch selfLink: /api/v1/namespaces/amazone-cloudwatch/configmaps/fluentbit-cluster data: cluster.name: EKS-SAMPLE-CLUSTER log.region: ap-northeast-1 read.head: \u0026#34;On\u0026#34; read.tail: \u0026#34;Off\u0026#34; --- apiVersion: v1 kind: ServiceAccount metadata: name: fluent-bit namespace: amazon-cloudwatch --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: fluent-bit-role rules: - nonResourceURLs: - /metrics verbs: - get - apiGroups: [\u0026#34;\u0026#34;] resources: - namespaces - pods - pods/logs verbs: [\u0026#34;get\u0026#34;, \u0026#34;list\u0026#34;, \u0026#34;watch\u0026#34;] --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: fluent-bit-role-binding roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: fluent-bit-role subjects: - kind: ServiceAccount name: fluent-bit namespace: amazon-cloudwatch  個別マニフェスト例 「個別のマニフェスト」というのはアプリの種類が複数存在して、各種別ごとに送信先（ロググループ/ログストリーム）を振り分けたいケースを想定している。しかしAWS公式サンプルをそのまま使うと要件的に期待値にならない。現状ネットにわかりやすい事例がなく大分迷ったが、最終的に以下のような形に落とした。詳細は後述。\n最初に骨組みを説明すると、前半がFluent Bitの設定であるConfigMap、後半がワーカーノード上で起動するDaemonSetの定義となっている。冒頭の[SERVICE]で全体共通の設定を行う。@INCLUDEで3種類のConfig名を指定しているが名称は適当でよい。各Config内に[INPUT] [FILTER] [OUTPUT] を定義していく。\n confの種類 containers.conf\nfluentbit, cloudwatch-agentやアプリ個別ログを定義。簡素化のため対象を絞っているが、aws-node, kube-proxy, corednsのログを送信する場合もここに含める。\nkube-systemd.conf\ndocker,kubeletのログを定義。\nhost.conf\nOS上のログ（基本的に/var/log/配下の各種ログ）を定義。簡素化のためここではmessagesのみ定義している。他に送信したい種別は同様に設定する。\nparsers.conf\nログフォーマットのパースの定義\n fluentbit-sample-app.yaml\napiVersion: v1 kind: ConfigMap metadata: name: fluent-bit-config namespace: amazon-cloudwatch labels: k8s-app: fluent-bit-sample data: fluent-bit.conf: |[SERVICE] Flush 5 Log_Level info Daemon off Parsers_File parsers.conf storage.path /var/fluent-bit/state/flb-storage/ storage.sync normal storage.checksum off storage.backlog.mem_limit 5M @INCLUDE containers.conf @INCLUDE kube-systemd.conf @INCLUDE host.conf # containers.confの定義 containers.conf: |[INPUT] Name tail Tag fluentbit.* Path /var/log/containers/fluentbit* Parser docker DB /var/fluent-bit/state/flb_log.db Mem_Buf_Limit 5MB Skip_Long_Lines On Refresh_Interval 10 Read_from_Head ${READ_FROM_HEAD} [INPUT] Name tail Tag cloudwatch-agent.* Path /var/log/containers/cloudwatch-agent* Docker_Mode On Docker_Mode_Flush 5 Docker_Mode_Parser cwagent_firstline Parser docker DB /var/fluent-bit/state/flb_cwagent.db Mem_Buf_Limit 5MB Skip_Long_Lines On Refresh_Interval 10 Read_from_Head ${READ_FROM_HEAD} [INPUT] Name tail Tag sample-app.* Path /var/log/containers/sample-app* Parser docker DB /var/fluent-bit/state/flb_sample-app.db Mem_Buf_Limit 5MB Skip_Long_Lines On Refresh_Interval 10 Read_from_Head ${READ_FROM_HEAD} # 各INPUTに対応するFILTERを定義する [FILTER] Name kubernetes Match fluentbit.* Kube_URL ${MASTER_URL} Kube_Tag_Prefix fluentbit.var.log.containers. Merge_Log On Merge_Log_Key log_processed K8S-Logging.Parser On K8S-Logging.Exclude Off Annotations Off [FILTER] Name kubernetes Match cloudwatch-agent.* Kube_URL ${MASTER_URL} Kube_Tag_Prefix cloudwatch-agent.var.log.containers. Merge_Log On Merge_Log_Key log_processed K8S-Logging.Parser On K8S-Logging.Exclude Off Annotations Off [FILTER] Name kubernetes Match sample-app.* Kube_URL ${MASTER_URL} Kube_Tag_Prefix sample-app.var.log.containers. Merge_Log On Merge_Log_Key log_processed K8S-Logging.Parser On K8S-Logging.Exclude Off Annotations Off # アイテムの変換や不要なメタデータ送信抑止を定義 [FILTER] Name nest Match * Operation lift Nested_under kubernetes Add_prefix Nested. [FILTER] Name modify Match * Rename Nested.docker_id Docker.container_id [FILTER] Name nest Match * Operation nest Wildcard Nested.* Nested_under kubernetes Remove_prefix Nested. [FILTER] Name nest Match * Operation nest Wildcard Docker.* Nested_under docker Remove_prefix Docker. [FILTER] Name nest Match * Operation lift Nested_under kubernetes Add_prefix Kube. [FILTER] Name modify Match * Remove Kube.container_hash  Remove Kube.container_image Remove Kube.pod_id [FILTER] Name nest Match * Operation nest Wildcard Kube.* Nested_under Kubernetes Remove_prefix Kube. # 送信時の定義 # ロググループ名例：/eks/stg/sample-app_fluentbit # ログストリーム名例：ip-10-1-2-3.ap-northeast-1.compute.internal_[Pod名]_[ネームスペース]_[コンテナ名] # $(tag[4])とした場合、上記のようなkubeのタグ定義が投入され、ユニークなログストリーム名になる。 [OUTPUT] Name cloudwatch Match fluentbit.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_fluentbit log_stream_name ${HOST_NODE_NAME}_$(tag[4]) auto_create_group true extra_user_agent container-insights Retry_Limit 5 [OUTPUT] Name cloudwatch Match cloudwatch-agent.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_cwagent log_stream_name ${HOST_NODE_NAME}_$(tag[4]) auto_create_group true extra_user_agent container-insights Retry_Limit 5 # 個別アプリログ送信用定義 [OUTPUT] Name cloudwatch Match sample-app.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_application log_stream_name ${HOST_NODE_NAME}_$(tag[4]) auto_create_group true extra_user_agent container-insights Retry_Limit 5 # docker,kubenetesログ定義 kube-systemd.conf: |[INPUT] Name systemd Tag dockerlog.systemd.* Systemd_Filter _SYSTEMD_UNIT=docker.service DB /var/fluent-bit/state/systemd.db Path /var/log/journal Read_From_Head ${READ_FROM_HEAD} [INPUT] Name systemd Tag kubelet.systemd.* Systemd_Filter _SYSTEMD_UNIT=kubelet.service DB /var/fluent-bit/state/systemd.db Path /var/log/journal Read_From_Head ${READ_FROM_HEAD} [FILTER] Name modify Match dockerlog.systemd.* Rename _HOSTNAME hostname Rename _SYSTEMD_UNIT systemd_unit Rename MESSAGE message Remove_regex ^((?!hostname|systemd_unit|message).)*$ [FILTER] Name modify Match kubelet.systemd.* Rename _HOSTNAME hostname Rename _SYSTEMD_UNIT systemd_unit Rename MESSAGE message Remove_regex ^((?!hostname|systemd_unit|message).)*$ [OUTPUT] Name cloudwatch Match kubelet.systemd.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_docker log_stream_name ${HOST_NODE_NAME}_$(tag[2]) auto_create_group true extra_user_agent container-insight [OUTPUT] Name cloudwatch Match kubelet.systemd.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_kubelet log_stream_name ${HOST_NODE_NAME}_$(tag[2]) auto_create_group true extra_user_agent container-insight # messages等、OSのログ定義 host-log.conf: | [INPUT] Name tail Tag host.messages Path /var/log/messages Parser syslog DB /var/fluent-bit/state/flb_messages.db Mem_Buf_Limit 5MB Skip_Long_Lines On Refresh_Interval 10 Read_from_Head ${READ_FROM_HEAD} # host.confの[OUTPUT]定義は、複数のINPUTがあっても1つでよい。 # $(tag[1]) にはこの場合messagesが入る。 [OUTPUT] Name cloudwatch Match host.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_$(tag[1]) log_stream_name ${HOST_NODE_NAME}_$(tag[1]) auto_create_group true extra_user_agent container-insights Retry _Limit 5 parsers.conf: |[PARSER] Name docker Format json Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%LZ [PARSER] Name syslog-rfc5424 Format regex Regex ^(?\u0026lt;time\u0026gt;[^ ]* {1.2}[^ ]* [^ ]*) (?\u0026lt;host\u0026gt;[^ ]*) (?\u0026lt;ident\u0026gt;[a-zA-Z0-9_¥/¥.¥-]*) (?:¥[?\u0026lt;pid\u0026gt;[-0-9]+)¥])?(?:[^¥:]*¥:)? * (?\u0026lt;message\u0026gt;.*)$ Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%L Time_Strict Off [PARSER] Name container_firstline Format regex Regex (?\u0026lt;log\u0026gt;(?\u0026lt;=\u0026#34;log\u0026#34;:\u0026#34;)\\S(?!\\.).*?)(?\u0026lt;!\\\\)\u0026#34;.*(?\u0026lt;stream\u0026gt;(?\u0026lt;=\u0026#34;stream\u0026#34;:\u0026#34;).*?)\u0026#34;.*(?\u0026lt;time\u0026gt;\\d{4}-\\d{1,2}-\\d{1,2}T\\d{2}:\\d{2}:\\d{2}\\.\\w*).*(?=}) Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%LZ [PARSER] Name cwagent_firstline Format regex Regex (?\u0026lt;log\u0026gt;(?\u0026lt;=\u0026#34;log\u0026#34;:\u0026#34;)\\d{4}[\\/-]\\d{1,2}[\\/-]\\d{1,2}[ T]\\d{2}:\\d{2}:\\d{2}(?!\\.).*?)(?\u0026lt;!\\\\)\u0026#34;.*(?\u0026lt;stream\u0026gt;(?\u0026lt;=\u0026#34;stream\u0026#34;:\u0026#34;).*?)\u0026#34;.*(?\u0026lt;time\u0026gt;\\d{4}-\\d{1,2}-\\d{1,2}T\\d{2}:\\d{2}:\\d{2}\\.\\w*).*(?=}) Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%LZ --- apiVersion: apps/v1 kind: DaemonSet metadata: name: fluent-bit-sample namespace: amazon-cloudwatch labels: k8s-app: fluent-bit-sample version: v1 kubernetes.io/cluster-service: \u0026#34;true\u0026#34; spec: selector: matchLabels: k8s-app: fluent-bit-sample template: metadata: labels: k8s-app: fluent-bit-sample version: v1 kubernetes.io/cluster-service: \u0026#34;true\u0026#34; spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: nodelabel operator: In values: - STG-NODELABEL-APP-001 containers: - name: fluent-bit-sample image: amazon/aws-for-fluent-bit:2.12.0 imagePullPolicy: Always env: - name: AWS_REGION valueFrom: configMapKeyRef: name: fluentbit-cluster key: logs.region - name: CLUSTER_NAME valueFrom: configMapKeyRef: name: fluentbit-cluster key: cluster.name - name: READ_FROM_HEAD valueFrom: configMapKeyRef: name: fluentbit-cluster key: read.head - name: READ_FROM_TAIL valueFrom: configMapKeyRef: name: fluentbit-cluster key: read.tail - name: HOST_NODE_NAME valueFrom: fieldRef: fieldPath: spec.nodeName - name: CI_VERSION value: \u0026#34;k8s/1.3.8\u0026#34; # これ以降独自に設定追加。設定項目はユースケースに合わせてください。 - name: ENVIRONMENT value: \u0026#34;stg\u0026#34; - name: NODEGROUP value: \u0026#34;sample-app\u0026#34; - name: MASTER_URL value: \u0026#34;https://kubernetes.default.svc:443\u0026#34; resources: limits: cpu: 200m memory: 200Mi requests: cpu: 200m memory: 100Mi volumeMounts: # Please don\u0026#39;t change below read-only permissions - name: fluentbitstate mountPath: /var/fluent-bit/state - name: varlog mountPath: /var/log readOnly: true - name: varlibdockercontainers mountPath: /var/lib/docker/containers readOnly: true - name: fluent-bit-config mountPath: /fluent-bit/etc/ - name: runlogjournal mountPath: /run/log/journal readOnly: true - name: dmesg mountPath: /var/log/dmesg readOnly: true terminationGracePeriodSeconds: 90 volumes: - name: fluentbitstate hostPath: path: /var/fluent-bit/state - name: varlog hostPath: path: /var/log - name: varlibdockercontainers hostPath: path: /var/lib/docker/containers - name: fluent-bit-config configMap: name: fluent-bit-config - name: runlogjournal hostPath: path: /run/log/journal - name: dmesg hostPath: path: /var/log/dmesg serviceAccountName: fluent-bit tolerations: - key: node-role.kubernetes.io/master operator: Exists effect: NoSchedule - operator: \u0026#34;Exists\u0026#34; effect: \u0026#34;NoExecute\u0026#34; - operator: \u0026#34;Exists\u0026#34; effect: \u0026#34;NoSchedule\u0026#34;  補足説明 imageパスの指定\n上記ではコンテナイメージをインターネットを通って都度落とすようになっているが、業務利用時はECRに格納してプライベートな通信で完結させるのが望ましい。ECRに格納した場合は以下のように指定する。\nimage: [AWS-AccoundID].dkr.ecr.ap-northeast-1.amazon.com/[repo-name]:2.12.0  nodeAffinityで起動するノードを指定\n今回の事例では、sample-appのPodが起動するワーカーノード上にsample-appログ送信用のDaemonSetを起動させる必要がある。そのためnodeAffinityを定義する。EKSノードグループのラベルにkey:nodelabel values:STG-SAMPLE-APPを設定している前提の場合以下の様になる。sample-app用のマニフェストにも同様の記述をする。\n spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: nodelabel operator: In values: - STG-SAMPLE-APP  停止時のGracePeriod\nDaemonSetがKillシグナル受信後に削除されるまでの猶予時間を指定。公式サンプル10秒だと、コンテナログを送信しきる前に削除されてしまう可能性がある。ここでは余裕を持たせて90秒。\nterminationGracePeriodSeconds: 90  syslogのPARSER\nAWS公式の設定だとTime_FormatがダメらしきエラーがでるのでFluent Bit公式の例を適用した。Fluent Bit公式ではsyslogではなくsyslog-rfc5424。ではINPUTのParserはsyslogではなくsyslog-rfc5424とするのが正ではないか？と思ったが、そうすると動作しない。謎だが深追いはしない。Time_StrictはOffにしておく。しかしそれでもまだエラーになるので調べると、Regexの正規表現が原因らしいのでそこも直した。参照サイトは失念。\n DaemonSetの起動〜ログ送信\n今回cloudwatch-agentについては触れていないが、cloudwatch-agentネームスペースが存在している状態でマニフェストをapplyする。この時点ではノードグループは停止中でもよい。\n$ kubectl apply -f fluentbit-cluster.yaml $ kubectl apply -f fluentbit-sample-app.yaml  ノードグループが起動すると、各種ログがCloudWatchLogsに送信される。アプリ用マニフェストをapplyすればアプリログも送信される。\nあとresourceのcpuはデフォルトが500mになっていたが、そこまで割り当てなくてもちゃんと動作する。よほどのことがなければ100mでもいい気がする。メモリもFlunetdに比べて全然余裕。さすが軽量版。その他細かいチューニング項目もあるにはあるのだが、これ以上の長文は避けたいのでまた別の機会に投稿しようと思う。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/fluentbit-eks-setting/","summary":"\u003cp\u003eAWS EKSでPodからログを送信する場合、Container Insightsを組み込んでFluentdかFluent Bitを利用するのが一般的と思われる。そしてFluent BitよりFluentdの方がメジャーなのでまずはそこから入る事例が多いと想像する。\u003c/p\u003e","title":"EKS Container InsightsのFluent Bit設定"},{"content":"マークダウン記法の参考リンク。取り急ぎこれくらいあればいいかな。\n  Markdown 早見表 \u0026amp; 詳細\n  かんたんMarkdownの記法\n  Markdown記法 チートシート\n  GitHub Markdownの「シンタックスハイライト」に対応している言語一覧\n   ","permalink":"https://ecnedaced-seirots.github.io/post/a/markdown/","summary":"マークダウン記法の参考リンク。取り急ぎこれくらいあればいいかな。\n  Markdown 早見表 \u0026amp; 詳細\n  かんたんMarkdownの記法\n  Markdown記法 チートシート\n  GitHub Markdownの「シンタックスハイライト」に対応している言語一覧\n   ","title":"マークダウン記法"},{"content":"とりあえず最初の投稿。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/first/","summary":"とりあえず最初の投稿。\n ","title":"最初の投稿"}]