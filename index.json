[{"content":"そして俺は相変わらず中指を1000本くらい突き立てたい気分の日々が継続中なのだ。日々アドレナリンが過剰放出されてしまい、心身によろしくない。けど怒りをそのままぶちまけるのは芸がないし、自分にとってプラスにならないからね、俺はプラスになることだけやりたいわけ、だから少しでも勉強になることを書く。\n \u0026ldquo;middle finger\u0026quot;って言ったらあれです、特別な意味を持つ「中指」。\n以下はすべて同じ意味。\u0026ldquo;the finger\u0026quot;でも同じ意味になるとは知らなかった。\n middle finger second finger the finger   侮蔑や怒りを示すジェスチャーとなる「中指を立てる」行為は以下の表現。\n give the middle finger give the finger   以下も同じ意味。知らなかった。でもどれだけポピュラーなんだろう？\n flip the bird fly the bird    しばらく前までは心の中だけで中指を突き立てていたが、最近もう耐えられなくなって物理的にも公の場で中指を立てている俺様なのだった。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/the-finger/","summary":"そして俺は相変わらず中指を1000本くらい突き立てたい気分の日々が継続中なのだ。日々アドレナリンが過剰放出されてしまい、心身によろしくない。けど怒りをそのままぶちまけるのは芸がないし、自分にとってプラスにならないからね、俺はプラスになることだけやりたいわけ、だから少しでも勉強になることを書く。\n \u0026ldquo;middle finger\u0026quot;って言ったらあれです、特別な意味を持つ「中指」。\n以下はすべて同じ意味。\u0026ldquo;the finger\u0026quot;でも同じ意味になるとは知らなかった。\n middle finger second finger the finger   侮蔑や怒りを示すジェスチャーとなる「中指を立てる」行為は以下の表現。\n give the middle finger give the finger   以下も同じ意味。知らなかった。でもどれだけポピュラーなんだろう？\n flip the bird fly the bird    しばらく前までは心の中だけで中指を突き立てていたが、最近もう耐えられなくなって物理的にも公の場で中指を立てている俺様なのだった。","title":"middle finger周辺の表現など"},{"content":"\u0026ldquo;rage\u0026quot;という英単語がある。名詞としては「激情、激怒、憤怒」、自動詞として「怒る、暴れる」という意味だ。これを知ったきっかけは、Tumblrで見かけた以下の引用だった。\n Do not go gentle into that good night.\nRage, rage against the dying of the light.\n  パッと見てすぐに意味は理解できなかったが何か心を捉えられた感があった。\u0026ldquo;rage\u0026quot;という単語を初めて見たので調べたところ、意味は先述の通り。\nこれはウェールズの詩人ディラン・トーマス(Dylan Thomas) の詩の一部である。でもTumblrの投稿にはOscar Wildeって書いたあったような記憶がある。それで最近までずっとこの引用元をOscar Wildeだと思い込んでいたんだから。間違いだったんだなあれは。\nそれはさておき、今日この詩について少し文献を調べてみたら、この引用に対して今までの自分の解釈が若干ズレていたことがわかった。以下は引用元の詩全体である。\n  Do not go gentle into that good night,\nOld age should burn and rage at close of day;\nRage, rage against the dying of the light.\nThough wise men at their end know dark is right,\nBecause their words had forked no lightning they\nDo not go gentle into that good night.\nGood men, the last wave by, crying how bright\nTheir frail deeds might have danced in a green bay,\nRage, rage against the dying of the light.\nWild men who caught and sang the sun in flight,\nAnd learn, too late, they grieved it on its way,\nDo not go gentle into that good night.\nGrave men, near death, who see with blinding sight\nBlind eyes could blaze like meteors and be gay,\nRage, rage against the dying of the light.\nAnd you, my father, there on the sad height,\nCurse, bless me now with your fierce tears, I pray.\nDo not go gentle into that good night.\nRage, rage against the dying of the light.\n (Dylan Thomas, Do Not Go Gentle Into That Good Night)\n  この詩は、ディランが死に瀕した父親へ向けて書いた詩である。（\u0026hellip;というのはもちろん拾った情報）\n詩を理解するのは難しい、言葉としての意味を理解するのと文脈を理解すること、さらにその裏に表現された暗喩を理解するのは別のことだ。しかも母国語以外で。\n俺の英語力はお粗末なので、言葉の意味と文脈はどうにか掴めても、その奥の本質までは手が届きそうで届かない。しかしこの時点で今までの自分の解釈がズレていたことに気づいた。\n俺はTumblrでこの引用を初めて目にしたとき、「大人しくなんかなるなよ、消えゆく灯りに激怒しろ、憤怒しろ」と文字通りの意味に捉えていた、作家がオスカー・ワイルドと思っていたせいもあり、今そこでまだエネルギーを保持して生きている人間が自分または他人をさらに奮い立たせる意図の言葉と解釈した。それで、何か心が「ザワザワッ」としたのである。そしてrageという単語を覚えたのである。\n  話変わって数ヶ月後、村上龍の「ピアッシング」を英語翻訳版で読む機会があった。そしてそこでrageという単語に再会した。コールガールのChiakiが妄想に取り憑かれた男Kawashimaに客として出会い、ふとしたきっかけでrageな状態に至る。そのシーンで、先の引用を真っ先に思い出した。ピピピッときたよね。\nその後また別の英文小説を読んだら、そこでも単語rageが登場してピピピッときた。言葉というものは、こういうプロセスを経て自分の内部に取り込まれていくのである。だからそのプロセスは、人の数だけバリエーションが存在する。\nで、話は戻って俺の英語力ではこの詩の奥深い意味を捉えるのは無理めだったので日本語訳を探してみたところ、素晴らしい翻訳があった。全部載せるのはアレなので一部だけ引用させてもらうと。\n  あんな風に「おやすみ」なんて言ってさっさと諦めるなよ\nもう若くなくたって，一日が人生が終わりそうなら，烈火のごとく怒り狂って，ギャアギャアそこで喚くんだ；\n太陽の光が薄れて消えていっても，死にものぐるいで抵抗しなきゃ\n Do Not Go Gentle Into That Night ディラン・トーマス (Dylan Thomas) より\n 全部はリンク先で読んでもらうとして、訳者ご本人が認めているようにかなり意訳色が強い翻訳である。しかし素晴らしい、最高だ。気持ちがストレートに伝わってくる。そしてこのリンク記事が2020年の大晦日に投稿され、「暗いニュースばかりが目立ったこの一年ですが，最後をこの力強い詩で締めくくりたい」と記されていることにもグッときた。泣けてくるぜ\u0026hellip;\n他の訳も発見したが、同じ原文がこうも異なる訳になるのかと驚く。どれが正しいということではないのだが、自分はやはり上のが一番だな。\n Do Not Go Gentle Into That Night （正当古典派訳）\natheistの意味は? – Do not go gentle into that good night （中庸派的訳）\n  話はあちこちに逸脱したが、この記事ではrageという単語がどのような経緯で自分に取り込まれたのかを書きたかったのである。何故書きたかったのか？まぁこうやって頭を整理しつつ記事を書くのも、一種のアンガー・マネジメントなのかもしれない。\n中指1000本突き立てても気が済まないくらいrageな日々を送っているが、整理して調べていく過程で先ほどの素晴らしい翻訳に出会うことができた。これは幸運の極みだよ、力強く美しい言葉は、人間に偉大な力を与えてくれるんだから。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/dylan-thomas/","summary":"\u0026ldquo;rage\u0026quot;という英単語がある。名詞としては「激情、激怒、憤怒」、自動詞として「怒る、暴れる」という意味だ。これを知ったきっかけは、Tumblrで見かけた以下の引用だった。\n Do not go gentle into that good night.\nRage, rage against the dying of the light.\n  パッと見てすぐに意味は理解できなかったが何か心を捉えられた感があった。\u0026ldquo;rage\u0026quot;という単語を初めて見たので調べたところ、意味は先述の通り。\nこれはウェールズの詩人ディラン・トーマス(Dylan Thomas) の詩の一部である。でもTumblrの投稿にはOscar Wildeって書いたあったような記憶がある。それで最近までずっとこの引用元をOscar Wildeだと思い込んでいたんだから。間違いだったんだなあれは。\nそれはさておき、今日この詩について少し文献を調べてみたら、この引用に対して今までの自分の解釈が若干ズレていたことがわかった。以下は引用元の詩全体である。\n  Do not go gentle into that good night,\nOld age should burn and rage at close of day;\nRage, rage against the dying of the light.\nThough wise men at their end know dark is right,\nBecause their words had forked no lightning they","title":"単語rageを覚えたきっかけはディラン・トーマスの詩だった"},{"content":"Mac OSで標準搭載されているdateコマンドはBSD版であり、Linux標準のGNU版と微妙に異なる。Linuxと実行結果が異なったり、使用できないオプションがあったりとか。それが困るから、自宅のMacでもGNU版のdateが使いたいのである。数年前に標準のdateを入れたのだが、その後Mac本体を買い替えたタイミングで消えてしまった。\n Mac OSでgnu/dateを使いたい場合、brewから入れる。install dateではなく、coreutilsとする。（他のGNU系コマンド一式が含まれる）\n$ brew install coreutils  /usr/local/bin/gdateにインストールされた。（正確にはシンボリックリンク）\nこのままだとコマンドがgdateなので、gdateを\u0026quot;date\u0026quot;で実行できるようにする。以下エイリアスを.bashrcに追記。\nalias date='/usr/local/bin/gdate'  やっとできた。以下は所定の日付時刻をエポックタイム(UNIXタイムスタンプ)に変換するコマンド。Mac版のdateだと使えないんだよこれが。\n$ date -d '2018/5/17 00:00:00' +'%s' 1526482800  参考\nMacでdateコマンドが違う件について\nUNIX時間に変換・UNIX時間を取得する方法\n (RWC2019, Tokyo Stadium)\n","permalink":"https://ecnedaced-seirots.github.io/post/a/mac-installe-gdate/","summary":"Mac OSで標準搭載されているdateコマンドはBSD版であり、Linux標準のGNU版と微妙に異なる。Linuxと実行結果が異なったり、使用できないオプションがあったりとか。それが困るから、自宅のMacでもGNU版のdateが使いたいのである。数年前に標準のdateを入れたのだが、その後Mac本体を買い替えたタイミングで消えてしまった。\n Mac OSでgnu/dateを使いたい場合、brewから入れる。install dateではなく、coreutilsとする。（他のGNU系コマンド一式が含まれる）\n$ brew install coreutils  /usr/local/bin/gdateにインストールされた。（正確にはシンボリックリンク）\nこのままだとコマンドがgdateなので、gdateを\u0026quot;date\u0026quot;で実行できるようにする。以下エイリアスを.bashrcに追記。\nalias date='/usr/local/bin/gdate'  やっとできた。以下は所定の日付時刻をエポックタイム(UNIXタイムスタンプ)に変換するコマンド。Mac版のdateだと使えないんだよこれが。\n$ date -d '2018/5/17 00:00:00' +'%s' 1526482800  参考\nMacでdateコマンドが違う件について\nUNIX時間に変換・UNIX時間を取得する方法\n (RWC2019, Tokyo Stadium)","title":"MacにGNU版dateをインストール"},{"content":"AWS CLI v2でデフォルトになっているページャを無効化する方法は2種類ある。\n configで設定  ~/.aws/configに以下記載する。\n[default] cli_pager=  環境変数で設定  $ export AWS_PAGER=\u0026quot;\u0026quot;  1.の方が推奨されているようだが、k8s(Kubernetes)のPodの場合は、マニフェストのENVに2.の環境変数を書いておけば期待値になる。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/awscli-pager/","summary":"AWS CLI v2でデフォルトになっているページャを無効化する方法は2種類ある。\n configで設定  ~/.aws/configに以下記載する。\n[default] cli_pager=  環境変数で設定  $ export AWS_PAGER=\u0026quot;\u0026quot;  1.の方が推奨されているようだが、k8s(Kubernetes)のPodの場合は、マニフェストのENVに2.の環境変数を書いておけば期待値になる。\n ","title":"AWS CLIのページャを無効化する"},{"content":"AWSで、CloudWatchアラームのメッセージをSNSトピックかましてメール送信。昔からよくあるオーソドックスなパターンだが、しばらく縁がなかったので記憶がかすんでいる。過去に構築した時の記録を掘り返してみる。\n数年前、CloudFormation（CFn）で環境構築したのだが（主担当は別のメンバー）、CWアラーム作成はCFnで作るのに不向きということでAWS CLIで作成していた。何故CFnが不向きなのか、理由は何だったか思い出せない。以下の記事を見ると普通にCFnでアラーム作成しているから問題なさそうではあるのだが\u0026hellip;\nCloudFormationでCloudWatchAlermを作成する\n ここで、書いていてうっすら思い出した。過去事例ではオートスケールのアラームだったが、その場合は他のアラームと異なるのかもしれない。（つまりオートスケールのアラームはポリシーを別出しにする）確かASG（オートスケーリンググループ）自体もCFnで作るのは不向きということでCLIで作成してた。CFnだと勝手に変な名前付けられるから、って理由だったかな。しかしハッキリとは思い出せない。\nもやもや感が払拭しきれないが、とりあえず過去のメモ書きをのせておく。\n ここから。\nオートスケーリンググループのCloudWatchアラーム作成時のポイントは、先にSNSトピック、ポリシーを作成する。ポリシー作成のCLIを実行するとARNが出力されるので、その値を定義してアラームを作成する。SNSトピック自体はCFnで作成していた。サブスクリプション作成はコンソールからやったような。グダグダな記憶だが、メールアドレスをサブスクライブする時に手動での承認が発生するのは確か。（設定したメールアドレスに届いたメール内のリンクを押下すると承認が完了する）\nサブスクリプション承認は手動になるが、アラーム作成時に指定するのはトピックARN。承認しないと後続作業ができないわけではない、と思われる。（ただし承認対応は3日以内に実施すること）\n以下、ec2オートスケーリングのスケールアウト/インポリシー作成CLIの例。ec2のオートスケールってパターンもすでにオールドファッション化しているけど\u0026hellip;、数年前の事例なので。\nスケールアウトポリシー\n$ aws autoscaling put-scaling-policy \\ --auto-scaling-group-name test-web-asg \\ --policy-name test-web-scaleout-policy \\ --scaling-adjustment 2 \\ --adjustment-type ChangeInCapacity \\ --cooldown 300 \\ --region ap-northeast-1  スケールインポリシー\n$ aws autoscaling put-scaling-policy \\ --auto-scaling-group-name test-web-asg \\ --policy-name test-web-scalein-policy \\ --scaling-adjustment -2 \\ --adjustment-type ChangeInCapacity \\ --cooldown 600 \\ --region ap-northeast-1  この後、以下のCLIを実行。スケールアウトアラーム作成CLI例。--alarm-actions オプションで 先に作成しておいた$snstopic, $scaleoutpolicy の値を指定している。\nsnstopic=\u0026quot;arn:aws:sns:ap-northeast-1:[AWSアカウントID]:test-alert-mail\u0026quot; scaleoutpolicy=\u0026quot;arn:aws:autoscaling:ap-northeast-1:[AWSアカウントID]:scalingPolicy:[ランダム値]:autoScalingGroupName/test-web-asg:policyName/test-web-scaleout-policy\u0026quot; $ aws cloudwatch put-metric-alarm \\ --alarm-name \u0026quot;test-web-scaleout-alarm\u0026quot; \\ --alarm-description \u0026quot;Alarm when CPU exceeds 70%\u0026quot; \\ --metric-name CPUUtilization \\ --namespace AWS/EC2 \\ --statistic Average \\ --period 60 \\ --threshold 70 \\ --comparison-operator GreaterThanThreshold \\ --dimensions Name=AutoScalingGroupName,Value=\u0026quot;test-web-asg\u0026quot; \\ --evaluation-periods 4 \\ --alarm-actions $scaleoutpolicy $snstopic \\ --unit Percent \\ --region ap-northeast-1  スケールイン時のアラームも同様に作成する。\n 以下備忘録。静観対応をどうするか\nCloudWatch アラームのダウンタイム（特定期間の発報抑止）を Metric Math を使用して実現してみた\n","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatch-alarm-memo/","summary":"AWSで、CloudWatchアラームのメッセージをSNSトピックかましてメール送信。昔からよくあるオーソドックスなパターンだが、しばらく縁がなかったので記憶がかすんでいる。過去に構築した時の記録を掘り返してみる。\n数年前、CloudFormation（CFn）で環境構築したのだが（主担当は別のメンバー）、CWアラーム作成はCFnで作るのに不向きということでAWS CLIで作成していた。何故CFnが不向きなのか、理由は何だったか思い出せない。以下の記事を見ると普通にCFnでアラーム作成しているから問題なさそうではあるのだが\u0026hellip;\nCloudFormationでCloudWatchAlermを作成する\n ここで、書いていてうっすら思い出した。過去事例ではオートスケールのアラームだったが、その場合は他のアラームと異なるのかもしれない。（つまりオートスケールのアラームはポリシーを別出しにする）確かASG（オートスケーリンググループ）自体もCFnで作るのは不向きということでCLIで作成してた。CFnだと勝手に変な名前付けられるから、って理由だったかな。しかしハッキリとは思い出せない。\nもやもや感が払拭しきれないが、とりあえず過去のメモ書きをのせておく。\n ここから。\nオートスケーリンググループのCloudWatchアラーム作成時のポイントは、先にSNSトピック、ポリシーを作成する。ポリシー作成のCLIを実行するとARNが出力されるので、その値を定義してアラームを作成する。SNSトピック自体はCFnで作成していた。サブスクリプション作成はコンソールからやったような。グダグダな記憶だが、メールアドレスをサブスクライブする時に手動での承認が発生するのは確か。（設定したメールアドレスに届いたメール内のリンクを押下すると承認が完了する）\nサブスクリプション承認は手動になるが、アラーム作成時に指定するのはトピックARN。承認しないと後続作業ができないわけではない、と思われる。（ただし承認対応は3日以内に実施すること）\n以下、ec2オートスケーリングのスケールアウト/インポリシー作成CLIの例。ec2のオートスケールってパターンもすでにオールドファッション化しているけど\u0026hellip;、数年前の事例なので。\nスケールアウトポリシー\n$ aws autoscaling put-scaling-policy \\ --auto-scaling-group-name test-web-asg \\ --policy-name test-web-scaleout-policy \\ --scaling-adjustment 2 \\ --adjustment-type ChangeInCapacity \\ --cooldown 300 \\ --region ap-northeast-1  スケールインポリシー\n$ aws autoscaling put-scaling-policy \\ --auto-scaling-group-name test-web-asg \\ --policy-name test-web-scalein-policy \\ --scaling-adjustment -2 \\ --adjustment-type ChangeInCapacity \\ --cooldown 600 \\ --region ap-northeast-1  この後、以下のCLIを実行。スケールアウトアラーム作成CLI例。--alarm-actions オプションで 先に作成しておいた$snstopic, $scaleoutpolicy の値を指定している。\nsnstopic=\u0026quot;arn:aws:sns:ap-northeast-1:[AWSアカウントID]:test-alert-mail\u0026quot; scaleoutpolicy=\u0026quot;arn:aws:autoscaling:ap-northeast-1:[AWSアカウントID]:scalingPolicy:[ランダム値]:autoScalingGroupName/test-web-asg:policyName/test-web-scaleout-policy\u0026quot; $ aws cloudwatch put-metric-alarm \\ --alarm-name \u0026quot;test-web-scaleout-alarm\u0026quot; \\ --alarm-description \u0026quot;Alarm when CPU exceeds 70%\u0026quot; \\ --metric-name CPUUtilization \\ --namespace AWS/EC2 \\ --statistic Average \\ --period 60 \\ --threshold 70 \\ --comparison-operator GreaterThanThreshold \\ --dimensions Name=AutoScalingGroupName,Value=\u0026quot;test-web-asg\u0026quot; \\ --evaluation-periods 4 \\ --alarm-actions $scaleoutpolicy $snstopic \\ --unit Percent \\ --region ap-northeast-1  スケールイン時のアラームも同様に作成する。","title":"CloudWatchアラーム作成時のメモ（過去事例）"},{"content":"SNSって誰をフォローするかも大きいけど誰にフォローされるか、も相当影響でかいんだなと思う。\nもともとSNS嫌いだからほとんどやってないけど、Tumblrは例外で、ここしばらく依存症に近いくらい使っている。全然使っていなかった時期もあるんだけどね。今は諸事情によりヘビーユーザー。\n当初はフォロワー僅か、だったが逆に好き勝手なことが書けた。Tumblrってテキスト投稿には向いてないと思うけど、それすら気にせずに画像だろうが音声だろうがテキストだろうが、好きなように投稿する。それがTumblrの良さ。\n当初投稿するのは自分の写真が中心で、たまにテキストあり、リブログはあまりしていなかった。特にフォローしたいアカウントもなかったけどたまに癒し系とか懐かし系画像投稿したいから適当に複数アカウントフォローしてた。でも、楽しくはなかったんだよね。「たまにこっち系の画像ポストするのはいいけどそれメインでやりたいわけじゃないし、なんか違う気がするなぁ」と違和感を覚え始めて、フォロー解除した。\n  しかしその後、何がきっかけか覚えていないのだが、あるアカウントとその周辺アカウントをフォロー開始してから、めっちゃ楽しくなってしまった。それらのアカウントは毎日投稿しているけど、リブログせずにいられないような、何かしらカッコイイポストが必ずある。経由されたポストやソースをポストしたアカウントを追うとこれまたセンスが良くて、芋づる式に夢中でlike,reblogしてしまうのである。\nTumblrのすごいところは、オリジナルのポスト作成者じゃなくても、センスのいいポストで構成されたブログが甚大な価値を持つことだ。「あなたのセンスは素晴らしい、本当に尊敬する！」と叫びたくなるようなアカウントが複数存在する。まだ出会えていないブログもあるかもしれない。実際最近になっても、「こんなセンスいいブログがあったんだ！」と新たに発見することがある。（もちろんそんなときに直接メッセージを送ったりはしない。1%程度の例外はあるだろうが、Tumblrでは誰もそんなこと望んでいないのだから）\nいいポストを集めたブログは自然にいいブログになる。オリジナルの作者かどうか、の区別はもはや意味をなさなくなる。いいものを発見してコレクションする、そのエネルギーが、見る人にインスピレーションや刺激を与えるのだ。それがTumblrの良さ。（二度目）\nこのことに気づいてから、俺は夢中になってしまった。Tumblr自体はずっと前からやっているのに、こんなに楽しいと感じたのは初めてといってもいい。\n  以上は「誰をフォローするか」による影響の話。ここから先、「誰にフォローされるか」について書いてみる。\n少し前のある日、これまで細々とした件数だった、零細アカウントの俺の通知が飛躍的に伸びた。たまに特定のポストのリアクションが増加することはあったが、その日は過去にない規模の反響だった。「何かあったか？」と追ってみると、ある人気アカウントが自分のポストを複数リブログしてた。そこから雪だるま式にリアクションが増えたわけである。これにより、自分のブログのフォロワーも増加した。増加といってもその日に十人くらい、その後日に数人ずつ程度のペースだが。ちなみに先の人気アカウントにもフォローされていた。\nしかし、正直あまりうれしくないし、逆に困る。「ある誰かが自分の投稿を見ている」ことを意識していると、書きにくいことが出てくるのである。画像のポストだけでみても、フォロワーにインフルエンサーとそのフォロワーがいると「何を投稿するか」について、これまで以上に他人を意識せざるを得なくなってしまうのである。それまでは「とにかく自分がポストしたいものをポストする」スタンスだったのに、他人にサービスするようなポストを挟んでしまうとか。実際その日以降、しばらくそんな状況が続いた。引き摺られてはいけない、と自覚しつつも、どこかで引き摺られてしまうのだ。\nで、この状況はストレスなのである。つまり楽しくないのである。楽しくないTumblrなんかやりなくない。自分が楽しむためにやっているんだから、プライオリティの優位をそっちに戻す必要がある。\u0026hellip;と、そのことを明確に言語化するためのこの投稿を書いた。\n実はこの件と前後して、先の方に書いたセンス抜群のアカウントからフォローしてもらった。これは嬉しかったね。俺のポストはそんなにリブログしてもらってないけど、たまにリブログしてもらうとやはり反響がすごい。まぁこの反響ってのも良し悪しだけどね、まったく反応がないと寂しいけどデカすぎても疲れる、さっき書いたように、よくない影響受けることがあるからね。まぁこれって、リアルライフで人混みに出ると疲れるのと同じことだと思う。\n  で、最終的に言いたいことは。\nリアルライフでもSNSでも、「自分の周囲に誰がいるか」の影響は非常に大きいのだ、と。\n人間は誰でもエネルギーを持っている。エネルギーは、良くも悪くも他者に影響を与える。ある人間が、良いエネルギーを放出している集団の中にいればおのずとよい影響を受ける。逆もまた然りである。リアルライフだとそのことを如実に実感するが、ネット上でもそれは同様だ。実際物事はそう単純ではないから、他者からの影響の方向や質はモザイクのように絡み合っているイメージではあるが\u0026hellip;\nTwitterとかFacebookみたいにガチで言葉の応酬をするようなSNSは当然その傾向が強いと思うが、Tumblrのように非常に関係性が薄いSNSでもそういうことがあるんだな、と今更ながら実感した次第。\n結論としては、Tumblrではいくつかのアカウントを本当にリスペクトしているけれど、自分の軸をずらさずにかつ一定の距離を保つ姿勢を貫くのが、長く楽しむコツだね。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/sns-influence/","summary":"SNSって誰をフォローするかも大きいけど誰にフォローされるか、も相当影響でかいんだなと思う。\nもともとSNS嫌いだからほとんどやってないけど、Tumblrは例外で、ここしばらく依存症に近いくらい使っている。全然使っていなかった時期もあるんだけどね。今は諸事情によりヘビーユーザー。\n当初はフォロワー僅か、だったが逆に好き勝手なことが書けた。Tumblrってテキスト投稿には向いてないと思うけど、それすら気にせずに画像だろうが音声だろうがテキストだろうが、好きなように投稿する。それがTumblrの良さ。\n当初投稿するのは自分の写真が中心で、たまにテキストあり、リブログはあまりしていなかった。特にフォローしたいアカウントもなかったけどたまに癒し系とか懐かし系画像投稿したいから適当に複数アカウントフォローしてた。でも、楽しくはなかったんだよね。「たまにこっち系の画像ポストするのはいいけどそれメインでやりたいわけじゃないし、なんか違う気がするなぁ」と違和感を覚え始めて、フォロー解除した。\n  しかしその後、何がきっかけか覚えていないのだが、あるアカウントとその周辺アカウントをフォロー開始してから、めっちゃ楽しくなってしまった。それらのアカウントは毎日投稿しているけど、リブログせずにいられないような、何かしらカッコイイポストが必ずある。経由されたポストやソースをポストしたアカウントを追うとこれまたセンスが良くて、芋づる式に夢中でlike,reblogしてしまうのである。\nTumblrのすごいところは、オリジナルのポスト作成者じゃなくても、センスのいいポストで構成されたブログが甚大な価値を持つことだ。「あなたのセンスは素晴らしい、本当に尊敬する！」と叫びたくなるようなアカウントが複数存在する。まだ出会えていないブログもあるかもしれない。実際最近になっても、「こんなセンスいいブログがあったんだ！」と新たに発見することがある。（もちろんそんなときに直接メッセージを送ったりはしない。1%程度の例外はあるだろうが、Tumblrでは誰もそんなこと望んでいないのだから）\nいいポストを集めたブログは自然にいいブログになる。オリジナルの作者かどうか、の区別はもはや意味をなさなくなる。いいものを発見してコレクションする、そのエネルギーが、見る人にインスピレーションや刺激を与えるのだ。それがTumblrの良さ。（二度目）\nこのことに気づいてから、俺は夢中になってしまった。Tumblr自体はずっと前からやっているのに、こんなに楽しいと感じたのは初めてといってもいい。\n  以上は「誰をフォローするか」による影響の話。ここから先、「誰にフォローされるか」について書いてみる。\n少し前のある日、これまで細々とした件数だった、零細アカウントの俺の通知が飛躍的に伸びた。たまに特定のポストのリアクションが増加することはあったが、その日は過去にない規模の反響だった。「何かあったか？」と追ってみると、ある人気アカウントが自分のポストを複数リブログしてた。そこから雪だるま式にリアクションが増えたわけである。これにより、自分のブログのフォロワーも増加した。増加といってもその日に十人くらい、その後日に数人ずつ程度のペースだが。ちなみに先の人気アカウントにもフォローされていた。\nしかし、正直あまりうれしくないし、逆に困る。「ある誰かが自分の投稿を見ている」ことを意識していると、書きにくいことが出てくるのである。画像のポストだけでみても、フォロワーにインフルエンサーとそのフォロワーがいると「何を投稿するか」について、これまで以上に他人を意識せざるを得なくなってしまうのである。それまでは「とにかく自分がポストしたいものをポストする」スタンスだったのに、他人にサービスするようなポストを挟んでしまうとか。実際その日以降、しばらくそんな状況が続いた。引き摺られてはいけない、と自覚しつつも、どこかで引き摺られてしまうのだ。\nで、この状況はストレスなのである。つまり楽しくないのである。楽しくないTumblrなんかやりなくない。自分が楽しむためにやっているんだから、プライオリティの優位をそっちに戻す必要がある。\u0026hellip;と、そのことを明確に言語化するためのこの投稿を書いた。\n実はこの件と前後して、先の方に書いたセンス抜群のアカウントからフォローしてもらった。これは嬉しかったね。俺のポストはそんなにリブログしてもらってないけど、たまにリブログしてもらうとやはり反響がすごい。まぁこの反響ってのも良し悪しだけどね、まったく反応がないと寂しいけどデカすぎても疲れる、さっき書いたように、よくない影響受けることがあるからね。まぁこれって、リアルライフで人混みに出ると疲れるのと同じことだと思う。\n  で、最終的に言いたいことは。\nリアルライフでもSNSでも、「自分の周囲に誰がいるか」の影響は非常に大きいのだ、と。\n人間は誰でもエネルギーを持っている。エネルギーは、良くも悪くも他者に影響を与える。ある人間が、良いエネルギーを放出している集団の中にいればおのずとよい影響を受ける。逆もまた然りである。リアルライフだとそのことを如実に実感するが、ネット上でもそれは同様だ。実際物事はそう単純ではないから、他者からの影響の方向や質はモザイクのように絡み合っているイメージではあるが\u0026hellip;\nTwitterとかFacebookみたいにガチで言葉の応酬をするようなSNSは当然その傾向が強いと思うが、Tumblrのように非常に関係性が薄いSNSでもそういうことがあるんだな、と今更ながら実感した次第。\n結論としては、Tumblrではいくつかのアカウントを本当にリスペクトしているけれど、自分の軸をずらさずにかつ一定の距離を保つ姿勢を貫くのが、長く楽しむコツだね。","title":"Tumblrについて、ひとり言"},{"content":"前回投稿でAWS CodePipelineのクロスアカウント設定（前半）ではリソース配布元のアカウントAの内容中心に書いた。後半は配布先となるアカウントBの設定内容を書いていく。\n前回投稿\nAWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-1）\n繰り返しになるけれども、前提条件をおさらいとして記載。\nやりたいこと\nAWSの異なるアカウント間で、CodePipelineによりCodeDeployからec2インスタンスにリソースをデプロイする。ソースはリソース配布側のCodeCommit。この記事では配布元を開発環境/アカウントA、配布先を検証環境/アカウントBとして話を進める。 主な参考ページ\n他のリソースを使用するパイプラインを CodePipeline で作成するAWSアカウント\n 主な構成要素 これも前回書いているが、こっちにも書いておかないとわけわからなくなるので再掲。\n1-資材配布元（アカウントA）\n① CodeCommitリポジトリ（ec2にローカルリポジトリを作成〜資材格納）\n② KMSキー (両方のアカウントにアクセス許可する)\n③ S3バケット (アカウントBにアクセス許可するバケットポリシーを付与）\n④ CodePipelineが使用するサービスロール\n⑤ CodePipleline定義（コンソールで作成したパイプライン定義JSONをCLIから更新）\n 2-資材配布先（アカウントB）\n① CodeDeploy定義（アプリケーション/デプロイメントグループ）\n② ec2用のIAMロール（CodeDeployがアカウントAのKMSキー、S3にアクセスするためのポリシーを付与）\n③ ②のIAMロールをアタッチしたデプロイ先ec2\n④ クロスアカウント用サービスロール（CodeDeployとS3操作にassumeする）\n 上記アイテムを作成済みとして、作業概要は前回記事に記載した。以降、アカウントB側で用意するアイテムの内容を書く。\n2-① CodeDeploy定義\nアカウントBのコンソールにて、アプリケーションとデプロイメントグループを作成する。詳細は割愛。\n2-② ec2用のIAMロール\nKMSとS3用のインラインポリシーを作成する。AWS参考ページでは2つに分けていたが統合しても問題ないと思う。\nKMS用インラインポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:DescribeKey\u0026#34;, \u0026#34;kms:GenerateDataKey*\u0026#34;, \u0026#34;kms:Encrypt\u0026#34;, \u0026#34;kms:ReEncrypt*\u0026#34;, \u0026#34;kms:Decrypt\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:kms:us-east-1:[アカウントAのID]:key/[Key ID]\u0026#34; #KMSのARN ] } ] }  S3用インラインポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:Get*\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::[アカウントAのS3バケット名]/*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::[アカウントAのS3バケット名]\u0026#34; ] } ] }  2-④ クロスアカウントデプロイ用IAMロール\nサービスをCodeDeployとしてロールを作成する。この時アカウントAにassumeする前提で以下設定を行う。以下図の矢印箇所にアカウントAのIDを入力して次へ進む。これ以降は通常のロール作成時と同じ。\n デプロイ用ロール信頼ポリシーのJSONは以下のようになる。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::[アカウントAのID]:root\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Condition\u0026#34;: {} }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;codedeploy.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] }  デプロイ用メインのカスタムポリシー。CodeDeployのパーミッションを定義。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;codedeploy:CreateDeployment\u0026#34;, \u0026#34;codedeploy:GetDeployment\u0026#34;, \u0026#34;codedeploy:GetDeploymentConfig\u0026#34;, \u0026#34;codedeploy:GetApplicationRevision\u0026#34;, \u0026#34;codedeploy:RegisterApplicationRevision\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] }  デプロイ用インラインポリシー。S3とCodeCommitのパーミッション定義。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject*\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:PutObjectAcl\u0026#34;, \u0026#34;codecommit:ListBranches\u0026#34;, \u0026#34;codecommit:ListRepositories\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::[S3バケット名]/*\u0026#34; ] } ] }  これとは別にec2周りのポリシーも割り当てる。検証時は取り急ぎマネージドのAmazonEC2ReadOnlyAccessでもアタッチしておけばいい。\n これでやっとアイテムが出揃った。ここまで来たら、前回投稿の分も重複するがアカウントAの環境にて以下実行。（2. までは前回までの段階で完了しているとして、3.以降を実施）\n コンソールで単体アカウント用にパイプラインを作成 そのJSON定義を取得してクロスアカウント向けに編集 パイプラインをアップデート  $ aws codepipeline update-pipeline --cli-input-json file://[パイプライン名].json  アップデートしたパイプラインをスタート  $ aws codepipeline start-pipeline-execution --name [パイプライン名]  特にエラーが出なければパイプラインは走っているが、その先でコケることはよくあるのでコンソール画面から状況を確認する。アカウントAのマネジメントコンソール画面から全体の状況は把握できる。デプロイステージの詳細はアカウントBのコンソールからしか見れない。\nというわけで、果てしなく続くと思われた長い旅路がようやく終わりましたよ。しかしいいかげんに普通の旅にも出たいもんだ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/aws-crossaccount-pipeline-2/","summary":"前回投稿でAWS CodePipelineのクロスアカウント設定（前半）ではリソース配布元のアカウントAの内容中心に書いた。後半は配布先となるアカウントBの設定内容を書いていく。\n前回投稿\nAWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-1）\n繰り返しになるけれども、前提条件をおさらいとして記載。\nやりたいこと\nAWSの異なるアカウント間で、CodePipelineによりCodeDeployからec2インスタンスにリソースをデプロイする。ソースはリソース配布側のCodeCommit。この記事では配布元を開発環境/アカウントA、配布先を検証環境/アカウントBとして話を進める。 主な参考ページ\n他のリソースを使用するパイプラインを CodePipeline で作成するAWSアカウント\n 主な構成要素 これも前回書いているが、こっちにも書いておかないとわけわからなくなるので再掲。\n1-資材配布元（アカウントA）\n① CodeCommitリポジトリ（ec2にローカルリポジトリを作成〜資材格納）\n② KMSキー (両方のアカウントにアクセス許可する)\n③ S3バケット (アカウントBにアクセス許可するバケットポリシーを付与）\n④ CodePipelineが使用するサービスロール\n⑤ CodePipleline定義（コンソールで作成したパイプライン定義JSONをCLIから更新）\n 2-資材配布先（アカウントB）\n① CodeDeploy定義（アプリケーション/デプロイメントグループ）\n② ec2用のIAMロール（CodeDeployがアカウントAのKMSキー、S3にアクセスするためのポリシーを付与）\n③ ②のIAMロールをアタッチしたデプロイ先ec2\n④ クロスアカウント用サービスロール（CodeDeployとS3操作にassumeする）\n 上記アイテムを作成済みとして、作業概要は前回記事に記載した。以降、アカウントB側で用意するアイテムの内容を書く。\n2-① CodeDeploy定義\nアカウントBのコンソールにて、アプリケーションとデプロイメントグループを作成する。詳細は割愛。\n2-② ec2用のIAMロール\nKMSとS3用のインラインポリシーを作成する。AWS参考ページでは2つに分けていたが統合しても問題ないと思う。\nKMS用インラインポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:DescribeKey\u0026#34;, \u0026#34;kms:GenerateDataKey*\u0026#34;, \u0026#34;kms:Encrypt\u0026#34;, \u0026#34;kms:ReEncrypt*\u0026#34;, \u0026#34;kms:Decrypt\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:kms:us-east-1:[アカウントAのID]:key/[Key ID]\u0026#34; #KMSのARN ] } ] }  S3用インラインポリシー","title":"AWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-2）"},{"content":"前回投稿ではパイプラインなしでAWS クロスアカウントデプロイをやった。次はパイプラインを使ってやってみる。長くなるので前半/後半に分ける。\n やりたいこと\nAWSの異なるアカウント間で、CodePipelineによりCodeDeployからec2インスタンスにリソースをデプロイする。ソースはリソース配布側のCodeCommit。この記事では配布元を開発環境/アカウントA、配布先を検証環境/アカウントBとして話を進める。（ec2はオートスケールもなくただ単に配布するだけなので単一アカウントだったら簡単な話なんだが、アカウント跨ぐとなるとめっちゃ面倒くさい\u0026hellip;）\n 主な参考ページ\n他のリソースを使用するパイプラインを CodePipeline で作成するAWSアカウント\n 基本的にこのページの通りにやればOK。アカウントA側で一度単一アカウント用の適当なパイプラインを作成して、そのJSON定義を取得。それをクロスアカウント用に編集してCLIからアップデートする。ちなみに上記リンクは日本語版だが機械翻訳の文章がまともな日本語ではなくイラッとくるので、ほぼオリジナルの英語版を参考にした。\n参考までに、以下クラメソさんの記事。当初これのBuildをDeployに置き換えてやってみたが失敗した。不足か誤りがあるんだろうがいきなりやったこともありわけがわからなすぎて頓挫。先述のAWS公式の方がやりたいことに近かったため仕切り直しした。\nクロスアカウントCodeBuild + パイプライン例\nCodePipelineでアカウントをまたいだパイプラインを作成してみる\n 制約事項\n クロスアカウントのパイプラインはマネジメントコンソールから作成不可のため、aws cliから作成/更新する CodeDeployの定義とデプロイ先のec2は同一アカウントであること クロスアカウントでパイプラインを組む場合、アーティファクト格納用S3バケットの暗号化キーはKMSを使用する（AWS デフォルトの暗号化キーはNG）   主な構成要素 2アカウント間で各種アイテムを用意することになり、混乱しがちなのでまとめておく。前回投稿では配布先となるアカウントB側にS3バケットがある構成だったが、今回は逆。ただし構成的にはこちらの方が自然かと思う。\n1-資材配布元（アカウントA）\n① CodeCommitリポジトリ（ec2にローカルリポジトリを作成〜資材格納）\n② KMSキー (両方のアカウントにアクセス許可する)\n③ S3バケット (アカウントBにアクセス許可するバケットポリシーを付与）\n④ CodePipelineが使用するサービスロール\n⑤ CodePipleline定義（コンソールで作成したパイプライン定義JSONをCLIから更新）\nJSON取得コマンド\n$ aws codepipeline get-pipeline --name [パイプライン名] \u0026gt; [パイプライン名].json  2-資材配布先（アカウントB）\n① CodeDeploy定義（アプリケーション/デプロイメントグループ）\n② ec2用のIAMロール（CodeDeployがアカウントAのKMSキー、S3にアクセスするためのポリシーを付与）\n③ ②のIAMロールをアタッチしたデプロイ先ec2\n④ クロスアカウント用サービスロール（CodeDeployとS3操作にassumeする）\n 作業概要 上記各リソースを作成済として、以下の作業を行う。\nアカウントAの作業用端末またはec2にログイン。1-⑤のパイプライン定義JSONを適当なパスに配置し、パイプラインをアップデートする\n$ cd /path/to/json $ aws codepipeline update-pipeline --cli-input-json file://[パイプライン名].json  アップデートしたパイプラインを実行する\n$ aws codepipeline start-pipeline-execution --name [パイプライン名]  アカウントBでは特に作業なし。デプロイステータスが成功になったら、ec2に資材がデプロイされていることを確認する。\nクロスアカウントパイプラインの処理中の見え方\nアカウントAのマネジメントコンソール：パイプライン全体の処理状況は見える。デプロイステージの詳細は見れない。\nアカウントBのコンソール : デプロイの詳細が見れる\n 各種アイテムのサンプル AWS公式でも基本内容は網羅されているが自分用メモとしてここにも載せておく。\nアカウントA側アイテム\n1-② KMSキーポリシー\nアーティファクト用S3バケットの暗号化キーポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;[key-policy-name]\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Enable IAM User Permissions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::[アカウントAのID]:root\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;kms:*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;Allow access for Key Administrators\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;[KMSの暗号化キーの管理ユーザのARN]\u0026#34; #アカウントA側のキーのオーナーを指定 }, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:Create*\u0026#34;, \u0026#34;kms:Describe*\u0026#34;, \u0026#34;kms:Enable*\u0026#34;, \u0026#34;kms:List*\u0026#34;, \u0026#34;kms:Put*\u0026#34;, \u0026#34;kms:Update*\u0026#34;, \u0026#34;kms:Revoke*\u0026#34;, \u0026#34;kms:Disable*\u0026#34;, \u0026#34;kms:Get*\u0026#34;, \u0026#34;kms:Delete*\u0026#34;, \u0026#34;kms:TagResource\u0026#34;, \u0026#34;kms:UntagResource\u0026#34;, \u0026#34;kms:ScheduleKeyDeletion\u0026#34;, \u0026#34;kms:CancelKeyDeletion\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;Allow use of the key\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: [ \u0026#34;[アカウントAのパイプライン用サービスロールのARN]\u0026#34;, #(注1) \u0026#34;arn:aws:iam::[アカウントBのID]:root\u0026#34; ] }, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:Encrypt\u0026#34;, \u0026#34;kms:Decrypt\u0026#34;, \u0026#34;kms:ReEncrypt*\u0026#34;, \u0026#34;kms:GenerateDataKey*\u0026#34;, \u0026#34;kms:DescribeKey\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;Allow attachment of persistent resources\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: [ \u0026#34;[アカウントAのパイプライン用サービスロールのARN]\u0026#34;, #(注1) \u0026#34;arn:aws:iam::[アカウントBのID]:root\u0026#34; ] }, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:CreateGrant\u0026#34;, \u0026#34;kms:ListGrants\u0026#34;, \u0026#34;kms:RevokeGrant\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;Bool\u0026#34;: { \u0026#34;kms:GrantIsForAWSResource\u0026#34;: \u0026#34;true\u0026#34; } } } ] } (注1) 構文\narn:aws:iam::[アカウントAのID]:role/[パイプラインロール名]\n 1-③ S3バケットポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;SSEAndSSLPolicy\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;DenyUnEncryptedObjectUploads\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::[S3バケット名]/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringNotEquals\u0026#34;: { \u0026#34;s3:x-amz-server-side-encryption\u0026#34;: \u0026#34;aws:kms\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;DenyInsecureConnections\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::[S3バケット名]/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;Bool\u0026#34;: { \u0026#34;aws:SecureTransport\u0026#34;: false } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::[アカウントBのID]:root\u0026#34; }, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:Get*\u0026#34;, \u0026#34;s3:Put*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::[S3バケット名]/*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::[アカウントBのID]:root\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::[S3バケット名]\u0026#34; } ] }  1-④ CodePipelineが使用するサービスロール(IAM)\nこのロールには以下のポリシーを割り当てる。1.はロール作成前に作成可能。コンソールからロール作成する時に選択可能なサービスにCodePipelineがないので一旦CodeDeployで作成して、後から信頼ポリシー編集した。\n 通常のCodePipeline作業用ポリシー アカウントBのassume用インラインポリシー 信頼ポリシー（編集）  以下CodePipeline作業用ポリシー。AWSが自動で付与するポリシーは他のパーミッションも多く含まれているがそこから削って最小限にしたのがこれ。autoscalingは使わないんだけど一応残す。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Action\u0026#34;: [ \u0026#34;iam:PassRole\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEqualsIfExists\u0026#34;: { \u0026#34;iam:PassedToService\u0026#34;: [ \u0026#34;ec2.amazonaws.com\u0026#34; ] } } }, { \u0026#34;Action\u0026#34;: [ \u0026#34;codecommit:CancelUploadArchive\u0026#34;, \u0026#34;codecommit:GetBranch\u0026#34;, \u0026#34;codecommit:GetCommit\u0026#34;, \u0026#34;codecommit:GetUploadArchiveStatus\u0026#34;, \u0026#34;codecommit:UploadArchive\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; }, { \u0026#34;Action\u0026#34;: [ \u0026#34;codedeploy:CreateDeployment\u0026#34;, \u0026#34;codedeploy:GetApplication\u0026#34;, \u0026#34;codedeploy:GetApplicationRevision\u0026#34;, \u0026#34;codedeploy:GetDeployment\u0026#34;, \u0026#34;codedeploy:GetDeploymentConfig\u0026#34;, \u0026#34;codedeploy:RegisterApplicationRevision\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; }, { \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:*\u0026#34;, \u0026#34;elasticloadbalancing:*\u0026#34;, \u0026#34;autoscaling:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;s3:*\u0026#34;, \u0026#34;tag:*\u0026#34;, \u0026#34;logs:*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; } ] }  アカウントBのassume用インラインポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:iam::[アカウントBのID]:role/*\u0026#34; ] } }  信頼ポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: [ \u0026#34;codepipeline.amazonaws.com\u0026#34;, \u0026#34;codedeploy.amazonaws.com\u0026#34;, \u0026#34;ec2.amazonaws.com\u0026#34; ] }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] }  1-⑤ CodePiplelineのJSON定義\n冒頭のAWS公式ページにもポイントは記載されているが、今回のケースでまとめたのがこれ。繰り返しになるが、「1.コンソールで単体アカウント用にパイプラインを作成 2. そのJSON定義を取得してクロスアカウント向けに編集 3. パイプラインをアップデート」という流れになる。最初にパイプラインを作成するときにCodeDeploy用定義が必要なため、事前にアカウントA内で適当なCodeDeployアプリケーション/デプロイメントグループのペアを用意しておく。\n以下のJSON後半でアカウントB側のアイテム定義名をいくつか記載しており、当然アカウントB側に実体が存在する前提だが、編集時点では存在していなくても構わない。\n{ \u0026#34;pipeline\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;A_crossdeploy_pipeline\u0026#34;, \u0026#34;roleArn\u0026#34;: \u0026#34;arn:aws:iam::[アカウントAのID]:role/[クロスアカウントパイプライン用IAMロール名]\u0026#34;, \u0026#34;artifactStore\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;S3\u0026#34;, \u0026#34;location\u0026#34;: \u0026#34;[S3バケット名]\u0026#34; \u0026#34;encryptionKey\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;arn:aws:kms:us-east-1:[アカウントAのID]:key/[キーのID]\u0026#34;, #KMSキーのARN \u0026#34;type\u0026#34;: \u0026#34;KMS\u0026#34; }, \u0026#34;stages\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Source\u0026#34;, \u0026#34;actions\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Source\u0026#34;, \u0026#34;actionTypeId\u0026#34;: { \u0026#34;category\u0026#34;: \u0026#34;Source\u0026#34;, \u0026#34;owner\u0026#34;: \u0026#34;AWS\u0026#34;, \u0026#34;provider\u0026#34;: \u0026#34;CodeCommit\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1\u0026#34; }, \u0026#34;runOrder\u0026#34;: 1, \u0026#34;configuration\u0026#34;: { \u0026#34;BranchName\u0026#34;: \u0026#34;master\u0026#34;, \u0026#34;OutputArtifactFormat\u0026#34;: \u0026#34;CODE_ZIP\u0026#34;, \u0026#34;PollForSourceChanges\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;RepositoryName\u0026#34;: \u0026#34;[ソースリポジトリ名]\u0026#34; }, \u0026#34;outputArtifacts\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;SourceArtifact\u0026#34; } ], \u0026#34;roleArn\u0026#34; : \u0026#34;arn:aws:iam::[アカウントAのID]:role/[クロスアカウントパイプライン用IAMロール名]\u0026#34;, #冒頭で指定したIAMと同じ \u0026#34;inputArtifacts\u0026#34;: [], \u0026#34;region\u0026#34;: \u0026#34;ap-northeast-1\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;SourceVariables\u0026#34; } ] }, { \u0026#34;name\u0026#34;: \u0026#34;Deploy\u0026#34;, \u0026#34;actions\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;ExternalDeploy\u0026#34;, #Deploy --＞ ExternalDeployに変更 \u0026#34;actionTypeId\u0026#34;: { \u0026#34;category\u0026#34;: \u0026#34;Deploy\u0026#34;, \u0026#34;owner\u0026#34;: \u0026#34;AWS\u0026#34;, \u0026#34;provider\u0026#34;: \u0026#34;CodeDeploy\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1\u0026#34; }, \u0026#34;runOrder\u0026#34;: 1, \u0026#34;configuration\u0026#34;: { \u0026#34;ApplicationName\u0026#34;: \u0026#34;[アカウントBのコードデプロイアプリケーション名]\u0026#34;, \u0026#34;DeploymentGroupName\u0026#34;: \u0026#34;[アカウントBのコードデプロイデプロイメントグループ名]\u0026#34; }, \u0026#34;outputArtifacts\u0026#34;: [], \u0026#34;inputArtifacts\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;SourceArtifact\u0026#34; } ], \u0026#34;roleArn\u0026#34; : \u0026#34;arn:aws:iam::[アカウントBのID]:role/[アカウントBのクロスデプロイ用IAMロール名]\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-northeast-1\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;DeployVariables\u0026#34; } ] } ], \u0026#34;version\u0026#34;: 1 } }  やっとここまできた\u0026hellip;長かった。しかしまだ道は続く。次回、アカウントB側の設定内容を書きます。\n続き\nAWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-2）\n","permalink":"https://ecnedaced-seirots.github.io/post/a/aws-crossaccount-pipeline-1/","summary":"前回投稿ではパイプラインなしでAWS クロスアカウントデプロイをやった。次はパイプラインを使ってやってみる。長くなるので前半/後半に分ける。\n やりたいこと\nAWSの異なるアカウント間で、CodePipelineによりCodeDeployからec2インスタンスにリソースをデプロイする。ソースはリソース配布側のCodeCommit。この記事では配布元を開発環境/アカウントA、配布先を検証環境/アカウントBとして話を進める。（ec2はオートスケールもなくただ単に配布するだけなので単一アカウントだったら簡単な話なんだが、アカウント跨ぐとなるとめっちゃ面倒くさい\u0026hellip;）\n 主な参考ページ\n他のリソースを使用するパイプラインを CodePipeline で作成するAWSアカウント\n 基本的にこのページの通りにやればOK。アカウントA側で一度単一アカウント用の適当なパイプラインを作成して、そのJSON定義を取得。それをクロスアカウント用に編集してCLIからアップデートする。ちなみに上記リンクは日本語版だが機械翻訳の文章がまともな日本語ではなくイラッとくるので、ほぼオリジナルの英語版を参考にした。\n参考までに、以下クラメソさんの記事。当初これのBuildをDeployに置き換えてやってみたが失敗した。不足か誤りがあるんだろうがいきなりやったこともありわけがわからなすぎて頓挫。先述のAWS公式の方がやりたいことに近かったため仕切り直しした。\nクロスアカウントCodeBuild + パイプライン例\nCodePipelineでアカウントをまたいだパイプラインを作成してみる\n 制約事項\n クロスアカウントのパイプラインはマネジメントコンソールから作成不可のため、aws cliから作成/更新する CodeDeployの定義とデプロイ先のec2は同一アカウントであること クロスアカウントでパイプラインを組む場合、アーティファクト格納用S3バケットの暗号化キーはKMSを使用する（AWS デフォルトの暗号化キーはNG）   主な構成要素 2アカウント間で各種アイテムを用意することになり、混乱しがちなのでまとめておく。前回投稿では配布先となるアカウントB側にS3バケットがある構成だったが、今回は逆。ただし構成的にはこちらの方が自然かと思う。\n1-資材配布元（アカウントA）\n① CodeCommitリポジトリ（ec2にローカルリポジトリを作成〜資材格納）\n② KMSキー (両方のアカウントにアクセス許可する)\n③ S3バケット (アカウントBにアクセス許可するバケットポリシーを付与）\n④ CodePipelineが使用するサービスロール\n⑤ CodePipleline定義（コンソールで作成したパイプライン定義JSONをCLIから更新）\nJSON取得コマンド\n$ aws codepipeline get-pipeline --name [パイプライン名] \u0026gt; [パイプライン名].json  2-資材配布先（アカウントB）\n① CodeDeploy定義（アプリケーション/デプロイメントグループ）\n② ec2用のIAMロール（CodeDeployがアカウントAのKMSキー、S3にアクセスするためのポリシーを付与）\n③ ②のIAMロールをアタッチしたデプロイ先ec2\n④ クロスアカウント用サービスロール（CodeDeployとS3操作にassumeする）\n 作業概要 上記各リソースを作成済として、以下の作業を行う。\nアカウントAの作業用端末またはec2にログイン。1-⑤のパイプライン定義JSONを適当なパスに配置し、パイプラインをアップデートする\n$ cd /path/to/json $ aws codepipeline update-pipeline --cli-input-json file://[パイプライン名].","title":"AWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-1）"},{"content":"AWS環境で、クロスアカウントでCI/CDしたい。とりあえずBuildフェーズはいらなくてDeployだけでいい。Deployの実行はパイプラインあり/なし両方可能。どちらも単一アカウント内なら複雑な設定もなく比較的容易にできることはわかっているが、クロスアカウントとなると何かと面倒だ。でもやってみる。ここではまずはパイプラインなしとする。\n 参考\n異なる AWS アカウントでアプリケーションをデプロイする\n（上記ページにリンクあり。assumeロールの設定は以下参考）\nIAM チュートリアル: AWS アカウント間の IAM ロールを使用したアクセスの委任\n 環境前提 配布元となるAWS開発環境(Dev)にCodeCommitのローカルリポジトリがあり、そこから別アカウントの検証環境(Stg)にデプロイする。その先には本番環境がある想定だが構成は同じになるはず。\n① 配布元(Dev)\n② 配布先(Stg)\n概要 ①配布元のアカウントから②配布先のec2にデプロイ可能とするため、②配布先アカウント側で①アカウントのassumeを可能とするIAMロールを作成する。（ロールAとする）① 配布元アカウント側でロールAにassumeし、デプロイを実行する。\n基本的に必要となるのはIAM周りの設定であり、ネットワーク系の特別な実装は必要ない。\n 作業内容   配布先②アカウントにて、配置用のS3バケットを作成する。IAMロールのポリシーでバケットへのアクセス権限を定義するため、バケットポリシーは設定しなくても問題なし。(注1)\n  配布先②アカウントにて、①がassumeするためのロールAを作成する。\n  ロールAで定義する内容 (1) 信頼ポリシーで②のアカウントIDを指定してassumeを許可する。このときrootか②側のIAMロールどちらかを指定する。\nrootに設定した場合は、①アカウントでデプロイを実行するユーザのグループにassume可能とするインラインポリシーを適用する。\nIAMに設定した場合は、①アカウントでデプロイを実行するec2にこのIAMロールを適用する。実行環境がec2の場合はこれでよいが、クライアント端末の場合はrootにする。\n インラインポリシー例 (①アカウントで設定) デプロイ実行ユーザが所属するグループの画面を開き、[アクセス許可] タブ \u0026ndash;\u0026gt; [アクセス許可の追加] \u0026ndash;\u0026gt; [インラインポリシーの作成] [JSON] タブ選択\n以下の内容を設定する。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:iam::②配布先のアカウントID:role/ロールA\u0026#34; } }  (2) ①のアカウントが資材配置用のS3にアクセスするための権限を定義したポリシーを適用する。ちゃんと書いてないけど以下にcodedeploy, ec2の操作権限も追加する。codedeployの権限は何が必要かわからないのでとりあえず全許可にしておいた。ECSへのデプロイだとec2のterminate権限が必要みたいだが、今回の場合ec2は参照のみでOKだと思う。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:GetBucketLocation\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::staging-app\u0026#34; #検証環境の資材格納バケット名 }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::staging-app/*\u0026#34; } ] }  ②配布先アカウントにて、deployのアプリケーションとデプロイメントグループを作成する。詳細は割愛。   ①配布元アカウントのec2（または同アカウントのcredentialsをセットした端末）にログインし、ロールAにスイッチする。ちなみにマネジメントコンソールでもスイッチして作業可能だが、deployのpushコマンドがCLIでしかできないため、ここではCLI前提で話を進める。  この時先で作成したロールAにスイッチするため、以下のコマンドを実行する。\n$ aws sts assume-role --role-arn \u0026quot;②配布先のアカウントID:role/ロールA\u0026quot; --role-session-name \u0026quot;deployment-test\u0026quot;  すると以下の形式の認証情報が出力される。\n{ \u0026#34;Credentials\u0026#34;: { \u0026#34;AccessKeyId\u0026#34;: \u0026#34;[access key id]\u0026#34; \u0026#34;SecretAccessKey\u0026#34;: \u0026#34;[secret access key id]\u0026#34;, \u0026#34;SessionToken\u0026#34;: \u0026#34;[token id]\u0026#34;, \u0026#34;Expiration\u0026#34;: \u0026#34;2021-09-20T15:08:00Z\u0026#34; } }  上記を環境変数にセットする。Windowsの場合はexportをsetに変更する。\n$ export AWS_ACCESS_KEY_ID=[access key id] $ export AWS_SECRET_ACCESS_KEY=[secret access key id] $ export AWS_SESSION_TOKEN=[token id]  これでセッション保持期間の間（expireの時刻)は②アカウントのロールAの権限で作業が可能となる。セッション時間はデフォルトで1時間だが、伸ばしたい場合は--duration-secondsオプションを使う。（2時間なら7200、3時間なら10800と指定。ロールAの最大セッション期間がそれに応じた時間に設定されている前提）\n デプロイ実行  最初にやる時はデプロイ前にaws s3 cpを実行して、対象S3バケットへ読み書き可能かチェックしておくとよい。\nCLIでpush [オプション]を実行し、S3に資材を格納する。この時 3.で作成したアプリケーション名を指定する。（これによりただ単にS3に資材を配置するのではなく、資材をアプリケーションのリビジョンと関連付けることになる）sourceはここではCodeCommitのローカルリポジトリパスを指定しているが、指定するのはappspec.ymlを配置したディレクトリとなる。\n$ aws deploy push ¥ --application-name [aplication-name] ¥ --s3-location s3://[staging-app]/[staging-app-key] ¥ --ignore-hidden-files ¥ --source /path/to/source  pushが成功すると資材がzip形式で格納される。ターミナル上ではE-Tagを含む実行コマンド情報が標準出力される。詳細は割愛するがこれを元にcreate-deploymentにてデプロイを実行する。この時 3.で作成したデプロイメントグループを指定する。成功すれば②配布先となるec2にS3から資材が配置される。ちなみにpushはコンソールから実行できないが、デプロイは可能である。しかしそのために実行画面を切り替えるのも面倒なので（コンソールでもassumeする）、ここは引き続きCLIでやる方が自然かと。\n (注1) 配布元①アカウントにバケットを作成してもよいが、また追加の設定が必要となる。今回は配布先②に作成した。\n その他ポイント 最初deployのコマンドは通ったがその先で失敗した。この時コンソール上では以下のエラーが表示されていた。\n The overall deployment failed because too many individual instances failed deployment, too few healthy instances are available for deployment, or some instances in your deployment group are experiencing problems.\n  これだけではわからないのでログを確認してみたところ、こんなエラーが繰り返し吐かれていた。\n/var/log/aws/codedeploy-agent/codedeploy-agent.log\n InstanceAgent::Plugins::CodeDeployPlugin::CommandPoller: Missing credentials - please check if this instance was started with an IAM instance profile\n  確かに配布先ec2にはIAMロールをアタッチしていなかったため、インスタンスプロファイルが存在しない。するとcodedepoloyエージェントが上記のログを吐くわけだ。配布先のec2にインスタンスプロファイルを割り当てるため、別途IAMロールを作成してIAMロールをアタッチしたところ成功した。\nIAMをアタッチしても同じエラーが出る場合、エージェントを再起動してみる。候補が表示されなかったりエラーになったりしてIAMのアタッチ自体が不可能な場合は、インスタンスを一旦停止して再試行してみる。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/cross-account-codedeploy/","summary":"AWS環境で、クロスアカウントでCI/CDしたい。とりあえずBuildフェーズはいらなくてDeployだけでいい。Deployの実行はパイプラインあり/なし両方可能。どちらも単一アカウント内なら複雑な設定もなく比較的容易にできることはわかっているが、クロスアカウントとなると何かと面倒だ。でもやってみる。ここではまずはパイプラインなしとする。\n 参考\n異なる AWS アカウントでアプリケーションをデプロイする\n（上記ページにリンクあり。assumeロールの設定は以下参考）\nIAM チュートリアル: AWS アカウント間の IAM ロールを使用したアクセスの委任\n 環境前提 配布元となるAWS開発環境(Dev)にCodeCommitのローカルリポジトリがあり、そこから別アカウントの検証環境(Stg)にデプロイする。その先には本番環境がある想定だが構成は同じになるはず。\n① 配布元(Dev)\n② 配布先(Stg)\n概要 ①配布元のアカウントから②配布先のec2にデプロイ可能とするため、②配布先アカウント側で①アカウントのassumeを可能とするIAMロールを作成する。（ロールAとする）① 配布元アカウント側でロールAにassumeし、デプロイを実行する。\n基本的に必要となるのはIAM周りの設定であり、ネットワーク系の特別な実装は必要ない。\n 作業内容   配布先②アカウントにて、配置用のS3バケットを作成する。IAMロールのポリシーでバケットへのアクセス権限を定義するため、バケットポリシーは設定しなくても問題なし。(注1)\n  配布先②アカウントにて、①がassumeするためのロールAを作成する。\n  ロールAで定義する内容 (1) 信頼ポリシーで②のアカウントIDを指定してassumeを許可する。このときrootか②側のIAMロールどちらかを指定する。\nrootに設定した場合は、①アカウントでデプロイを実行するユーザのグループにassume可能とするインラインポリシーを適用する。\nIAMに設定した場合は、①アカウントでデプロイを実行するec2にこのIAMロールを適用する。実行環境がec2の場合はこれでよいが、クライアント端末の場合はrootにする。\n インラインポリシー例 (①アカウントで設定) デプロイ実行ユーザが所属するグループの画面を開き、[アクセス許可] タブ \u0026ndash;\u0026gt; [アクセス許可の追加] \u0026ndash;\u0026gt; [インラインポリシーの作成] [JSON] タブ選択\n以下の内容を設定する。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:iam::②配布先のアカウントID:role/ロールA\u0026#34; } }  (2) ①のアカウントが資材配置用のS3にアクセスするための権限を定義したポリシーを適用する。ちゃんと書いてないけど以下にcodedeploy, ec2の操作権限も追加する。codedeployの権限は何が必要かわからないのでとりあえず全許可にしておいた。ECSへのデプロイだとec2のterminate権限が必要みたいだが、今回の場合ec2は参照のみでOKだと思う。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:GetBucketLocation\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::staging-app\u0026#34; #検証環境の資材格納バケット名 }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::staging-app/*\u0026#34; } ] }  ②配布先アカウントにて、deployのアプリケーションとデプロイメントグループを作成する。詳細は割愛。   ①配布元アカウントのec2（または同アカウントのcredentialsをセットした端末）にログインし、ロールAにスイッチする。ちなみにマネジメントコンソールでもスイッチして作業可能だが、deployのpushコマンドがCLIでしかできないため、ここではCLI前提で話を進める。  この時先で作成したロールAにスイッチするため、以下のコマンドを実行する。","title":"AWS CodeDeployでクロスアカウントデプロイの実行（パイプラインなし）"},{"content":"かつてブラウザで全画面キャプチャしたい時はChromeにアドオンを入れて使っていたがこのアドオンはキャプチャしたデータをどこかに送信しているという話をどこかで読んで、ちょっとなぁ、と思った。しかし最近になってChromeでもFirefoxでもアドオンなしで全画面キャプチャが可能になっていることを知った。自宅で見るブラウザはほぼFirefoxでChromeは滅多に使わないが、職場では事情が変わったりするので両方書いておく。\nFirefoxの場合 F12キーで開発ツール画面を表示する。ツール画面右上のカメラアイコンをクリック。これだけ。素晴らしい。画像はデフォルトでDwonloadディレクトリに保存される。\n\u0026hellip;が、画面左側に小さな字でさりげなく「画像が大きすぎたため、xxxxxのサイズに切り抜きました」と言われている。画面が長すぎると途中で切られてしまうわけだ。結果的には以下のようになった。矢印の箇所は実際にここで画面が切れている。自分の投稿記事でやってみたんだけどまぁ実際この記事は長すぎるね。\nChromeの場合 Chromeでやる場合は一手間増える。\nWindows  Ctrl + Shift + I 同時押しで開発ツール画面を表示 Ctrl + Shift + P 同時押しで入力欄を表示させる 「full」と入力してreturn。少し待つとDwonloadディレクトリに保存される。  Mac  command + option + I 同時押しで開発ツール画面を表示 command + Shift + P同時押しで入力欄を表示させる 「full」と入力してreturn。少し待つとDwonloadディレクトリに保存される。\n（デフォルト保存先）  手間といっても大したことじゃないが、なにせものぐさなんで。それでもアドオンなしで全画面キャプチャ可能になったのはありがたい。\nしかしここでもやはり画面が長すぎておかしなことになっている。途中で一回途切れて（矢印箇所）、再度記事の初めから出力されるというループに陥っている。ま、とにかくFirefoxでもChromeでも長すぎるとダメつうことだ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/browser-capture-all/","summary":"かつてブラウザで全画面キャプチャしたい時はChromeにアドオンを入れて使っていたがこのアドオンはキャプチャしたデータをどこかに送信しているという話をどこかで読んで、ちょっとなぁ、と思った。しかし最近になってChromeでもFirefoxでもアドオンなしで全画面キャプチャが可能になっていることを知った。自宅で見るブラウザはほぼFirefoxでChromeは滅多に使わないが、職場では事情が変わったりするので両方書いておく。\nFirefoxの場合 F12キーで開発ツール画面を表示する。ツール画面右上のカメラアイコンをクリック。これだけ。素晴らしい。画像はデフォルトでDwonloadディレクトリに保存される。\n\u0026hellip;が、画面左側に小さな字でさりげなく「画像が大きすぎたため、xxxxxのサイズに切り抜きました」と言われている。画面が長すぎると途中で切られてしまうわけだ。結果的には以下のようになった。矢印の箇所は実際にここで画面が切れている。自分の投稿記事でやってみたんだけどまぁ実際この記事は長すぎるね。\nChromeの場合 Chromeでやる場合は一手間増える。\nWindows  Ctrl + Shift + I 同時押しで開発ツール画面を表示 Ctrl + Shift + P 同時押しで入力欄を表示させる 「full」と入力してreturn。少し待つとDwonloadディレクトリに保存される。  Mac  command + option + I 同時押しで開発ツール画面を表示 command + Shift + P同時押しで入力欄を表示させる 「full」と入力してreturn。少し待つとDwonloadディレクトリに保存される。\n（デフォルト保存先）  手間といっても大したことじゃないが、なにせものぐさなんで。それでもアドオンなしで全画面キャプチャ可能になったのはありがたい。\nしかしここでもやはり画面が長すぎておかしなことになっている。途中で一回途切れて（矢印箇所）、再度記事の初めから出力されるというループに陥っている。ま、とにかくFirefoxでもChromeでも長すぎるとダメつうことだ。","title":"Firefox/Chromeでアドオンなし全画面キャプチャ"},{"content":" 私的にMacで必須のショートカットを3つ挙げるとしたらこんなところかな。\n  フルスクリーン解除 control+ command + F\n  アプリケーションの強制終了 command + option + esc\n  スクリーンショット command + shift + 3\n   それにしてもフルスクリーンて、あれ何のためにあるん？意図的にフルスクリーンにすることなくて変な風にキーボード触ってしまった時になっちまうんだけど、迷惑極まりない\u0026hellip;\n 追記\nもうひとつ迷惑なショートカット思い出したから追加。ターミナル画面が分割されるやつ。command + D同時押しでなってしまうらしい。絶対使わんのに。戻すには、command + Shift + D。3選といいつつ、思い出したらまた書くかもな\u0026hellip;\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/mac-shortcut/","summary":" 私的にMacで必須のショートカットを3つ挙げるとしたらこんなところかな。\n  フルスクリーン解除 control+ command + F\n  アプリケーションの強制終了 command + option + esc\n  スクリーンショット command + shift + 3\n   それにしてもフルスクリーンて、あれ何のためにあるん？意図的にフルスクリーンにすることなくて変な風にキーボード触ってしまった時になっちまうんだけど、迷惑極まりない\u0026hellip;\n 追記\nもうひとつ迷惑なショートカット思い出したから追加。ターミナル画面が分割されるやつ。command + D同時押しでなってしまうらしい。絶対使わんのに。戻すには、command + Shift + D。3選といいつつ、思い出したらまた書くかもな\u0026hellip;\n ","title":"Macで必須のショートカット3選"},{"content":"サクラエディタで半角スペースを可視化したい。環境が変わって入れ直した時とか都度やり直す羽目になるからメモ。\nメニューから[設定] 〜 [タイプ別設定] を選択。\n 「カラー」タブ 半角空白 「色分け/表示」にチェック  ","permalink":"https://ecnedaced-seirots.github.io/post/a/sakura/","summary":"サクラエディタで半角スペースを可視化したい。環境が変わって入れ直した時とか都度やり直す羽目になるからメモ。\nメニューから[設定] 〜 [タイプ別設定] を選択。\n 「カラー」タブ 半角空白 「色分け/表示」にチェック  ","title":"サクラエディタで半角スペースを可視化"},{"content":"小ネタでもいいからどんどんポストしたいと思っているけどそれもなかなかできないもんだな。写真だけ。2018年4月の東京・井の頭公園。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/inokashira-park/","summary":"小ネタでもいいからどんどんポストしたいと思っているけどそれもなかなかできないもんだな。写真だけ。2018年4月の東京・井の頭公園。\n ","title":"井の頭公園 - 2018年4月"},{"content":"AWS EKSでPodからログを送信する場合、Container Insightsを組み込んでFluentdかFluent Bitを利用するのが一般的と思われる。そしてFluent BitよりFluentdの方がメジャーなのでまずはそこから入る事例が多いと想像する。しかし、元々組み込みLinux用に開発されて軽量リソースで動作するFluent Bitの方がコンテナログ送信に向いていると思う。ということで、この記事ではFluent Bitに焦点を当てる。\n 参照\nFluent Bit ドキュメント（設定詳細は画面左「DATA PIPELINE」配下のメニュー参照）\nFluent Bit Documentation\nContainer Insights全般\nAmazon EKS と Kubernetes での Container Insights のセットアップ\nFluent Bit on Container Insights\nCloudWatch Logs へログを送信する DaemonSet として Fluent Bit を設定する\nサンプルマニフェスト\nfluent-bit-compatible.yaml\n※AWSがサンプルとして提供しているFluent BitのマニフェストはFluent Bit最適化用とFluentd互換用がある。今回は過去にFluentd使用事例があることから、Fluentd互換用マニフェストをDLしてカスタマイズした。\n 共通マニフェスト例 クラスタの全般的な設定と、アプリ個別のケースでマニフェストを二つに分けた。AWS公式では基本となるEKSクラスタの定義をコマンドでセットしているが、運用の際はマニフェストに落とし込むのが普通だと思う。以下のようなマニフェストを共通用として作成し、個別のマニフェストから参照させる。EKSクラスタ名はdata:cluster.nameで指定している。\nfluentbit-cluster.yaml\napiVersion: v1 kind: ConfigMap metadata: name: fluentbit-cluster namespace: amazon-cloudwatch selfLink: /api/v1/namespaces/amazone-cloudwatch/configmaps/fluentbit-cluster data: cluster.name: EKS-SAMPLE-CLUSTER log.region: ap-northeast-1 read.head: \u0026#34;On\u0026#34; read.tail: \u0026#34;Off\u0026#34; --- apiVersion: v1 kind: ServiceAccount metadata: name: fluent-bit namespace: amazon-cloudwatch --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: fluent-bit-role rules: - nonResourceURLs: - /metrics verbs: - get - apiGroups: [\u0026#34;\u0026#34;] resources: - namespaces - pods - pods/logs verbs: [\u0026#34;get\u0026#34;, \u0026#34;list\u0026#34;, \u0026#34;watch\u0026#34;] --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: fluent-bit-role-binding roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: fluent-bit-role subjects: - kind: ServiceAccount name: fluent-bit namespace: amazon-cloudwatch  個別マニフェスト例 「個別のマニフェスト」というのはアプリの種類が複数存在して、各種別ごとに送信先（ロググループ/ログストリーム）を振り分けたいケースを想定している。しかしAWS公式サンプルをそのまま使うと要件的に期待値にならない。現状ネットにわかりやすい事例がなく大分迷ったが、最終的に以下のような形に落とした。詳細は後述。\n最初に骨組みを説明すると、前半がFluent Bitの設定であるConfigMap、後半がワーカーノード上で起動するDaemonSetの定義となっている。冒頭の[SERVICE]で全体共通の設定を行う。@INCLUDEで3種類のConfig名を指定しているが名称は適当でよい。各Config内に[INPUT] [FILTER] [OUTPUT] を定義していく。\n confの種類 containers.conf\nfluentbit, cloudwatch-agentやアプリ個別ログを定義。簡素化のため対象を絞っているが、aws-node, kube-proxy, corednsのログを送信する場合もここに含める。\nkube-systemd.conf\ndocker,kubeletのログを定義。\nhost.conf\nOS上のログ（基本的に/var/log/配下の各種ログ）を定義。簡素化のためここではmessagesのみ定義している。他に送信したい種別は同様に設定する。\nparsers.conf\nログフォーマットのパースの定義\n fluentbit-sample-app.yaml\napiVersion: v1 kind: ConfigMap metadata: name: fluent-bit-config namespace: amazon-cloudwatch labels: k8s-app: fluent-bit-sample data: fluent-bit.conf: |[SERVICE] Flush 5 Log_Level info Daemon off Parsers_File parsers.conf storage.path /var/fluent-bit/state/flb-storage/ storage.sync normal storage.checksum off storage.backlog.mem_limit 5M @INCLUDE containers.conf @INCLUDE kube-systemd.conf @INCLUDE host.conf # containers.confの定義 containers.conf: |[INPUT] Name tail Tag fluentbit.* Path /var/log/containers/fluentbit* Parser docker DB /var/fluent-bit/state/flb_log.db Mem_Buf_Limit 5MB Skip_Long_Lines On Refresh_Interval 10 Read_from_Head ${READ_FROM_HEAD} [INPUT] Name tail Tag cloudwatch-agent.* Path /var/log/containers/cloudwatch-agent* Docker_Mode On Docker_Mode_Flush 5 Docker_Mode_Parser cwagent_firstline Parser docker DB /var/fluent-bit/state/flb_cwagent.db Mem_Buf_Limit 5MB Skip_Long_Lines On Refresh_Interval 10 Read_from_Head ${READ_FROM_HEAD} [INPUT] Name tail Tag sample-app.* Path /var/log/containers/sample-app* Parser docker DB /var/fluent-bit/state/flb_sample-app.db Mem_Buf_Limit 5MB Skip_Long_Lines On Refresh_Interval 10 Read_from_Head ${READ_FROM_HEAD} # 各INPUTに対応するFILTERを定義する [FILTER] Name kubernetes Match fluentbit.* Kube_URL ${MASTER_URL} Kube_Tag_Prefix fluentbit.var.log.containers. Merge_Log On Merge_Log_Key log_processed K8S-Logging.Parser On K8S-Logging.Exclude Off Annotations Off [FILTER] Name kubernetes Match cloudwatch-agent.* Kube_URL ${MASTER_URL} Kube_Tag_Prefix cloudwatch-agent.var.log.containers. Merge_Log On Merge_Log_Key log_processed K8S-Logging.Parser On K8S-Logging.Exclude Off Annotations Off [FILTER] Name kubernetes Match sample-app.* Kube_URL ${MASTER_URL} Kube_Tag_Prefix sample-app.var.log.containers. Merge_Log On Merge_Log_Key log_processed K8S-Logging.Parser On K8S-Logging.Exclude Off Annotations Off # アイテムの変換や不要なメタデータ送信抑止を定義 [FILTER] Name nest Match * Operation lift Nested_under kubernetes Add_prefix Nested. [FILTER] Name modify Match * Rename Nested.docker_id Docker.container_id [FILTER] Name nest Match * Operation nest Wildcard Nested.* Nested_under kubernetes Remove_prefix Nested. [FILTER] Name nest Match * Operation nest Wildcard Docker.* Nested_under docker Remove_prefix Docker. [FILTER] Name nest Match * Operation lift Nested_under kubernetes Add_prefix Kube. [FILTER] Name modify Match * Remove Kube.container_hash  Remove Kube.container_image Remove Kube.pod_id [FILTER] Name nest Match * Operation nest Wildcard Kube.* Nested_under Kubernetes Remove_prefix Kube. # 送信時の定義 # ロググループ名例：/eks/stg/sample-app_fluentbit # ログストリーム名例：ip-10-1-2-3.ap-northeast-1.compute.internal_[Pod名]_[ネームスペース]_[コンテナ名] # $(tag[4])とした場合、上記のようなkubeのタグ定義が投入され、ユニークなログストリーム名になる。 [OUTPUT] Name cloudwatch Match fluentbit.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_fluentbit log_stream_name ${HOST_NODE_NAME}_$(tag[4]) auto_create_group true extra_user_agent container-insights Retry_Limit 5 [OUTPUT] Name cloudwatch Match cloudwatch-agent.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_cwagent log_stream_name ${HOST_NODE_NAME}_$(tag[4]) auto_create_group true extra_user_agent container-insights Retry_Limit 5 # 個別アプリログ送信用定義 [OUTPUT] Name cloudwatch Match sample-app.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_application log_stream_name ${HOST_NODE_NAME}_$(tag[4]) auto_create_group true extra_user_agent container-insights Retry_Limit 5 # docker,kubenetesログ定義 kube-systemd.conf: |[INPUT] Name systemd Tag dockerlog.systemd.* Systemd_Filter _SYSTEMD_UNIT=docker.service DB /var/fluent-bit/state/systemd.db Path /var/log/journal Read_From_Head ${READ_FROM_HEAD} [INPUT] Name systemd Tag kubelet.systemd.* Systemd_Filter _SYSTEMD_UNIT=kubelet.service DB /var/fluent-bit/state/systemd.db Path /var/log/journal Read_From_Head ${READ_FROM_HEAD} [FILTER] Name modify Match dockerlog.systemd.* Rename _HOSTNAME hostname Rename _SYSTEMD_UNIT systemd_unit Rename MESSAGE message Remove_regex ^((?!hostname|systemd_unit|message).)*$ [FILTER] Name modify Match kubelet.systemd.* Rename _HOSTNAME hostname Rename _SYSTEMD_UNIT systemd_unit Rename MESSAGE message Remove_regex ^((?!hostname|systemd_unit|message).)*$ [OUTPUT] Name cloudwatch Match kubelet.systemd.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_docker log_stream_name ${HOST_NODE_NAME}_$(tag[2]) auto_create_group true extra_user_agent container-insight [OUTPUT] Name cloudwatch Match kubelet.systemd.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_kubelet log_stream_name ${HOST_NODE_NAME}_$(tag[2]) auto_create_group true extra_user_agent container-insight # messages等、OSのログ定義 host-log.conf: | [INPUT] Name tail Tag host.messages Path /var/log/messages Parser syslog DB /var/fluent-bit/state/flb_messages.db Mem_Buf_Limit 5MB Skip_Long_Lines On Refresh_Interval 10 Read_from_Head ${READ_FROM_HEAD} # host.confの[OUTPUT]定義は、複数のINPUTがあっても1つでよい。 # $(tag[1]) にはこの場合messagesが入る。 [OUTPUT] Name cloudwatch Match host.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_$(tag[1]) log_stream_name ${HOST_NODE_NAME}_$(tag[1]) auto_create_group true extra_user_agent container-insights Retry _Limit 5 parsers.conf: |[PARSER] Name docker Format json Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%LZ [PARSER] Name syslog-rfc5424 Format regex Regex ^(?\u0026lt;time\u0026gt;[^ ]* {1.2}[^ ]* [^ ]*) (?\u0026lt;host\u0026gt;[^ ]*) (?\u0026lt;ident\u0026gt;[a-zA-Z0-9_¥/¥.¥-]*) (?:¥[?\u0026lt;pid\u0026gt;[-0-9]+)¥])?(?:[^¥:]*¥:)? * (?\u0026lt;message\u0026gt;.*)$ Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%L Time_Strict Off [PARSER] Name container_firstline Format regex Regex (?\u0026lt;log\u0026gt;(?\u0026lt;=\u0026#34;log\u0026#34;:\u0026#34;)\\S(?!\\.).*?)(?\u0026lt;!\\\\)\u0026#34;.*(?\u0026lt;stream\u0026gt;(?\u0026lt;=\u0026#34;stream\u0026#34;:\u0026#34;).*?)\u0026#34;.*(?\u0026lt;time\u0026gt;\\d{4}-\\d{1,2}-\\d{1,2}T\\d{2}:\\d{2}:\\d{2}\\.\\w*).*(?=}) Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%LZ [PARSER] Name cwagent_firstline Format regex Regex (?\u0026lt;log\u0026gt;(?\u0026lt;=\u0026#34;log\u0026#34;:\u0026#34;)\\d{4}[\\/-]\\d{1,2}[\\/-]\\d{1,2}[ T]\\d{2}:\\d{2}:\\d{2}(?!\\.).*?)(?\u0026lt;!\\\\)\u0026#34;.*(?\u0026lt;stream\u0026gt;(?\u0026lt;=\u0026#34;stream\u0026#34;:\u0026#34;).*?)\u0026#34;.*(?\u0026lt;time\u0026gt;\\d{4}-\\d{1,2}-\\d{1,2}T\\d{2}:\\d{2}:\\d{2}\\.\\w*).*(?=}) Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%LZ --- apiVersion: apps/v1 kind: DaemonSet metadata: name: fluent-bit-sample namespace: amazon-cloudwatch labels: k8s-app: fluent-bit-sample version: v1 kubernetes.io/cluster-service: \u0026#34;true\u0026#34; spec: selector: matchLabels: k8s-app: fluent-bit-sample template: metadata: labels: k8s-app: fluent-bit-sample version: v1 kubernetes.io/cluster-service: \u0026#34;true\u0026#34; spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: nodelabel operator: In values: - STG-NODELABEL-APP-001 containers: - name: fluent-bit-sample image: amazon/aws-for-fluent-bit:2.12.0 imagePullPolicy: Always env: - name: AWS_REGION valueFrom: configMapKeyRef: name: fluentbit-cluster key: logs.region - name: CLUSTER_NAME valueFrom: configMapKeyRef: name: fluentbit-cluster key: cluster.name - name: READ_FROM_HEAD valueFrom: configMapKeyRef: name: fluentbit-cluster key: read.head - name: READ_FROM_TAIL valueFrom: configMapKeyRef: name: fluentbit-cluster key: read.tail - name: HOST_NODE_NAME valueFrom: fieldRef: fieldPath: spec.nodeName - name: CI_VERSION value: \u0026#34;k8s/1.3.8\u0026#34; # これ以降独自に設定追加。設定項目はユースケースに合わせてください。 - name: ENVIRONMENT value: \u0026#34;stg\u0026#34; - name: NODEGROUP value: \u0026#34;sample-app\u0026#34; - name: MASTER_URL value: \u0026#34;https://kubernetes.default.svc:443\u0026#34; resources: limits: cpu: 200m memory: 200Mi requests: cpu: 200m memory: 100Mi volumeMounts: # Please don\u0026#39;t change below read-only permissions - name: fluentbitstate mountPath: /var/fluent-bit/state - name: varlog mountPath: /var/log readOnly: true - name: varlibdockercontainers mountPath: /var/lib/docker/containers readOnly: true - name: fluent-bit-config mountPath: /fluent-bit/etc/ - name: runlogjournal mountPath: /run/log/journal readOnly: true - name: dmesg mountPath: /var/log/dmesg readOnly: true terminationGracePeriodSeconds: 90 volumes: - name: fluentbitstate hostPath: path: /var/fluent-bit/state - name: varlog hostPath: path: /var/log - name: varlibdockercontainers hostPath: path: /var/lib/docker/containers - name: fluent-bit-config configMap: name: fluent-bit-config - name: runlogjournal hostPath: path: /run/log/journal - name: dmesg hostPath: path: /var/log/dmesg serviceAccountName: fluent-bit tolerations: - key: node-role.kubernetes.io/master operator: Exists effect: NoSchedule - operator: \u0026#34;Exists\u0026#34; effect: \u0026#34;NoExecute\u0026#34; - operator: \u0026#34;Exists\u0026#34; effect: \u0026#34;NoSchedule\u0026#34;  補足説明 imageパスの指定\n上記ではコンテナイメージをインターネットを通って都度落とすようになっているが、業務利用時はECRに格納してプライベートな通信で完結させるのが望ましい。ECRに格納した場合は以下のように指定する。\nimage: [AWS-AccoundID].dkr.ecr.ap-northeast-1.amazon.com/[repo-name]:2.12.0  nodeAffinityで起動するノードを指定\n今回の事例では、sample-appのPodが起動するワーカーノード上にsample-appログ送信用のDaemonSetを起動させる必要がある。そのためnodeAffinityを定義する。EKSノードグループのラベルにkey:nodelabel values:STG-SAMPLE-APPを設定している前提の場合以下の様になる。sample-app用のマニフェストにも同様の記述をする。\n spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: nodelabel operator: In values: - STG-SAMPLE-APP  停止時のGracePeriod\nDaemonSetがKillシグナル受信後に削除されるまでの猶予時間を指定。公式サンプル10秒だと、コンテナログを送信しきる前に削除されてしまう可能性がある。ここでは余裕を持たせて90秒。\nterminationGracePeriodSeconds: 90  syslogのPARSER\nAWS公式の設定だとTime_FormatがダメらしきエラーがでるのでFluent Bit公式の例を適用した。Fluent Bit公式ではsyslogではなくsyslog-rfc5424。ではINPUTのParserはsyslogではなくsyslog-rfc5424とするのが正ではないか？と思ったが、そうすると動作しない。謎だが深追いはしない。Time_StrictはOffにしておく。しかしそれでもまだエラーになるので調べると、Regexの正規表現が原因らしいのでそこも直した。参照サイトは失念。\n DaemonSetの起動〜ログ送信\n今回cloudwatch-agentについては触れていないが、cloudwatch-agentネームスペースが存在している状態でマニフェストをapplyする。この時点ではノードグループは停止中でもよい。\n$ kubectl apply -f fluentbit-cluster.yaml $ kubectl apply -f fluentbit-sample-app.yaml  ノードグループが起動すると、各種ログがCloudWatchLogsに送信される。アプリ用マニフェストをapplyすればアプリログも送信される。\nあとresourceのcpuはデフォルトが500mになっていたが、そこまで割り当てなくてもちゃんと動作する。よほどのことがなければ100mでもいい気がする。メモリもFlunetdに比べて全然余裕。さすが軽量版。その他細かいチューニング項目もあるにはあるのだが、これ以上の長文は避けたいのでまた別の機会に投稿しようと思う。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/fluentbit/","summary":"AWS EKSでPodからログを送信する場合、Container Insightsを組み込んでFluentdかFluent Bitを利用するのが一般的と思われる。そしてFluent BitよりFluentdの方がメジャーなのでまずはそこから入る事例が多いと想像する。しかし、元々組み込みLinux用に開発されて軽量リソースで動作するFluent Bitの方がコンテナログ送信に向いていると思う。ということで、この記事ではFluent Bitに焦点を当てる。\n 参照\nFluent Bit ドキュメント（設定詳細は画面左「DATA PIPELINE」配下のメニュー参照）\nFluent Bit Documentation\nContainer Insights全般\nAmazon EKS と Kubernetes での Container Insights のセットアップ\nFluent Bit on Container Insights\nCloudWatch Logs へログを送信する DaemonSet として Fluent Bit を設定する\nサンプルマニフェスト\nfluent-bit-compatible.yaml\n※AWSがサンプルとして提供しているFluent BitのマニフェストはFluent Bit最適化用とFluentd互換用がある。今回は過去にFluentd使用事例があることから、Fluentd互換用マニフェストをDLしてカスタマイズした。\n 共通マニフェスト例 クラスタの全般的な設定と、アプリ個別のケースでマニフェストを二つに分けた。AWS公式では基本となるEKSクラスタの定義をコマンドでセットしているが、運用の際はマニフェストに落とし込むのが普通だと思う。以下のようなマニフェストを共通用として作成し、個別のマニフェストから参照させる。EKSクラスタ名はdata:cluster.nameで指定している。\nfluentbit-cluster.yaml\napiVersion: v1 kind: ConfigMap metadata: name: fluentbit-cluster namespace: amazon-cloudwatch selfLink: /api/v1/namespaces/amazone-cloudwatch/configmaps/fluentbit-cluster data: cluster.name: EKS-SAMPLE-CLUSTER log.region: ap-northeast-1 read.head: \u0026#34;On\u0026#34; read.tail: \u0026#34;Off\u0026#34; --- apiVersion: v1 kind: ServiceAccount metadata: name: fluent-bit namespace: amazon-cloudwatch --- apiVersion: rbac.","title":"EKS Container InsightsのFluent Bit設定"},{"content":"マークダウン記法の参考リンク。取り急ぎこれくらいあればいいかな。\n  Markdown 早見表 \u0026amp; 詳細\n  かんたんMarkdownの記法\n  Markdown記法 チートシート\n  ","permalink":"https://ecnedaced-seirots.github.io/post/a/markdown/","summary":"マークダウン記法の参考リンク。取り急ぎこれくらいあればいいかな。\n  Markdown 早見表 \u0026amp; 詳細\n  かんたんMarkdownの記法\n  Markdown記法 チートシート\n  ","title":"マークダウン記法"},{"content":"とりあえず最初の投稿。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/first/","summary":"とりあえず最初の投稿。\n ","title":"最初の投稿"}]