[{"content":"elaborate   複雑な、入り組んだ 精巧な、精密な 入念な、苦心の末の  他動詞としては「〜を詳しく調べる」\n Irvine Welshの\u0026quot;Trainspotting\u0026quot;読書中に登場した単語だと思うが、何ページかはもう覚えていない。\n  ","permalink":"https://ecnedaced-seirots.github.io/post/a/english-elaborate/","summary":"elaborate   複雑な、入り組んだ 精巧な、精密な 入念な、苦心の末の  他動詞としては「〜を詳しく調べる」\n Irvine Welshの\u0026quot;Trainspotting\u0026quot;読書中に登場した単語だと思うが、何ページかはもう覚えていない。\n  ","title":"英単語メモ - elaborate"},{"content":"AWSで過去普通にやってた監視実装も、2,3年経つと（或いはそれより短い周期で）陳腐化する。以前は限られたサービスのリソース範囲でやれることをやっていればよかったが、今はSSM(Systems Manager)、Lambda、EventBridgeなどの「登場人物」が増えて、カスタマイズが可能になったからだ。やれることが増えた分、実装が複雑になる。その分チャレンジングな分野になって楽しめると言えないこともないが\u0026hellip;、時間が足りないんだ。頭痛ぇな、まったく。絡み合った糸をほぐすためにまとめてみる。\n監視の種別としては大枠としてノード監視、閾値監視、ログ監視、プロセス監視、イベント監視と想定する。それぞれの実装方式が若干異なってくるため整理したい。\n  監視方式大枠  ノード監視\nCloudWatchアラーム(ステータスチェック) ー＞ (EventBridgeルール) ー＞ Lambda ー＞ SNSトピック ー＞ メール送信  ※ハード障害等でインスタンスが落ちた時に発動される想定。手動で落とした時は発動しないので通知は来ない。\n閾値監視\nCloudWatchアラーム（閾値チェック） ー＞ (EventBridgeルール) ー＞ Lambda ー＞ SNSトピック ー＞ メール送信  ※EC2インスタンスのCPU使用率、ディスク使用率を想定。メモリ監視は別途カスタムメトリクスの実装がいる。\nログ監視\nCloudWatchLogsでログ出力（サブスクリプションフィルタキーワード検知）ー＞ Lambda ー＞ SNSトピック ー＞ メール送信  ※これだけEventBridgeを使用しない。\nプロセス監視\nEC2インスタンス上のプロセス数監視に相当する。検索すると「プロセス落ちていたらインスタンス再起動」アクションの事例が多いが、今回やりたいのはメール通知だけ。一応メモっておくけど。  CWエージェント + SSM + インスタンス停止、Lamabdaなし\nEC2上のプロセスを監視し自動復旧する\nCWエージェント + SSM + 自動再起動、Lamabdaなし\nAWSでプロセス監視を実装したい\nCWエージェント + Lamabda + SSM + 自動再起動\nEC2のプロセス監視と自動再起動\n procstat事例\n以下はSSMを使用せず、procstatプラグインを使用してプロセス監視する例。記事には監視設定以降の通知イベント事例はなし。\nCloudWatch Agent でProcstatプラグインの利用が可能になりました\nSSMを使わずCloudwatchでEC2上のプロセス監視をしてみる\n 以下は途中まで参照したところ（後半は有料サービスの案内）、アラームを作成するところまでわかりやすかった。であれば、閾値監視と同様にEBルールを挟んでLambdaをターゲットに指定 ー＞ SNSトピックに渡されてメール送信、でいけるはず。\nCloudWatchでプロセス監視する手順をLinuxとWindowsともに詳しく紹介\nイベント監視\nイベント発生 ー＞ (EventBridgeルール) ー＞ Lambda ー＞ SNSトピック ー＞ メール送信  ※1. 2. のアラームがイベントに置き換わるだけで、後続のフローは同様となる想定。\n  上記の中で、私的には4.のプロセス監視が一番面倒な気がする。プロセス監視の詳細は保留として、全体の登場人物を整理しておこう。\n 登場人物整理 整理したらこうなった。方式をどうするかによって変わる部分もあるが、今のところこの想定。すべての監視でLambdaを使うのは、メール件名や本文をカスタマイズしたいため。\n    ノード監視 閾値監視 ログ監視 プロセス監視 イベント監視     CloudWatchAlarm ● ● - ● -   CloudWatchLogs - - ● - -   SSM(Systems Manager) - - - ● -   EventBridge rule ● ● - ● ●   Lambda ● ● ● ● ●   SNS topic ● ● ● ● ●     次のステップとして、これらの各アイテムにおいて「共通化できるもの / 個別に作成するもの」に分類する必要がある。\n  その他メモ  メール件名のカスタマイズ\nメール件名のカスタマイズをLambdaの環境変数でやるかコード本体でやるか。\nイベントの中身を拾って詳細に設定するならLambdaコード内でやるしかないが、そんな体力はない。そもそもイベントの中身が元ネタによって異なるからメッセージ内容別に大幅な差分が発生するはず。やれなくもないがそんな体力は(ry)。となると、カッコ悪いかもしれないがほぼ決め打ちの値で環境変数にセット、でいく方がいい。   メッセージ本文のカスタマイズ\n① Lambdaコード内で実装\n② EventBridgeルールの入力トランスフォーマーで実装  ②を試したが期待値ならず。深追いしている時間はない。どっちにしろログ監視では本文をLambdaに渡しているからそっちに寄せる方がいい。ここでやってるマッピングがLambdaコードにも適用できるか検討しようと思ったが、スキーマレジストリとかよくわからん。\n aws configの通知をどうするか\nconfigのログはS3にしか飛ばせない。ログ監視ではなく、イベント監視でやる。検知を制御したい時はイベント検知無効化で対応とか。   Amazon CloudWatch Events を使用すると、AWS Config イベントのステータスで変更を検出し対応することができます。\n AWS Config でのログ記録とモニタリング\n Configの変更はCloudTrailにつながるから、下手すると監視が重複するかもしれない。が、考えてる時間が(ry) 以下はCloudTrailの設定で直接SNSを指定しているっぽいが、これもEventBridgeに渡す、に統一させた方がよさげ。\n CloudTrail が、新しいログファイルを Amazon S3 バケットに発行するときに通知を受け取ることができます。\n CloudTrail の Amazon SNS 通知の設定\n 以下は通知事例の記載はないが一応メモ\nAWSリソースの設定変更履歴を管理する「AWS Config」とは？実際に使用してみた\n  果てしない旅路。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatch-monitoring-idea/","summary":"AWSで過去普通にやってた監視実装も、2,3年経つと（或いはそれより短い周期で）陳腐化する。以前は限られたサービスのリソース範囲でやれることをやっていればよかったが、今はSSM(Systems Manager)、Lambda、EventBridgeなどの「登場人物」が増えて、カスタマイズが可能になったからだ。やれることが増えた分、実装が複雑になる。その分チャレンジングな分野になって楽しめると言えないこともないが\u0026hellip;、時間が足りないんだ。頭痛ぇな、まったく。絡み合った糸をほぐすためにまとめてみる。\n監視の種別としては大枠としてノード監視、閾値監視、ログ監視、プロセス監視、イベント監視と想定する。それぞれの実装方式が若干異なってくるため整理したい。\n  監視方式大枠  ノード監視\nCloudWatchアラーム(ステータスチェック) ー＞ (EventBridgeルール) ー＞ Lambda ー＞ SNSトピック ー＞ メール送信  ※ハード障害等でインスタンスが落ちた時に発動される想定。手動で落とした時は発動しないので通知は来ない。\n閾値監視\nCloudWatchアラーム（閾値チェック） ー＞ (EventBridgeルール) ー＞ Lambda ー＞ SNSトピック ー＞ メール送信  ※EC2インスタンスのCPU使用率、ディスク使用率を想定。メモリ監視は別途カスタムメトリクスの実装がいる。\nログ監視\nCloudWatchLogsでログ出力（サブスクリプションフィルタキーワード検知）ー＞ Lambda ー＞ SNSトピック ー＞ メール送信  ※これだけEventBridgeを使用しない。\nプロセス監視\nEC2インスタンス上のプロセス数監視に相当する。検索すると「プロセス落ちていたらインスタンス再起動」アクションの事例が多いが、今回やりたいのはメール通知だけ。一応メモっておくけど。  CWエージェント + SSM + インスタンス停止、Lamabdaなし\nEC2上のプロセスを監視し自動復旧する\nCWエージェント + SSM + 自動再起動、Lamabdaなし\nAWSでプロセス監視を実装したい\nCWエージェント + Lamabda + SSM + 自動再起動\nEC2のプロセス監視と自動再起動\n procstat事例\n以下はSSMを使用せず、procstatプラグインを使用してプロセス監視する例。記事には監視設定以降の通知イベント事例はなし。\nCloudWatch Agent でProcstatプラグインの利用が可能になりました\nSSMを使わずCloudwatchでEC2上のプロセス監視をしてみる","title":"AWS監視の方式を整理したい"},{"content":"タウリンの効果。過去に見つけたネタをバラバラにメモっていたのをまとめておく。\n タウリンとは、一言で言うと。\nタウリンは分子量124の含硫アミノ酸。タンパク質の構成成分にはならないが、細胞内の遊離アミノ酸としてはグルタミンと並んでもっとも高濃度に存在し、かつグルタミンに類似する成分。またタウリンは脳内のアミノ酸の中では2番目に多く存在する。\nタウリンは疲れが溜まっていると多く消費される、年齢を重ねると減少、男性より女性が不足しがち、とも言われている。\nタウリンの効果としてはアセトアルデヒトの代謝促進による肝機能サポートがよく知られているが、記憶力や認知能力の改善、目の網膜の保護、便通の改善等、意外な効能もある様子。\nそんなタウリンの効果について、とりあえず箇条書きで。\n  神経伝達、海馬の増強や安定化をサポート。 記憶力に関与するグリア細胞の活性化を促進する。(注1) アルコールや有害物質から発生するアセトアルデヒトの代謝を促進する。 心筋を強くして疲労回復を促す。（ただし即効性はないらしい？） 心臓のポンプ作用を高めて筋肉により多くの血液を送り込み、持久力を高める。（ドイツの研究より） 細胞のミトコンドリアの数を増やす（ミトコンドリアのタンパク質合成に必須）(注2) 目の網膜や角膜を保護する。 腸管の抗炎症作用 血圧や血糖値のバランスをサポート。 肝臓・心臓の機能強化 胆汁を生成し、コレステロールや中性脂肪の代謝をコントロール インスリン分泌促進 便の水分を増やし、便秘を改善する。 ニューロンのカリウム除去をサポートし、ニューロンが過度に活発化することを防ぐ。 タウリンはレシチンと併用することで細胞の細胞膜を丈夫にし、細胞が正常な形状を保つようにサポートをする。 髪の毛の成長にも不可欠なタンパク質IGF-1(インスリン様成長因子)を増やす   (注1) 記憶を司ると言われる海馬にはグリア細胞が多く存在する。\nまた以下のように認知機能の改善を示す研究がある。\n 迷路試験（Y-maze test）と受動的回避試験（passive avoidance test）で、タウリンを摂取したマウスの認知機能が正常な状態に回復することが確認された。さらに、アルツハイマー病の症状である大脳皮質の炎症が抑えられたほか、脳の海馬から分泌されるアミロイドベータの量も減り、記憶力に深く関与するグリア細胞の活性化が促進されることが確認された。\n注目すべき特徴は、タウリンの脳機能改善効果がアルツハイマー病において選択的に表れるということだ。従来の治療薬物が正常のマウスでは脳機能の異常を来たしたのに対し、タウリンは正常のマウスで脳機能の異常を来たすことはなかった。タウリンの持つもう一つの特性は、タウリンが脳の血管壁を透過しやすいため、口から摂取しても脳にうまく吸収されることだ。別途の複雑な投与過程を経る必要がなく、飲料水などの食物からタウリンを摂っても効果が高い。\n タウリンがアルツハイマー病治療に有効だと判明\n(注2) 「ただしタウリンが細胞内のエネルギー生産組織であるミトコンドリアの数を増やすのは、タウリン サプリを継続的に数か月～半年ほど摂取した場合に限られます。」（参照リンクは消滅）\n タウリンを多く含む食材\n 貝・甲殻類（サザエ、牡蠣、帆立、蛤、あさり、しじみ、タコ、イカ、カニ等） ブリやカツオの血合い 鯵や鯖などの近海魚  タウリンを多く含む食材としてはタコ・イカのイメージが強かったのだが、ダントツで多いのは牡蠣だった。100g中1180mg。サザエの方が100g1500mgで含有量としては多いが、摂取量・摂取回数は一般的に考えて少ない。\n余談だが牡蠣は亜鉛も多く含んでいて、その亜鉛はグルタミン酸興奮毒性（神経細胞死の一因）から脳を守る機能を果たす。また、記憶を司る海馬には最高濃度の亜鉛が存在する。脳の海馬をサポートするタウリンと亜鉛を両方含む牡蠣は、最強ブレインフードだった！\nタウリンを多く含む食品一覧 ポイントは魚介類と血合肉\n タウリン摂取時の注意\n 食間・空腹時の摂取が有効。 アスピリンと併用しないこと。（薬理作用を増強させてしまうため余計な負担がかかる。バファリンは原材料としてアスピリンを含む）   \u0026hellip;と、万能選手的なタウリンではあるが、日本国内ではタウリン単体のサプリメントは販売されていない。このためタウリンのサプリはiHerbで時々購入しているが、在庫切れのことが多く割と入手困難ではある。日本の薬事法に規制があって、一回で購入可能な量・個数が制限されているから、まとめ買いもできないのだ。（おそらく鷲のマークの製薬会社の圧力）\niHerb独自ブランドのタウリンサプリが安価で嬉しいけど、数ヶ月前から在庫切れ状態が続いている。しょうがないから、今日別の高いやつをポチってしまった。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/healthcare-taurine/","summary":"タウリンの効果。過去に見つけたネタをバラバラにメモっていたのをまとめておく。\n タウリンとは、一言で言うと。\nタウリンは分子量124の含硫アミノ酸。タンパク質の構成成分にはならないが、細胞内の遊離アミノ酸としてはグルタミンと並んでもっとも高濃度に存在し、かつグルタミンに類似する成分。またタウリンは脳内のアミノ酸の中では2番目に多く存在する。\nタウリンは疲れが溜まっていると多く消費される、年齢を重ねると減少、男性より女性が不足しがち、とも言われている。\nタウリンの効果としてはアセトアルデヒトの代謝促進による肝機能サポートがよく知られているが、記憶力や認知能力の改善、目の網膜の保護、便通の改善等、意外な効能もある様子。\nそんなタウリンの効果について、とりあえず箇条書きで。\n  神経伝達、海馬の増強や安定化をサポート。 記憶力に関与するグリア細胞の活性化を促進する。(注1) アルコールや有害物質から発生するアセトアルデヒトの代謝を促進する。 心筋を強くして疲労回復を促す。（ただし即効性はないらしい？） 心臓のポンプ作用を高めて筋肉により多くの血液を送り込み、持久力を高める。（ドイツの研究より） 細胞のミトコンドリアの数を増やす（ミトコンドリアのタンパク質合成に必須）(注2) 目の網膜や角膜を保護する。 腸管の抗炎症作用 血圧や血糖値のバランスをサポート。 肝臓・心臓の機能強化 胆汁を生成し、コレステロールや中性脂肪の代謝をコントロール インスリン分泌促進 便の水分を増やし、便秘を改善する。 ニューロンのカリウム除去をサポートし、ニューロンが過度に活発化することを防ぐ。 タウリンはレシチンと併用することで細胞の細胞膜を丈夫にし、細胞が正常な形状を保つようにサポートをする。 髪の毛の成長にも不可欠なタンパク質IGF-1(インスリン様成長因子)を増やす   (注1) 記憶を司ると言われる海馬にはグリア細胞が多く存在する。\nまた以下のように認知機能の改善を示す研究がある。\n 迷路試験（Y-maze test）と受動的回避試験（passive avoidance test）で、タウリンを摂取したマウスの認知機能が正常な状態に回復することが確認された。さらに、アルツハイマー病の症状である大脳皮質の炎症が抑えられたほか、脳の海馬から分泌されるアミロイドベータの量も減り、記憶力に深く関与するグリア細胞の活性化が促進されることが確認された。\n注目すべき特徴は、タウリンの脳機能改善効果がアルツハイマー病において選択的に表れるということだ。従来の治療薬物が正常のマウスでは脳機能の異常を来たしたのに対し、タウリンは正常のマウスで脳機能の異常を来たすことはなかった。タウリンの持つもう一つの特性は、タウリンが脳の血管壁を透過しやすいため、口から摂取しても脳にうまく吸収されることだ。別途の複雑な投与過程を経る必要がなく、飲料水などの食物からタウリンを摂っても効果が高い。\n タウリンがアルツハイマー病治療に有効だと判明\n(注2) 「ただしタウリンが細胞内のエネルギー生産組織であるミトコンドリアの数を増やすのは、タウリン サプリを継続的に数か月～半年ほど摂取した場合に限られます。」（参照リンクは消滅）\n タウリンを多く含む食材\n 貝・甲殻類（サザエ、牡蠣、帆立、蛤、あさり、しじみ、タコ、イカ、カニ等） ブリやカツオの血合い 鯵や鯖などの近海魚  タウリンを多く含む食材としてはタコ・イカのイメージが強かったのだが、ダントツで多いのは牡蠣だった。100g中1180mg。サザエの方が100g1500mgで含有量としては多いが、摂取量・摂取回数は一般的に考えて少ない。\n余談だが牡蠣は亜鉛も多く含んでいて、その亜鉛はグルタミン酸興奮毒性（神経細胞死の一因）から脳を守る機能を果たす。また、記憶を司る海馬には最高濃度の亜鉛が存在する。脳の海馬をサポートするタウリンと亜鉛を両方含む牡蠣は、最強ブレインフードだった！\nタウリンを多く含む食品一覧 ポイントは魚介類と血合肉\n タウリン摂取時の注意\n 食間・空腹時の摂取が有効。 アスピリンと併用しないこと。（薬理作用を増強させてしまうため余計な負担がかかる。バファリンは原材料としてアスピリンを含む）   \u0026hellip;と、万能選手的なタウリンではあるが、日本国内ではタウリン単体のサプリメントは販売されていない。このためタウリンのサプリはiHerbで時々購入しているが、在庫切れのことが多く割と入手困難ではある。日本の薬事法に規制があって、一回で購入可能な量・個数が制限されているから、まとめ買いもできないのだ。（おそらく鷲のマークの製薬会社の圧力）\niHerb独自ブランドのタウリンサプリが安価で嬉しいけど、数ヶ月前から在庫切れ状態が続いている。しょうがないから、今日別の高いやつをポチってしまった。","title":"タウリン(taurine)の効能いろいろ"},{"content":"CloudWatchアラーム + SNSトピックでメール飛ばす時の件名を変更したい。ということで、過去記事 AWS EventBridge + SNSからのメール件名をカスタマイズする でイベントからのメール通知でやったことを、アラームに変えてやってみた。アラームのトリガーはEC2インスタンスCPU使用率閾値超えとする。\n ベースの参照は以下クラメソさんネタ。ただしこちらは本文のカスタマイズであり、件名は変えていない。またLambdaも使用していない。これに先の過去記事パターンを合体させてやってみた。\nCloudWatch アラームの通知メールを少しでも読みやすくしたい\n 処理概要  CloudWatchアラームのステータスがALARMに変わる。 Lambda関数起動 SNSに連携される メール通知   作業概要  SNSトピック作成〜サブスクライブ CloudWatchアラーム作成 Lambda関数作成（Lambda用IAMロールは既存流用） EventBridgeルール作成 EventBridgeルールのターゲットに3.のLambda関数を設定する 対象EC2インスタンスのCPU負荷を上げてアラームステータスにする メール通知確認   検証に使用したアイテム    アイテム 名称     SNSトピック alarm-notification-topic   CloudWatchアラーム CPU_Utilization_Test   Lambda関数 cw-alarm-sns-function   EventBridgeルール cw-alarm-rule    やったこと SNSトピック作成、Lambda関数作成は冒頭のリンク過去記事でもやったので省略。Lambda関数の環境変数でSNSトピック、メール件名を指定している。一応後半にスクショあり。\nCLIよりCloudWatchアラーム作成。少ない負荷でもアラームステータスになるように閾値は10%にしてある。\n$ aws cloudwatch put-metric-alarm --alarm-name \u0026quot;CPU_Utilization_Test\u0026quot; \\ --metric-name \u0026quot;CPUUtilization\u0026quot; \\ --namespace \u0026quot;AWS/EC2\u0026quot; \\ --statistic \u0026quot;Maximum\u0026quot; \\ --period 60 \\ --evaluation-periods 1 \\ --datapoints-to-alarm 1 \\ --threshold 10 \\ --comparison-operator \u0026quot;GreaterThanThreshold\u0026quot; \\ --dimensions \u0026quot;Name=InstanceId,Value=i-0xxxxxxxxxxx9\u0026quot;  EventBridgeルールの作成。以下の場合、\u0026ldquo;CPU_Utilization_\u0026ldquo;を含むアラームと関連付けられる\n$ AWSREGION=ap-northeast-1 $ AWSACCOUNT=my-account-id $ aws events put-rule --name \u0026quot;cw-alarm-rule\u0026quot; \\ --event-pattern \u0026quot;{\\\u0026quot;source\\\u0026quot;: [\\\u0026quot;aws.cloudwatch\\\u0026quot;],\\\u0026quot;detail-type\\\u0026quot;: [\\\u0026quot;CloudWatch Alarm State Change\\\u0026quot;],\\\u0026quot;resources\\\u0026quot;: [{\\\u0026quot;prefix\\\u0026quot;: \\\u0026quot;arn:aws:cloudwatch:${AWSREGION}:${AWSACCOUNT}:alarm:CPU_Utilization_\\\u0026quot;}],\\\u0026quot;detail\\\u0026quot;: {\\\u0026quot;state\\\u0026quot;: {\\\u0026quot;value\\\u0026quot;: [\\\u0026quot;ALARM\\\u0026quot;]}}}\u0026quot;  以下の様にルールが作成された。\n しかしこの段階ではまだターゲットが存在しない。前回はコマンドでターゲット指定したが、今回はマネコンからやった。対象のルールを選択して「Edit」ー＞ 「Select targets」で作成済みのLambda関数を指定して、「Update」\n すると、以下の様にLambda側のトリガーとして、セットしたルールが設定される。\n ここまでやったら、以下の流れでメール通知される、はず。\n① EC2インスタンスのCPU使用率を上げてアラーム発行させる ② EventBridgeルールでターゲットに指定したLambdaに渡される ③ Lambdaで設定したSNSに渡される\nちなみにCPU使用率UP時はこんなのをshellにしてバックグラウンドで複数実行させた。アラームの設定で閾値10%にしたが、これをt3.microマシン上で3回くらい同時に回せば軽く90%くらいになる。\nCNT=0; while [ $CNT -lt 100000 ]; do CNT=$(( CNT + 1 ));done\n 少し経つとアラームのステータスが変わって、カスタム件名のメールが届いた！しかし本文がひどい\u0026hellip;\n サンプルコードではMessage=json.dumps(event) としているから、JSONデータをそのまま吐き出しているだけ。本文をカスタマイズする場合はこのeventをいじる必要がある。冒頭のクラメソさんの事例もはっきりいって面倒くさそうだったが、コードでやるのも面倒だなぁ、何せサンデープログラマだから。\neventに相当するJSONデータ\n{\u0026#34;version\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;86fa8a3f-7470-8c16-ef56-aaba9821771e\u0026#34;, \u0026#34;detail-type\u0026#34;: \u0026#34;CloudWatch Alarm State Change\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;aws.cloudwatch\u0026#34;, \u0026#34;account\u0026#34;: \u0026#34;123456789101\u0026#34;, \u0026#34;time\u0026#34;: \u0026#34;2021-11-03T10:17:51Z\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-northeast-1\u0026#34;, \u0026#34;resources\u0026#34;: [\u0026#34;arn:aws:cloudwatch:ap-northeast-1:123456789101:alarm:CPU_Utilization_Test\u0026#34;], \u0026#34;detail\u0026#34;: {\u0026#34;alarmName\u0026#34;: \u0026#34;CPU_Utilization_Test\u0026#34;, \u0026#34;state\u0026#34;: {\u0026#34;value\u0026#34;: \u0026#34;ALARM\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;Threshold Crossed: 1 out of the last 1 datapoints [100.0 (03/11/21 10:11:00)] was greater than the threshold (10.0) (minimum 1 datapoint for OK -\u0026gt; ALARM transition).\u0026#34;, \u0026#34;reasonData\u0026#34;: \u0026#34;{\\\u0026#34;version\\\u0026#34;:\\\u0026#34;1.0\\\u0026#34;,\\\u0026#34;queryDate\\\u0026#34;:\\\u0026#34;2021-11-03T10:17:51.018+0000\\\u0026#34;,\\\u0026#34;startDate\\\u0026#34;:\\\u0026#34;2021-11-03T10:11:00.000+0000\\\u0026#34;,\\\u0026#34;statistic\\\u0026#34;:\\\u0026#34;Maximum\\\u0026#34;,\\\u0026#34;period\\\u0026#34;:60,\\\u0026#34;recentDatapoints\\\u0026#34;:[100.0],\\\u0026#34;threshold\\\u0026#34;:10.0,\\\u0026#34;evaluatedDatapoints\\\u0026#34;:[{\\\u0026#34;timestamp\\\u0026#34;:\\\u0026#34;2021-11-03T10:11:00.000+0000\\\u0026#34;,\\\u0026#34;sampleCount\\\u0026#34;:5.0,\\\u0026#34;value\\\u0026#34;:100.0}]}\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2021-11-03T10:17:51.020+0000\u0026#34;}, \u0026#34;previousState\u0026#34;: {\u0026#34;value\u0026#34;: \u0026#34;INSUFFICIENT_DATA\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;Insufficient Data: 1 datapoint was unknown.\u0026#34;, \u0026#34;reasonData\u0026#34;: \u0026#34;{\\\u0026#34;version\\\u0026#34;:\\\u0026#34;1.0\\\u0026#34;,\\\u0026#34;queryDate\\\u0026#34;:\\\u0026#34;2021-11-03T10:13:51.019+0000\\\u0026#34;,\\\u0026#34;statistic\\\u0026#34;:\\\u0026#34;Maximum\\\u0026#34;,\\\u0026#34;period\\\u0026#34;:60,\\\u0026#34;recentDatapoints\\\u0026#34;:[],\\\u0026#34;threshold\\\u0026#34;:10.0,\\\u0026#34;evaluatedDatapoints\\\u0026#34;:[{\\\u0026#34;timestamp\\\u0026#34;:\\\u0026#34;2021-11-03T10:13:00.000+0000\\\u0026#34;}]}\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2021-11-03T10:13:51.023+0000\u0026#34;}, \u0026#34;configuration\u0026#34;: {\u0026#34;metrics\u0026#34;: [{\u0026#34;id\u0026#34;: \u0026#34;4cbe7286-d70f-fcb9-4a0a-758612d568db\u0026#34;, \u0026#34;metricStat\u0026#34;: {\u0026#34;metric\u0026#34;: {\u0026#34;namespace\u0026#34;: \u0026#34;AWS/EC2\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;CPUUtilization\u0026#34;, \u0026#34;dimensions\u0026#34;: {\u0026#34;InstanceId\u0026#34;: \u0026#34;i-0b22a89b0bb3faf49\u0026#34;}}, \u0026#34;period\u0026#34;: 60, \u0026#34;stat\u0026#34;: \u0026#34;Maximum\u0026#34;}, \u0026#34;returnData\u0026#34;: true}]}}}  と、ここで別途最近実施した、特別カスタマイズをしないアラーム + SNS送信検証時のメールを見たら、英語のみとはいえこっちの方がまだ全然見やすい。そりゃわかりにくいけど、JSON生データよりマシ。もう本文はこれでいいんじゃね？という気もするんだが。件名も、アラーム名が件名に入るんだから識別・フィルタしやすいアラーム名にすればどうにかなりそうな気もする。\u0026hellip;と、減速気味になってきた。\n \u0026hellip;が！以下の補足事項を思い出した。アラーム単体では無効化・有効化の制御ができない。となると、やはりEventBridgに組み込む方がいいんだよな。うーむ\u0026hellip;。頭痛いから明日考えよう。明後日かもしれない。\n 補足 アラームを一時無効化したい場合は、Rule側で制御する。マネコンで対象のルールを選択して、「Distable/無効にする」ボタンを押下。（アラーム単体ではこの機能がない）\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatch-alarm-lambda/","summary":"CloudWatchアラーム + SNSトピックでメール飛ばす時の件名を変更したい。ということで、過去記事 AWS EventBridge + SNSからのメール件名をカスタマイズする でイベントからのメール通知でやったことを、アラームに変えてやってみた。アラームのトリガーはEC2インスタンスCPU使用率閾値超えとする。\n ベースの参照は以下クラメソさんネタ。ただしこちらは本文のカスタマイズであり、件名は変えていない。またLambdaも使用していない。これに先の過去記事パターンを合体させてやってみた。\nCloudWatch アラームの通知メールを少しでも読みやすくしたい\n 処理概要  CloudWatchアラームのステータスがALARMに変わる。 Lambda関数起動 SNSに連携される メール通知   作業概要  SNSトピック作成〜サブスクライブ CloudWatchアラーム作成 Lambda関数作成（Lambda用IAMロールは既存流用） EventBridgeルール作成 EventBridgeルールのターゲットに3.のLambda関数を設定する 対象EC2インスタンスのCPU負荷を上げてアラームステータスにする メール通知確認   検証に使用したアイテム    アイテム 名称     SNSトピック alarm-notification-topic   CloudWatchアラーム CPU_Utilization_Test   Lambda関数 cw-alarm-sns-function   EventBridgeルール cw-alarm-rule    やったこと SNSトピック作成、Lambda関数作成は冒頭のリンク過去記事でもやったので省略。Lambda関数の環境変数でSNSトピック、メール件名を指定している。一応後半にスクショあり。\nCLIよりCloudWatchアラーム作成。少ない負荷でもアラームステータスになるように閾値は10%にしてある。\n$ aws cloudwatch put-metric-alarm --alarm-name \u0026quot;CPU_Utilization_Test\u0026quot; \\ --metric-name \u0026quot;CPUUtilization\u0026quot; \\ --namespace \u0026quot;AWS/EC2\u0026quot; \\ --statistic \u0026quot;Maximum\u0026quot; \\ --period 60 \\ --evaluation-periods 1 \\ --datapoints-to-alarm 1 \\ --threshold 10 \\ --comparison-operator \u0026quot;GreaterThanThreshold\u0026quot; \\ --dimensions \u0026quot;Name=InstanceId,Value=i-0xxxxxxxxxxx9\u0026quot;  EventBridgeルールの作成。以下の場合、\u0026ldquo;CPU_Utilization_\u0026ldquo;を含むアラームと関連付けられる","title":"CloudWatchアラーム + SNSからのメール件名をカスタマイズする"},{"content":"職場とか、いろんなチーム・グループの中で、「この人がいてくれると安心」「いてくれるだけでいい」と思える人が稀にいる。本当に、稀に、だが。そういう人と、その他の人々の違いは一体何なのか、とモヤっと不思議に思っていた。若干解明できそうなのが、以下の記事。ここに書かれている要因だけではないと思うが、理由の一部としては納得できる。\n「いるだけでチームの雰囲気をよくする人」の口癖4つ。“ど” から始まるあの言葉がかなり使える\n （以降軽くNSFW画像あり。閲覧注意）\n 記事では「いるだけでチームの雰囲気をよくする人」の4つの要素を述べている。\n 「ちょうどよかった」悪い状況にある時でもポジティブに捉える 「ありがとう」を言う時に別途感謝の言葉を添える どの、どのように、どちらか、等「ど」ではじまる質問で相手の話を引き出す 「教えてください」で相手へのリスペクトの気持ちを表す   上記のうち、1.と2.は他の自己啓発系コンテンツでもよく目にする話なので割愛する。まぁ「感謝の言葉を出し惜しみしない」、これは確かに大事だよ、俺も実践してる。相手によるけどね。\n3.は、俺はこれは実践する気ないけど、要するに聞き上手になって相手の気分をよくしてやれ、つうことだ。\n  ハーバード大学の研究論文（2012年）によると、自分の話をしているとき、おいしい食事をするときや収入を得るときと同じように脳の報酬系という部位が活性化したことが、 約300人の脳をfMRIでスキャンした結果からわかったのだそう。私たちが聞き上手な人に好感を抱くのは、「自分の話をするのが好き！」という人間の本能を満たしてくれるからなのかもしれません。\n  「上手に質問をすれば共感力が上がり、相手に好感を抱かせることができる」につながる、と。俺は「聞き上手ボランティア」をやる気はさらさらないが、興味深いのは先の引用にある「自分の話をするのが好き！という人間の本能」だ。よくいるよな、人の話は全然聞かないで、延々と自分のことを話したがるやつ。（ま、経験上女に多いという傾向は、ある）\n俺は今までそういうやつのことを、ただ自己愛が強くて、その自己愛を充足させるために他人に自分話を押売りして聞かせているもんだと思っていた。しかし上記引用で、「自分の話をしているときに脳の報酬系が活性化する」というのを読んで「そうか！」とひらめいた。脳の報酬系とはドーパミンのことである。ドーパミンは快楽を司る神経伝達物質だ。つまり自分のことを話すのは、人類共通の快感だったのだ！\nまぁ確かに、自分だってそういう面があるのは認めるよ。よく「話を聞いてもらってスッキリした」って言うもんな。何で話すだけでスッキリするのかって、ちゃんと理由があったんだな。しかしこれも度がすぎると聞かされる相手が迷惑だし、みっともないという自覚はある。自分のことを延々と話す人は、その制御が効かなくて、自らの快感原則に従って暴走しているんだろう。プラス自己愛もあるだろうけどね、どっちにしろこの手の人間とは遠い距離を置きたいものである。相手だけ満足して、自分はエネルギー吸い取られるだけだからな\u0026hellip;\n  話が大分脱線した、本来の主旨に戻る。うまい質問の仕方。「ど」で始まる疑問符がキーらしいが、具体的には記事の引用を俺なりにアレンジすると以下のようになる。（仕事関連の想定じゃないとピンと来ないもんで\u0026hellip;）\n   キーワード 質問例     What ー＞「どう、どんな」 どんな理由でこの仕事を始めたんですか？   Who ー＞「どの人、どんな人」 どんな人と仕事してみたいですか？   When ー＞「どんなとき、どのタイミング」 どんなときに達成感を感じますか？   Where ー＞「どこに、どこで」 どこでその分野を学んだのですか？   Why ー＞「どうして」 どうしてその製品に人気が集中するんでしょうね？   Which ー＞「どれ、どっち」 どちらのアイデアが気に入りましたか？   How ー＞「どうやって、どのように」 どのようにしてその課題を解決したんですか？     自己愛満々野郎の自分話を聞かされるのはゴメンだが、まともな相手とのコミュニケーション手法としては頭の片隅においておこう。\n   人はだれでも、自分に助言を求めてくる人の見識を高く評価する\n（We all admire the wisdom of people who come to us for advice.）\n ー 19世紀のイギリスの作家 アーサー・ヘルプスの言葉\n 最後の「教えてください」。これは相手を間接的に褒める手法だそうだ。ほぉぉ。\n  ブリガム・ヤング大学助教授で、組織の対人関係を研究するケイティ・リルエンクイスト氏らは、「助言を求められることは、基本的に嬉しいことだ」と言います。 なぜなら、助言を求める行為には、暗黙に「あなたの考えや価値観を支持している」というメッセージが含まれるから。 「教えてください」とアドバイスを求めることは、相手を立てることと同様の意味をもつのです。\n  うん、これはわかる気がするな、同じ助言の依頼でも「教えてくれくれ」的に無作法または横暴に聞かれると不愉快でしかないが、リスペクトの気持ちを込めた依頼は、相手の気分をよくすることができる。\nそこには「あなたは私が知らない知見/情報を持っていると思う、あなたのその知恵を私に分けて貰えたら非常にうれしい」という、メタメッセージが込められているんだ。そういうメッセージを受け取って悪い気分になる人間は、滅多にいないだろう。\n  まぁ自分今もいろいろ思うことがあってこの記事を書いているわけだが\u0026hellip;.、まったく関係なく、ふと別の言葉を思い出した。\n村上龍の小説「5分後の世界」に登場するミズノ少尉は、「絶対に最悪の事態を想像するな」と言った。俺はミズノ少尉のような器ではない。けど、ミズノ少尉のような存在をリスペクトするし、こういう人物と一緒に仕事ができたら嬉しいし、（それこそ、いてくれるだけでいい）少なくとも自分もミズノ少尉に近づけるように努めたいとは思う。\n 何か主旨が散逸してしまい、「いてくれるだけでいい人」の理由は解明されていない気がする。まぁ理由は他にもいろいろあるよね、ということで。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/skill-in-communication/","summary":"職場とか、いろんなチーム・グループの中で、「この人がいてくれると安心」「いてくれるだけでいい」と思える人が稀にいる。本当に、稀に、だが。そういう人と、その他の人々の違いは一体何なのか、とモヤっと不思議に思っていた。若干解明できそうなのが、以下の記事。ここに書かれている要因だけではないと思うが、理由の一部としては納得できる。\n「いるだけでチームの雰囲気をよくする人」の口癖4つ。“ど” から始まるあの言葉がかなり使える\n （以降軽くNSFW画像あり。閲覧注意）\n 記事では「いるだけでチームの雰囲気をよくする人」の4つの要素を述べている。\n 「ちょうどよかった」悪い状況にある時でもポジティブに捉える 「ありがとう」を言う時に別途感謝の言葉を添える どの、どのように、どちらか、等「ど」ではじまる質問で相手の話を引き出す 「教えてください」で相手へのリスペクトの気持ちを表す   上記のうち、1.と2.は他の自己啓発系コンテンツでもよく目にする話なので割愛する。まぁ「感謝の言葉を出し惜しみしない」、これは確かに大事だよ、俺も実践してる。相手によるけどね。\n3.は、俺はこれは実践する気ないけど、要するに聞き上手になって相手の気分をよくしてやれ、つうことだ。\n  ハーバード大学の研究論文（2012年）によると、自分の話をしているとき、おいしい食事をするときや収入を得るときと同じように脳の報酬系という部位が活性化したことが、 約300人の脳をfMRIでスキャンした結果からわかったのだそう。私たちが聞き上手な人に好感を抱くのは、「自分の話をするのが好き！」という人間の本能を満たしてくれるからなのかもしれません。\n  「上手に質問をすれば共感力が上がり、相手に好感を抱かせることができる」につながる、と。俺は「聞き上手ボランティア」をやる気はさらさらないが、興味深いのは先の引用にある「自分の話をするのが好き！という人間の本能」だ。よくいるよな、人の話は全然聞かないで、延々と自分のことを話したがるやつ。（ま、経験上女に多いという傾向は、ある）\n俺は今までそういうやつのことを、ただ自己愛が強くて、その自己愛を充足させるために他人に自分話を押売りして聞かせているもんだと思っていた。しかし上記引用で、「自分の話をしているときに脳の報酬系が活性化する」というのを読んで「そうか！」とひらめいた。脳の報酬系とはドーパミンのことである。ドーパミンは快楽を司る神経伝達物質だ。つまり自分のことを話すのは、人類共通の快感だったのだ！\nまぁ確かに、自分だってそういう面があるのは認めるよ。よく「話を聞いてもらってスッキリした」って言うもんな。何で話すだけでスッキリするのかって、ちゃんと理由があったんだな。しかしこれも度がすぎると聞かされる相手が迷惑だし、みっともないという自覚はある。自分のことを延々と話す人は、その制御が効かなくて、自らの快感原則に従って暴走しているんだろう。プラス自己愛もあるだろうけどね、どっちにしろこの手の人間とは遠い距離を置きたいものである。相手だけ満足して、自分はエネルギー吸い取られるだけだからな\u0026hellip;\n  話が大分脱線した、本来の主旨に戻る。うまい質問の仕方。「ど」で始まる疑問符がキーらしいが、具体的には記事の引用を俺なりにアレンジすると以下のようになる。（仕事関連の想定じゃないとピンと来ないもんで\u0026hellip;）\n   キーワード 質問例     What ー＞「どう、どんな」 どんな理由でこの仕事を始めたんですか？   Who ー＞「どの人、どんな人」 どんな人と仕事してみたいですか？   When ー＞「どんなとき、どのタイミング」 どんなときに達成感を感じますか？   Where ー＞「どこに、どこで」 どこでその分野を学んだのですか？   Why ー＞「どうして」 どうしてその製品に人気が集中するんでしょうね？   Which ー＞「どれ、どっち」 どちらのアイデアが気に入りましたか？   How ー＞「どうやって、どのように」 どのようにしてその課題を解決したんですか？     自己愛満々野郎の自分話を聞かされるのはゴメンだが、まともな相手とのコミュニケーション手法としては頭の片隅においておこう。","title":"「いてくれるだけでいい人」の理由"},{"content":"AWSでのログ監視メール送信はサブスクリプションフィルタ + Lambda + SNSを使用するのがスタンダード。みんなやっていそうなことだが未経験だったのでやってみた。基本参考にしたのは王道クラメソさんの記事だったが、ちょっとわかりにくいところがあったので他の記事も合わせて参照して若干やり方変えつつ検証した。\n今回はマネコン作業メインでやったが、CLIやTerraformなどAPI経由で実装する場合追加作業が発生するため注意が必要。(後述 補足事項に記載)\n 参考\n CloudWatch Logs を文字列検知してログ内容をメールを送信してみた サブスクリプションフィルター版 【AWS】CloudWatch Logsからシステムログをメール通知する。 CloudWatch Logs のサブスクリプションフィルタを使って特定文字列を検知したログをEメール通知する ※CLI実装例   以下は今後の参考用\n CloudWatchLogsの内容をフィルタリングしてLambdaで通知させたい ※除外キーワードをコードで記述する例 CloudWatchLogsからLambda経由でログメッセージを通知する ※Terraform実装例   処理概要  CWLにログが出力される CWLのサブスクリプションフィルタでキーワード検知 Lambda関数起動 SNSに連携される メール通知   作業概要  SNSトピック作成〜サブスクライブ Lambda用IAMロール作成 Lambda関数作成 ロググループ/ログストリーム作成 ロググループにサブスクリプションフィルタ作成 （配信先に3.のLambda関数を指定） テストログ送信〜メール通知確認  ※ログストリーム作成は検証時のみ。通常は自動生成される。\n 今回の検証に使用したアイテム（個人メモ）    アイテム 名称     SNSトピック log-monitor-topic   Lambda用IAMロール send-log-filter-role   Lambda関数 send-log-filter-function   サブスクリプションフィルタ send-log-filter     やったこと  SNSトピック作成〜サブスクライブ\n過去記事:AWS EventBridge + SNSからのメール件名をカスタマイズするに書いたので省略。ここではCLIでやってるけどマネコンでも特にハマるところはない。アクセスポリシーはデフォルトにした。   Lambda用IAMロール作成\nとりあえず以下のマネージドポリシーをアタッチ。   CloudEatchLogsFullAccess AmazonSNSFullAccess   Lambda関数作成\n(1) 参考ブログのコード貼り付け  import base64 import json import zlib import datetime import os import boto3 from botocore.exceptions import ClientError print(\u0026#39;Loading function\u0026#39;) def lambda_handler(event, context): data = zlib.decompress(base64.b64decode(event[\u0026#39;awslogs\u0026#39;][\u0026#39;data\u0026#39;]), 16+zlib.MAX_WBITS) data_json = json.loads(data) log_entire_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;], ensure_ascii=False)) log_entire_len = len(log_entire_json) print(log_entire_json) for i in range(log_entire_len): log_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;][i], ensure_ascii=False)) try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = log_json[\u0026#39;message\u0026#39;], Subject = os.environ[\u0026#39;ALARM_SUBJECT\u0026#39;] ) except Exception as e: print(e)  (2) 環境変数をセット(Configration/設定タブ ー＞ 左ペインのEnvironment variables/環境変数)\n   Key Value     SNS_TOPIC_ARN arn:aws:sns:ap-northeast-1:my-account-id:log-monitor-topic   CUSTOM_SUBJECT エラーログ送信テスト    ロググループ/ログストリーム作成\nマネコンから普通にできるので省略。   サブスクリプションフィルタ作成\nロググループの画面から作成する。   配信先として先に作成したLambda関数を指定する。ログフォーマットは当初OtherにしたがJSONでいいらしい。（まだよくわかっていない\u0026hellip;）\n 事前にメッセージを投入しておけばここでテストできる。メッセージが何もない場合はスキップ。\n 最後に[Start streaming]押下で完了。\n 作成後のサブスクリプションフィルタ。作成後に変更したい場合はマネコンからはできないため、CLIから設定する。詳細は後述の補足事項に記載。\n テストログ送信〜メール通知確認\nこのテストログ送信方法については、クラメソさんや他の記事ではCLIからput-log-eventsを実行しているが、正直面倒くさい。マネコンからやる方が簡単なのでここではその手順を記載。  対象のログストリーム画面から、[Actions(アクション)] ー＞ [Create log event（ログイベントの作成）]と遷移し、テストイベントを発行する。\n メール通知を確認。届いた！\n \u0026hellip;と、ここまで普通にできたっぽく書いているが、実際には何かとハマって手こずってしまった。当初メールが届かなくてね。複数の記事を参考にしているが、それぞれ微妙に手順や実装が異なるから、少しどこかをいじるとNGになったりする。\nメールが届かないのはSNSが原因と思ったけど（Lambdaでエラー出ていないから）、Lambda自体のログにテストイベントのメッセージが何も出力されていないことに気づいて、Lambdaがイベントを取得できていなくてSNSにメッセージが渡っていないことが原因とわかった。コードも若干入れ替えたり編集したりしたんで。自分は紆余曲折しておかしなことになったが、最初はクラメソさんのコードをそのまま使って手順通りにやればできるはず。応用はその後。\n 補足事項  サブスクリプション作成後の変更\nサブスク作成後はマネコンからは直接変更できないが、CLIで編集可能。aws logs put-subscripution-filterで同じサブスク名を指定すれば設定が上書きされる。  $ aws logs put-subscription-filter ¥ --log-group-name [your log group name] ¥ --filter-name [your subscription filter name] ¥ --filter-pattern [your filter pattern] ¥ --destination-arn [your destination arn] ※今回の場合Lambda関数のARN  フィルタパターン編集\nフィルタパターンでOR条件するには、キーワード間はスペース区切りとし、各キーワードの先頭に?をつける。除外フィルタはまた別に必要で複雑になる。Lambda関数内で設定することも可能なので、要件に応じて検討。  フィルタパターンOR条件例\nこれを作成済みのサブスクに適用したい場合は、上記1.のCLIコマンドの--filter-patternオプションの値として指定すればよい。\n\u0026quot;?error ?Error ?ERROR ?fail ?Fail ?FAIL\u0026quot;  除外キーワードをセットするのはちょっと面倒で、こんな風になる。以下の場合、メッセージが\u0026quot;error event\u0026quot;の場合は検知され、\u0026ldquo;error test\u0026quot;の場合は検知されない。\n\u0026quot;[( msg=¥\u0026quot;*error*¥\u0026quot; || msg=¥\u0026quot;*Error*¥\u0026quot; ) \u0026amp;\u0026amp; ( msg!=¥\u0026quot;*test*¥\u0026quot; \u0026amp;\u0026amp; msg!=¥\u0026quot;*Test*¥\u0026quot; \u0026amp;\u0026amp; msg!=¥\u0026quot;*TEST*¥\u0026quot; )]\u0026quot;  Lambdaコード内で除外キーワード定義することも可能だが、検知キーワードと除外キーワードが別れるのもどうなんかと思うし、迷うところ。\n APIから実装する際の追加作業\nサブスクリプションフィルタ作成時、マネコンだと自動で付与される権限がCLIでは付与されないため、事前にLambda側で権限を追加する。--statement-idは適当な文字列でいいと思われる。多分。  $ aws lambda add-permission ¥ --function-name [your function name] ¥ --statement-id \u0026quot;your statement id\u0026quot; ¥ --principal \u0026quot;logs.ap-northeast-1.amazonaws.com\u0026quot; ¥ --action \u0026quot;lambda:InvokeFunction\u0026quot; ¥ --source-arn \u0026quot;arn:aws:logs:ap-northeast-1:[your account id]:log-group:*:*\u0026quot; ¥ --source-account [your account id]  TerraformやCFnから作成する場合も同じ作業が必要になるはずだから要注意。\n参考: add-permission\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatchlogs-send-filter-mail/","summary":"AWSでのログ監視メール送信はサブスクリプションフィルタ + Lambda + SNSを使用するのがスタンダード。みんなやっていそうなことだが未経験だったのでやってみた。基本参考にしたのは王道クラメソさんの記事だったが、ちょっとわかりにくいところがあったので他の記事も合わせて参照して若干やり方変えつつ検証した。\n今回はマネコン作業メインでやったが、CLIやTerraformなどAPI経由で実装する場合追加作業が発生するため注意が必要。(後述 補足事項に記載)\n 参考\n CloudWatch Logs を文字列検知してログ内容をメールを送信してみた サブスクリプションフィルター版 【AWS】CloudWatch Logsからシステムログをメール通知する。 CloudWatch Logs のサブスクリプションフィルタを使って特定文字列を検知したログをEメール通知する ※CLI実装例   以下は今後の参考用\n CloudWatchLogsの内容をフィルタリングしてLambdaで通知させたい ※除外キーワードをコードで記述する例 CloudWatchLogsからLambda経由でログメッセージを通知する ※Terraform実装例   処理概要  CWLにログが出力される CWLのサブスクリプションフィルタでキーワード検知 Lambda関数起動 SNSに連携される メール通知   作業概要  SNSトピック作成〜サブスクライブ Lambda用IAMロール作成 Lambda関数作成 ロググループ/ログストリーム作成 ロググループにサブスクリプションフィルタ作成 （配信先に3.のLambda関数を指定） テストログ送信〜メール通知確認  ※ログストリーム作成は検証時のみ。通常は自動生成される。\n 今回の検証に使用したアイテム（個人メモ）    アイテム 名称     SNSトピック log-monitor-topic   Lambda用IAMロール send-log-filter-role   Lambda関数 send-log-filter-function   サブスクリプションフィルタ send-log-filter     やったこと  SNSトピック作成〜サブスクライブ","title":"CloudWatchlogsからサブスクリプションフィルタ + Lambdaでメール送信"},{"content":"昨年の過去ツイのスレッドでちょっと気になるのを見つけたので、若干手を入れてここにまとめて書いておく。\n  暴力の加害者に対して被害者が好意を抱く「ストックホルム症候群」と567脳、マスク厨の心理は似てないか？側から見ると、あの人たちは自由や人権を奪われている今の状況を愛しているように見える。\nその裏では「認知的不協和の解消」が発生している可能性がある。これは、自分の内部の矛盾に一貫性を持たせようとする機能。「新しい生活様式」だの、自粛しろマスクつけろだの、不自由で不本意な状況を強いられているが、それを受け入れている自分に葛藤が生じているはずなのだ。\nだからマナーだの何だの言って正当化している。または無意識に自分を麻痺させている。どちらにしても認知に修正を加えて不協和（矛盾）を解消しようとしているわけで、つまり認知に歪みが発生している。だから苦痛さえ感じなくなっているのではないかと想像する。\nそれから、「沖縄から貧困がなくならない本当の理由」（樋口耕太郎著）からの引用なのだが、こういった自己防衛の心理も働いているかとも。\n 人間は激しい痛みを感じると、自分の感覚を鈍らせて自己防衛を図る性質があるが、それは絶望の耐え難い痛みを和らげるために、自分自身に打つ麻酔のようなものだ。\n  自分に麻酔を打って思考や身体感覚を麻痺させたり、自ら認知を歪ませれば、見かけ上は苦痛が和らぐ。しかし同時に生きる上でのあらゆる喜びもまた、感じることができなくなる。そして本来あるべき自分の自由と権利を、忘却の彼方に押しやっている。それは虚構の世界を生きているだけなのだ。\n  \u0026hellip;と、まぁ当時はこんなことを思いつくままに呟いてみたが、大半の世間のコロナ恐怖脳はここまで複雑な心理の綾などなく、自分で調べたり考察することもなくひたすら垂れ流される情報を鵜呑みにして怖いね怖いねと決まり文句を言ってるだけのように見える、それが世間の掟だから。\nもちろん、マスク・アルコール消毒・検温や在宅勤務を強制または半強制されることに疑問を抱くこともない。一切の疑問も抱かずに、受け入れているのだ。昼の外食時に周りから聞こえてくる会話を聞いていると呆れる、それなりに一流と呼ばれる企業に勤めていてある程度の地位についていそうな人たちが、そんな具合なのである。\nまぁ何にせよ、認知の歪みが生じていることは確か、40度近い真夏日に病気でもないのにマスクとか異常でしかないよ。\n それから「家庭内ストックホルム症候群」という言葉もある。児童虐待やDVを受けている被害者が、自分を虐待・無視などで苦しめる親や配偶者（多くの場合夫）に不満や憎しみを抱きつつも、見捨てられたらどうしようと、過剰な不安や恐怖心が芽生える。そこで無意識の内に親や配偶者が気に入られるように「良い子」「良い妻」を演じてしまう\u0026hellip;ということらしい。\nいやでもこれって別に、ストックホルム症候群という名称を持ち出すまでもなく、より普遍的な事象だと思うな、人間が暴力・抑圧・嫌がらせに対して自分の心を麻痺させて適応を試みる心理が働くのは、きっと人間のデフォルト機能なんだよ、悲しい機能だけど。\nDVの他に大学内の教授と生徒の間に発生する「アカハラ」、職場のパワハラでも同様の状態になるよね、理不尽なハラスメントを受けているのに、それを客観視できない状態にあると、相手に気に入られようとして相手に従い、相手の意に沿うように行動してしまうんだ。\nこれには2つの要因がある、生き延びるための生存本能と、他者に愛されたい、承認されたいという、ヒトとしての社会的本能。しかしそれで相手がハラスメントを辞めるかと言ったら逆だ、「こいつはいじめれば何でも言うことをきく」と思われてエスカレートするだけだ、全く本質的な解決にはならず、状況が悪化するだけなんだよ。\n  ここまでの文章は、今年2021年の1月に別のブログに投稿した内容を編集・加筆したものだ。そこに置いておいても塩漬けになるだけだからこっちに持ってきた。文章中に登場するツイは、とうにアカウント削除したので今は存在しない。「家庭内ストックホルム症候群」から先は今回追記したもの。主旨が途中からずれている気がするが、まぁ気にしない。\nTwitterなんか最低のクソメディアだと思うが、ふと思いついて書いたことでも後でこうして振り返って考察することもあるから、そういう意味では少しはやる価値あったかな。\n結局何が言いたいのかってね、多くの人間は、ハラスメントを受けている最中は、状況を客観視できないんだよ、かつ、生存本能と社会的本能のためにその状況に適応しようとして、自分を押し殺してハラスメントをする相手や周囲に従ったり、意に沿わない行動をとったりしがちなんだ。これは自覚しないといけないし、あらゆるハラスメントには声をあげ、全力で抵抗しなけりゃいけないんだ、それこそ、羊や奴隷ではなく、主権を持った人間として生きるために。\n  過去記事にも書いたDylan Thomasの詩の一部。本来の詩の主旨は違うけど、今のこの世界に対して、全く同じことを言いたいね。\n Do not go gentle into that good night,\nRage, rage against the dying of the light.\n  あぁまったく、俺はやっぱりこのまま死ぬわけにはいかねぇ、大人しく従ってちゃダメなんだ、激怒して、憤怒して、死にもの狂いで抵抗しなくちゃいけないんだ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/stockholm-syndrome/","summary":"昨年の過去ツイのスレッドでちょっと気になるのを見つけたので、若干手を入れてここにまとめて書いておく。\n  暴力の加害者に対して被害者が好意を抱く「ストックホルム症候群」と567脳、マスク厨の心理は似てないか？側から見ると、あの人たちは自由や人権を奪われている今の状況を愛しているように見える。\nその裏では「認知的不協和の解消」が発生している可能性がある。これは、自分の内部の矛盾に一貫性を持たせようとする機能。「新しい生活様式」だの、自粛しろマスクつけろだの、不自由で不本意な状況を強いられているが、それを受け入れている自分に葛藤が生じているはずなのだ。\nだからマナーだの何だの言って正当化している。または無意識に自分を麻痺させている。どちらにしても認知に修正を加えて不協和（矛盾）を解消しようとしているわけで、つまり認知に歪みが発生している。だから苦痛さえ感じなくなっているのではないかと想像する。\nそれから、「沖縄から貧困がなくならない本当の理由」（樋口耕太郎著）からの引用なのだが、こういった自己防衛の心理も働いているかとも。\n 人間は激しい痛みを感じると、自分の感覚を鈍らせて自己防衛を図る性質があるが、それは絶望の耐え難い痛みを和らげるために、自分自身に打つ麻酔のようなものだ。\n  自分に麻酔を打って思考や身体感覚を麻痺させたり、自ら認知を歪ませれば、見かけ上は苦痛が和らぐ。しかし同時に生きる上でのあらゆる喜びもまた、感じることができなくなる。そして本来あるべき自分の自由と権利を、忘却の彼方に押しやっている。それは虚構の世界を生きているだけなのだ。\n  \u0026hellip;と、まぁ当時はこんなことを思いつくままに呟いてみたが、大半の世間のコロナ恐怖脳はここまで複雑な心理の綾などなく、自分で調べたり考察することもなくひたすら垂れ流される情報を鵜呑みにして怖いね怖いねと決まり文句を言ってるだけのように見える、それが世間の掟だから。\nもちろん、マスク・アルコール消毒・検温や在宅勤務を強制または半強制されることに疑問を抱くこともない。一切の疑問も抱かずに、受け入れているのだ。昼の外食時に周りから聞こえてくる会話を聞いていると呆れる、それなりに一流と呼ばれる企業に勤めていてある程度の地位についていそうな人たちが、そんな具合なのである。\nまぁ何にせよ、認知の歪みが生じていることは確か、40度近い真夏日に病気でもないのにマスクとか異常でしかないよ。\n それから「家庭内ストックホルム症候群」という言葉もある。児童虐待やDVを受けている被害者が、自分を虐待・無視などで苦しめる親や配偶者（多くの場合夫）に不満や憎しみを抱きつつも、見捨てられたらどうしようと、過剰な不安や恐怖心が芽生える。そこで無意識の内に親や配偶者が気に入られるように「良い子」「良い妻」を演じてしまう\u0026hellip;ということらしい。\nいやでもこれって別に、ストックホルム症候群という名称を持ち出すまでもなく、より普遍的な事象だと思うな、人間が暴力・抑圧・嫌がらせに対して自分の心を麻痺させて適応を試みる心理が働くのは、きっと人間のデフォルト機能なんだよ、悲しい機能だけど。\nDVの他に大学内の教授と生徒の間に発生する「アカハラ」、職場のパワハラでも同様の状態になるよね、理不尽なハラスメントを受けているのに、それを客観視できない状態にあると、相手に気に入られようとして相手に従い、相手の意に沿うように行動してしまうんだ。\nこれには2つの要因がある、生き延びるための生存本能と、他者に愛されたい、承認されたいという、ヒトとしての社会的本能。しかしそれで相手がハラスメントを辞めるかと言ったら逆だ、「こいつはいじめれば何でも言うことをきく」と思われてエスカレートするだけだ、全く本質的な解決にはならず、状況が悪化するだけなんだよ。\n  ここまでの文章は、今年2021年の1月に別のブログに投稿した内容を編集・加筆したものだ。そこに置いておいても塩漬けになるだけだからこっちに持ってきた。文章中に登場するツイは、とうにアカウント削除したので今は存在しない。「家庭内ストックホルム症候群」から先は今回追記したもの。主旨が途中からずれている気がするが、まぁ気にしない。\nTwitterなんか最低のクソメディアだと思うが、ふと思いついて書いたことでも後でこうして振り返って考察することもあるから、そういう意味では少しはやる価値あったかな。\n結局何が言いたいのかってね、多くの人間は、ハラスメントを受けている最中は、状況を客観視できないんだよ、かつ、生存本能と社会的本能のためにその状況に適応しようとして、自分を押し殺してハラスメントをする相手や周囲に従ったり、意に沿わない行動をとったりしがちなんだ。これは自覚しないといけないし、あらゆるハラスメントには声をあげ、全力で抵抗しなけりゃいけないんだ、それこそ、羊や奴隷ではなく、主権を持った人間として生きるために。\n  過去記事にも書いたDylan Thomasの詩の一部。本来の詩の主旨は違うけど、今のこの世界に対して、全く同じことを言いたいね。\n Do not go gentle into that good night,\nRage, rage against the dying of the light.\n  あぁまったく、俺はやっぱりこのまま死ぬわけにはいかねぇ、大人しく従ってちゃダメなんだ、激怒して、憤怒して、死にもの狂いで抵抗しなくちゃいけないんだ。","title":"「ストックホルム症候群」の心理はヒトのデフォルト機能だった"},{"content":"Mac上のpython3。しばらく前にhomebrewと一緒に削除してしまったので入れ直した。\n$ brew install python3  $ which python3 /usr/local/bin/python3 $ python3 -V Python 3.9.7 $ pip3 -V pip 21.2.4 from /usr/local/lib/python3.9/site-packages/pip (python 3.9)  pythonだけで実行するとゴニョゴニョ言われる。\n$ python Your PYTHONPATH points to a site-packages dir for Python 3.x but you are running Python 2.x! PYTHONPATH is currently: \u0026quot;/usr/local/lib/python3.9/site-packages:\u0026quot; You should `unset PYTHONPATH` to fix this. $ unset PYTHONPATH  で、この後pythonを実行すると2系になってしまう。\n$ python WARNING: Python 2.7 is not recommended. This version is included in macOS for compatibility with legacy software. Future versions of macOS will not include Python 2.7. Instead, it is recommended that you transition to using 'python3' from within Terminal. Python 2.7.16 (default, Aug 30 2021, 14:43:11) [GCC Apple LLVM 12.0.5 (clang-1205.0.19.59.6) [+internal-os, ptrauth-isa=deploy on darwin Type \u0026quot;help\u0026quot;, \u0026quot;copyright\u0026quot;, \u0026quot;credits\u0026quot; or \u0026quot;license\u0026quot; for more information. \u0026gt;\u0026gt;\u0026gt;  python3を実行するにはpython3とタイプ。\n$ python3 Python 3.9.7 (default, Oct 13 2021, 06:45:31) [Clang 13.0.0 (clang-1300.0.29.3)] on darwin Type \u0026quot;help\u0026quot;, \u0026quot;copyright\u0026quot;, \u0026quot;credits\u0026quot; or \u0026quot;license\u0026quot; for more information. \u0026gt;\u0026gt;\u0026gt;  boto3が消えていたのでこれも再インストールした。\n$ pip3 install boto3 $ pip3 freeze boto3==1.18.63 botocore==1.21.63 Jinja2==2.11.2 jmespath==0.10.0 MarkupSafe==1.1.1 python-dateutil==2.8.2 PyYAML==5.3.1 s3transfer==0.5.0 six==1.16.0 urllib3==1.26.7  全く無関係に在りし日の記録。\n  はるばるアルゼンチンから、こんなに大勢の人が日本に来てくれたんだよ？嗚呼。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/mac-python3-re-install/","summary":"Mac上のpython3。しばらく前にhomebrewと一緒に削除してしまったので入れ直した。\n$ brew install python3  $ which python3 /usr/local/bin/python3 $ python3 -V Python 3.9.7 $ pip3 -V pip 21.2.4 from /usr/local/lib/python3.9/site-packages/pip (python 3.9)  pythonだけで実行するとゴニョゴニョ言われる。\n$ python Your PYTHONPATH points to a site-packages dir for Python 3.x but you are running Python 2.x! PYTHONPATH is currently: \u0026quot;/usr/local/lib/python3.9/site-packages:\u0026quot; You should `unset PYTHONPATH` to fix this. $ unset PYTHONPATH  で、この後pythonを実行すると2系になってしまう。\n$ python WARNING: Python 2.7 is not recommended. This version is included in macOS for compatibility with legacy software.","title":"MacにPython3を再インストール"},{"content":"あー、マジやべぇ、息が詰まりそうだ、いろいろと、勘弁してくれよもう的な動きが多くてさ、めっちゃやり辛い。まじで、10月入ってからすげえやり辛くなった。鬱屈がたまってどうしようもねぇ。\nしばらく前から通勤時に英文小説読む余力もないし、Tumblrやり過ぎるとDVT症候群で頭痛と目眩がするし、イヤホンで大音量で音楽聴きすぎて耳がイカレそうだし、もう何を支えにしていいかわからないな、オレは生き延びることができるんだろうか？\nそりゃ仕事があるだけありがたい立場だってことは忘れちゃいけないけどね、もし今「戦争」状態じゃなかったらいつでも出ていけるんだからな、なにせ俺様能力高いからな。\n \u0026hellip;うん、そのつもりでやっていくしかねぇな\u0026hellip;\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/life-1027/","summary":"あー、マジやべぇ、息が詰まりそうだ、いろいろと、勘弁してくれよもう的な動きが多くてさ、めっちゃやり辛い。まじで、10月入ってからすげえやり辛くなった。鬱屈がたまってどうしようもねぇ。\nしばらく前から通勤時に英文小説読む余力もないし、Tumblrやり過ぎるとDVT症候群で頭痛と目眩がするし、イヤホンで大音量で音楽聴きすぎて耳がイカレそうだし、もう何を支えにしていいかわからないな、オレは生き延びることができるんだろうか？\nそりゃ仕事があるだけありがたい立場だってことは忘れちゃいけないけどね、もし今「戦争」状態じゃなかったらいつでも出ていけるんだからな、なにせ俺様能力高いからな。\n \u0026hellip;うん、そのつもりでやっていくしかねぇな\u0026hellip;\n ","title":"ひとり言 - 10月27日"},{"content":"10月25日の明け方に見た夢。コンサート会場みたいなところ。そこはロンドンである。観客が大勢いて賑わっている。そしてノーマスク。「あぁ、マスク圧解禁されたのか！」と嬉しい。よく見ると数人はマスクしている、でもほぼノーマスク。あぁ。\n もうずっとリアル世界で不快なものしか見てないから、せめてここだけでも。これくらいいいだろ\u0026hellip;.\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/life-1025/","summary":"10月25日の明け方に見た夢。コンサート会場みたいなところ。そこはロンドンである。観客が大勢いて賑わっている。そしてノーマスク。「あぁ、マスク圧解禁されたのか！」と嬉しい。よく見ると数人はマスクしている、でもほぼノーマスク。あぁ。\n もうずっとリアル世界で不快なものしか見てないから、せめてここだけでも。これくらいいいだろ\u0026hellip;.\n ","title":"Eye Candyがいるんだ"},{"content":"表題の件、通知メールの件名はわかりやすいのにしたいよねというニーズに対応すべく、以下参考に試してみた。やったことはほぼこちらの記事の通り。\nAmazon SNS で送られる CloudWatch Events ルールの通知内容をカスタマイズする\n 上記の通りやっていけばできるんだけれど、整理するためにも自分用に記録残す。ちなみに2021年10月現在、CloudWatch EventsはEventBridgeになっている。移行期間中だからまだ違和感があるが、この記事では名称は「EventBridge」とする。それと後半で書いているが、今回の事例ではCloudTrailが有効になっていることが前提なので、現状無効の場合は有効にしておく。\n各種リソースに類似の名称が多くて混乱するので、これも自分用に整理。以下、今回作成したリソース名称。\n   アイテム 名称     SNSトピック custom-event-notification   Lambda用IAMロール custom-event-mail-role   Lambda関数 custom-mail-function   evetnsルール custom-mail-rule     ではここから作業内容の記録に入る。\nSNSトピック作成\n$ aws sns create-topic --name custom-event-notification  サブスク（サブスクリプション）作成\n$ aws sns subscribe --topic-arn arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification --protocol email --notification-endpoint [my mail address] { \u0026quot;SubscriptionArn\u0026quot;: \u0026quot;pending confirmation\u0026quot; }  指定したアドレスにメールが届くので、リンク押下してconfirmする。その後マネコンのSNS画面を見るとサブスクのステータスがconfirmedになっているはず。\nまたは、以下確認コマンド\n$ aws sns list-subscriptions-by-topic --topic-arn arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification  ここからLambdaの作業に入る。最初にLambda用のIAMロールを作成。以下の内容で信頼ポリシー用のJSONファイルを用意し、それを指定してロール作成実行。\ntrust-policy.json\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;lambda.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] }  $ aws iam create-role --role-name custom-event-mail-role --assume-role-policy-document file://trust-policy.json  ロールにAWSマネージドポリシーをアタッチ。\n$ aws iam attach-role-policy --role-name custom-event-mail-role --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole $ aws iam attach-role-policy --role-name custom-event-mail-role --policy-arn arn:aws:iam::aws:policy/AmazonSNSFullAccess  ここまでで、IAMロール完成。次に、以下内容のLambda関数のコードを用意する。\ncustom-mail.py\nimport boto3 import json import os sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] custom_subject = os.environ[\u0026#39;CUSTOM_SUBJECT\u0026#39;] def lambda_handler(event, context): print(sns_arn) client = boto3.client(\u0026#34;sns\u0026#34;) resp = client.publish(TargetArn=sns_arn, Message=json.dumps(event), Subject=custom_subject)  これをzipにする。\n$ zip custom-mail.zip custom-mail.py  IAMロールとzipファイルを指定してLambda関数を作成。\n$ aws lambda create-function --function-name custom-mail-function --role arn:aws:iam::my-account-id:role/custom-event-mail-role --runtime python3.8 --handler custom-mail.lambda_handler --zip-file fileb://custom-mail.zip  環境変数をセット。ここでSNSトピックARNと、送信したいメール件名を定義している。\n$ aws lambda update-function-configuration --function-name custom-mail-function --environment Variables='{SNS_TOPIC_ARN=\u0026quot;arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification\u0026quot;,CUSTOM_SUBJECT=\u0026quot;カスタムメールタイトル送信テスト\u0026quot;}'     変数名 値     SNS_TOPIC_ARN arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification   CUSTOM_SUBJECT カスタムメールタイトル送信テスト     トリガーとなるイベントルールを作成。本当はec2のCPU使用率のアラームでメール飛ばしたいがここは参考ページの通りにする。\nevent-pattern.json\n{ \u0026#34;source\u0026#34;: [ \u0026#34;aws.s3\u0026#34; ], \u0026#34;detail-type\u0026#34;: [ \u0026#34;AWS API Call via CloudTrail\u0026#34; ], \u0026#34;detail\u0026#34;: { \u0026#34;eventSource\u0026#34;: [ \u0026#34;s3.amazonaws.com\u0026#34; ], \u0026#34;eventName\u0026#34;: [ \u0026#34;CreateBucket\u0026#34;, \u0026#34;DeleteBucket\u0026#34; ] } }  eventsのルールを作成する。\n$ aws events put-rule --name custom-mail-rule --event-pattern file://event-pattern.json { \u0026quot;RuleArn\u0026quot;: \u0026quot;arn:aws:events:ap-northeast-1:my-account-id:rule/custom-mail-rule\u0026quot; }  Lambdaにルールの実行権限を追加。\n$ aws lambda add-permission --function-name custom-mail-function --statement-id 1 --principal events.amazonaws.com --action 'lambda:InvokeFunction' --source-arn arn:aws:events:ap-northeast-1:my-account-id:rule/custom-mail-rule { \u0026quot;Statement\u0026quot;: \u0026quot;{\\\u0026quot;Sid\\\u0026quot;:\\\u0026quot;1\\\u0026quot;,\\\u0026quot;Effect\\\u0026quot;:\\\u0026quot;Allow\\\u0026quot;,\\\u0026quot;Principal\\\u0026quot;:{\\\u0026quot;Service\\\u0026quot;:\\\u0026quot;events.amazonaws.com\\\u0026quot;},\\\u0026quot;Action\\\u0026quot;:\\\u0026quot;lambda:InvokeFunction\\\u0026quot;,\\\u0026quot;Resource\\\u0026quot;:\\\u0026quot;arn:aws:lambda:ap-northeast-1:my-account-id:function:custom-mail-function\\\u0026quot;,\\\u0026quot;Condition\\\u0026quot;:{\\\u0026quot;ArnLike\\\u0026quot;:{\\\u0026quot;AWS:SourceArn\\\u0026quot;:\\\u0026quot;arn:aws:events:ap-northeast-1:my-account-id:rule/custom-mail-rule\\\u0026quot;}}}\u0026quot; }  Lambda関数をルールのターゲットとしてセットする。\n$ aws events put-targets --rule custom-mail-rule --targets \u0026quot;Id\u0026quot;=\u0026quot;Target1\u0026quot;,\u0026quot;Arn\u0026quot;=\u0026quot;arn:aws:lambda:ap-northeast-1:my-account-id:function:custom-mail-function\u0026quot; { \u0026quot;FailedEntryCount\u0026quot;: 0, \u0026quot;FailedEntries\u0026quot;: [] }  バケットを作成して通知テスト\n$ aws s3 mb s3://custom-mail-sending-test-xxxx  \u0026hellip;しかしメール届かない。て、CloudTrailが無効になっているんだから当然である。で、CloudTrailを有効にしてから先ほど作成したバケットを消してみる。したら、\u0026hellip;設定した件名「カスタムメールタイトル送信テスト」で通知メールが届いた！\nLambda関数の画面ではトリガーがEventBridgeになっているが、移行期間中はカッコでCloudWatche Eventsも併記されるっぽい。\n Events側でもルールとLambda関数が紐付いていることがわかる。ちなみにこれはCloudWatche Eventsの画面から見ているが、同じルールがEventBridgeの画面にも存在するはずである。\n メール本文。JSONの生データそのまんま。「人間」の感覚としてはこんなん送られてもなぁ\u0026hellip;としか思えないが、\u0026ldquo;DeleteBucket\u0026quot;の記録があることは一応わかる。\n CloudTrailはもういらんので削除。\u0026hellip;で、SNSからのメールは件名カスタマイズできるのはわかったが、アラームと組み合わせるとなるとまた別の調整が必要。その辺がわからん。次回の課題。\n（追記）以下、後日やってみた記録。\nCloudWatchアラーム + SNSからのメール件名をカスタマイズする \n 本文のカスタマイズ例。これはLambda使ってないけど、今回のコードをアレンジすればできるっぽいからそっちに寄せたい感じ。\nCloudWatch アラームの通知メールを少しでも読みやすくしたい\nEventBridgeって結局元CloudWatchEventsのことなんだが、まだよくわかっていないのでこの辺も調べておく。\nAmazon EventBridgeとは何か\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/aws-events-custom-mail/","summary":"表題の件、通知メールの件名はわかりやすいのにしたいよねというニーズに対応すべく、以下参考に試してみた。やったことはほぼこちらの記事の通り。\nAmazon SNS で送られる CloudWatch Events ルールの通知内容をカスタマイズする\n 上記の通りやっていけばできるんだけれど、整理するためにも自分用に記録残す。ちなみに2021年10月現在、CloudWatch EventsはEventBridgeになっている。移行期間中だからまだ違和感があるが、この記事では名称は「EventBridge」とする。それと後半で書いているが、今回の事例ではCloudTrailが有効になっていることが前提なので、現状無効の場合は有効にしておく。\n各種リソースに類似の名称が多くて混乱するので、これも自分用に整理。以下、今回作成したリソース名称。\n   アイテム 名称     SNSトピック custom-event-notification   Lambda用IAMロール custom-event-mail-role   Lambda関数 custom-mail-function   evetnsルール custom-mail-rule     ではここから作業内容の記録に入る。\nSNSトピック作成\n$ aws sns create-topic --name custom-event-notification  サブスク（サブスクリプション）作成\n$ aws sns subscribe --topic-arn arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification --protocol email --notification-endpoint [my mail address] { \u0026quot;SubscriptionArn\u0026quot;: \u0026quot;pending confirmation\u0026quot; }  指定したアドレスにメールが届くので、リンク押下してconfirmする。その後マネコンのSNS画面を見るとサブスクのステータスがconfirmedになっているはず。\nまたは、以下確認コマンド\n$ aws sns list-subscriptions-by-topic --topic-arn arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification  ここからLambdaの作業に入る。最初にLambda用のIAMロールを作成。以下の内容で信頼ポリシー用のJSONファイルを用意し、それを指定してロール作成実行。","title":"AWS EventBridge + SNSからのメール件名をカスタマイズする"},{"content":"CloudWatchLogsからS3へログをエクスポートする。基本的に以下の通りにやればできるのだが、説明が冗長だったりわかりにくいところがあるので自分用に書いておく。IAMユーザ作成の手順とかいらん。親切のつもりだろうけど、無駄に記事が長くなって読む気が失せる\u0026hellip;\nコンソールを使用してログデータを Amazon S3 にエクスポートする\n 概要。ログストリームのエクスポートはログストリームの画面ではなく、ロググループの画面から行う。事前にログエクスポート専用S3バケットを用意し、ドキュメントの通りにバケットポリシーを設定しておく。適当なランダム値のプレフィクスを作成し、バケットポリシーに反映する。\n バケットポリシーサンプル\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::my-app-logs\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; } }, { \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34; , \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::my-app-logs/sjh6dert3a/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;s3:x-amz-acl\u0026#34;: \u0026#34;bucket-owner-full-control\u0026#34; } }, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; } } ] }  上記前提条件が整った上で、以下実行する。カッコ内は英語表記の場合。\n 対象のログストリーム画面上で、「アクション」(Actions)のプルダウンから、「データをAmazon S3に エクスポート」(Export data to Amazon S3)を選択。 次画面でバケット名、作成しておいたS3のプレフィクス名、ログストリーム、時間の範囲指定を行い、「エクスポート」実行   エクスポート先のS3では確かzip化された状態で格納されていたと思う。\nドキュメント中の表現一部「ランダムに生成されたプレフィクス」、これがわかりにくかった。ログエクスポート先のS3にランダム文字列のプレフィクスが存在するのが望ましいようだ。なぜ普通の文字列ではなくランダム値が望ましいのかはよくわからん。「生成されたランダム文字列」と書かれているもんだから、どこで生成してるんだ？と混乱した。これは自分で適当に決めた値でよい。\n 上記に書いた作業はもちろん必要に応じてアドホック的に行う対応であり、定常的対応であればLambdaなりshellなりでバッチ化するのが普通だろう。しかしね、たかがログエクスポートだろ？て舐めちゃいけないよ、作り込みがいけてないせいで、処理に24時間以上かかる例があったんだから。（もちろん作ったのはオレじゃない）\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/cwl-s3-export/","summary":"CloudWatchLogsからS3へログをエクスポートする。基本的に以下の通りにやればできるのだが、説明が冗長だったりわかりにくいところがあるので自分用に書いておく。IAMユーザ作成の手順とかいらん。親切のつもりだろうけど、無駄に記事が長くなって読む気が失せる\u0026hellip;\nコンソールを使用してログデータを Amazon S3 にエクスポートする\n 概要。ログストリームのエクスポートはログストリームの画面ではなく、ロググループの画面から行う。事前にログエクスポート専用S3バケットを用意し、ドキュメントの通りにバケットポリシーを設定しておく。適当なランダム値のプレフィクスを作成し、バケットポリシーに反映する。\n バケットポリシーサンプル\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::my-app-logs\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; } }, { \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34; , \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::my-app-logs/sjh6dert3a/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;s3:x-amz-acl\u0026#34;: \u0026#34;bucket-owner-full-control\u0026#34; } }, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; } } ] }  上記前提条件が整った上で、以下実行する。カッコ内は英語表記の場合。\n 対象のログストリーム画面上で、「アクション」(Actions)のプルダウンから、「データをAmazon S3に エクスポート」(Export data to Amazon S3)を選択。 次画面でバケット名、作成しておいたS3のプレフィクス名、ログストリーム、時間の範囲指定を行い、「エクスポート」実行   エクスポート先のS3では確かzip化された状態で格納されていたと思う。\nドキュメント中の表現一部「ランダムに生成されたプレフィクス」、これがわかりにくかった。ログエクスポート先のS3にランダム文字列のプレフィクスが存在するのが望ましいようだ。なぜ普通の文字列ではなくランダム値が望ましいのかはよくわからん。「生成されたランダム文字列」と書かれているもんだから、どこで生成してるんだ？と混乱した。これは自分で適当に決めた値でよい。\n 上記に書いた作業はもちろん必要に応じてアドホック的に行う対応であり、定常的対応であればLambdaなりshellなりでバッチ化するのが普通だろう。しかしね、たかがログエクスポートだろ？て舐めちゃいけないよ、作り込みがいけてないせいで、処理に24時間以上かかる例があったんだから。（もちろん作ったのはオレじゃない）\n ","title":"CloudWatchLogsからS3へログをエクスポートする"},{"content":"GitHub ActionsでCIか。このブログについては今の時点でも不自由していないから無理にやらなくてもいい気がする、けど調べておこう。\nHugo + GitHub Pages + GitHub Actions で独自ドメインのウェブサイトを構築する\n  今日はとうとう電車の中で堂々と中指を突き立てた俺様であったが、週末くらいは心穏やかに過ごそう、ふぅ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/github-actions/","summary":"GitHub ActionsでCIか。このブログについては今の時点でも不自由していないから無理にやらなくてもいい気がする、けど調べておこう。\nHugo + GitHub Pages + GitHub Actions で独自ドメインのウェブサイトを構築する\n  今日はとうとう電車の中で堂々と中指を突き立てた俺様であったが、週末くらいは心穏やかに過ごそう、ふぅ。","title":"Github Actionsメモ"},{"content":"そして俺は相変わらず中指を1000本くらい突き立てたい気分の日々が継続中なのだ。日々アドレナリンが過剰放出されてしまい、心身によろしくない。けど怒りをそのままぶちまけるのは芸がないし、自分にとってプラスにならないからね、俺はプラスになることだけやりたいわけ、だから少しでも勉強になることを書く。\n \u0026ldquo;middle finger\u0026quot;って言ったらあれです、特別な意味を持つ「中指」。\n以下はすべて同じ意味。\u0026ldquo;the finger\u0026quot;でも同じ意味になるとは知らなかった。\n middle finger second finger the finger   侮蔑や怒りを示すジェスチャーとなる「中指を立てる」行為は以下の表現。\n give the middle finger give the finger   以下も同じ意味。知らなかった。でもどれだけポピュラーなんだろう？\n flip the bird fly the bird    しばらく前までは心の中だけで中指を突き立てていたが、最近もう耐えられなくなって物理的にも公の場で中指を立てている俺様なのだった。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/the-finger/","summary":"そして俺は相変わらず中指を1000本くらい突き立てたい気分の日々が継続中なのだ。日々アドレナリンが過剰放出されてしまい、心身によろしくない。けど怒りをそのままぶちまけるのは芸がないし、自分にとってプラスにならないからね、俺はプラスになることだけやりたいわけ、だから少しでも勉強になることを書く。\n \u0026ldquo;middle finger\u0026quot;って言ったらあれです、特別な意味を持つ「中指」。\n以下はすべて同じ意味。\u0026ldquo;the finger\u0026quot;でも同じ意味になるとは知らなかった。\n middle finger second finger the finger   侮蔑や怒りを示すジェスチャーとなる「中指を立てる」行為は以下の表現。\n give the middle finger give the finger   以下も同じ意味。知らなかった。でもどれだけポピュラーなんだろう？\n flip the bird fly the bird    しばらく前までは心の中だけで中指を突き立てていたが、最近もう耐えられなくなって物理的にも公の場で中指を立てている俺様なのだった。","title":"middle finger周辺の表現など"},{"content":"\u0026ldquo;rage\u0026quot;という英単語がある。名詞としては「激情、激怒、憤怒」、自動詞として「怒る、暴れる」という意味だ。これを知ったきっかけは、Tumblrで見かけた以下の引用だった。\n Do not go gentle into that good night.\nRage, rage against the dying of the light.\n  パッと見てすぐに意味は理解できなかったが何か心を捉えられた感があった。\u0026ldquo;rage\u0026quot;という単語を初めて見たので調べたところ、意味は先述の通り。\nこれはウェールズの詩人ディラン・トーマス(Dylan Thomas) の詩の一部である。でもTumblrの投稿にはOscar Wildeって書いたあったような記憶がある。それで最近までずっとこの引用元をOscar Wildeだと思い込んでいたんだから。間違いだったんだなあれは。\nそれはさておき、今日この詩について少し文献を調べてみたら、この引用に対して今までの自分の解釈が若干ズレていたことがわかった。以下は引用元の詩全体である。\n  Do not go gentle into that good night,\nOld age should burn and rage at close of day;\nRage, rage against the dying of the light.\nThough wise men at their end know dark is right,\nBecause their words had forked no lightning they\nDo not go gentle into that good night.\nGood men, the last wave by, crying how bright\nTheir frail deeds might have danced in a green bay,\nRage, rage against the dying of the light.\nWild men who caught and sang the sun in flight,\nAnd learn, too late, they grieved it on its way,\nDo not go gentle into that good night.\nGrave men, near death, who see with blinding sight\nBlind eyes could blaze like meteors and be gay,\nRage, rage against the dying of the light.\nAnd you, my father, there on the sad height,\nCurse, bless me now with your fierce tears, I pray.\nDo not go gentle into that good night.\nRage, rage against the dying of the light.\n (Dylan Thomas, Do Not Go Gentle Into That Good Night)\n  この詩は、ディランが死に瀕した父親へ向けて書いた詩である。（\u0026hellip;というのはもちろん拾った情報）\n詩を理解するのは難しい、言葉としての意味を理解するのと文脈を理解すること、さらにその裏に表現された暗喩を理解するのは別のことだ。しかも母国語以外で。\n俺の英語力はお粗末なので、言葉の意味と文脈はどうにか掴めても、その奥の本質までは手が届きそうで届かない。しかしこの時点で今までの自分の解釈がズレていたことに気づいた。\n俺はTumblrでこの引用を初めて目にしたとき、「大人しくなんかなるなよ、消えゆく灯りに激怒しろ、憤怒しろ」と文字通りの意味に捉えていた、作家がオスカー・ワイルドと思っていたせいもあり、今そこでまだエネルギーを保持して生きている人間が自分または他人をさらに奮い立たせる意図の言葉と解釈した。それで、何か心が「ザワザワッ」としたのである。そしてrageという単語を覚えたのである。\n  話変わって数ヶ月後、村上龍の「ピアッシング」を英語翻訳版で読む機会があった。そしてそこでrageという単語に再会した。コールガールのChiakiが妄想に取り憑かれた男Kawashimaに客として出会い、ふとしたきっかけでrageな状態に至る。そのシーンで、先の引用を真っ先に思い出した。ピピピッときたよね。\nその後また別の英文小説を読んだら、そこでも単語rageが登場してピピピッときた。言葉というものは、こういうプロセスを経て自分の内部に取り込まれていくのである。だからそのプロセスは、人の数だけバリエーションが存在する。\nで、話は戻って俺の英語力ではこの詩の奥深い意味を捉えるのは無理めだったので日本語訳を探してみたところ、素晴らしい翻訳があった。全部載せるのはアレなので一部だけ引用させてもらうと。\n  あんな風に「おやすみ」なんて言ってさっさと諦めるなよ\nもう若くなくたって，一日が人生が終わりそうなら，烈火のごとく怒り狂って，ギャアギャアそこで喚くんだ；\n太陽の光が薄れて消えていっても，死にものぐるいで抵抗しなきゃ\n Do Not Go Gentle Into That Night ディラン・トーマス (Dylan Thomas) より\n 全文はリンク先で読んでもらうとして、訳者ご本人が認めているようにかなり意訳色が強い翻訳である。しかし素晴らしい、最高だ。気持ちがストレートに伝わってくる。そしてこのリンク記事が2020年の大晦日に投稿され、「暗いニュースばかりが目立ったこの一年ですが，最後をこの力強い詩で締めくくりたい」と記されていることにもグッときた。泣けてくるぜ\u0026hellip;\n他の訳も発見したが、同じ原文がこうも異なる訳になるのかと驚く。どれが正しいということではないのだが、自分はやはり上のが一番だな。\n Do Not Go Gentle Into That Night （正当古典派訳）\natheistの意味は? – Do not go gentle into that good night （中庸派的訳）\n  話はあちこちに逸脱したが、この記事ではrageという単語がどのような経緯で自分に取り込まれたのかを書きたかったのである。何故書きたかったのか？まぁこうやって頭を整理しつつ記事を書くのも、一種のアンガー・マネジメントなのかもしれない。\n中指1000本突き立てても気が済まないくらいrageな日々を送っているが、整理して調べていく過程で先ほどの素晴らしい翻訳に出会うことができた。これは幸運の極みだよ、力強く美しい言葉は、人間に偉大な力を与えてくれるんだから。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/dylan-thomas/","summary":"\u0026ldquo;rage\u0026quot;という英単語がある。名詞としては「激情、激怒、憤怒」、自動詞として「怒る、暴れる」という意味だ。これを知ったきっかけは、Tumblrで見かけた以下の引用だった。\n Do not go gentle into that good night.\nRage, rage against the dying of the light.\n  パッと見てすぐに意味は理解できなかったが何か心を捉えられた感があった。\u0026ldquo;rage\u0026quot;という単語を初めて見たので調べたところ、意味は先述の通り。\nこれはウェールズの詩人ディラン・トーマス(Dylan Thomas) の詩の一部である。でもTumblrの投稿にはOscar Wildeって書いたあったような記憶がある。それで最近までずっとこの引用元をOscar Wildeだと思い込んでいたんだから。間違いだったんだなあれは。\nそれはさておき、今日この詩について少し文献を調べてみたら、この引用に対して今までの自分の解釈が若干ズレていたことがわかった。以下は引用元の詩全体である。\n  Do not go gentle into that good night,\nOld age should burn and rage at close of day;\nRage, rage against the dying of the light.\nThough wise men at their end know dark is right,\nBecause their words had forked no lightning they","title":"単語rageを覚えたきっかけはディラン・トーマスの詩だった"},{"content":"Mac OSで標準搭載されているdateコマンドはBSD版であり、Linux標準のGNU版と微妙に異なる。Linuxと実行結果が異なったり、使用できないオプションがあったりとか。それが困るから、自宅のMacでもGNU版のdateが使いたいのである。数年前に標準のdateを入れたのだが、その後Mac本体を買い替えたタイミングで消えてしまった。\n Mac OSでgnu/dateを使いたい場合、brewから入れる。install dateではなく、coreutilsとする。（他のGNU系コマンド一式が含まれる）\n$ brew install coreutils  /usr/local/bin/gdateにインストールされた。（正確にはシンボリックリンク）\nこのままだとコマンドがgdateなので、gdateを\u0026quot;date\u0026quot;で実行できるようにする。以下エイリアスを.bashrcに追記。\nalias date='/usr/local/bin/gdate'  やっとできた。以下は所定の日付時刻をエポックタイム(UNIXタイムスタンプ)に変換するコマンド。Mac版のdateだと使えないんだよこれが。\n$ date -d '2018/5/17 00:00:00' +'%s' 1526482800  参考\nMacでdateコマンドが違う件について\nUNIX時間に変換・UNIX時間を取得する方法\n (RWC2019, Tokyo Stadium)\n","permalink":"https://ecnedaced-seirots.github.io/post/a/mac-installe-gdate/","summary":"Mac OSで標準搭載されているdateコマンドはBSD版であり、Linux標準のGNU版と微妙に異なる。Linuxと実行結果が異なったり、使用できないオプションがあったりとか。それが困るから、自宅のMacでもGNU版のdateが使いたいのである。数年前に標準のdateを入れたのだが、その後Mac本体を買い替えたタイミングで消えてしまった。\n Mac OSでgnu/dateを使いたい場合、brewから入れる。install dateではなく、coreutilsとする。（他のGNU系コマンド一式が含まれる）\n$ brew install coreutils  /usr/local/bin/gdateにインストールされた。（正確にはシンボリックリンク）\nこのままだとコマンドがgdateなので、gdateを\u0026quot;date\u0026quot;で実行できるようにする。以下エイリアスを.bashrcに追記。\nalias date='/usr/local/bin/gdate'  やっとできた。以下は所定の日付時刻をエポックタイム(UNIXタイムスタンプ)に変換するコマンド。Mac版のdateだと使えないんだよこれが。\n$ date -d '2018/5/17 00:00:00' +'%s' 1526482800  参考\nMacでdateコマンドが違う件について\nUNIX時間に変換・UNIX時間を取得する方法\n (RWC2019, Tokyo Stadium)","title":"MacにGNU版dateをインストール"},{"content":"AWS CLI v2でデフォルトになっているページャを無効化する方法は2種類ある。\n configで設定  ~/.aws/configに以下記載する。\n[default] cli_pager=  環境変数で設定  $ export AWS_PAGER=\u0026quot;\u0026quot;  1.の方が推奨されているようだが、k8s(Kubernetes)のPodの場合は、マニフェストのENVに2.の環境変数を書いておけば期待値になる。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/awscli-pager/","summary":"AWS CLI v2でデフォルトになっているページャを無効化する方法は2種類ある。\n configで設定  ~/.aws/configに以下記載する。\n[default] cli_pager=  環境変数で設定  $ export AWS_PAGER=\u0026quot;\u0026quot;  1.の方が推奨されているようだが、k8s(Kubernetes)のPodの場合は、マニフェストのENVに2.の環境変数を書いておけば期待値になる。\n ","title":"AWS CLIのページャを無効化する"},{"content":"AWSで、CloudWatchアラームのメッセージをSNSトピックかましてメール送信。昔からよくあるオーソドックスなパターンだが、しばらく縁がなかったので記憶がかすんでいる。過去に構築した時の記録を掘り返してみる。\n数年前、CloudFormation（CFn）で環境構築したのだが（主担当は別のメンバー）、CWアラーム作成はCFnで作るのに不向きということでAWS CLIで作成していた。何故CFnが不向きなのか、理由は何だったか思い出せない。以下の記事を見ると普通にCFnでアラーム作成しているから問題なさそうではあるのだが\u0026hellip;\nCloudFormationでCloudWatchAlermを作成する\n ここで、書いていてうっすら思い出した。過去事例ではオートスケールのアラームだったが、その場合は他のアラームと異なるのかもしれない。（つまりオートスケールのアラームはポリシーを別出しにする）確かASG（オートスケーリンググループ）自体もCFnで作るのは不向きということでCLIで作成してた。CFnだと勝手に変な名前付けられるから、って理由だったかな。しかしハッキリとは思い出せない。\nもやもや感が払拭しきれないが、とりあえず過去のメモ書きをのせておく。\n ここから。\nオートスケーリンググループのCloudWatchアラーム作成時のポイントは、先にSNSトピック、ポリシーを作成する。ポリシー作成のCLIを実行するとARNが出力されるので、その値を定義してアラームを作成する。SNSトピック自体はCFnで作成していた。サブスクリプション作成はコンソールからやったような。グダグダな記憶だが、メールアドレスをサブスクライブする時に手動での承認が発生するのは確か。（設定したメールアドレスに届いたメール内のリンクを押下すると承認が完了する）\nサブスクリプション承認は手動になるが、アラーム作成時に指定するのはトピックARN。承認しないと後続作業ができないわけではない、と思われる。（ただし承認対応は3日以内に実施すること）\n以下、ec2オートスケーリングのスケールアウト/インポリシー作成CLIの例。ec2のオートスケールってパターンもすでにオールドファッション化しているけど\u0026hellip;、数年前の事例なので。\nスケールアウトポリシー\n$ aws autoscaling put-scaling-policy \\ --auto-scaling-group-name test-web-asg \\ --policy-name test-web-scaleout-policy \\ --scaling-adjustment 2 \\ --adjustment-type ChangeInCapacity \\ --cooldown 300 \\ --region ap-northeast-1  スケールインポリシー\n$ aws autoscaling put-scaling-policy \\ --auto-scaling-group-name test-web-asg \\ --policy-name test-web-scalein-policy \\ --scaling-adjustment -2 \\ --adjustment-type ChangeInCapacity \\ --cooldown 600 \\ --region ap-northeast-1  この後、以下のCLIを実行。スケールアウトアラーム作成CLI例。--alarm-actions オプションで 先に作成しておいた$snstopic, $scaleoutpolicy の値を指定している。\nsnstopic=\u0026quot;arn:aws:sns:ap-northeast-1:[AWSアカウントID]:test-alert-mail\u0026quot; scaleoutpolicy=\u0026quot;arn:aws:autoscaling:ap-northeast-1:[AWSアカウントID]:scalingPolicy:[ランダム値]:autoScalingGroupName/test-web-asg:policyName/test-web-scaleout-policy\u0026quot; $ aws cloudwatch put-metric-alarm \\ --alarm-name \u0026quot;test-web-scaleout-alarm\u0026quot; \\ --alarm-description \u0026quot;Alarm when CPU exceeds 70%\u0026quot; \\ --metric-name CPUUtilization \\ --namespace AWS/EC2 \\ --statistic Average \\ --period 60 \\ --threshold 70 \\ --comparison-operator GreaterThanThreshold \\ --dimensions Name=AutoScalingGroupName,Value=\u0026quot;test-web-asg\u0026quot; \\ --evaluation-periods 4 \\ --alarm-actions $scaleoutpolicy $snstopic \\ --unit Percent \\ --region ap-northeast-1  スケールイン時のアラームも同様に作成する。\n 以下備忘録。静観対応をどうするか\nCloudWatch アラームのダウンタイム（特定期間の発報抑止）を Metric Math を使用して実現してみた\n","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatch-alarm-memo/","summary":"AWSで、CloudWatchアラームのメッセージをSNSトピックかましてメール送信。昔からよくあるオーソドックスなパターンだが、しばらく縁がなかったので記憶がかすんでいる。過去に構築した時の記録を掘り返してみる。\n数年前、CloudFormation（CFn）で環境構築したのだが（主担当は別のメンバー）、CWアラーム作成はCFnで作るのに不向きということでAWS CLIで作成していた。何故CFnが不向きなのか、理由は何だったか思い出せない。以下の記事を見ると普通にCFnでアラーム作成しているから問題なさそうではあるのだが\u0026hellip;\nCloudFormationでCloudWatchAlermを作成する\n ここで、書いていてうっすら思い出した。過去事例ではオートスケールのアラームだったが、その場合は他のアラームと異なるのかもしれない。（つまりオートスケールのアラームはポリシーを別出しにする）確かASG（オートスケーリンググループ）自体もCFnで作るのは不向きということでCLIで作成してた。CFnだと勝手に変な名前付けられるから、って理由だったかな。しかしハッキリとは思い出せない。\nもやもや感が払拭しきれないが、とりあえず過去のメモ書きをのせておく。\n ここから。\nオートスケーリンググループのCloudWatchアラーム作成時のポイントは、先にSNSトピック、ポリシーを作成する。ポリシー作成のCLIを実行するとARNが出力されるので、その値を定義してアラームを作成する。SNSトピック自体はCFnで作成していた。サブスクリプション作成はコンソールからやったような。グダグダな記憶だが、メールアドレスをサブスクライブする時に手動での承認が発生するのは確か。（設定したメールアドレスに届いたメール内のリンクを押下すると承認が完了する）\nサブスクリプション承認は手動になるが、アラーム作成時に指定するのはトピックARN。承認しないと後続作業ができないわけではない、と思われる。（ただし承認対応は3日以内に実施すること）\n以下、ec2オートスケーリングのスケールアウト/インポリシー作成CLIの例。ec2のオートスケールってパターンもすでにオールドファッション化しているけど\u0026hellip;、数年前の事例なので。\nスケールアウトポリシー\n$ aws autoscaling put-scaling-policy \\ --auto-scaling-group-name test-web-asg \\ --policy-name test-web-scaleout-policy \\ --scaling-adjustment 2 \\ --adjustment-type ChangeInCapacity \\ --cooldown 300 \\ --region ap-northeast-1  スケールインポリシー\n$ aws autoscaling put-scaling-policy \\ --auto-scaling-group-name test-web-asg \\ --policy-name test-web-scalein-policy \\ --scaling-adjustment -2 \\ --adjustment-type ChangeInCapacity \\ --cooldown 600 \\ --region ap-northeast-1  この後、以下のCLIを実行。スケールアウトアラーム作成CLI例。--alarm-actions オプションで 先に作成しておいた$snstopic, $scaleoutpolicy の値を指定している。\nsnstopic=\u0026quot;arn:aws:sns:ap-northeast-1:[AWSアカウントID]:test-alert-mail\u0026quot; scaleoutpolicy=\u0026quot;arn:aws:autoscaling:ap-northeast-1:[AWSアカウントID]:scalingPolicy:[ランダム値]:autoScalingGroupName/test-web-asg:policyName/test-web-scaleout-policy\u0026quot; $ aws cloudwatch put-metric-alarm \\ --alarm-name \u0026quot;test-web-scaleout-alarm\u0026quot; \\ --alarm-description \u0026quot;Alarm when CPU exceeds 70%\u0026quot; \\ --metric-name CPUUtilization \\ --namespace AWS/EC2 \\ --statistic Average \\ --period 60 \\ --threshold 70 \\ --comparison-operator GreaterThanThreshold \\ --dimensions Name=AutoScalingGroupName,Value=\u0026quot;test-web-asg\u0026quot; \\ --evaluation-periods 4 \\ --alarm-actions $scaleoutpolicy $snstopic \\ --unit Percent \\ --region ap-northeast-1  スケールイン時のアラームも同様に作成する。","title":"CloudWatchアラーム作成時のメモ（過去事例）"},{"content":"SNSって誰をフォローするかも大きいけど誰にフォローされるか、も相当影響でかいんだなと思う。\nもともとSNS嫌いだからほとんどやってないけど、Tumblrは例外で、ここしばらく依存症に近いくらい使っている。全然使っていなかった時期もあるんだけどね。今は諸事情によりヘビーユーザー。\n当初はフォロワー僅か、だったが逆に好き勝手なことが書けた。Tumblrってテキスト投稿には向いてないと思うけど、それすら気にせずに画像だろうが音声だろうがテキストだろうが、好きなように投稿する。それがTumblrの良さ。\n当初投稿するのは自分の写真が中心で、たまにテキストあり、リブログはあまりしていなかった。特にフォローしたいアカウントもなかったけどたまに癒し系とか懐かし系画像投稿したいから適当に複数アカウントフォローしてた。でも、楽しくはなかったんだよね。「たまにこっち系の画像ポストするのはいいけどそれメインでやりたいわけじゃないし、なんか違う気がするなぁ」と違和感を覚え始めて、フォロー解除した。\n  しかしその後、何がきっかけか覚えていないのだが、あるアカウントとその周辺アカウントをフォロー開始してから、めっちゃ楽しくなってしまった。それらのアカウントは毎日投稿しているけど、リブログせずにいられないような、何かしらカッコイイポストが必ずある。経由されたポストやソースをポストしたアカウントを追うとこれまたセンスが良くて、芋づる式に夢中でlike,reblogしてしまうのである。\nTumblrのすごいところは、オリジナルのポスト作成者じゃなくても、センスのいいポストで構成されたブログが甚大な価値を持つことだ。「あなたのセンスは素晴らしい、本当に尊敬する！」と叫びたくなるようなアカウントが複数存在する。まだ出会えていないブログもあるかもしれない。実際最近になっても、「こんなセンスいいブログがあったんだ！」と新たに発見することがある。（もちろんそんなときに直接メッセージを送ったりはしない。1%程度の例外はあるだろうが、Tumblrでは誰もそんなこと望んでいないのだから）\nいいポストを集めたブログは自然にいいブログになる。オリジナルの作者かどうか、の区別はもはや意味をなさなくなる。いいものを発見してコレクションする、そのエネルギーが、見る人にインスピレーションや刺激を与えるのだ。それがTumblrの良さ。（二度目）\nこのことに気づいてから、俺は夢中になってしまった。Tumblr自体はずっと前からやっているのに、こんなに楽しいと感じたのは初めてといってもいい。\n  以上は「誰をフォローするか」による影響の話。ここから先、「誰にフォローされるか」について書いてみる。\n少し前のある日、これまで細々とした件数だった、零細アカウントの俺の通知が飛躍的に伸びた。たまに特定のポストのリアクションが増加することはあったが、その日は過去にない規模の反響だった。「何かあったか？」と追ってみると、ある人気アカウントが自分のポストを複数リブログしてた。そこから雪だるま式にリアクションが増えたわけである。これにより、自分のブログのフォロワーも増加した。増加といってもその日に十人くらい、その後日に数人ずつ程度のペースだが。ちなみに先の人気アカウントにもフォローされていた。\nしかし、正直あまりうれしくないし、逆に困る。「ある誰かが自分の投稿を見ている」ことを意識していると、書きにくいことが出てくるのである。画像のポストだけでみても、フォロワーにインフルエンサーとそのフォロワーがいると「何を投稿するか」について、これまで以上に他人を意識せざるを得なくなってしまうのである。それまでは「とにかく自分がポストしたいものをポストする」スタンスだったのに、他人にサービスするようなポストを挟んでしまうとか。実際その日以降、しばらくそんな状況が続いた。引き摺られてはいけない、と自覚しつつも、どこかで引き摺られてしまうのだ。\nで、この状況はストレスなのである。つまり楽しくないのである。楽しくないTumblrなんかやりなくない。自分が楽しむためにやっているんだから、プライオリティの優位をそっちに戻す必要がある。\u0026hellip;と、そのことを明確に言語化するためのこの投稿を書いた。\n実はこの件と前後して、先の方に書いたセンス抜群のアカウントからフォローしてもらった。これは嬉しかったね。俺のポストはそんなにリブログしてもらってないけど、たまにリブログしてもらうとやはり反響がすごい。まぁこの反響ってのも良し悪しだけどね、まったく反応がないと寂しいけどデカすぎても疲れる、さっき書いたように、よくない影響受けることがあるからね。まぁこれって、リアルライフで人混みに出ると疲れるのと同じことだと思う。\n  で、最終的に言いたいことは。\nリアルライフでもSNSでも、「自分の周囲に誰がいるか」の影響は非常に大きいのだ、と。\n人間は誰でもエネルギーを持っている。エネルギーは、良くも悪くも他者に影響を与える。ある人間が、良いエネルギーを放出している集団の中にいればおのずとよい影響を受ける。逆もまた然りである。リアルライフだとそのことを如実に実感するが、ネット上でもそれは同様だ。実際物事はそう単純ではないから、他者からの影響の方向や質はモザイクのように絡み合っているイメージではあるが\u0026hellip;\nTwitterとかFacebookみたいにガチで言葉の応酬をするようなSNSは当然その傾向が強いと思うが、Tumblrのように非常に関係性が薄いSNSでもそういうことがあるんだな、と今更ながら実感した次第。\n結論としては、Tumblrではいくつかのアカウントを本当にリスペクトしているけれど、自分の軸をずらさずにかつ一定の距離を保つ姿勢を貫くのが、長く楽しむコツだね。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/sns-influence/","summary":"SNSって誰をフォローするかも大きいけど誰にフォローされるか、も相当影響でかいんだなと思う。\nもともとSNS嫌いだからほとんどやってないけど、Tumblrは例外で、ここしばらく依存症に近いくらい使っている。全然使っていなかった時期もあるんだけどね。今は諸事情によりヘビーユーザー。\n当初はフォロワー僅か、だったが逆に好き勝手なことが書けた。Tumblrってテキスト投稿には向いてないと思うけど、それすら気にせずに画像だろうが音声だろうがテキストだろうが、好きなように投稿する。それがTumblrの良さ。\n当初投稿するのは自分の写真が中心で、たまにテキストあり、リブログはあまりしていなかった。特にフォローしたいアカウントもなかったけどたまに癒し系とか懐かし系画像投稿したいから適当に複数アカウントフォローしてた。でも、楽しくはなかったんだよね。「たまにこっち系の画像ポストするのはいいけどそれメインでやりたいわけじゃないし、なんか違う気がするなぁ」と違和感を覚え始めて、フォロー解除した。\n  しかしその後、何がきっかけか覚えていないのだが、あるアカウントとその周辺アカウントをフォロー開始してから、めっちゃ楽しくなってしまった。それらのアカウントは毎日投稿しているけど、リブログせずにいられないような、何かしらカッコイイポストが必ずある。経由されたポストやソースをポストしたアカウントを追うとこれまたセンスが良くて、芋づる式に夢中でlike,reblogしてしまうのである。\nTumblrのすごいところは、オリジナルのポスト作成者じゃなくても、センスのいいポストで構成されたブログが甚大な価値を持つことだ。「あなたのセンスは素晴らしい、本当に尊敬する！」と叫びたくなるようなアカウントが複数存在する。まだ出会えていないブログもあるかもしれない。実際最近になっても、「こんなセンスいいブログがあったんだ！」と新たに発見することがある。（もちろんそんなときに直接メッセージを送ったりはしない。1%程度の例外はあるだろうが、Tumblrでは誰もそんなこと望んでいないのだから）\nいいポストを集めたブログは自然にいいブログになる。オリジナルの作者かどうか、の区別はもはや意味をなさなくなる。いいものを発見してコレクションする、そのエネルギーが、見る人にインスピレーションや刺激を与えるのだ。それがTumblrの良さ。（二度目）\nこのことに気づいてから、俺は夢中になってしまった。Tumblr自体はずっと前からやっているのに、こんなに楽しいと感じたのは初めてといってもいい。\n  以上は「誰をフォローするか」による影響の話。ここから先、「誰にフォローされるか」について書いてみる。\n少し前のある日、これまで細々とした件数だった、零細アカウントの俺の通知が飛躍的に伸びた。たまに特定のポストのリアクションが増加することはあったが、その日は過去にない規模の反響だった。「何かあったか？」と追ってみると、ある人気アカウントが自分のポストを複数リブログしてた。そこから雪だるま式にリアクションが増えたわけである。これにより、自分のブログのフォロワーも増加した。増加といってもその日に十人くらい、その後日に数人ずつ程度のペースだが。ちなみに先の人気アカウントにもフォローされていた。\nしかし、正直あまりうれしくないし、逆に困る。「ある誰かが自分の投稿を見ている」ことを意識していると、書きにくいことが出てくるのである。画像のポストだけでみても、フォロワーにインフルエンサーとそのフォロワーがいると「何を投稿するか」について、これまで以上に他人を意識せざるを得なくなってしまうのである。それまでは「とにかく自分がポストしたいものをポストする」スタンスだったのに、他人にサービスするようなポストを挟んでしまうとか。実際その日以降、しばらくそんな状況が続いた。引き摺られてはいけない、と自覚しつつも、どこかで引き摺られてしまうのだ。\nで、この状況はストレスなのである。つまり楽しくないのである。楽しくないTumblrなんかやりなくない。自分が楽しむためにやっているんだから、プライオリティの優位をそっちに戻す必要がある。\u0026hellip;と、そのことを明確に言語化するためのこの投稿を書いた。\n実はこの件と前後して、先の方に書いたセンス抜群のアカウントからフォローしてもらった。これは嬉しかったね。俺のポストはそんなにリブログしてもらってないけど、たまにリブログしてもらうとやはり反響がすごい。まぁこの反響ってのも良し悪しだけどね、まったく反応がないと寂しいけどデカすぎても疲れる、さっき書いたように、よくない影響受けることがあるからね。まぁこれって、リアルライフで人混みに出ると疲れるのと同じことだと思う。\n  で、最終的に言いたいことは。\nリアルライフでもSNSでも、「自分の周囲に誰がいるか」の影響は非常に大きいのだ、と。\n人間は誰でもエネルギーを持っている。エネルギーは、良くも悪くも他者に影響を与える。ある人間が、良いエネルギーを放出している集団の中にいればおのずとよい影響を受ける。逆もまた然りである。リアルライフだとそのことを如実に実感するが、ネット上でもそれは同様だ。実際物事はそう単純ではないから、他者からの影響の方向や質はモザイクのように絡み合っているイメージではあるが\u0026hellip;\nTwitterとかFacebookみたいにガチで言葉の応酬をするようなSNSは当然その傾向が強いと思うが、Tumblrのように非常に関係性が薄いSNSでもそういうことがあるんだな、と今更ながら実感した次第。\n結論としては、Tumblrではいくつかのアカウントを本当にリスペクトしているけれど、自分の軸をずらさずにかつ一定の距離を保つ姿勢を貫くのが、長く楽しむコツだね。","title":"Tumblrについて、ひとり言"},{"content":"前回投稿でAWS CodePipelineのクロスアカウント設定（前半）ではリソース配布元のアカウントAの内容中心に書いた。後半は配布先となるアカウントBの設定内容を書いていく。\n前回投稿\nAWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-1）\n繰り返しになるけれども、前提条件をおさらいとして記載。\nやりたいこと\nAWSの異なるアカウント間で、CodePipelineによりCodeDeployからec2インスタンスにリソースをデプロイする。ソースはリソース配布側のCodeCommit。この記事では配布元を開発環境/アカウントA、配布先を検証環境/アカウントBとして話を進める。 主な参考ページ\n他のリソースを使用するパイプラインを CodePipeline で作成するAWSアカウント\n 主な構成要素 これも前回書いているが、こっちにも書いておかないとわけわからなくなるので再掲。\n1-資材配布元（アカウントA）\n① CodeCommitリポジトリ（ec2にローカルリポジトリを作成〜資材格納）\n② KMSキー (両方のアカウントにアクセス許可する)\n③ S3バケット (アカウントBにアクセス許可するバケットポリシーを付与）\n④ CodePipelineが使用するサービスロール\n⑤ CodePipleline定義（コンソールで作成したパイプライン定義JSONをCLIから更新）\n 2-資材配布先（アカウントB）\n① CodeDeploy定義（アプリケーション/デプロイメントグループ）\n② ec2用のIAMロール（CodeDeployがアカウントAのKMSキー、S3にアクセスするためのポリシーを付与）\n③ ②のIAMロールをアタッチしたデプロイ先ec2\n④ クロスアカウント用サービスロール（CodeDeployとS3操作にassumeする）\n 上記アイテムを作成済みとして、作業概要は前回記事に記載した。以降、アカウントB側で用意するアイテムの内容を書く。\n2-① CodeDeploy定義\nアカウントBのコンソールにて、アプリケーションとデプロイメントグループを作成する。詳細は割愛。\n2-② ec2用のIAMロール\nKMSとS3用のインラインポリシーを作成する。AWS参考ページでは2つに分けていたが統合しても問題ないと思う。\nKMS用インラインポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:DescribeKey\u0026#34;, \u0026#34;kms:GenerateDataKey*\u0026#34;, \u0026#34;kms:Encrypt\u0026#34;, \u0026#34;kms:ReEncrypt*\u0026#34;, \u0026#34;kms:Decrypt\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:kms:us-east-1:[アカウントAのID]:key/[Key ID]\u0026#34; #KMSのARN ] } ] }  S3用インラインポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:Get*\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::[アカウントAのS3バケット名]/*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::[アカウントAのS3バケット名]\u0026#34; ] } ] }  2-④ クロスアカウントデプロイ用IAMロール\nサービスをCodeDeployとしてロールを作成する。この時アカウントAにassumeする前提で以下設定を行う。以下図の矢印箇所にアカウントAのIDを入力して次へ進む。これ以降は通常のロール作成時と同じ。\n デプロイ用ロール信頼ポリシーのJSONは以下のようになる。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::[アカウントAのID]:root\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Condition\u0026#34;: {} }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;codedeploy.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] }  デプロイ用メインのカスタムポリシー。CodeDeployのパーミッションを定義。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;codedeploy:CreateDeployment\u0026#34;, \u0026#34;codedeploy:GetDeployment\u0026#34;, \u0026#34;codedeploy:GetDeploymentConfig\u0026#34;, \u0026#34;codedeploy:GetApplicationRevision\u0026#34;, \u0026#34;codedeploy:RegisterApplicationRevision\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] }  デプロイ用インラインポリシー。S3とCodeCommitのパーミッション定義。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject*\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:PutObjectAcl\u0026#34;, \u0026#34;codecommit:ListBranches\u0026#34;, \u0026#34;codecommit:ListRepositories\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::[S3バケット名]/*\u0026#34; ] } ] }  これとは別にec2周りのポリシーも割り当てる。検証時は取り急ぎマネージドのAmazonEC2ReadOnlyAccessでもアタッチしておけばいい。\n これでやっとアイテムが出揃った。ここまで来たら、前回投稿の分も重複するがアカウントAの環境にて以下実行。（2. までは前回までの段階で完了しているとして、3.以降を実施）\n コンソールで単体アカウント用にパイプラインを作成 そのJSON定義を取得してクロスアカウント向けに編集 パイプラインをアップデート  $ aws codepipeline update-pipeline --cli-input-json file://[パイプライン名].json  アップデートしたパイプラインをスタート  $ aws codepipeline start-pipeline-execution --name [パイプライン名]  特にエラーが出なければパイプラインは走っているが、その先でコケることはよくあるのでコンソール画面から状況を確認する。アカウントAのマネジメントコンソール画面から全体の状況は把握できる。デプロイステージの詳細はアカウントBのコンソールからしか見れない。\nというわけで、果てしなく続くと思われた長い旅路がようやく終わりましたよ。しかしいいかげんに普通の旅にも出たいもんだ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/aws-crossaccount-pipeline-2/","summary":"前回投稿でAWS CodePipelineのクロスアカウント設定（前半）ではリソース配布元のアカウントAの内容中心に書いた。後半は配布先となるアカウントBの設定内容を書いていく。\n前回投稿\nAWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-1）\n繰り返しになるけれども、前提条件をおさらいとして記載。\nやりたいこと\nAWSの異なるアカウント間で、CodePipelineによりCodeDeployからec2インスタンスにリソースをデプロイする。ソースはリソース配布側のCodeCommit。この記事では配布元を開発環境/アカウントA、配布先を検証環境/アカウントBとして話を進める。 主な参考ページ\n他のリソースを使用するパイプラインを CodePipeline で作成するAWSアカウント\n 主な構成要素 これも前回書いているが、こっちにも書いておかないとわけわからなくなるので再掲。\n1-資材配布元（アカウントA）\n① CodeCommitリポジトリ（ec2にローカルリポジトリを作成〜資材格納）\n② KMSキー (両方のアカウントにアクセス許可する)\n③ S3バケット (アカウントBにアクセス許可するバケットポリシーを付与）\n④ CodePipelineが使用するサービスロール\n⑤ CodePipleline定義（コンソールで作成したパイプライン定義JSONをCLIから更新）\n 2-資材配布先（アカウントB）\n① CodeDeploy定義（アプリケーション/デプロイメントグループ）\n② ec2用のIAMロール（CodeDeployがアカウントAのKMSキー、S3にアクセスするためのポリシーを付与）\n③ ②のIAMロールをアタッチしたデプロイ先ec2\n④ クロスアカウント用サービスロール（CodeDeployとS3操作にassumeする）\n 上記アイテムを作成済みとして、作業概要は前回記事に記載した。以降、アカウントB側で用意するアイテムの内容を書く。\n2-① CodeDeploy定義\nアカウントBのコンソールにて、アプリケーションとデプロイメントグループを作成する。詳細は割愛。\n2-② ec2用のIAMロール\nKMSとS3用のインラインポリシーを作成する。AWS参考ページでは2つに分けていたが統合しても問題ないと思う。\nKMS用インラインポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:DescribeKey\u0026#34;, \u0026#34;kms:GenerateDataKey*\u0026#34;, \u0026#34;kms:Encrypt\u0026#34;, \u0026#34;kms:ReEncrypt*\u0026#34;, \u0026#34;kms:Decrypt\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:kms:us-east-1:[アカウントAのID]:key/[Key ID]\u0026#34; #KMSのARN ] } ] }  S3用インラインポリシー","title":"AWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-2）"},{"content":"前回投稿ではパイプラインなしでAWS クロスアカウントデプロイをやった。次はパイプラインを使ってやってみる。長くなるので前半/後半に分ける。\n やりたいこと\nAWSの異なるアカウント間で、CodePipelineによりCodeDeployからec2インスタンスにリソースをデプロイする。ソースはリソース配布側のCodeCommit。この記事では配布元を開発環境/アカウントA、配布先を検証環境/アカウントBとして話を進める。（ec2はオートスケールもなくただ単に配布するだけなので単一アカウントだったら簡単な話なんだが、アカウント跨ぐとなるとめっちゃ面倒くさい\u0026hellip;）\n 主な参考ページ\n他のリソースを使用するパイプラインを CodePipeline で作成するAWSアカウント\n 基本的にこのページの通りにやればOK。アカウントA側で一度単一アカウント用の適当なパイプラインを作成して、そのJSON定義を取得。それをクロスアカウント用に編集してCLIからアップデートする。ちなみに上記リンクは日本語版だが機械翻訳の文章がまともな日本語ではなくイラッとくるので、ほぼオリジナルの英語版を参考にした。\n参考までに、以下クラメソさんの記事。当初これのBuildをDeployに置き換えてやってみたが失敗した。不足か誤りがあるんだろうがいきなりやったこともありわけがわからなすぎて頓挫。先述のAWS公式の方がやりたいことに近かったため仕切り直しした。\nクロスアカウントCodeBuild + パイプライン例\nCodePipelineでアカウントをまたいだパイプラインを作成してみる\n 制約事項\n クロスアカウントのパイプラインはマネジメントコンソールから作成不可のため、aws cliから作成/更新する CodeDeployの定義とデプロイ先のec2は同一アカウントであること クロスアカウントでパイプラインを組む場合、アーティファクト格納用S3バケットの暗号化キーはKMSを使用する（AWS デフォルトの暗号化キーはNG）   主な構成要素 2アカウント間で各種アイテムを用意することになり、混乱しがちなのでまとめておく。前回投稿では配布先となるアカウントB側にS3バケットがある構成だったが、今回は逆。ただし構成的にはこちらの方が自然かと思う。\n1-資材配布元（アカウントA）\n① CodeCommitリポジトリ（ec2にローカルリポジトリを作成〜資材格納）\n② KMSキー (両方のアカウントにアクセス許可する)\n③ S3バケット (アカウントBにアクセス許可するバケットポリシーを付与）\n④ CodePipelineが使用するサービスロール\n⑤ CodePipleline定義（コンソールで作成したパイプライン定義JSONをCLIから更新）\nJSON取得コマンド\n$ aws codepipeline get-pipeline --name [パイプライン名] \u0026gt; [パイプライン名].json  2-資材配布先（アカウントB）\n① CodeDeploy定義（アプリケーション/デプロイメントグループ）\n② ec2用のIAMロール（CodeDeployがアカウントAのKMSキー、S3にアクセスするためのポリシーを付与）\n③ ②のIAMロールをアタッチしたデプロイ先ec2\n④ クロスアカウント用サービスロール（CodeDeployとS3操作にassumeする）\n 作業概要 上記各リソースを作成済として、以下の作業を行う。\nアカウントAの作業用端末またはec2にログイン。1-⑤のパイプライン定義JSONを適当なパスに配置し、パイプラインをアップデートする\n$ cd /path/to/json $ aws codepipeline update-pipeline --cli-input-json file://[パイプライン名].json  アップデートしたパイプラインを実行する\n$ aws codepipeline start-pipeline-execution --name [パイプライン名]  アカウントBでは特に作業なし。デプロイステータスが成功になったら、ec2に資材がデプロイされていることを確認する。\nクロスアカウントパイプラインの処理中の見え方\nアカウントAのマネジメントコンソール：パイプライン全体の処理状況は見える。デプロイステージの詳細は見れない。\nアカウントBのコンソール : デプロイの詳細が見れる\n 各種アイテムのサンプル AWS公式でも基本内容は網羅されているが自分用メモとしてここにも載せておく。\nアカウントA側アイテム\n1-② KMSキーポリシー\nアーティファクト用S3バケットの暗号化キーポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;[key-policy-name]\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Enable IAM User Permissions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::[アカウントAのID]:root\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;kms:*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;Allow access for Key Administrators\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;[KMSの暗号化キーの管理ユーザのARN]\u0026#34; #アカウントA側のキーのオーナーを指定 }, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:Create*\u0026#34;, \u0026#34;kms:Describe*\u0026#34;, \u0026#34;kms:Enable*\u0026#34;, \u0026#34;kms:List*\u0026#34;, \u0026#34;kms:Put*\u0026#34;, \u0026#34;kms:Update*\u0026#34;, \u0026#34;kms:Revoke*\u0026#34;, \u0026#34;kms:Disable*\u0026#34;, \u0026#34;kms:Get*\u0026#34;, \u0026#34;kms:Delete*\u0026#34;, \u0026#34;kms:TagResource\u0026#34;, \u0026#34;kms:UntagResource\u0026#34;, \u0026#34;kms:ScheduleKeyDeletion\u0026#34;, \u0026#34;kms:CancelKeyDeletion\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;Allow use of the key\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: [ \u0026#34;[アカウントAのパイプライン用サービスロールのARN]\u0026#34;, #(注1) \u0026#34;arn:aws:iam::[アカウントBのID]:root\u0026#34; ] }, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:Encrypt\u0026#34;, \u0026#34;kms:Decrypt\u0026#34;, \u0026#34;kms:ReEncrypt*\u0026#34;, \u0026#34;kms:GenerateDataKey*\u0026#34;, \u0026#34;kms:DescribeKey\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;Allow attachment of persistent resources\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: [ \u0026#34;[アカウントAのパイプライン用サービスロールのARN]\u0026#34;, #(注1) \u0026#34;arn:aws:iam::[アカウントBのID]:root\u0026#34; ] }, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:CreateGrant\u0026#34;, \u0026#34;kms:ListGrants\u0026#34;, \u0026#34;kms:RevokeGrant\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;Bool\u0026#34;: { \u0026#34;kms:GrantIsForAWSResource\u0026#34;: \u0026#34;true\u0026#34; } } } ] } (注1) 構文\narn:aws:iam::[アカウントAのID]:role/[パイプラインロール名]\n 1-③ S3バケットポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;SSEAndSSLPolicy\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;DenyUnEncryptedObjectUploads\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::[S3バケット名]/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringNotEquals\u0026#34;: { \u0026#34;s3:x-amz-server-side-encryption\u0026#34;: \u0026#34;aws:kms\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;DenyInsecureConnections\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::[S3バケット名]/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;Bool\u0026#34;: { \u0026#34;aws:SecureTransport\u0026#34;: false } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::[アカウントBのID]:root\u0026#34; }, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:Get*\u0026#34;, \u0026#34;s3:Put*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::[S3バケット名]/*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::[アカウントBのID]:root\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::[S3バケット名]\u0026#34; } ] }  1-④ CodePipelineが使用するサービスロール(IAM)\nこのロールには以下のポリシーを割り当てる。1.はロール作成前に作成可能。コンソールからロール作成する時に選択可能なサービスにCodePipelineがないので一旦CodeDeployで作成して、後から信頼ポリシー編集した。\n 通常のCodePipeline作業用ポリシー アカウントBのassume用インラインポリシー 信頼ポリシー（編集）  以下CodePipeline作業用ポリシー。AWSが自動で付与するポリシーは他のパーミッションも多く含まれているがそこから削って最小限にしたのがこれ。autoscalingは使わないんだけど一応残す。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Action\u0026#34;: [ \u0026#34;iam:PassRole\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEqualsIfExists\u0026#34;: { \u0026#34;iam:PassedToService\u0026#34;: [ \u0026#34;ec2.amazonaws.com\u0026#34; ] } } }, { \u0026#34;Action\u0026#34;: [ \u0026#34;codecommit:CancelUploadArchive\u0026#34;, \u0026#34;codecommit:GetBranch\u0026#34;, \u0026#34;codecommit:GetCommit\u0026#34;, \u0026#34;codecommit:GetUploadArchiveStatus\u0026#34;, \u0026#34;codecommit:UploadArchive\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; }, { \u0026#34;Action\u0026#34;: [ \u0026#34;codedeploy:CreateDeployment\u0026#34;, \u0026#34;codedeploy:GetApplication\u0026#34;, \u0026#34;codedeploy:GetApplicationRevision\u0026#34;, \u0026#34;codedeploy:GetDeployment\u0026#34;, \u0026#34;codedeploy:GetDeploymentConfig\u0026#34;, \u0026#34;codedeploy:RegisterApplicationRevision\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; }, { \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:*\u0026#34;, \u0026#34;elasticloadbalancing:*\u0026#34;, \u0026#34;autoscaling:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;s3:*\u0026#34;, \u0026#34;tag:*\u0026#34;, \u0026#34;logs:*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; } ] }  アカウントBのassume用インラインポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:iam::[アカウントBのID]:role/*\u0026#34; ] } }  信頼ポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: [ \u0026#34;codepipeline.amazonaws.com\u0026#34;, \u0026#34;codedeploy.amazonaws.com\u0026#34;, \u0026#34;ec2.amazonaws.com\u0026#34; ] }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] }  1-⑤ CodePiplelineのJSON定義\n冒頭のAWS公式ページにもポイントは記載されているが、今回のケースでまとめたのがこれ。繰り返しになるが、「1.コンソールで単体アカウント用にパイプラインを作成 2. そのJSON定義を取得してクロスアカウント向けに編集 3. パイプラインをアップデート」という流れになる。最初にパイプラインを作成するときにCodeDeploy用定義が必要なため、事前にアカウントA内で適当なCodeDeployアプリケーション/デプロイメントグループのペアを用意しておく。\n以下のJSON後半でアカウントB側のアイテム定義名をいくつか記載しており、当然アカウントB側に実体が存在する前提だが、編集時点では存在していなくても構わない。\n{ \u0026#34;pipeline\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;A_crossdeploy_pipeline\u0026#34;, \u0026#34;roleArn\u0026#34;: \u0026#34;arn:aws:iam::[アカウントAのID]:role/[クロスアカウントパイプライン用IAMロール名]\u0026#34;, \u0026#34;artifactStore\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;S3\u0026#34;, \u0026#34;location\u0026#34;: \u0026#34;[S3バケット名]\u0026#34; \u0026#34;encryptionKey\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;arn:aws:kms:us-east-1:[アカウントAのID]:key/[キーのID]\u0026#34;, #KMSキーのARN \u0026#34;type\u0026#34;: \u0026#34;KMS\u0026#34; }, \u0026#34;stages\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Source\u0026#34;, \u0026#34;actions\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Source\u0026#34;, \u0026#34;actionTypeId\u0026#34;: { \u0026#34;category\u0026#34;: \u0026#34;Source\u0026#34;, \u0026#34;owner\u0026#34;: \u0026#34;AWS\u0026#34;, \u0026#34;provider\u0026#34;: \u0026#34;CodeCommit\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1\u0026#34; }, \u0026#34;runOrder\u0026#34;: 1, \u0026#34;configuration\u0026#34;: { \u0026#34;BranchName\u0026#34;: \u0026#34;master\u0026#34;, \u0026#34;OutputArtifactFormat\u0026#34;: \u0026#34;CODE_ZIP\u0026#34;, \u0026#34;PollForSourceChanges\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;RepositoryName\u0026#34;: \u0026#34;[ソースリポジトリ名]\u0026#34; }, \u0026#34;outputArtifacts\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;SourceArtifact\u0026#34; } ], \u0026#34;roleArn\u0026#34; : \u0026#34;arn:aws:iam::[アカウントAのID]:role/[クロスアカウントパイプライン用IAMロール名]\u0026#34;, #冒頭で指定したIAMと同じ \u0026#34;inputArtifacts\u0026#34;: [], \u0026#34;region\u0026#34;: \u0026#34;ap-northeast-1\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;SourceVariables\u0026#34; } ] }, { \u0026#34;name\u0026#34;: \u0026#34;Deploy\u0026#34;, \u0026#34;actions\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;ExternalDeploy\u0026#34;, #Deploy --＞ ExternalDeployに変更 \u0026#34;actionTypeId\u0026#34;: { \u0026#34;category\u0026#34;: \u0026#34;Deploy\u0026#34;, \u0026#34;owner\u0026#34;: \u0026#34;AWS\u0026#34;, \u0026#34;provider\u0026#34;: \u0026#34;CodeDeploy\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1\u0026#34; }, \u0026#34;runOrder\u0026#34;: 1, \u0026#34;configuration\u0026#34;: { \u0026#34;ApplicationName\u0026#34;: \u0026#34;[アカウントBのコードデプロイアプリケーション名]\u0026#34;, \u0026#34;DeploymentGroupName\u0026#34;: \u0026#34;[アカウントBのコードデプロイデプロイメントグループ名]\u0026#34; }, \u0026#34;outputArtifacts\u0026#34;: [], \u0026#34;inputArtifacts\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;SourceArtifact\u0026#34; } ], \u0026#34;roleArn\u0026#34; : \u0026#34;arn:aws:iam::[アカウントBのID]:role/[アカウントBのクロスデプロイ用IAMロール名]\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-northeast-1\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;DeployVariables\u0026#34; } ] } ], \u0026#34;version\u0026#34;: 1 } }  やっとここまできた\u0026hellip;長かった。しかしまだ道は続く。次回、アカウントB側の設定内容を書く。\n続き\nAWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-2）\n","permalink":"https://ecnedaced-seirots.github.io/post/a/aws-crossaccount-pipeline-1/","summary":"前回投稿ではパイプラインなしでAWS クロスアカウントデプロイをやった。次はパイプラインを使ってやってみる。長くなるので前半/後半に分ける。\n やりたいこと\nAWSの異なるアカウント間で、CodePipelineによりCodeDeployからec2インスタンスにリソースをデプロイする。ソースはリソース配布側のCodeCommit。この記事では配布元を開発環境/アカウントA、配布先を検証環境/アカウントBとして話を進める。（ec2はオートスケールもなくただ単に配布するだけなので単一アカウントだったら簡単な話なんだが、アカウント跨ぐとなるとめっちゃ面倒くさい\u0026hellip;）\n 主な参考ページ\n他のリソースを使用するパイプラインを CodePipeline で作成するAWSアカウント\n 基本的にこのページの通りにやればOK。アカウントA側で一度単一アカウント用の適当なパイプラインを作成して、そのJSON定義を取得。それをクロスアカウント用に編集してCLIからアップデートする。ちなみに上記リンクは日本語版だが機械翻訳の文章がまともな日本語ではなくイラッとくるので、ほぼオリジナルの英語版を参考にした。\n参考までに、以下クラメソさんの記事。当初これのBuildをDeployに置き換えてやってみたが失敗した。不足か誤りがあるんだろうがいきなりやったこともありわけがわからなすぎて頓挫。先述のAWS公式の方がやりたいことに近かったため仕切り直しした。\nクロスアカウントCodeBuild + パイプライン例\nCodePipelineでアカウントをまたいだパイプラインを作成してみる\n 制約事項\n クロスアカウントのパイプラインはマネジメントコンソールから作成不可のため、aws cliから作成/更新する CodeDeployの定義とデプロイ先のec2は同一アカウントであること クロスアカウントでパイプラインを組む場合、アーティファクト格納用S3バケットの暗号化キーはKMSを使用する（AWS デフォルトの暗号化キーはNG）   主な構成要素 2アカウント間で各種アイテムを用意することになり、混乱しがちなのでまとめておく。前回投稿では配布先となるアカウントB側にS3バケットがある構成だったが、今回は逆。ただし構成的にはこちらの方が自然かと思う。\n1-資材配布元（アカウントA）\n① CodeCommitリポジトリ（ec2にローカルリポジトリを作成〜資材格納）\n② KMSキー (両方のアカウントにアクセス許可する)\n③ S3バケット (アカウントBにアクセス許可するバケットポリシーを付与）\n④ CodePipelineが使用するサービスロール\n⑤ CodePipleline定義（コンソールで作成したパイプライン定義JSONをCLIから更新）\nJSON取得コマンド\n$ aws codepipeline get-pipeline --name [パイプライン名] \u0026gt; [パイプライン名].json  2-資材配布先（アカウントB）\n① CodeDeploy定義（アプリケーション/デプロイメントグループ）\n② ec2用のIAMロール（CodeDeployがアカウントAのKMSキー、S3にアクセスするためのポリシーを付与）\n③ ②のIAMロールをアタッチしたデプロイ先ec2\n④ クロスアカウント用サービスロール（CodeDeployとS3操作にassumeする）\n 作業概要 上記各リソースを作成済として、以下の作業を行う。\nアカウントAの作業用端末またはec2にログイン。1-⑤のパイプライン定義JSONを適当なパスに配置し、パイプラインをアップデートする\n$ cd /path/to/json $ aws codepipeline update-pipeline --cli-input-json file://[パイプライン名].","title":"AWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-1）"},{"content":"AWS環境で、クロスアカウントでCI/CDしたい。とりあえずBuildフェーズはいらなくてDeployだけでいい。Deployの実行はパイプラインあり/なし両方可能。どちらも単一アカウント内なら複雑な設定もなく比較的容易にできることはわかっているが、クロスアカウントとなると何かと面倒だ。でもやってみる。ここではまずはパイプラインなしとする。\n 参考\n異なる AWS アカウントでアプリケーションをデプロイする\n（上記ページにリンクあり。assumeロールの設定は以下参考）\nIAM チュートリアル: AWS アカウント間の IAM ロールを使用したアクセスの委任\n 環境前提 配布元となるAWS開発環境(Dev)にCodeCommitのローカルリポジトリがあり、そこから別アカウントの検証環境(Stg)にデプロイする。その先には本番環境がある想定だが構成は同じになるはず。\n① 配布元(Dev)\n② 配布先(Stg)\n概要 ①配布元のアカウントから②配布先のec2にデプロイ可能とするため、②配布先アカウント側で①アカウントのassumeを可能とするIAMロールを作成する。（ロールAとする）① 配布元アカウント側でロールAにassumeし、デプロイを実行する。\n基本的に必要となるのはIAM周りの設定であり、ネットワーク系の特別な実装は必要ない。\n 作業内容   配布先②アカウントにて、配置用のS3バケットを作成する。IAMロールのポリシーでバケットへのアクセス権限を定義するため、バケットポリシーは設定しなくても問題なし。(注1)\n  配布先②アカウントにて、①がassumeするためのロールAを作成する。\n  ロールAで定義する内容 (1) 信頼ポリシーで②のアカウントIDを指定してassumeを許可する。このときrootか②側のIAMロールどちらかを指定する。\nrootに設定した場合は、①アカウントでデプロイを実行するユーザのグループにassume可能とするインラインポリシーを適用する。\nIAMに設定した場合は、①アカウントでデプロイを実行するec2にこのIAMロールを適用する。実行環境がec2の場合はこれでよいが、クライアント端末の場合はrootにする。\n インラインポリシー例 (①アカウントで設定) デプロイ実行ユーザが所属するグループの画面を開き、[アクセス許可] タブ \u0026ndash;\u0026gt; [アクセス許可の追加] \u0026ndash;\u0026gt; [インラインポリシーの作成] [JSON] タブ選択\n以下の内容を設定する。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:iam::②配布先のアカウントID:role/ロールA\u0026#34; } }  (2) ①のアカウントが資材配置用のS3にアクセスするための権限を定義したポリシーを適用する。ちゃんと書いてないけど以下にcodedeploy, ec2の操作権限も追加する。codedeployの権限は何が必要かわからないのでとりあえず全許可にしておいた。ECSへのデプロイだとec2のterminate権限が必要みたいだが、今回の場合ec2は参照のみでOKだと思う。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:GetBucketLocation\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::staging-app\u0026#34; #検証環境の資材格納バケット名 }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::staging-app/*\u0026#34; } ] }  ②配布先アカウントにて、deployのアプリケーションとデプロイメントグループを作成する。詳細は割愛。   ①配布元アカウントのec2（または同アカウントのcredentialsをセットした端末）にログインし、ロールAにスイッチする。ちなみにマネジメントコンソールでもスイッチして作業可能だが、deployのpushコマンドがCLIでしかできないため、ここではCLI前提で話を進める。  この時先で作成したロールAにスイッチするため、以下のコマンドを実行する。\n$ aws sts assume-role --role-arn \u0026quot;②配布先のアカウントID:role/ロールA\u0026quot; --role-session-name \u0026quot;deployment-test\u0026quot;  すると以下の形式の認証情報が出力される。\n{ \u0026#34;Credentials\u0026#34;: { \u0026#34;AccessKeyId\u0026#34;: \u0026#34;[access key id]\u0026#34; \u0026#34;SecretAccessKey\u0026#34;: \u0026#34;[secret access key id]\u0026#34;, \u0026#34;SessionToken\u0026#34;: \u0026#34;[token id]\u0026#34;, \u0026#34;Expiration\u0026#34;: \u0026#34;2021-09-20T15:08:00Z\u0026#34; } }  上記を環境変数にセットする。Windowsの場合はexportをsetに変更する。\n$ export AWS_ACCESS_KEY_ID=[access key id] $ export AWS_SECRET_ACCESS_KEY=[secret access key id] $ export AWS_SESSION_TOKEN=[token id]  これでセッション保持期間の間（expireの時刻)は②アカウントのロールAの権限で作業が可能となる。セッション時間はデフォルトで1時間だが、伸ばしたい場合は--duration-secondsオプションを使う。（2時間なら7200、3時間なら10800と指定。ロールAの最大セッション期間がそれに応じた時間に設定されている前提）\n デプロイ実行  最初にやる時はデプロイ前にaws s3 cpを実行して、対象S3バケットへ読み書き可能かチェックしておくとよい。\nCLIでpush [オプション]を実行し、S3に資材を格納する。この時 3.で作成したアプリケーション名を指定する。（これによりただ単にS3に資材を配置するのではなく、資材をアプリケーションのリビジョンと関連付けることになる）sourceはここではCodeCommitのローカルリポジトリパスを指定しているが、指定するのはappspec.ymlを配置したディレクトリとなる。\n$ aws deploy push ¥ --application-name [aplication-name] ¥ --s3-location s3://[staging-app]/[staging-app-key] ¥ --ignore-hidden-files ¥ --source /path/to/source  pushが成功すると資材がzip形式で格納される。ターミナル上ではE-Tagを含む実行コマンド情報が標準出力される。詳細は割愛するがこれを元にcreate-deploymentにてデプロイを実行する。この時 3.で作成したデプロイメントグループを指定する。成功すれば②配布先となるec2にS3から資材が配置される。ちなみにpushはコンソールから実行できないが、デプロイは可能である。しかしそのために実行画面を切り替えるのも面倒なので（コンソールでもassumeする）、ここは引き続きCLIでやる方が自然かと。\n (注1) 配布元①アカウントにバケットを作成してもよいが、また追加の設定が必要となる。今回は配布先②に作成した。\n その他ポイント 最初deployのコマンドは通ったがその先で失敗した。この時コンソール上では以下のエラーが表示されていた。\n The overall deployment failed because too many individual instances failed deployment, too few healthy instances are available for deployment, or some instances in your deployment group are experiencing problems.\n  これだけではわからないのでログを確認してみたところ、こんなエラーが繰り返し吐かれていた。\n/var/log/aws/codedeploy-agent/codedeploy-agent.log\n InstanceAgent::Plugins::CodeDeployPlugin::CommandPoller: Missing credentials - please check if this instance was started with an IAM instance profile\n  確かに配布先ec2にはIAMロールをアタッチしていなかったため、インスタンスプロファイルが存在しない。するとcodedepoloyエージェントが上記のログを吐くわけだ。配布先のec2にインスタンスプロファイルを割り当てるため、別途IAMロールを作成してIAMロールをアタッチしたところ成功した。\nIAMをアタッチしても同じエラーが出る場合、エージェントを再起動してみる。候補が表示されなかったりエラーになったりしてIAMのアタッチ自体が不可能な場合は、インスタンスを一旦停止して再試行してみる。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/cross-account-codedeploy/","summary":"AWS環境で、クロスアカウントでCI/CDしたい。とりあえずBuildフェーズはいらなくてDeployだけでいい。Deployの実行はパイプラインあり/なし両方可能。どちらも単一アカウント内なら複雑な設定もなく比較的容易にできることはわかっているが、クロスアカウントとなると何かと面倒だ。でもやってみる。ここではまずはパイプラインなしとする。\n 参考\n異なる AWS アカウントでアプリケーションをデプロイする\n（上記ページにリンクあり。assumeロールの設定は以下参考）\nIAM チュートリアル: AWS アカウント間の IAM ロールを使用したアクセスの委任\n 環境前提 配布元となるAWS開発環境(Dev)にCodeCommitのローカルリポジトリがあり、そこから別アカウントの検証環境(Stg)にデプロイする。その先には本番環境がある想定だが構成は同じになるはず。\n① 配布元(Dev)\n② 配布先(Stg)\n概要 ①配布元のアカウントから②配布先のec2にデプロイ可能とするため、②配布先アカウント側で①アカウントのassumeを可能とするIAMロールを作成する。（ロールAとする）① 配布元アカウント側でロールAにassumeし、デプロイを実行する。\n基本的に必要となるのはIAM周りの設定であり、ネットワーク系の特別な実装は必要ない。\n 作業内容   配布先②アカウントにて、配置用のS3バケットを作成する。IAMロールのポリシーでバケットへのアクセス権限を定義するため、バケットポリシーは設定しなくても問題なし。(注1)\n  配布先②アカウントにて、①がassumeするためのロールAを作成する。\n  ロールAで定義する内容 (1) 信頼ポリシーで②のアカウントIDを指定してassumeを許可する。このときrootか②側のIAMロールどちらかを指定する。\nrootに設定した場合は、①アカウントでデプロイを実行するユーザのグループにassume可能とするインラインポリシーを適用する。\nIAMに設定した場合は、①アカウントでデプロイを実行するec2にこのIAMロールを適用する。実行環境がec2の場合はこれでよいが、クライアント端末の場合はrootにする。\n インラインポリシー例 (①アカウントで設定) デプロイ実行ユーザが所属するグループの画面を開き、[アクセス許可] タブ \u0026ndash;\u0026gt; [アクセス許可の追加] \u0026ndash;\u0026gt; [インラインポリシーの作成] [JSON] タブ選択\n以下の内容を設定する。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:iam::②配布先のアカウントID:role/ロールA\u0026#34; } }  (2) ①のアカウントが資材配置用のS3にアクセスするための権限を定義したポリシーを適用する。ちゃんと書いてないけど以下にcodedeploy, ec2の操作権限も追加する。codedeployの権限は何が必要かわからないのでとりあえず全許可にしておいた。ECSへのデプロイだとec2のterminate権限が必要みたいだが、今回の場合ec2は参照のみでOKだと思う。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:GetBucketLocation\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::staging-app\u0026#34; #検証環境の資材格納バケット名 }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::staging-app/*\u0026#34; } ] }  ②配布先アカウントにて、deployのアプリケーションとデプロイメントグループを作成する。詳細は割愛。   ①配布元アカウントのec2（または同アカウントのcredentialsをセットした端末）にログインし、ロールAにスイッチする。ちなみにマネジメントコンソールでもスイッチして作業可能だが、deployのpushコマンドがCLIでしかできないため、ここではCLI前提で話を進める。  この時先で作成したロールAにスイッチするため、以下のコマンドを実行する。","title":"AWS CodeDeployでクロスアカウントデプロイの実行（パイプラインなし）"},{"content":"かつてブラウザで全画面キャプチャしたい時はChromeにアドオンを入れて使っていたがこのアドオンはキャプチャしたデータをどこかに送信しているという話をどこかで読んで、ちょっとなぁ、と思った。しかし最近になってChromeでもFirefoxでもアドオンなしで全画面キャプチャが可能になっていることを知った。自宅で見るブラウザはほぼFirefoxでChromeは滅多に使わないが、職場では事情が変わったりするので両方書いておく。\nFirefoxの場合 F12キーで開発ツール画面を表示する。ツール画面右上のカメラアイコンをクリック。これだけ。素晴らしい。画像はデフォルトでDwonloadディレクトリに保存される。\n\u0026hellip;が、画面左側に小さな字でさりげなく「画像が大きすぎたため、xxxxxのサイズに切り抜きました」と言われている。画面が長すぎると途中で切られてしまうわけだ。結果的には以下のようになった。矢印の箇所は実際にここで画面が切れている。自分の投稿記事でやってみたんだけどまぁ実際この記事は長すぎるね。\nChromeの場合 Chromeでやる場合は一手間増える。\nWindows  Ctrl + Shift + I 同時押しで開発ツール画面を表示 Ctrl + Shift + P 同時押しで入力欄を表示させる 「full」と入力してreturn。少し待つとDwonloadディレクトリに保存される。  Mac  command + option + I 同時押しで開発ツール画面を表示 command + Shift + P同時押しで入力欄を表示させる 「full」と入力してreturn。少し待つとDwonloadディレクトリに保存される。\n（デフォルト保存先）  手間といっても大したことじゃないが、なにせものぐさなんで。それでもアドオンなしで全画面キャプチャ可能になったのはありがたい。\nしかしここでもやはり画面が長すぎておかしなことになっている。途中で一回途切れて（矢印箇所）、再度記事の初めから出力されるというループに陥っている。ま、とにかくFirefoxでもChromeでも長すぎるとダメつうことだ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/browser-capture-all/","summary":"かつてブラウザで全画面キャプチャしたい時はChromeにアドオンを入れて使っていたがこのアドオンはキャプチャしたデータをどこかに送信しているという話をどこかで読んで、ちょっとなぁ、と思った。しかし最近になってChromeでもFirefoxでもアドオンなしで全画面キャプチャが可能になっていることを知った。自宅で見るブラウザはほぼFirefoxでChromeは滅多に使わないが、職場では事情が変わったりするので両方書いておく。\nFirefoxの場合 F12キーで開発ツール画面を表示する。ツール画面右上のカメラアイコンをクリック。これだけ。素晴らしい。画像はデフォルトでDwonloadディレクトリに保存される。\n\u0026hellip;が、画面左側に小さな字でさりげなく「画像が大きすぎたため、xxxxxのサイズに切り抜きました」と言われている。画面が長すぎると途中で切られてしまうわけだ。結果的には以下のようになった。矢印の箇所は実際にここで画面が切れている。自分の投稿記事でやってみたんだけどまぁ実際この記事は長すぎるね。\nChromeの場合 Chromeでやる場合は一手間増える。\nWindows  Ctrl + Shift + I 同時押しで開発ツール画面を表示 Ctrl + Shift + P 同時押しで入力欄を表示させる 「full」と入力してreturn。少し待つとDwonloadディレクトリに保存される。  Mac  command + option + I 同時押しで開発ツール画面を表示 command + Shift + P同時押しで入力欄を表示させる 「full」と入力してreturn。少し待つとDwonloadディレクトリに保存される。\n（デフォルト保存先）  手間といっても大したことじゃないが、なにせものぐさなんで。それでもアドオンなしで全画面キャプチャ可能になったのはありがたい。\nしかしここでもやはり画面が長すぎておかしなことになっている。途中で一回途切れて（矢印箇所）、再度記事の初めから出力されるというループに陥っている。ま、とにかくFirefoxでもChromeでも長すぎるとダメつうことだ。","title":"Firefox/Chromeでアドオンなし全画面キャプチャ"},{"content":" 私的にMacで必須のショートカットを3つ挙げるとしたらこんなところかな。\n  フルスクリーン解除 control+ command + F\n  アプリケーションの強制終了 command + option + esc\n  スクリーンショット command + shift + 3\n   それにしてもフルスクリーンて、あれ何のためにあるん？意図的にフルスクリーンにすることなくて変な風にキーボード触ってしまった時になっちまうんだけど、迷惑極まりない\u0026hellip;\n 追記\nもうひとつ迷惑なショートカット思い出したから追加。ターミナル画面が分割されるやつ。command + D同時押しでなってしまうらしい。絶対使わんのに。戻すには、command + Shift + D。3選といいつつ、思い出したらまた書くかもな\u0026hellip;\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/mac-shortcut/","summary":" 私的にMacで必須のショートカットを3つ挙げるとしたらこんなところかな。\n  フルスクリーン解除 control+ command + F\n  アプリケーションの強制終了 command + option + esc\n  スクリーンショット command + shift + 3\n   それにしてもフルスクリーンて、あれ何のためにあるん？意図的にフルスクリーンにすることなくて変な風にキーボード触ってしまった時になっちまうんだけど、迷惑極まりない\u0026hellip;\n 追記\nもうひとつ迷惑なショートカット思い出したから追加。ターミナル画面が分割されるやつ。command + D同時押しでなってしまうらしい。絶対使わんのに。戻すには、command + Shift + D。3選といいつつ、思い出したらまた書くかもな\u0026hellip;\n ","title":"Macで必須のショートカット3選"},{"content":"サクラエディタで半角スペースを可視化したい。環境が変わって入れ直した時とか都度やり直す羽目になるからメモ。\nメニューから[設定] 〜 [タイプ別設定] を選択。\n 「カラー」タブ 半角空白 「色分け/表示」にチェック  ","permalink":"https://ecnedaced-seirots.github.io/post/a/sakura/","summary":"サクラエディタで半角スペースを可視化したい。環境が変わって入れ直した時とか都度やり直す羽目になるからメモ。\nメニューから[設定] 〜 [タイプ別設定] を選択。\n 「カラー」タブ 半角空白 「色分け/表示」にチェック  ","title":"サクラエディタで半角スペースを可視化"},{"content":"小ネタでもいいからどんどんポストしたいと思っているけどそれもなかなかできないもんだな。写真だけ。2018年4月の東京・井の頭公園。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/inokashira-park/","summary":"小ネタでもいいからどんどんポストしたいと思っているけどそれもなかなかできないもんだな。写真だけ。2018年4月の東京・井の頭公園。\n ","title":"井の頭公園 - 2018年4月"},{"content":"AWS EKSでPodからログを送信する場合、Container Insightsを組み込んでFluentdかFluent Bitを利用するのが一般的と思われる。そしてFluent BitよりFluentdの方がメジャーなのでまずはそこから入る事例が多いと想像する。しかし、元々組み込みLinux用に開発されて軽量リソースで動作するFluent Bitの方がコンテナログ送信に向いていると思う。ということで、この記事ではFluent Bitに焦点を当てる。\n 参照\nFluent Bit ドキュメント（設定詳細は画面左「DATA PIPELINE」配下のメニュー参照）\nFluent Bit Documentation\nContainer Insights全般\nAmazon EKS と Kubernetes での Container Insights のセットアップ\nFluent Bit on Container Insights\nCloudWatch Logs へログを送信する DaemonSet として Fluent Bit を設定する\nサンプルマニフェスト\nfluent-bit-compatible.yaml\n※AWSがサンプルとして提供しているFluent BitのマニフェストはFluent Bit最適化用とFluentd互換用がある。今回は過去にFluentd使用事例があることから、Fluentd互換用マニフェストをDLしてカスタマイズした。\n 共通マニフェスト例 クラスタの全般的な設定と、アプリ個別のケースでマニフェストを二つに分けた。AWS公式では基本となるEKSクラスタの定義をコマンドでセットしているが、運用の際はマニフェストに落とし込むのが普通だと思う。以下のようなマニフェストを共通用として作成し、個別のマニフェストから参照させる。EKSクラスタ名はdata:cluster.nameで指定している。\nfluentbit-cluster.yaml\napiVersion: v1 kind: ConfigMap metadata: name: fluentbit-cluster namespace: amazon-cloudwatch selfLink: /api/v1/namespaces/amazone-cloudwatch/configmaps/fluentbit-cluster data: cluster.name: EKS-SAMPLE-CLUSTER log.region: ap-northeast-1 read.head: \u0026#34;On\u0026#34; read.tail: \u0026#34;Off\u0026#34; --- apiVersion: v1 kind: ServiceAccount metadata: name: fluent-bit namespace: amazon-cloudwatch --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: fluent-bit-role rules: - nonResourceURLs: - /metrics verbs: - get - apiGroups: [\u0026#34;\u0026#34;] resources: - namespaces - pods - pods/logs verbs: [\u0026#34;get\u0026#34;, \u0026#34;list\u0026#34;, \u0026#34;watch\u0026#34;] --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: fluent-bit-role-binding roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: fluent-bit-role subjects: - kind: ServiceAccount name: fluent-bit namespace: amazon-cloudwatch  個別マニフェスト例 「個別のマニフェスト」というのはアプリの種類が複数存在して、各種別ごとに送信先（ロググループ/ログストリーム）を振り分けたいケースを想定している。しかしAWS公式サンプルをそのまま使うと要件的に期待値にならない。現状ネットにわかりやすい事例がなく大分迷ったが、最終的に以下のような形に落とした。詳細は後述。\n最初に骨組みを説明すると、前半がFluent Bitの設定であるConfigMap、後半がワーカーノード上で起動するDaemonSetの定義となっている。冒頭の[SERVICE]で全体共通の設定を行う。@INCLUDEで3種類のConfig名を指定しているが名称は適当でよい。各Config内に[INPUT] [FILTER] [OUTPUT] を定義していく。\n confの種類 containers.conf\nfluentbit, cloudwatch-agentやアプリ個別ログを定義。簡素化のため対象を絞っているが、aws-node, kube-proxy, corednsのログを送信する場合もここに含める。\nkube-systemd.conf\ndocker,kubeletのログを定義。\nhost.conf\nOS上のログ（基本的に/var/log/配下の各種ログ）を定義。簡素化のためここではmessagesのみ定義している。他に送信したい種別は同様に設定する。\nparsers.conf\nログフォーマットのパースの定義\n fluentbit-sample-app.yaml\napiVersion: v1 kind: ConfigMap metadata: name: fluent-bit-config namespace: amazon-cloudwatch labels: k8s-app: fluent-bit-sample data: fluent-bit.conf: |[SERVICE] Flush 5 Log_Level info Daemon off Parsers_File parsers.conf storage.path /var/fluent-bit/state/flb-storage/ storage.sync normal storage.checksum off storage.backlog.mem_limit 5M @INCLUDE containers.conf @INCLUDE kube-systemd.conf @INCLUDE host.conf # containers.confの定義 containers.conf: |[INPUT] Name tail Tag fluentbit.* Path /var/log/containers/fluentbit* Parser docker DB /var/fluent-bit/state/flb_log.db Mem_Buf_Limit 5MB Skip_Long_Lines On Refresh_Interval 10 Read_from_Head ${READ_FROM_HEAD} [INPUT] Name tail Tag cloudwatch-agent.* Path /var/log/containers/cloudwatch-agent* Docker_Mode On Docker_Mode_Flush 5 Docker_Mode_Parser cwagent_firstline Parser docker DB /var/fluent-bit/state/flb_cwagent.db Mem_Buf_Limit 5MB Skip_Long_Lines On Refresh_Interval 10 Read_from_Head ${READ_FROM_HEAD} [INPUT] Name tail Tag sample-app.* Path /var/log/containers/sample-app* Parser docker DB /var/fluent-bit/state/flb_sample-app.db Mem_Buf_Limit 5MB Skip_Long_Lines On Refresh_Interval 10 Read_from_Head ${READ_FROM_HEAD} # 各INPUTに対応するFILTERを定義する [FILTER] Name kubernetes Match fluentbit.* Kube_URL ${MASTER_URL} Kube_Tag_Prefix fluentbit.var.log.containers. Merge_Log On Merge_Log_Key log_processed K8S-Logging.Parser On K8S-Logging.Exclude Off Annotations Off [FILTER] Name kubernetes Match cloudwatch-agent.* Kube_URL ${MASTER_URL} Kube_Tag_Prefix cloudwatch-agent.var.log.containers. Merge_Log On Merge_Log_Key log_processed K8S-Logging.Parser On K8S-Logging.Exclude Off Annotations Off [FILTER] Name kubernetes Match sample-app.* Kube_URL ${MASTER_URL} Kube_Tag_Prefix sample-app.var.log.containers. Merge_Log On Merge_Log_Key log_processed K8S-Logging.Parser On K8S-Logging.Exclude Off Annotations Off # アイテムの変換や不要なメタデータ送信抑止を定義 [FILTER] Name nest Match * Operation lift Nested_under kubernetes Add_prefix Nested. [FILTER] Name modify Match * Rename Nested.docker_id Docker.container_id [FILTER] Name nest Match * Operation nest Wildcard Nested.* Nested_under kubernetes Remove_prefix Nested. [FILTER] Name nest Match * Operation nest Wildcard Docker.* Nested_under docker Remove_prefix Docker. [FILTER] Name nest Match * Operation lift Nested_under kubernetes Add_prefix Kube. [FILTER] Name modify Match * Remove Kube.container_hash  Remove Kube.container_image Remove Kube.pod_id [FILTER] Name nest Match * Operation nest Wildcard Kube.* Nested_under Kubernetes Remove_prefix Kube. # 送信時の定義 # ロググループ名例：/eks/stg/sample-app_fluentbit # ログストリーム名例：ip-10-1-2-3.ap-northeast-1.compute.internal_[Pod名]_[ネームスペース]_[コンテナ名] # $(tag[4])とした場合、上記のようなkubeのタグ定義が投入され、ユニークなログストリーム名になる。 [OUTPUT] Name cloudwatch Match fluentbit.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_fluentbit log_stream_name ${HOST_NODE_NAME}_$(tag[4]) auto_create_group true extra_user_agent container-insights Retry_Limit 5 [OUTPUT] Name cloudwatch Match cloudwatch-agent.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_cwagent log_stream_name ${HOST_NODE_NAME}_$(tag[4]) auto_create_group true extra_user_agent container-insights Retry_Limit 5 # 個別アプリログ送信用定義 [OUTPUT] Name cloudwatch Match sample-app.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_application log_stream_name ${HOST_NODE_NAME}_$(tag[4]) auto_create_group true extra_user_agent container-insights Retry_Limit 5 # docker,kubenetesログ定義 kube-systemd.conf: |[INPUT] Name systemd Tag dockerlog.systemd.* Systemd_Filter _SYSTEMD_UNIT=docker.service DB /var/fluent-bit/state/systemd.db Path /var/log/journal Read_From_Head ${READ_FROM_HEAD} [INPUT] Name systemd Tag kubelet.systemd.* Systemd_Filter _SYSTEMD_UNIT=kubelet.service DB /var/fluent-bit/state/systemd.db Path /var/log/journal Read_From_Head ${READ_FROM_HEAD} [FILTER] Name modify Match dockerlog.systemd.* Rename _HOSTNAME hostname Rename _SYSTEMD_UNIT systemd_unit Rename MESSAGE message Remove_regex ^((?!hostname|systemd_unit|message).)*$ [FILTER] Name modify Match kubelet.systemd.* Rename _HOSTNAME hostname Rename _SYSTEMD_UNIT systemd_unit Rename MESSAGE message Remove_regex ^((?!hostname|systemd_unit|message).)*$ [OUTPUT] Name cloudwatch Match kubelet.systemd.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_docker log_stream_name ${HOST_NODE_NAME}_$(tag[2]) auto_create_group true extra_user_agent container-insight [OUTPUT] Name cloudwatch Match kubelet.systemd.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_kubelet log_stream_name ${HOST_NODE_NAME}_$(tag[2]) auto_create_group true extra_user_agent container-insight # messages等、OSのログ定義 host-log.conf: | [INPUT] Name tail Tag host.messages Path /var/log/messages Parser syslog DB /var/fluent-bit/state/flb_messages.db Mem_Buf_Limit 5MB Skip_Long_Lines On Refresh_Interval 10 Read_from_Head ${READ_FROM_HEAD} # host.confの[OUTPUT]定義は、複数のINPUTがあっても1つでよい。 # $(tag[1]) にはこの場合messagesが入る。 [OUTPUT] Name cloudwatch Match host.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_$(tag[1]) log_stream_name ${HOST_NODE_NAME}_$(tag[1]) auto_create_group true extra_user_agent container-insights Retry _Limit 5 parsers.conf: |[PARSER] Name docker Format json Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%LZ [PARSER] Name syslog-rfc5424 Format regex Regex ^(?\u0026lt;time\u0026gt;[^ ]* {1.2}[^ ]* [^ ]*) (?\u0026lt;host\u0026gt;[^ ]*) (?\u0026lt;ident\u0026gt;[a-zA-Z0-9_¥/¥.¥-]*) (?:¥[?\u0026lt;pid\u0026gt;[-0-9]+)¥])?(?:[^¥:]*¥:)? * (?\u0026lt;message\u0026gt;.*)$ Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%L Time_Strict Off [PARSER] Name container_firstline Format regex Regex (?\u0026lt;log\u0026gt;(?\u0026lt;=\u0026#34;log\u0026#34;:\u0026#34;)\\S(?!\\.).*?)(?\u0026lt;!\\\\)\u0026#34;.*(?\u0026lt;stream\u0026gt;(?\u0026lt;=\u0026#34;stream\u0026#34;:\u0026#34;).*?)\u0026#34;.*(?\u0026lt;time\u0026gt;\\d{4}-\\d{1,2}-\\d{1,2}T\\d{2}:\\d{2}:\\d{2}\\.\\w*).*(?=}) Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%LZ [PARSER] Name cwagent_firstline Format regex Regex (?\u0026lt;log\u0026gt;(?\u0026lt;=\u0026#34;log\u0026#34;:\u0026#34;)\\d{4}[\\/-]\\d{1,2}[\\/-]\\d{1,2}[ T]\\d{2}:\\d{2}:\\d{2}(?!\\.).*?)(?\u0026lt;!\\\\)\u0026#34;.*(?\u0026lt;stream\u0026gt;(?\u0026lt;=\u0026#34;stream\u0026#34;:\u0026#34;).*?)\u0026#34;.*(?\u0026lt;time\u0026gt;\\d{4}-\\d{1,2}-\\d{1,2}T\\d{2}:\\d{2}:\\d{2}\\.\\w*).*(?=}) Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%LZ --- apiVersion: apps/v1 kind: DaemonSet metadata: name: fluent-bit-sample namespace: amazon-cloudwatch labels: k8s-app: fluent-bit-sample version: v1 kubernetes.io/cluster-service: \u0026#34;true\u0026#34; spec: selector: matchLabels: k8s-app: fluent-bit-sample template: metadata: labels: k8s-app: fluent-bit-sample version: v1 kubernetes.io/cluster-service: \u0026#34;true\u0026#34; spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: nodelabel operator: In values: - STG-NODELABEL-APP-001 containers: - name: fluent-bit-sample image: amazon/aws-for-fluent-bit:2.12.0 imagePullPolicy: Always env: - name: AWS_REGION valueFrom: configMapKeyRef: name: fluentbit-cluster key: logs.region - name: CLUSTER_NAME valueFrom: configMapKeyRef: name: fluentbit-cluster key: cluster.name - name: READ_FROM_HEAD valueFrom: configMapKeyRef: name: fluentbit-cluster key: read.head - name: READ_FROM_TAIL valueFrom: configMapKeyRef: name: fluentbit-cluster key: read.tail - name: HOST_NODE_NAME valueFrom: fieldRef: fieldPath: spec.nodeName - name: CI_VERSION value: \u0026#34;k8s/1.3.8\u0026#34; # これ以降独自に設定追加。設定項目はユースケースに合わせてください。 - name: ENVIRONMENT value: \u0026#34;stg\u0026#34; - name: NODEGROUP value: \u0026#34;sample-app\u0026#34; - name: MASTER_URL value: \u0026#34;https://kubernetes.default.svc:443\u0026#34; resources: limits: cpu: 200m memory: 200Mi requests: cpu: 200m memory: 100Mi volumeMounts: # Please don\u0026#39;t change below read-only permissions - name: fluentbitstate mountPath: /var/fluent-bit/state - name: varlog mountPath: /var/log readOnly: true - name: varlibdockercontainers mountPath: /var/lib/docker/containers readOnly: true - name: fluent-bit-config mountPath: /fluent-bit/etc/ - name: runlogjournal mountPath: /run/log/journal readOnly: true - name: dmesg mountPath: /var/log/dmesg readOnly: true terminationGracePeriodSeconds: 90 volumes: - name: fluentbitstate hostPath: path: /var/fluent-bit/state - name: varlog hostPath: path: /var/log - name: varlibdockercontainers hostPath: path: /var/lib/docker/containers - name: fluent-bit-config configMap: name: fluent-bit-config - name: runlogjournal hostPath: path: /run/log/journal - name: dmesg hostPath: path: /var/log/dmesg serviceAccountName: fluent-bit tolerations: - key: node-role.kubernetes.io/master operator: Exists effect: NoSchedule - operator: \u0026#34;Exists\u0026#34; effect: \u0026#34;NoExecute\u0026#34; - operator: \u0026#34;Exists\u0026#34; effect: \u0026#34;NoSchedule\u0026#34;  補足説明 imageパスの指定\n上記ではコンテナイメージをインターネットを通って都度落とすようになっているが、業務利用時はECRに格納してプライベートな通信で完結させるのが望ましい。ECRに格納した場合は以下のように指定する。\nimage: [AWS-AccoundID].dkr.ecr.ap-northeast-1.amazon.com/[repo-name]:2.12.0  nodeAffinityで起動するノードを指定\n今回の事例では、sample-appのPodが起動するワーカーノード上にsample-appログ送信用のDaemonSetを起動させる必要がある。そのためnodeAffinityを定義する。EKSノードグループのラベルにkey:nodelabel values:STG-SAMPLE-APPを設定している前提の場合以下の様になる。sample-app用のマニフェストにも同様の記述をする。\n spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: nodelabel operator: In values: - STG-SAMPLE-APP  停止時のGracePeriod\nDaemonSetがKillシグナル受信後に削除されるまでの猶予時間を指定。公式サンプル10秒だと、コンテナログを送信しきる前に削除されてしまう可能性がある。ここでは余裕を持たせて90秒。\nterminationGracePeriodSeconds: 90  syslogのPARSER\nAWS公式の設定だとTime_FormatがダメらしきエラーがでるのでFluent Bit公式の例を適用した。Fluent Bit公式ではsyslogではなくsyslog-rfc5424。ではINPUTのParserはsyslogではなくsyslog-rfc5424とするのが正ではないか？と思ったが、そうすると動作しない。謎だが深追いはしない。Time_StrictはOffにしておく。しかしそれでもまだエラーになるので調べると、Regexの正規表現が原因らしいのでそこも直した。参照サイトは失念。\n DaemonSetの起動〜ログ送信\n今回cloudwatch-agentについては触れていないが、cloudwatch-agentネームスペースが存在している状態でマニフェストをapplyする。この時点ではノードグループは停止中でもよい。\n$ kubectl apply -f fluentbit-cluster.yaml $ kubectl apply -f fluentbit-sample-app.yaml  ノードグループが起動すると、各種ログがCloudWatchLogsに送信される。アプリ用マニフェストをapplyすればアプリログも送信される。\nあとresourceのcpuはデフォルトが500mになっていたが、そこまで割り当てなくてもちゃんと動作する。よほどのことがなければ100mでもいい気がする。メモリもFlunetdに比べて全然余裕。さすが軽量版。その他細かいチューニング項目もあるにはあるのだが、これ以上の長文は避けたいのでまた別の機会に投稿しようと思う。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/fluentbit/","summary":"AWS EKSでPodからログを送信する場合、Container Insightsを組み込んでFluentdかFluent Bitを利用するのが一般的と思われる。そしてFluent BitよりFluentdの方がメジャーなのでまずはそこから入る事例が多いと想像する。しかし、元々組み込みLinux用に開発されて軽量リソースで動作するFluent Bitの方がコンテナログ送信に向いていると思う。ということで、この記事ではFluent Bitに焦点を当てる。\n 参照\nFluent Bit ドキュメント（設定詳細は画面左「DATA PIPELINE」配下のメニュー参照）\nFluent Bit Documentation\nContainer Insights全般\nAmazon EKS と Kubernetes での Container Insights のセットアップ\nFluent Bit on Container Insights\nCloudWatch Logs へログを送信する DaemonSet として Fluent Bit を設定する\nサンプルマニフェスト\nfluent-bit-compatible.yaml\n※AWSがサンプルとして提供しているFluent BitのマニフェストはFluent Bit最適化用とFluentd互換用がある。今回は過去にFluentd使用事例があることから、Fluentd互換用マニフェストをDLしてカスタマイズした。\n 共通マニフェスト例 クラスタの全般的な設定と、アプリ個別のケースでマニフェストを二つに分けた。AWS公式では基本となるEKSクラスタの定義をコマンドでセットしているが、運用の際はマニフェストに落とし込むのが普通だと思う。以下のようなマニフェストを共通用として作成し、個別のマニフェストから参照させる。EKSクラスタ名はdata:cluster.nameで指定している。\nfluentbit-cluster.yaml\napiVersion: v1 kind: ConfigMap metadata: name: fluentbit-cluster namespace: amazon-cloudwatch selfLink: /api/v1/namespaces/amazone-cloudwatch/configmaps/fluentbit-cluster data: cluster.name: EKS-SAMPLE-CLUSTER log.region: ap-northeast-1 read.head: \u0026#34;On\u0026#34; read.tail: \u0026#34;Off\u0026#34; --- apiVersion: v1 kind: ServiceAccount metadata: name: fluent-bit namespace: amazon-cloudwatch --- apiVersion: rbac.","title":"EKS Container InsightsのFluent Bit設定"},{"content":"マークダウン記法の参考リンク。取り急ぎこれくらいあればいいかな。\n  Markdown 早見表 \u0026amp; 詳細\n  かんたんMarkdownの記法\n  Markdown記法 チートシート\n  GitHub Markdownの「シンタックスハイライト」に対応している言語一覧\n  ","permalink":"https://ecnedaced-seirots.github.io/post/a/markdown/","summary":"マークダウン記法の参考リンク。取り急ぎこれくらいあればいいかな。\n  Markdown 早見表 \u0026amp; 詳細\n  かんたんMarkdownの記法\n  Markdown記法 チートシート\n  GitHub Markdownの「シンタックスハイライト」に対応している言語一覧\n  ","title":"マークダウン記法"},{"content":"とりあえず最初の投稿。\n ","permalink":"https://ecnedaced-seirots.github.io/post/a/first/","summary":"とりあえず最初の投稿。\n ","title":"最初の投稿"}]